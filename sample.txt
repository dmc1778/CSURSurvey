
Jin Wang, Hui Xiao, Shuwen Zhong, Yinhao Xiao,
DeepVulSeeker: A novel vulnerability identification framework via code graph structure and pre-training mechanism,
Future Generation Computer Systems,
Volume 148,
2023,
Pages 15-26,
ISSN 0167-739X,
https://doi.org/10.1016/j.future.2023.05.016.
(https://www.sciencedirect.com/science/article/pii/S0167739X23001978)
Abstract: Software vulnerabilities can pose severe harms to a computing system. They can lead to system crash, privacy leakage, or even physical damage. Correctly identifying vulnerabilities among enormous software codes in a timely manner is so far the essential prerequisite to patch them. Unfortunately, the current vulnerability identification methods, either the classic ones or the deep-learning-based ones, have several critical drawbacks, making them unable to meet the present-day demands put forward by the software industry. To overcome the drawbacks, in this paper, we propose DeepVulSeeker, a novel fully automated vulnerability identification framework, which leverages both code graph structures and the semantic features with the help of the recently advanced Graph Representation Self-Attention and pre-training mechanisms. Our experiments show that DeepVulSeeker not only reaches an accuracy as high as 0.99 on traditional CWE datasets, but also outperforms all other existing methods on two highly-complicated datasets. We also testified DeepVulSeeker based on three case studies, and found that DeepVulSeeker is able to understand the implications of the vulnerabilities. We have fully implemented DeepVulSeeker and open-sourced it for future follow-up research.
Keywords: Vulnerability identification; Software security; Neural network; Pre-training; Vulnerability pattern; Code feature

Gaigai Tang, Lin Yang, Long Zhang, Hongyu Kuang, Huiqiang Wang,
MRC-VulLoc: Software source code vulnerability localization based on multi-choice reading comprehension,
Computers & Security,
Volume 141,
2024,
103816,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103816.
(https://www.sciencedirect.com/science/article/pii/S0167404824001172)
Abstract: Recently, automatic vulnerability detection approaches based on machine learning (ML) have outperformed traditional rule-based approaches in terms of detection performance. Existing ML-based approaches typically concentrate on function or line granularity, which fail to realize accurate vulnerability localization and are insufficient to support effective root cause analysis of vulnerability. To address this issue, we propose a new approach that maps the multi-choice reading comprehension (MRC) task to the vulnerability localization task at the granularity of vulnerability triggering path named MRC-VulLoc. Initially, we design six large datasets (including C/C++ and Java languages) in the form of MRC. Subsequently, we introduce a novel pre-trained vulnerability localization model, combining the effective code semantic comprehension ability of pre-trained model with the advantages of Bidirectional Short-Term Memory Network (Bi-LSTM) and Convolutional Neural Network (CNN) models. Lastly, we conduct experiments to evaluate the vulnerability localization with several state-of-the-art MRC approaches and vulnerability detectors. Experimental results demonstrate the effectiveness of the proposed datasets in evaluating MRC approaches for vulnerability localization. Furthermore, MRC-VulLoc achieves higher precision on vulnerability localization compared to comparative vulnerability detectors.
Keywords: Source code; Vulnerability localization; Machine learning; MRC

Zhilong Cai, Yongwei Cai, Xiang Chen, Guilong Lu, Wenlong Pei, Junjie Zhao,
CSVD-TF: Cross-project software vulnerability detection with TrAdaBoost by fusing expert metrics and semantic metrics,
Journal of Systems and Software,
Volume 213,
2024,
112038,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2024.112038.
(https://www.sciencedirect.com/science/article/pii/S0164121224000815)
Abstract: Recently, deep learning-based software vulnerability detection (SVD) approaches have achieved promising performance. However, the scarcity of high-quality labeled SVD data influences the practicality of these approaches. Therefore, cross-project software vulnerability detection (CSVD) has gradually attracted the attention of researchers since CSVD can utilize the labeled SVD data from the source project to construct an effective CSVD model for the target project via transfer learning. However, if a certain number of program modules in the target project can be labeled by security experts, it can help to improve CSVD model performance by effectively utilizing similar SVD data in the source project. For this more practical CSVD scenario, we propose a novel approach CSVD-TF via the transfer learning method TrAdaBoost. Moreover, we find expert metrics and semantic metrics extracted from the functions show a certain complementary in our investigated scenario. Therefore, we utilize a model-level metric fusion method to further improve the performance. We perform a comprehensive study to evaluate the effectiveness of CSVD-TF on four real-world projects. Our empirical results show that CSVD-TF can achieve performance improvements of 7.5% to 24.6% in terms of AUC when compared to five state-of-the-art baselines.
Keywords: Cross-project software vulnerability detection; Transfer learning; Expert metrics; Semantic metrics; Metric fusion

Kuo Zhou, Jing Huang, Honggui Han, Bei Gong, Ao Xiong, Wei Wang, Qihui Wu,
Smart contracts vulnerability detection model based on adversarial multi-task learning,
Journal of Information Security and Applications,
Volume 77,
2023,
103555,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2023.103555.
(https://www.sciencedirect.com/science/article/pii/S2214212623001394)
Abstract: Vulnerability detection is important for smart contracts because of their immutable and irreversible features. In this work, a new detection method based on adversarial multi-task learning is proposed to improve the accuracy of existing vulnerability detection methods, which is based on the multi-task learning framework, including a shared part and a task-specific part. We optimize the multi-task learning frameworks and propose the mixed parameter sharing method to make each task not only maintain its uniqueness, but also share features with other tasks, which helps solve the problem that the hard parameter sharing method cannot constrain the underlying shared layer and improve the quality of extracted features. In addition, we introduce adversarial transfer learning to reduce noise pollution caused by the private feature and interference between the general feature and the private feature. We experimented on datasets obtained from our previous work, and the experimental results prove that our proposed model can judge whether there are vulnerabilities in smart contracts and then identify their types. Additionally, the results also show that our model effectively improves detection accuracy and has an advantage in performance over representative methods.
Keywords: Vulnerability detection; Smart contracts; Multi-task learning; Adversarial transfer learning; Blockchain security supervision

Han Yan, Senlin Luo, Limin Pan, Yifei Zhang,
HAN-BSVD: A hierarchical attention network for binary software vulnerability detection,
Computers & Security,
Volume 108,
2021,
102286,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2021.102286.
(https://www.sciencedirect.com/science/article/pii/S0167404821001103)
Abstract: Deep learning has shown effectiveness in binary software vulnerability detection due to its outstanding feature extraction capability independent of human expert experience. However, detection approaches such as Instruction2vec still have the following defects: (1) the context between an instruction’s elements (opcode, registers, etc.) is not fully incorporated when embedding a single instruction into its vector representation; (2) the crucial regions that related to vulnerability are not highlighted when extracting features of the vulnerable code. In this paper, we propose a hierarchical attention network for binary software vulnerability detection (HAN-BSVD). Through HAN-BSVD, the contextual information is first enriched by the preprocessor with unifying jump address and normalizing instruction, and then preserved by the instruction embedding network that composed of Bi-GRU and word-attention module; the local features are captured and the crucial regions are highlighted by the feature extraction network that composed of Text-CNN and spatial-attention module. The proposed approach is evaluated on the Juliet Test Suite dataset and the ICLR19 dataset, detection result performs better than the other compared approaches. Extensive ablation studies are also conducted to further prove the effectiveness of each design choice.
Keywords: Vulnerability detection; Static binary analysis; Hierarchical attention; Instruction embedding; Deep learning

Jie Cai, Bin Li, Jiale Zhang, Xiaobing Sun, Bing Chen,
Combine sliced joint graph with graph neural networks for smart contract vulnerability detection,
Journal of Systems and Software,
Volume 195,
2023,
111550,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2022.111550.
(https://www.sciencedirect.com/science/article/pii/S0164121222002266)
Abstract: Smart contract security has drawn extensive attention in recent years because of the enormous economic losses caused by vulnerabilities. Even worse, fixing bugs in a deployed smart contract is difficult, so developers must detect security vulnerabilities in a smart contract before deployment. Existing smart contract vulnerability detection efforts heavily rely on fixed rules defined by experts, which are inefficient and inflexible. To overcome the limitations of existing vulnerability detection approaches, we propose a GNN based approach for smart contract vulnerability detection. First, we construct a graph representation for a smart contract function with syntactic and semantic features by combining abstract syntax tree (AST), control flow graph (CFG), and program dependency graph (PDG). To further strengthen the presentation ability of our approach, we perform program slicing to normalize the graph and eliminate the redundant information unrelated to vulnerabilities. Then, we use a Bidirectional Gated Graph Neural-Network model with hybrid attention pooling to identify potential vulnerabilities in smart contract functions. Empirical results show that our approach can achieve 89.2% precision and 92.9% recall in smart contract vulnerability detection on our dataset and reveal the effectiveness and efficiency of our approach.
Keywords: Smart contract; Vulnerability detection; Code representation; Graph neural network

Christoforos Ntantogian, Panagiotis Bountakas, Dimitris Antonaropoulos, Constantinos Patsakis, Christos Xenakis,
NodeXP: NOde.js server-side JavaScript injection vulnerability DEtection and eXPloitation,
Journal of Information Security and Applications,
Volume 58,
2021,
102752,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2021.102752.
(https://www.sciencedirect.com/science/article/pii/S221421262100003X)
Abstract: Web applications are widely used, and new ways for easier and cost-effective methods to develop them are constantly introduced. A common omission among the new development and implementation techniques when designing them is security; Node.js is no exception, as Server-Side JavaScript Injection (SSJI) attacks are possible due to the use of vulnerable functions and neglecting to sanitize data input provided by untrusted sources. This specific kind of injection attack stands out because it has the potential to compromise servers, where the JavaScript code is executed. In this work, we fill a significant gap in the literature by introducing NodeXP, which, to the best of our knowledge, is the first methodology (presented as a software tool) that detects and automatically exploits SSJI vulnerabilities. Beyond the capabilities of the current state-of-the-art tools, NodeXP uses obfuscation methods, making it more stealth and adaptive to the current needs of red teaming. To this end, we provide a thorough analysis of SSJI attacks and the foundation upon which they rely on, along with concrete examples to facilitate the reader to comprehend the underlying concepts. Finally, we evaluate NodeXP, compare it to its peers, and discuss its efficacy.
Keywords: Code injection; Server-Side Javascript Injection; Detection; Exploitation; Deep learning; Node.js

Qian Wang, Zhengdao Li, Hetong Liang, Xiaowei Pan, Hui Li, Tingting Li, Xiaochen Li, Chenchen Li, Shikai Guo,
Graph Confident Learning for Software Vulnerability Detection,
Engineering Applications of Artificial Intelligence,
Volume 133, Part C,
2024,
108296,
ISSN 0952-1976,
https://doi.org/10.1016/j.engappai.2024.108296.
(https://www.sciencedirect.com/science/article/pii/S0952197624004548)
Abstract: Code vulnerability exposes millions of software to the possibility of being attacked, as evidence every year on increasing reports of security issues, such as information leaks, system compromise, and denial of service. Despite with many vulnerability detection models proposed so far, their effectiveness is still limited due to the ignorance of syntactic structural information analysis in source code and the improper handling of labeling errors. To address these issues, we propose the Graph Confident Learning for Software Vulnerability Detection (GCL4SVD) model, a machine learning model to detect software vulnerability in the development phase. It comprises two components: code graph embedding and graph confident learning denoising. To address the syntactic structural information analysis limitation, the code graph embedding component extracts the structure and semantic information of source code with a sliding window mechanism, and then encodes source code into a graph structure to capture the patterns and characteristics of code vulnerabilities. Additionally, the graph confident learning denoising component identifies labeling errors to improve the quality of training set. Experimental results show that GCL4SVD outperforms the state-of-the-art vulnerability detection models on four open source datasets by 3.7%, 3.3%, 2.5%, 0.8% in terms of Accuracy, respectively, and by 10.2%, 21.8%, 8.2%, 11.2% in terms of F1-score.
Keywords: Software code vulnerability detection; Learning with noisy labels; Gated graph neural networks

Zhenzhou Tian, Binhui Tian, Jiajun Lv, Yanping Chen, Lingwei Chen,
Enhancing vulnerability detection via AST decomposition and neural sub-tree encoding,
Expert Systems with Applications,
Volume 238, Part B,
2024,
121865,
ISSN 0957-4174,
https://doi.org/10.1016/j.eswa.2023.121865.
(https://www.sciencedirect.com/science/article/pii/S0957417423023679)
Abstract: The explosive growth of software vulnerabilities poses a serious threat to the system security and has become one of the urgent problems of the day. However, existing vulnerability detection methods are still faced with limitations in reaching the balance between detection accuracy, efficiency and applicability. Following a divide-and-conquer strategy, this paper proposes TrVD (abstract syntax Tree decomposition based Vulnerability Detector) to disclose the indicative semantics implied in the source code fragments for accurate and efficient vulnerability detection. To facilitate the capture of subtle semantic features, TrVD converts the AST of a code fragment into an ordered set of sub-trees of restricted sizes and depths with a novel decomposition algorithm. The semantics of each sub-tree can thus be effectively collected with a carefully designed tree-structured neural network. Finally, a Transformer-style encoder is utilized to aggregate the long-range contextual semantics of all sub-trees into a vulnerability-specific vector to represent the target code fragment. The extensive experiments conducted on five large datasets consisting of diverse real-world and synthetic vulnerable samples demonstrate the performance superiority of TrVD against SOTA approaches in detecting the presence of vulnerabilities and pinpointing the vulnerability types. The ablation studies also confirm the effectiveness of TrVD’s core designs.
Keywords: Vulnerability detection; Tree decomposition; Tree-structured neural network; Deep semantic extraction

Jinxiong Zhao, Sensen Guo, Dejun Mu,
DouBiGRU-A: Software defect detection algorithm based on attention mechanism and double BiGRU,
Computers & Security,
Volume 111,
2021,
102459,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2021.102459.
(https://www.sciencedirect.com/science/article/pii/S0167404821002832)
Abstract: Software defects such as errors, bugs, and failures lead to poor usability and low efficiency, severely degrading the user experience. Bugs in the code are among the key areas of software defects. The exploitability of such vulnerabilities can bring about a series of security problems, such as user information leakage and network attacks. Most traditional solutions in software vulnerability detection rely on practical knowledge and experience for manual labeling and classification. Manual methods can effectively detect vulnerabilities with a high degree of attention, but those with a low degree of attention have relatively high false negative and false positive rates. Solutions based on software defect code data sets are available, which use deep learning to train software vulnerability identification models, reducing the dependence on manual knowledge and experience, but the precision rate (P) of the models and the F1 score are generally low. In this paper, based on the NVD and SARD data sets, we propose a software defect detection algorithm DouBiGRU-A that combines bidirectional gated recurrent unit (BiGRU) and an attention mechanism. In the experimental simulation, comparison with the Li-Method, bilateral long short-term memory (BiLSTM), BiGRU, and BiLSTM&Attention shows that on the CWE-399 data set, the P and F1 scores of DouBiGRU-A are 0.7% and 0.80% higher than the Li-Method, respectively. Moreover, in the CWE-399 data set, the P and F1 scores of DouBiGRU-A are 28.2% and 43.45% higher than the average values for Flawfinder and RATS, respectively. On the CWE-119 data set, the F1 score of DouBiGRU-A is 2.73% higher than the Li-Method; the P and F1 scores of DouBiGRU-A are 63.07% and 53.98% higher than the average values of Flawfinder and RATS, respectively. On the combined CWE-119&CWE-399 data set, the P and F1 scores of DouBiGRU-A are 5.22% and 4.29% higher than Li-Method, respectively. The P and F1 scores of DouBiGRU-A are 59.72% and 46.59% higher than the average values of Flawfinder and RATS, respectively.
Keywords: DouBiGRU-A; Software defect detection; Vulnerability identification; Flawfinder, RATS

Matteo Esposito, Davide Falessi,
VALIDATE: A deep dive into vulnerability prediction datasets,
Information and Software Technology,
Volume 170,
2024,
107448,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2024.107448.
(https://www.sciencedirect.com/science/article/pii/S0950584924000533)
Abstract: Context:
Vulnerabilities are an essential issue today, as they cause economic damage to the industry and endanger our daily life by threatening critical national security infrastructures. Vulnerability prediction supports software engineers in preventing the use of vulnerabilities by malicious attackers, thus improving the security and reliability of software. Datasets are vital to vulnerability prediction studies, as machine learning models require a dataset. Dataset creation is time-consuming, error-prone, and difficult to validate.
Objectives:
This study aims to characterise the datasets of prediction studies in terms of availability and features. Moreover, to support researchers in finding and sharing datasets, we provide the first VulnerAbiLty predIction DatAseT rEpository (VALIDATE).
Methods:
We perform a systematic literature review of the datasets of vulnerability prediction studies.
Results:
Our results show that out of 50 primary studies, only 22 studies (i.e., 38%) provide a reachable dataset. Of these 22 studies, only one study provides a dataset in a stable repository.
Conclusions:
Our repository of 31 datasets, 22 reachable plus nine datasets provided by authors via email, supports researchers in finding datasets of interest, hence avoiding reinventing the wheel; this translates into less effort, more reliability, and more reproducibility in dataset creation and use.
Keywords: Security; Replicability; Vulnerability; Machine learning; Repository; Dataset

Yan Wang, Peng Jia, Xi Peng, Cheng Huang, Jiayong Liu,
BinVulDet: Detecting vulnerability in binary program via decompiled pseudo code and BiLSTM-attention,
Computers & Security,
Volume 125,
2023,
103023,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.103023.
(https://www.sciencedirect.com/science/article/pii/S0167404822004151)
Abstract: Static detection of security vulnerabilities in binary programs is an important research field in software supply chain security. However, existing vulnerability detection methods based on code similarity can only detect known vulnerabilities. Vulnerability features generated by vulnerability pattern-based detection methods are low robust due to the influence of manually defined patterns, compiler diversity, and irrelevant function instructions. In this paper, we propose BinVulDet, which is a binary level vulnerability detection tool for accurate known and unknown vulnerability detection. BinVulDet uses decompilation techniques to obtain pseudo code containing high-level semantic information against the impact of compilation diversity. Then the program slicing technique is used to extract the statements with data dependencies and control dependencies related to the vulnerability. A BiLSTM-attention neural network is used to extract rich contextual semantic information from slice codes to generate more robust vulnerability patterns to detect vulnerabilities. The experimental results show that BinVulDet outperforms the state-of-the-art binary vulnerability detection methods. The FPR and FNR of BinVulDet are 1.04% and 0.89% on average, respectively, which are 3.93% and 22.86% lower than the baseline model on average. BinVulDet can effectively against the influence of compilation diversity and successfully be used for real-world vulnerability detection by being evaluated in three CVE vulnerability projects.
Keywords: Binary program; Decompile; Vulnerability detection; Program slicing; BiLSTM-attention

A. Germán Márquez, Ángel Jesús Varela-Vaca, María Teresa Gómez López, José A. Galindo, David Benavides,
Vulnerability impact analysis in software project dependencies based on Satisfiability Modulo Theories (SMT),
Computers & Security,
Volume 139,
2024,
103669,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103669.
(https://www.sciencedirect.com/science/article/pii/S0167404823005795)
Abstract: Software development projects are built on top of external libraries and tools that help manage code and databases and/or facilitate deployment. The external libraries that assist in these tasks create dependent relations with the developed software, thereby increasing the use of dependencies as a common practice. There exist mechanisms in the projects to set up software dependencies in terms of versions and restrictions between said projects. However, any problem, error, or vulnerability affecting a software's configuration dependencies can render the whole project vulnerable. This turns a secure dependency into an insecure dependency, and hinders the maintenance of security in software development projects, since current tools do not cover all possible configurations of dependencies. In this paper, our approach that enables the analysis and inference of the configuration of dependencies of projects in terms of potentially vulnerable configurations. The proposal is developed by constructing a dependency graph network attributed to vulnerabilities. Formal models are integrated based on Satisfiability Modulo Theories (SMT) to enable automatic analysis, such as the identification of the most secure configuration of dependencies. The automatic analysis facilitates ascertaining the vulnerability-free configurations of dependencies with maximum and minimum vulnerability impacts. This proposal has been evaluated by analysing more than 140 Python open-source code repositories and better results than other proposals have been achieved.
Keywords: Security; Vulnerability; Automated analysis; Satisfiability Modulo Theories (SMT); Dependency network; Software development

Xiaozhi Du, Shiming Zhang, Yanrong Zhou, Hongyuan Du,
A vulnerability severity prediction method based on bimodal data and multi-task learning,
Journal of Systems and Software,
Volume 213,
2024,
112039,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2024.112039.
(https://www.sciencedirect.com/science/article/pii/S0164121224000827)
Abstract: Facing the increasing number of software vulnerabilities, the automatic analysis of vulnerabilities has become an important task in the field of software security. However, the existing severity prediction methods are mainly based on vulnerability descriptions and ignore the relevant features of vulnerability code, which only includes unimodal information and result in low prediction accuracy. This paper proposes a vulnerability severity prediction method based on bimodal data and multi-task learning. First the bimodal data, which consists of the description and source code of each vulnerability, is preprocessed. Next the GraphCodeBert is used for the word embedding module to extract different vulnerability features from the bimodal data. Then the Bi-GRU with attention mechanism is adopted for further feature extraction of vulnerability severity. Considering the strong correlation between the two tasks of vulnerability severity prediction and exploitability prediction, this paper proposes a multi-task learning approach, which allows the model to learn the connection and shared information between different tasks through a hard parameter sharing strategy, so as to achieve more accurate and reliable prediction of vulnerability severity. Experimental results show that the severity prediction method proposed in this paper outperforms state-of-the-art methods, and can achieve an average F1 score of 93.83 % on the public vulnerability dataset.
Keywords: Vulnerability severity prediction; Bimodal data; Multi-task learning; GraphCodeBert

Jie Cai, Bin Li, Tao Zhang, Jiale Zhang, Xiaobing Sun,
Fine-grained smart contract vulnerability detection by heterogeneous code feature learning and automated dataset construction,
Journal of Systems and Software,
Volume 209,
2024,
111919,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111919.
(https://www.sciencedirect.com/science/article/pii/S016412122300314X)
Abstract: Context:
Recently, several deep learning based smart contract vulnerability detection approaches have been proposed. However, challenges still exist in applying deep learning for fine-grained vulnerability detection in smart contracts, including the lack of the dataset with sufficient statement-level labeled smart contract samples and neglect of heterogeneity between syntax and semantic features during code feature learning.
Objective:
To utilize deep learning for fine-grained smart contract vulnerability detection, we propose a security best practices (SBP) based dataset construction approach to address the scarcity of datasets. Moreover, we propose a syntax-sensitive graph neural network to address the challenge of heterogeneous code feature learning.
Method:
The dataset construction approach is motivated by the insight that smart contract code fragments guarded by security best practices may contain vulnerabilities in their original unguarded code form. Thus, we locate and strip security best practices from the smart contract code to recover its original vulnerable code form and perform sample labeling. Meanwhile, as the heterogeneity between tree-structured syntax features embodied inside the abstract syntax tree (AST) and graph-structured semantic features reflected by relations between statements, we propose a code graph whose nodes are each statement’s AST subtree with a syntax-sensitive graph neural network that enhances the graph neural network by a child-sum tree-LSTM cell to learn these heterogeneous features for fine-grained smart contract vulnerability detection.
Results:
We compare our approach with three state-of-the-art deep learning-based approaches that only support contract-level vulnerability detection and two popular static analysis-based approaches that support fine detection granularity. The experiment results show that our approach outperforms the baselines at both coarse and fine granularities.
Conclusion:
In this paper, we propose utilizing security best practices inside the smart contract code to construct the dataset with statement-level labels. To learn both tree-structured syntax and graph-structured semantic code features, we propose a syntax-sensitive graph neural network. The experimental results show that our approach outperforms the baselines.
Keywords: Smart contract; Static analysis; Vulnerability detection; Graph neural network

Lejun Zhang, Jinlong Wang, Weizheng Wang, Zilong Jin, Yansen Su, Huiling Chen,
Smart contract vulnerability detection combined with multi-objective detection,
Computer Networks,
Volume 217,
2022,
109289,
ISSN 1389-1286,
https://doi.org/10.1016/j.comnet.2022.109289.
(https://www.sciencedirect.com/science/article/pii/S1389128622003437)
Abstract: Blockchains have been booming in recent years. As a decentralized system architecture, smart contracts give blockchains a user-defined logic. A smart contract is an executable program that can automatically carry out transactions on the Ethereum blockchain. However, some security issues in smart contracts are difficult to fix, and smart contracts also lack quality assessment standards. Therefore, this study proposes a Multiple-Objective Detection Neural Network (MODNN), a more scalable smart contract vulnerability detection tool. MODNN can validate 12 types of vulnerabilities, including 10 recognized threats, and identify more unknown types without the need for specialist or predefined knowledge through implicit features and Multi-Objective detection (MOD) algorithms. It supports the parallel detection of multiple vulnerabilities and has high scalability, eliminating the need to train separate models for each type of vulnerability and reducing significant time and labor costs. This paper also developed a data processing tool called Smart Contract-Crawler (SCC) to address the lack of smart contract vulnerability datasets. MODNN was evaluated using more than 18,000 smart contracts from Ethereum. Experiments showed that MODNN could achieve an average F1 Score of 94.8%, the current highest compared to several standard machine learning (ML) classification models.
Keywords: Blockchain; Smart contract; Vulnerability detection; Machine learning; Multi-objective

Yaoyuan Zhang, Yu-an Tan, Mingfeng Lu, Lu Liu, Dianxin Wang, Quanxing Zhang, Yuanzhang Li,
Towards interpreting vulnerability of object detection models via adversarial distillation,
Journal of Information Security and Applications,
Volume 72,
2023,
103410,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2022.103410.
(https://www.sciencedirect.com/science/article/pii/S221421262200254X)
Abstract: Recent works have shown that deep learning models are highly vulnerable to adversarial examples, limiting the application of deep learning in security-critical systems. This paper aims to interpret the vulnerability of deep learning models to adversarial examples. We propose adversarial distillation to illustrate that adversarial examples are generalizable data features. Deep learning models are vulnerable to adversarial examples because models do not learn this data distribution. More specifically, we obtain adversarial features by introducing a generation and extraction mechanism. The generation mechanism generates adversarial examples, which mislead the source model trained on the original clean samples. The extraction term removes the original features and selects valid and generalizable adversarial features. Valuable adversarial features guide the model to learn the data distribution of adversarial examples and realize the model’s generalization on the adversarial dataset. Extensive experimental evaluations have proved the excellent generalization performance of the adversarial distillation model. Compared with the normally trained model, the mAP has increased by 2.17% on their respective test sets, while the mAP on the opponent’s test set is very low. The experimental results further prove that adversarial examples are also generalizable data features, which obey a different data distribution from the clean data.
Keywords: Adversarial examples; Interpretability; Object detection; Deep learning

Mingke Wang, Chuanqi Tao, Hongjing Guo,
LCVD: Loop-oriented code vulnerability detection via graph neural network,
Journal of Systems and Software,
Volume 202,
2023,
111706,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111706.
(https://www.sciencedirect.com/science/article/pii/S0164121223001012)
Abstract: Due to the unique mechanism and complex structure, loops in programs can easily lead to various vulnerabilities such as dead loops, memory leaks, resource depletion, etc. Traditional approaches to loop-oriented program analysis (e.g. loop summarization) are costly with a high rate of false positives in complex software systems. To address the issues above, recent works have applied deep learning (DL) techniques to vulnerability detection. However, existing DL-based approaches mainly focused on the general characteristics of most vulnerabilities without considering the semantic information of specific vulnerabilities. As a typical structure in programs, loops are highly iterative with multi-paths. Currently, there is a lack of available approaches to represent loops, as well as useful methods to extract the implicit vulnerability patterns. Therefore, this paper introduces LCVD, an automated loop-oriented code vulnerability detection approach. LCVD represents the source code as the Loop-flow Abstract Syntax Tree (LFAST), which focuses on interleaving multi-paths around loop structures. Then a novel Loop-flow Graph Neural Network (LFGNN) is proposed to learn both the local and overall structure of loop-oriented vulnerabilities. The experimental results demonstrate that LCVD outperforms the three static analysis-based and four state-of-the-art DL-based vulnerability detection approaches across evaluation settings.
Keywords: Loop-oriented vulnerability; Vulnerability detection; Deep learning; Code representation; Graph neural network

Lingdi Kong, Senlin Luo, Limin Pan, Zhouting Wu, Xinshuai Li,
A multi-type vulnerability detection framework with parallel perspective fusion and hierarchical feature enhancement,
Computers & Security,
Volume 140,
2024,
103787,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103787.
(https://www.sciencedirect.com/science/article/pii/S0167404824000889)
Abstract: A core problem of vulnerability detection is to detect multi-type vulnerabilities simultaneously by characterizing vulnerabilities of high diversity and complexity in real program source code. Current methods mainly adjust and compromise multiple code representations such as code sequence and code graph based on composite graph. However, sequential features extracted by graph are hardly sufficient to model the contextual semantic associations of the token sequence. Meanwhile, structural features of the code graph extracted by models based on Euclidean Graph Neural Network are difficult to fit the tree-like calling relationships between code lines. These limitations make it difficult to detect diverse vulnerabilities. In addition, most of the existing models ignore the type of code statement, which is closely associated with some specific vulnerability types. In this paper, we propose a Parallelism Framework with Hierarchical feature Enhancement for Multi-type Vulnerability Detection (PFHE-MVD). PFHE-MVD models program code from three parallel perspectives, containing sequence, code graph, and Abstract Syntax Tree statistic. Hyperbolic Graph Convolutional Neural Network is integrated to model the top-down hierarchical calling structure in program code graph through hyperbolic space mapping. Besides, the statement type of code is embedded along with the code text to strengthen the identification ability for different types of vulnerabilities. Experimental results show that PFHE-MVD achieves new state-of-the-art results in multi-type vulnerability detection. PFHE-MVD captures tree-like hierarchical code structure feature and enhances the distinguishing ability for vulnerabilities by code statement type embedding.
Keywords: Vulnerability detection; Multiple types; Hyperbolic graph; Feature fusion

Zhangqi Zheng, Yongshan Liu, Bing Zhang, Xinqian Liu, Hongyan He, Xiang Gong,
A multitype software buffer overflow vulnerability prediction method based on a software graph structure and a self-attentive graph neural network,
Information and Software Technology,
Volume 160,
2023,
107246,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107246.
(https://www.sciencedirect.com/science/article/pii/S0950584923001003)
Abstract: Context
Buffer overflow vulnerabilities are one of the most common and dangerous software vulnerabilities; however, the complexity of software code makes predicting buffer overflow vulnerabilities in software challenging.
Objective
To accurately predict multiple types of software buffer overflow vulnerabilities, this paper proposes a multitype software buffer overflow vulnerability prediction method called MSVAGraph that is based on the graph structure of software and a self-attentive graph neural network.
Method
First, by analyzing software buffer overflow type vulnerabilities, a vulnerability feature set GSVFset extraction method based on graph structure is proposed to act as the software's basic unit. Second, a self-attentive pooling mechanism is used to design a vulnerability feature update mechanism based on a self-attentive graph neural network to transform the graph structure of the vulnerability feature set GSVFset into a feature vector representation. Finally, based on the updated GSVFset feature vector, a time-recursive-based neural network is designed to construct a prediction method for multitype software buffer overflow vulnerabilities.
Results
The method proposed in this paper validates executable programs of four types of buffer overflow vulnerabilities in the Juliet dataset using precision, accuracy, recall and F1 value as evaluation metrics. The prediction results have higher values after introducing the self-attentive pooling mechanism.
Conclusion
The proposed MSVAGraph achieves high precision, accuracy, recall and F1 value, and can better preserve the network topology and node content information of graphs in the software's graph structure.
Keywords: Software graph structure; Self-attentive; Graph neural networks; Multitype buffer overflow vulnerability

Panchanan Nath, Jaya Rani Mushahary, Ujjal Roy, Maharaj Brahma, Pranav Kumar Singh,
AI and Blockchain-based source code vulnerability detection and prevention system for multiparty software development,
Computers and Electrical Engineering,
Volume 106,
2023,
108607,
ISSN 0045-7906,
https://doi.org/10.1016/j.compeleceng.2023.108607.
(https://www.sciencedirect.com/science/article/pii/S0045790623000320)
Abstract: With the growing demand for application software, there is a race among industries to develop software as quickly as possible. However, maintaining pace and ensuring bug-free software has become increasingly challenging in a work-from-home arrangement as software developers are not under constant supervision. It increases the possibility of buggy products, and traditional testing techniques fail to provide optimal performance. We propose an Artificial Intelligence (AI) and blockchain-based novel decentralized software testing system. The proposed system aims to detect and prevent vulnerable code by synergizing deep learning capabilities and smart-contract-powered blockchain. The vulnerability detection is performed automatically without relying on manually written rules. We propose a non-vulnerability score range map to classify the source code. Furthermore, we integrate an InterPlanetary File System (IPFS) to ensure efficient storage over the blockchain. We conduct a testbed-based experiment to demonstrate the effectiveness of AI and blockchain integration for secure code development and testing.
Keywords: Deep learning; Blockchain; Smart contract; IPFS; Software testing; Software development

Yeming Gu, Hui Shu, Fei Kang,
BinAIV: Semantic-enhanced vulnerability detection for Linux x86 binaries,
Computers & Security,
Volume 135,
2023,
103508,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103508.
(https://www.sciencedirect.com/science/article/pii/S0167404823004182)
Abstract: Binary code vulnerability detection is an important research direction in the field of network security. The extensive reuse of open-source code has led to the spread of vulnerabilities that originally only affected a small number of targets to other software. Existing vulnerability detection methods are mainly based on binary code similarity analysis, that is, by comparing the similarity of code embedding to detect vulnerabilities. However, existing methods lack semantic understanding of binary code and cannot distinguish between different functions with similar code structures, which reduces the accuracy of vulnerability detection. This paper proposes a binary vulnerability detection method BinAIV based on function semantics. BinAIV is based on a neural network model, which defines and constructs binary function semantics to achieve more accurate similarity analysis. Experimental results show that in terms of binary code similarity analysis performance, BinAIV has a significant improvement compared to traditional methods that only use function embedding. In cross-compiler function search, cross-optimization function search, and cross-obfuscation function search experiments, the average Recall@1 value of BinAIV compared to the best-performing baseline methods increased by 40.1 %, 99.8 %, and 184.0 %. In the real-world vulnerability detection experiment, BinAIV had the highest detection accuracy for all vulnerabilities, with an improvement of 155.1 % and 97.7 % compared to Asm2Vec and SAFE, respectively.
Keywords: Function semantic; Vulnerability detection; Code similarity; Binary code; Deep learning

Dawei Yuan, Xiaohui Wang, Yao Li, Tao Zhang,
Optimizing smart contract vulnerability detection via multi-modality code and entropy embedding,
Journal of Systems and Software,
Volume 202,
2023,
111699,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111699.
(https://www.sciencedirect.com/science/article/pii/S0164121223000948)
Abstract: Smart contracts have been widely used in the blockchain world these years, and simultaneously vulnerability detection has gained more and more attention due to the staggering economic losses caused by the attacker. Existing tools that analyze vulnerabilities for smart contracts heavily rely on rules predefined by experts, which are labour-intense and require domain knowledge. Moreover, predefined rules tend to be misconceptions and increase the risk of crafty potential back-doors in the future. Recently, researchers mainly used static and dynamic execution analysis to detect the vulnerabilities of smart contracts and have achieved acceptable results. However, the dynamic method cannot cover all the program inputs and execution paths, which leads to some vulnerabilities that are hard to detect. The static analysis method commonly includes symbolic execution and theorem proving, which requires using constraints to detect vulnerability. These shortcomings show that traditional methods are challenging to apply and expand on a large scale. This paper aims to detect vulnerabilities via the Bug Injection framework and transfer learning techniques. First, we train a Transformer encoder using multi-modality code, which contains source code, intermediate representation, and assembly code. The input code consists separately of Solidity source code, intermediate representation, and assembly code. Specifically, we translate source code into the intermediate representation and decompile the byte code into assembly code by the EVM compiler. Then, we propose a novel entropy embedding technique, which combines token embedding, segment embedding, and positional embedding of the Transformer encoder in our approach. After that, we utilize the Bug Injection framework to automatically generate specific types of buggy code for fine-tuning and evaluating the performance of vulnerability detection. The experimental results show that our proposed approach improves the performance in detecting reentrancy vulnerabilities and timestamp dependence. Moreover, our approach is more flexible and scalable than static and dynamic analysis approaches in detecting smart contract vulnerabilities. Our approach improves the baseline approaches by an average of 11.89% in term of F1 score.
Keywords: Smart contract; Bug injection; Transfer learning; Vulnerability detection

Wenxin Tao, Xiaohong Su, Jiayuan Wan, Hongwei Wei, Weining Zheng,
Vulnerability detection through cross-modal feature enhancement and fusion,
Computers & Security,
Volume 132,
2023,
103341,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103341.
(https://www.sciencedirect.com/science/article/pii/S0167404823002511)
Abstract: Software vulnerability detection is critical to computer security. Most existing vulnerability detection methods use single modal-based vulnerability detection models, which cannot effectively extract cross-modal features. To solve this problem, we propose a new multimodal deep learning based vulnerability detection method through a cross-modal feature enhancement and fusion. Firstly, we utilize a special compilation and debugging method to obtain the alignment relationship between source code statements and assembly instructions, as well as between source code variables and assembly code registers. Based on this alignment relationship and program slicing technology, we propose a cross-slicing method to generate bimodal program slices. Then, we propose a cross-modal feature enhanced code representation learning model to capture the fine-grained semantic correlation between source code and assembly code by using the co-attention mechanisms. Finally, vulnerability detection is achieved by feature level fusion of semantic features captured in fine-grained aligned source code and assembly code. Extensive experiments show that our method improves the performance of vulnerability detection compared with state-of-the-art methods. Specifically, our method achieves an accuracy of 97.4% and an F1-measure of 93.4% on the SARD dataset. An average accuracy of 95.4% and an F1-measure of 89.1% on two real-world software projects (i.e., FFmpeg and OpenSSL) is also achieved by our method, improving over SOTA method 4.5% and 2.9%.
Keywords: Software security; Multimodal deep learning; Fine-grained cross modal alignment; Co-attention; Vulnerability detection

Hussien Al-haj Ahmad, Yasser Sedaghat,
An automated framework for selectively tolerating SDC errors based on rigorous instruction-level vulnerability assessment,
Future Generation Computer Systems,
Volume 157,
2024,
Pages 392-407,
ISSN 0167-739X,
https://doi.org/10.1016/j.future.2024.04.006.
(https://www.sciencedirect.com/science/article/pii/S0167739X24001365)
Abstract: The recent trend in most processor manufacturing technologies has significantly increased the vulnerability of embedded systems operating in harsh environments against soft errors. These errors can cause Silent Data Corruptions (SDCs) that produce erroneous execution results silently, disturbing the system’s execution and potentially leading to severe financial, human or environmental disasters. The use of fault tolerance techniques that take into account the performance and constraints of safety-critical systems is therefore essential to improve system reliability efficiently. Given the significant overhead imposed by conventional techniques, e.g., performance loss, increased memory usage, and additional hardware costs, researchers have developed cost-effective software-based techniques for fault tolerance. However, as detection rates grow, these techniques can increase code size and execution time significantly, which creates a challenge. This paper proposes an automated framework for selective fault tolerance of SDCs in software running on different architectures. The framework comprises a sequence of several consecutive techniques executed automatically. It offers a software-based technique that operates at the microarchitecture level and evaluates the vulnerability of program instructions against SDC errors. The framework conducts vulnerability assessment at the binary code level using a non-intrusive, runtime fault injection mechanism. It can inject faults at different granularity levels to maximize fault activation, including fine-grained injection at specific instruction fields or encoding bits, and coarse-grained injection into the entire software system. The framework makes minor modifications to the software being tested, enabling it to run at near-native speed. When SDC vulnerable instructions are identified, the framework selectively protects them automatically using a compiler extension, achieving a more appropriate trade-off between SDC detection and overhead by avoiding overprotection. Our framework was evaluated by conducting a large number of fault injection-based experiments on real-world benchmark programs using the cycle-accurate Gem5 simulator. Leveraging the accurate vulnerability assessment results provided by our framework, the proposed selective technique reduces SDC errors by up to 99% by selectively protecting only 45% of the program’s static instructions, with a performance overhead ranging from 8% to 35%.
Keywords: Fault tolerance; Transient hardware fault; Silent data corruptions; Vulnerability assessment; Fault injection

Huiwen Yang, Xiguo Gu, Xiang Chen, Liwei Zheng, Zhanqi Cui,
CrossFuzz: Cross-contract fuzzing for smart contract vulnerability detection,
Science of Computer Programming,
Volume 234,
2024,
103076,
ISSN 0167-6423,
https://doi.org/10.1016/j.scico.2023.103076.
(https://www.sciencedirect.com/science/article/pii/S0167642323001582)
Abstract: Context:
Smart contracts are computer programs that run on a blockchain. As the functions implemented by smart contracts become increasingly complex, the number of cross-contract interactions within them also rises. Consequently, the combinatorial explosion of transaction sequences poses a significant challenge for smart contract security vulnerability detection. Existing static analysis-based methods for detecting cross-contract vulnerabilities suffer from high false-positive rates and cannot generate test cases, while fuzz testing-based methods exhibit low code coverage and may not accurately detect security vulnerabilities.
Objective:
The goal of this paper is to address the above limitations and efficiently detect cross-contract vulnerabilities. To achieve this goal, we present CrossFuzz, a fuzz testing-based method for detecting cross-contract vulnerabilities.
Method:
First, CrossFuzz generates parameters of constructors by tracing data propagation paths. Then, it collects inter-contract data flow information. Finally, CrossFuzz optimizes mutation strategies for transaction sequences based on inter-contract data flow information to improve the performance of fuzz testing.
Results:
We implemented CrossFuzz, which is an extension of ConFuzzius, and conducted experiments on a real-world dataset containing 396 smart contracts. The results show that CrossFuzz outperforms xFuzz, a fuzz testing-based tool optimized for cross-contract vulnerability detection, with a 10.58% increase in bytecode coverage. Furthermore, CrossFuzz detects 1.82 times more security vulnerabilities than ConFuzzius.
Conclusion:
Our method utilizes data flow information to optimize mutation strategies. It significantly improves the efficiency of fuzz testing for detecting cross-contract vulnerabilities.
Keywords: Smart contract; Fuzz testing; Cross-contract vulnerability; Security vulnerability detection

Mingwei Tang, Wei Tang, Qingchi Gui, Jie Hu, Mingfeng Zhao,
A vulnerability detection algorithm based on residual graph attention networks for source code imbalance (RGAN),
Expert Systems with Applications,
Volume 238, Part D,
2024,
122216,
ISSN 0957-4174,
https://doi.org/10.1016/j.eswa.2023.122216.
(https://www.sciencedirect.com/science/article/pii/S0957417423027185)
Abstract: It is essential to detect potential vulnerabilities in software to ensure its safety. As software systems become more complex, traditional static vulnerability detection methods perform poorly. Currently, deep learning-based vulnerability detection models only extract source code vulnerability features using sequences or graphs. Sequential neural networks ignore structural information in the code, such as control flow diagrams and data flow diagrams. Additionally, graph neural networks cannot accurately extract features due to the lack of effective methods for extracting nodes’ features and aggregating global information. To address the above issue, we propose a vulnerability detection algorithm based on residual graph attention networks for source code imbalance (RGAN). Firstly, a local feature extraction module (PE-BL-A module) is designed. Using the sequence neural network, the module extracts various useful features, including node features in a control flow diagram based on local semantic features. Secondly, we present the Residual Graph Attention Network module (RGAT). To learn and update node features along the control flow direction, the module uses a graph attention network with residual connections. In this module, a mean biaffine attention pooling mechanism is proposed that can extract total graph vulnerability features more effectively. Thirdly, a dynamic cross-entropy loss function is designed. Using this function, it can handle sample imbalances during training. Finally, experiments conducted on several benchmark datasets demonstrate that the proposed model achieves state-of-the-art results.
Keywords: Source code vulnerability detection; Sequence neural network; Graph neural network; Attention mechanism; Imbalance processing

Wenjing Cai, Junlin Chen, Jiaping Yu, Lipeng Gao,
A software vulnerability detection method based on deep learning with complex network analysis and subgraph partition,
Information and Software Technology,
Volume 164,
2023,
107328,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107328.
(https://www.sciencedirect.com/science/article/pii/S0950584923001830)
Abstract: The increasing size and complexity of software programs have made them an integral part of modern society’s infrastructure, making software vulnerabilities a major threat to computer security. To address this issue, the use of deep learning-based software vulnerability detection methods has become increasingly popular. Although the effectiveness of the deep learning-based methods has been demonstrated, these methods have faced challenges in scalability and detection performance. To tackle this challenge, we propose a new vulnerability detection method based on deep learning with complex network analysis and subgraph partition that enhances detection accuracy while maintaining scalability. The method uses complex network analysis theory to convert the CPG into an image-like matrix, and then utilizes TextCNN for vulnerability detection. As a result, our method shows a 6% improvement in accuracy and a 10% reduction in false positive rates compared to state-of-the-art methods. In addition, our approach is able to detect some of the vulnerabilities recently released by CVE.
Keywords: Vulnerability detection; Code representation; Complex network analysis; TextCNN

Pingyan Wang, Shaoying Liu, Ai Liu, Wen Jiang,
Detecting security vulnerabilities with vulnerability nets,
Journal of Systems and Software,
Volume 208,
2024,
111902,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111902.
(https://www.sciencedirect.com/science/article/pii/S0164121223002972)
Abstract: Detecting security vulnerabilities is a crucial part in secure software development. Many static analysis tools have proved to be effective in finding vulnerabilities, but generally there are some complex and subtle vulnerabilities that can escape from detection. Manual audits are a complementary approach to using tools. Unfortunately, most manual analyses are tedious and error prone. To benefit from both the tools and manual audits, some approaches incorporate the auditor's expertise into a static analysis tool during vulnerability discovery. Following this strategy, this paper presents a representation of source code called a vulnerability net, which is a special Petri net that integrates with data dependence graphs and control flow graphs. The combined representation can facilitate the detection of taint-style vulnerabilities such as buffer overflows and injection vulnerabilities. We test the proposed approach on Securibench Micro and demonstrate that it has the capability to identify a variety of vulnerabilities while keeping the rates of false negatives and positives low.
Keywords: Vulnerability; Security; Static analysis; Manual audits; Petri nets

Da Chen, Lin Feng, Yuqi Fan, Siyuan Shang, Zhenchun Wei,
Smart contract vulnerability detection based on semantic graph and residual graph convolutional networks with edge attention,
Journal of Systems and Software,
Volume 202,
2023,
111705,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111705.
(https://www.sciencedirect.com/science/article/pii/S0164121223001000)
Abstract: Smart contracts are becoming the forefront of blockchain technology, allowing the performance of credible transactions without third parties. However, smart contracts on blockchain are not immune to vulnerability exploitation and cannot be modified after being deployed on the blockchain. Therefore, it is imperative to assure the security of smart contracts via intelligent vulnerability detection tools with the exponential increase in the number of smart contracts. The remarkably developing deep learning technology provides a promising way to detect potential smart contract vulnerabilities. Nevertheless, existing deep learning-based approaches fail to effectively capture the rich syntax and semantic information embedded in smart contracts for vulnerability detection. In this paper, we tackle the problem of smart contract vulnerability detection at the function level by constructing a novel semantic graph (SG) for each function and learning the SGs using graph convolutional networks (GCNs) with residual blocks and edge attention. Our proposed method consists of three stages. In the first stage, we create the SG which contains rich syntax and semantic information including the data–data, instruction–instruction and instruction–data relationships, variables, operations, etc., by building an abstract syntax tree (AST) from the code of each function, removing the unimportant nodes in the AST, and adding edges between the nodes to represent the data flows and the execution sequence of the statements. In the second stage, we propose a new graph convolutional network model EA-RGCN to learn the content and semantic features of the code. EA-RGCN contains three parts: node and edge representation via word2vec, content feature extraction with a residual GCN (RGCN) module, and semantic feature extraction using an edge attention (EA) module. In the third stage, we concatenate the code content features and the semantic features to obtain the global code feature and use a classifier to identify whether the function is vulnerable. We conduct experiments on the datasets constructed from real-world smart contracts. Experimental results demonstrate that the proposed semantic graph and the EA-RGCN model can effectively improve the performance in terms of accuracy, precision, recall, and F1-score on smart contract vulnerability detection.
Keywords: Smart contract vulnerability detection; Code graph; Graph convolutional networks; Edge attention; Residual block

Miles Q. Li, Benjamin C.M. Fung, Ashita Diwan,
A Novel Deep Multi-head Attentive Vulnerable Line Detector,
Procedia Computer Science,
Volume 222,
2023,
Pages 35-44,
ISSN 1877-0509,
https://doi.org/10.1016/j.procs.2023.08.142.
(https://www.sciencedirect.com/science/article/pii/S1877050923009079)
Abstract: Detecting and fixing vulnerabilities in software programs before production is crucial in software engineering. Manual vulnerability detection is labor-intensive, especially for large programs, leading to the proposal of machine learning-based methods for automation. However, existing approaches primarily detect vulnerabilities at the function level, providing non-specific results that require additional developer effort to locate vulnerabilities. Detection at the line-of-code level is an underexplored area. In this paper, we propose a novel deep learning method for line-of-code vulnerability detection. Our hybrid neural network combines a memory network and multi-head attention mechanism. Through comprehensive experiments, we analyze the impact of each modification, demonstrating significant improvements in performance. Our approach outperforms existing methods for comparison, showcasing its effectiveness in vulnerability detection.
Keywords: Deep learning; vulnerability detection; memory networks; multi-head attention

Hao Sun, Lei Cui, Lun Li, Zhenquan Ding, Zhiyu Hao, Jiancong Cui, Peng Liu,
VDSimilar: Vulnerability detection based on code similarity of vulnerabilities and patches,
Computers & Security,
Volume 110,
2021,
102417,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2021.102417.
(https://www.sciencedirect.com/science/article/pii/S0167404821002418)
Abstract: Vulnerability detection using machine learning is a hot topic in improving software security. However, existing works formulate detection as a classification problem, which requires a large set of labelled data while capturing semantical and syntactic similarity. In this work, we argue that similarity in the view of vulnerability is the key in detecting vulnerabilities. We prepare a relatively smaller data set composed of both vulnerabilities and associated patches, and attempt to realize security similarity from (i) the similarity between pair of vulnerabilities and (ii) the difference between a pair of vulnerability and patch. To achieve this, we setup the detection model using the Siamese network cooperated with BiLSTM and Attention to deal with source code, Attention network to improve the detection accuracy. On a data set of 876 vulnerabilities and patches of OpenSSL and Linux, the proposed model (VDSimilar) achieves about 97.17% in AUC value of OpenSSL (where the Attention network contributes 1.21% than BiLSTM in Siamese), which is more outstanding than the most advanced methods based on deep learning.
Keywords: Siamese network; BiLSTM; Attention; Vulnerability detection; Code similarity

Jiaming Ye, Mingliang Ma, Yun Lin, Lei Ma, Yinxing Xue, Jianjun Zhao,
Vulpedia: Detecting vulnerable ethereum smart contracts via abstracted vulnerability signatures,
Journal of Systems and Software,
Volume 192,
2022,
111410,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2022.111410.
(https://www.sciencedirect.com/science/article/pii/S0164121222001236)
Abstract: Recent years have seen smart contracts are getting increasingly popular in building trustworthy decentralized applications. Previous research has proposed static and dynamic techniques to detect vulnerabilities in smart contracts. These tools check vulnerable contracts against several predefined rules. However, the emerging new vulnerable types and programming skills to prevent possible vulnerabilities emerging lead to a large number of false positive and false negative reports of tools. To address this, we propose Vulpedia, which mines expressive vulnerability signatures from contracts. Vulpedia is based on the relaxed assumption that the owner of contract is not malicious. Specifically, we extract structural program features from vulnerable and benign contracts as vulnerability signatures, and construct a systematic detection method based on detection rules composed of vulnerability signatures. Compared with the rules defined by state-of-the-arts, our approach can extract more expressive rules to achieve better completeness (i.e., detection recall) and soundness (i.e., precision). We further evaluate Vulpedia with four baselines (i.e., Slither, Securify, SmartCheck and Oyente) on the testing dataset consisting of 17,770 contracts. The experiment results show that Vulpedia achieves best performance of precision on 4 types of vulnerabilities and leading recall on 3 types of vulnerabilities meanwhile exhibiting the great efficiency performance.
Keywords: Software analysis; Software clone analysis; Smart contract; Blockchain security; Software testing

Janaka Senanayake, Harsha Kalutarage, Andrei Petrovski, Luca Piras, Mhd Omar Al-Kadri,
Defendroid: Real-time Android code vulnerability detection via blockchain federated neural network with XAI,
Journal of Information Security and Applications,
Volume 82,
2024,
103741,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2024.103741.
(https://www.sciencedirect.com/science/article/pii/S2214212624000449)
Abstract: Ensuring strict adherence to security during the phases of Android app development is essential, primarily due to the prevalent issue of apps being released without adequate security measures in place. While a few automated tools are employed to reduce potential vulnerabilities during development, their effectiveness in detecting vulnerabilities may fall short. To address this, “Defendroid”, a blockchain-based federated neural network enhanced with Explainable Artificial Intelligence (XAI) is introduced in this work. Trained on the LVDAndro dataset, the vanilla neural network model achieves a 96% accuracy and 0.96 F1-Score in binary classification for vulnerability detection. Additionally, in multi-class classification, the model accurately identifies Common Weakness Enumeration (CWE) categories with a 93% accuracy and 0.91 F1-Score. In a move to foster collaboration and model improvement, the model has been deployed within a blockchain-based federated environment. This environment enables community-driven collaborative training and enhancements in partnership with other clients. The extended model demonstrates improved accuracy of 96% and F1-Score of 0.96 in both binary and multi-class classifications. The use of XAI plays a pivotal role in presenting vulnerability detection results to developers, offering prediction probabilities for each word within the code. This model has been integrated into an Application Programming Interface (API) as the backend and further incorporated into Android Studio as a plugin, facilitating real-time vulnerability detection. Notably, Defendroid exhibits high efficiency, delivering prediction probabilities for a single code line in an average processing time of a mere 300 ms. The weight-sharing transparency in the blockchain-driven federated model enhances trust and traceability, fostering community engagement while preserving source code privacy and contributing to accuracy improvement.
Keywords: Android application protection; Code vulnerability; Neural network; Federated learning; Source code privacy; Explainable AI; Blockchain

Uelinton Brezolin, Andressa Vergütz, Michele Nogueira,
A method for vulnerability detection by IoT network traffic analytics,
Ad Hoc Networks,
Volume 149,
2023,
103247,
ISSN 1570-8705,
https://doi.org/10.1016/j.adhoc.2023.103247.
(https://www.sciencedirect.com/science/article/pii/S1570870523001671)
Abstract: The Internet of Things comprises wireless devices with limited computing resources. It targets attacks that exploit vulnerabilities such as unencrypted data transfer. Conventional vulnerability detection occurs from databases that list the most common vulnerabilities and exploits (CVEs). However, these bases are limited to known vulnerabilities, which is not the case for the IoT context most of the time. This work proposes MANDRAKE: a Method for vulnerAbilities detectioN baseD on the IoT netwoRk pAcKEt traffic using machine learning techniques. A performance evaluation has been conducted in a smart home scenario taking as basis two datasets, one generated experimentally for this work and the other from the literature. The results have achieved 99% precision in detecting vulnerabilities in network traffic.
Keywords: Internet of Things; Vulnerability detection; Entropy; Traffic analysis

Yukun Dong, Yeer Tang, Xiaotong Cheng, Yufei Yang, Shuqi Wang,
SedSVD: Statement-level software vulnerability detection based on Relational Graph Convolutional Network with subgraph embedding,
Information and Software Technology,
Volume 158,
2023,
107168,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107168.
(https://www.sciencedirect.com/science/article/pii/S0950584923000228)
Abstract: Context:
Current deep-learning based vulnerability detection methods have been proven more automatic and correct to a certain extent, nonetheless, they are limited to detect at function-level or file-level, which can hinder software developers from acquiring more detailed information and conducting more targeted repairs. Graph-based detection methods have shown dominant performance over others. Unfortunately, the information they reveal has not been fully utilized.
Objective:
We design SedSVD (Subgraph embedding driven Statement-level Vulnerability Detection) with two objectives: (i) to better utilize the information the code-related graphs can reflect; (ii) to detect vulnerabilities at a finer-grained level.
Method:
In our work, we propose a novel graph-based detection framework that embeds graphs at subgraph-level to realize statement-level detection. It first leverages Code Property Graph (CPG) to learn both semantic and syntactic information from source code, and then selects several center nodes (code elements) in CPG to build their subgraphs. After embedding each subgraph with its nodes and edges, we apply Relational Graph Convolutional Network (RGCN) to process different edges differently. A Multi-Layer Perceptron (MLP) layer is further added to ensure its prediction performance.
Results:
We conduct our experiments on C/C++ projects from NVD and SARD. Experimental results show that SedSVD achieves 95.15% in F1-measure which proves our work to be more effective.
Conclusion:
Our work detects at a finer-grained level and achieves higher F1-measure than existing state-of-art vulnerability detection techniques. Besides, we provide a more detailed detection report pointing the specific error code elements within statements.
Keywords: Software vulnerability detection; Code property graph; Relational graph convolutional network; Subgraph embedding; Statement-level detection

Xin Li, Yang Xin, Hongliang Zhu, Yixian Yang, Yuling Chen,
Cross-domain vulnerability detection using graph embedding and domain adaptation,
Computers & Security,
Volume 125,
2023,
103017,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.103017.
(https://www.sciencedirect.com/science/article/pii/S0167404822004096)
Abstract: Vulnerability detection is an effective means to maintain cyberspace security. Machine learning methods have risen much attention in software security due to their advantage of accuracy and automation. However, current researches mainly focus on in-domain vulnerability detection where the training data and test data belong to the same domain. Due to application scenarios, coding habits, and other factors, vulnerabilities in different software projects may obey different probability distributions. This discrepancy compromises the performance of machine learning methods when they are applied to a brand-new project. To address this cold start problem, we propose a cross-domain vulnerability detection framework using graph embedding and deep domain adaption (VulGDA). It works in a variety of cross-domain fashions, including the Zero-Shot fashion that no labeled data in the target domain is available for training. VulGDA is decomposed to graph embedding and domain adaptation. At the graph embedding stage, we transform the samples in source code into graph representations where elements are directly concatenated according to their syntactic and semantic relationships. Then, we aggregate information from neighbors and edges defined in the graph into real-valued vectors. By graph embedding, VulGDA extracts comprehensive vulnerability features and compromises the challenge of long-term dependency. Aiming at the discrepancy between training data and test data, domain adaption is used to train a feature generator. This feature generator maps the graph embedding to a “deep” feature that is discriminative for vulnerability detection, and invariant to the shift between domains. We perform a systematic experiment to validate the effectiveness of VulGDA. The results show that combining graph embedding and deep domain adaptation promotes VulGDA's performance in cross-domain vulnerability detection. Compared with the state-of-the-art methods, our method has better performance under the cold start condition.
Keywords: Cross-domain; Vulnerability detection; Graph embedding; Domain adaption; Software security

Wangyang Yu, Jie Feng, Lu Liu, Xiaojun Zhai, Yumeng Cheng,
Enhancing security in e-business processes: Utilizing dynamic slicing of Colored Petri Nets for logical vulnerability detection,
Future Generation Computer Systems,
Volume 158,
2024,
Pages 210-218,
ISSN 0167-739X,
https://doi.org/10.1016/j.future.2024.04.035.
(https://www.sciencedirect.com/science/article/pii/S0167739X2400164X)
Abstract: The field of e-business covers multiple aspects and has undergone rapid development, profoundly changing our transaction methods and shopping experiences. However, with the increasing complexity of its business processes, logical vulnerabilities have become an inevitable issue. These logical vulnerabilities can lead to a range of security problems, seriously threatening business stability and consumer trust. To address the challenge of logical vulnerabilities in e-business, we developed a model based on Colored Petri Nets (CPN), the Interactive Business Process Fusion (IBPF) net, which is adept at identifying such vulnerabilities during the design phase. However, the analysis methods for IBPF net still urgently need innovation. In addressing this issue, we use dynamic slicing techniques to analyze IBPF net, serving as a method for revealing logical vulnerabilities. We obtain backward slice, partial forward slice, and bidirectional slice through the slicing algorithms. Eventually, these three types of slices are merged to form the final dynamic slice. This technique, which involves a more targeted analysis than examining the entire IBPF net, simplifies analysis process and prevents state space explosion, thereby providing a distinct advantage. The results of this research are of great value in enhancing system reliability, reducing maintenance costs, and providing analysis techniques in the field of e-business security.
Keywords: E-business security; Logic vulnerability; Colored Petri Nets; Dynamic slicing

Bolun Wu, Futai Zou, Ping Yi, Yue Wu, Liang Zhang,
SlicedLocator: Code vulnerability locator based on sliced dependence graph,
Computers & Security,
Volume 134,
2023,
103469,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103469.
(https://www.sciencedirect.com/science/article/pii/S0167404823003796)
Abstract: Machine learning-based fine-grained vulnerability detection is an important technique for locating vulnerable statements, which assists engineers in efficiently analyzing and fixing the vulnerabilities. However, due to insufficient code representations, code embeddings, and neural network design, current methods suffer low vulnerability localization performance. In this paper, we propose to address these shortcomings by presenting SlicedLocator, a novel fine-grained code vulnerability detection model that is trained in a dual-grained manner and can predict both program-level and statement-level vulnerabilities. We design the sliced dependence graph, a new code representation that not only preserves rich interprocedural relations but also eliminates vulnerability-irrelevant statements. We create attention-based code embedding networks that are trained with the entire model to extract vulnerability-aware code features. In addition, we present a new LSTM-GNN model as a fusion of semantic modeling and structural modeling. Experiment results on a large-scale C/C++ vulnerability dataset reveal that SlicedLocator outperforms state-of-the-art machine learning-based vulnerability detectors, especially in terms of localization metrics.
Keywords: Vulnerability detection; Localization; Program analysis; Program representation; Deep learning

Huan Mei, Guanjun Lin, Da Fang, Jun Zhang,
Detecting vulnerabilities in IoT software: New hybrid model and comprehensive data analysis,
Journal of Information Security and Applications,
Volume 74,
2023,
103467,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2023.103467.
(https://www.sciencedirect.com/science/article/pii/S2214212623000510)
Abstract: Software vulnerabilities have always been an essential issue in cyberspace, for which many vulnerability detection techniques have been investigated. Among them, deep learning-based detection techniques have demonstrated promising detection results. However, due to the various programming patterns of developers, vulnerabilities are usually associated with the code context, such as Internet of Things (IoT) programs. Therefore, we propose a contextual embedding model to integrate three hybrid models, CLSTM, CBiLSTM (sequential structure), and CNN-BiLSTM (parallel structure), based on the code characteristics of IoT applications. To further improve the precision and robustness, we apply information augment by adding synthetic data to the real-world vulnerability data to address the severe data imbalance and facilitate neural models learning vulnerability patterns. The new method inherits the architecture of CodeBERT with multiheaded attention mechanisms and learns a richer set of vulnerable code patterns with long-range context dependencies when processing code sequence data. To assess the effectiveness of hybrid contextual embedding, we contrast the neural network models developed using the representations obtained from the three embedding methods, including CodeBERT, Word2Vec, and FastText. The experiments involve IoT applications and well-known open-source APIs. The results show that the hybrid model built based on the neural features outperforms the non-hybrid model in vulnerability detection.
Keywords: Vulnerability detection; IoT; CodeBERT; Contextual embedding; Deep learning; Hybrid model

Arvinder Kaur, Ruchikaa Nayyar,
A Comparative Study of Static Code Analysis tools for Vulnerability Detection in C/C++ and JAVA Source Code,
Procedia Computer Science,
Volume 171,
2020,
Pages 2023-2029,
ISSN 1877-0509,
https://doi.org/10.1016/j.procs.2020.04.217.
(https://www.sciencedirect.com/science/article/pii/S1877050920312023)
Abstract: Software security has become an essential component of software development process. It is necessary for an organisation to maintain software security in order to ensure integrity, authenticity and availability of the software product. To ensure software security, one of the major task is to identify vulnerabilities present in the source code before the software is being deployed. Detecting vulnerabilities in early phases of software development cycle, makes the process of fixing those vulnerabilities much easier for software developers. The vulnerability detection can be done either at the production phase, this means when the software is still being developed by statically auditing the source code, or dynamically at run time. In this study, vulnerability detection was done through Static code analysis process. Static code analysis can be done either manually or through automated tools. This paper focuses on using automated source code scanning tools for vulnerabilities detection in a software. Automated static Code Analysis tools audits the entire source code for its quality and identify any potential security vulnerability, if present. Unlike dynamic source code analysis that evaluates the source code behaviour during code execution, which is done quite late in the software development life cycle, Static Code Analysis leads to detection of security vulnerabilities in a source code in early stages of software development process, when the software is still in production phase because it does not require code to be in execution state. This paper firstly explains the importance of incorporating static code analysis in software development life cycle process so as to facilitate early detection of vulnerabilities in software product, and then present a comparative study of various static code analysis tools available for vulnerability detection in C/C++ and JAVA source code. The comparative study of three C/C++ static code analysis tools (flawfinder, RATS and CPPCheck) and two JAVA static code analysis tools (spotbugs and PMD) is done using Juliet (version1.3) test suite and APACHE tomcat dataset respectively, on the basis of category of vulnerability detected by each of the selected tool and the likelihood of false positive reported by each tool. Results showed that Flawfinder detected maximum categories of vulnerabilities and RATS and CPPCheck were almost similar in types of vulnerabilities detected. Also, it was observed that CPPCheck reported maximum number of false positives as compared to other two tools. Java static code analysis tools Spot bugs was able to detect more number of vulnerabilities than PMD.
Keywords: software security; vulnerabilities; static code analysis

Sultan S. Alqahtani,
A study on the use of vulnerabilities databases in software engineering domain,
Computers & Security,
Volume 116,
2022,
102661,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.102661.
(https://www.sciencedirect.com/science/article/pii/S0167404822000608)
Abstract: Over the last decade several software vulnerability databases have been introduced to guide researchers and developers in developing more secure and reliable software. While the Software Engineering research community is increasingly becoming aware of these vulnerabilities databases, no comprehensive literature survey exists that studies how they are used in software development. The objective of our survey is to provide insights on how the software vulnerability database (SVDBs) research landscape has evolved over the past 17 years and outline some open challenges associated with their use in non-security domain. More specifically, we introduce a semi-automated methodology based on topic modeling, to discover relevant topics from our dataset of 99 relevant SE research articles. We find 24 topics discussing the use of SVDBs in SE domain. The results shows that i) topics describing the use of SVDBs range from security empirical (case) studies to tools for generating security test cases; ii) the majority of the surveyed papers cover a limited number of software engineering contributions or activities (e.g., maintenance) and iii) that most of the surveyed articles rely on only one SVDB as their knowledge source. Dataset and results are available at https://github.com/isultane/svdbs_dataset
Keywords: Security; Vulnerability databases; Software development; Software security; Vulnerability analysis

Chunyong Zhang, Yang Xin,
VulGAI: vulnerability detection based on graphs and images,
Computers & Security,
Volume 135,
2023,
103501,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103501.
(https://www.sciencedirect.com/science/article/pii/S016740482300411X)
Abstract: Deep learning models have been widely used in the field of vulnerability detection. Deep learning-based vulnerability detection methods can automatically learn code patterns. Some methods consider processing codes as text sequences to achieve scalable vulnerability detection. They leverage natural language processing models to extract code features. These methods do not consider the code's semantic structure and treat code slices as text. Vulnerability detection methods based on graph structures and graph neural networks are more accurate than text-based methods. However, these methods lack scalability in practice. Both graph generation and graph neural network training are all time-consuming. We propose a vulnerability detection method based on graphs and images (VulGAI). VulGAI choose the more reasonable node centrality to generate the image. It can preserve program details and distinguish node importance from different perspectives. In addition, we design a more efficient CNN model, which reduces computational overhead and improves detection performance (Time and Accuracy). We implement VulGAI and evaluate six methods (VulDePecker, SySeVR, Devign, VulCNN, mVulPreter, and VulGAI) on 40,657 functions. Experimental results show that VulGAI achieves higher Accuracy, TPR, and F1-Score than the others. In addition, we compare VulGAI and VulCNN on 30270 real-world functions. VulGAI outperforms VulCNN by 1.48 times in the number of TP. VulGAI is about 3.9 times faster than VulCNN in detection time.
Keywords: Vulnerability detection; Program dependency graph; Node centrality; RGB image; CNN

Maud Ranchet, Roland Brémond, Prashant Pala, Michèle Colomb, Viola Cavallo,
The detection of vulnerable road users by younger and older drivers,
Transportation Research Part F: Traffic Psychology and Behaviour,
Volume 91,
2022,
Pages 357-367,
ISSN 1369-8478,
https://doi.org/10.1016/j.trf.2022.10.018.
(https://www.sciencedirect.com/science/article/pii/S1369847822002534)
Abstract: The detection of vulnerable road users (VRUs), especially under time constraints, may be impaired in elderly drivers, due to their visual and cognitive decline. This represents a major concern for road safety. The objective of the present study was to investigate the effect of aging on the detection of VRUs. A further aim was to investigate the impact of external factors on VRU detection. Twenty-two young adults, 20 younger-old adults, and 32 older-old adults were included in the study. A series of photographs were displayed for 500 ms. Participants were asked to detect the VRU, which could be a motorcyclist, a cyclist, or a pedestrian. The VRU was located at one of two distances (near/far), one of two locations (off-centered/centered), and in two car-DRL (daytime running lights) environments (on/off). The ability to correctly detect a VRU was measured. An eye-tracker was used to record eye movements. The main findings showed that VRU-detection performance decreased with aging, even in the younger-old group (ages 55–68). The ability to correctly detect a VRU by older-old adults was poorer particularly when the VRU was a motorcyclist or a cyclist. As a whole, the older-old adults made more fixations to correctly detect the VRU than the other two age groups did. Moreover, the visual angle between the gaze of the participant’s last fixation and the target in the older-old group was lower than in the other two groups, particularly when the VRU was off-centered. This finding suggests that older-old adults compensated for their visual-field decline by doing more visual exploration than the other two groups did to correctly detect the VRU. The results are discussed with regards to age-related cognitive and visual deficits. Word count: 279.
Keywords: Older drivers; Vulnerable road users; Detection performance; Visual exploration

Hazim Hanif, Mohd Hairul Nizam Md Nasir, Mohd Faizal Ab Razak, Ahmad Firdaus, Nor Badrul Anuar,
The rise of software vulnerability: Taxonomy of software vulnerabilities detection and machine learning approaches,
Journal of Network and Computer Applications,
Volume 179,
2021,
103009,
ISSN 1084-8045,
https://doi.org/10.1016/j.jnca.2021.103009.
(https://www.sciencedirect.com/science/article/pii/S1084804521000369)
Abstract: The detection of software vulnerability requires critical attention during the development phase to make it secure and less vulnerable. Vulnerable software always invites hackers to perform malicious activities and disrupt the operation of the software, which leads to millions in financial losses to software companies. In order to reduce the losses, there are many reliable and effective vulnerability detection systems introduced by security communities aiming to detect the software vulnerabilities as early as in the development or testing phases. To summarise the software vulnerability detection system, existing surveys discussed the conventional and data mining approaches. These approaches are widely used and mostly consist of traditional detection techniques. However, they lack discussion on the newly trending machine learning approaches, such as supervised learning and deep learning techniques. Furthermore, existing studies fail to discuss the growing research interest in the software vulnerability detection community throughout the years. With more discussion on this, we can predict and focus on what are the research problems in software vulnerability detection that need to be urgently addressed. Aiming to reduce these gaps, this paper presents the research interests’ taxonomy in software vulnerability detection, such as methods, detection, features, code and dataset. The research interest categories exhibit current trends in software vulnerability detection. The analysis shows that there is considerable interest in addressing methods and detection problems, while only a few are interested in code and dataset problems. This indicates that there is still much work to be done in terms of code and dataset problems in the future. Furthermore, this paper extends the machine learning approaches taxonomy, which is used to detect the software vulnerabilities, like supervised learning, semi-supervised learning, ensemble learning and deep learning. Based on the analysis, supervised learning and deep learning approaches are trending in the software vulnerability detection community as these techniques are able to detect vulnerabilities such as buffer overflow, SQL injection and cross-site scripting effectively with a significant detection performance, up to 95% of F1 score. Finally, this paper concludes with several discussions on potential future work in software vulnerability detection in terms of datasets, multi-vulnerabilities detection, transfer learning and real-world applications.
Keywords: Software vulnerability detection; Software security; Computer security; Machine learning; Deep learning

Zihua Song, Junfeng Wang, Kaiyuan Yang, Jigang Wang,
HGIVul: Detecting inter-procedural vulnerabilities based on hypergraph convolution,
Information and Software Technology,
Volume 160,
2023,
107219,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107219.
(https://www.sciencedirect.com/science/article/pii/S0950584923000733)
Abstract: Context:
Detecting source code vulnerabilities is one way to block cyber attacks from an early stage. Vulnerability-triggered code typically involves one or more function procedures, while current research pays more attention to the code on a single procedure. Due to lacking a comprehensive analysis of multiple vulnerability-related procedures, current methods suffer disorder false-positive and false-negative rates, especially in detecting inter-procedural vulnerability.
Objective:
This paper proposes HGIVul, an inter-procedural vulnerability detection method for source code based on hypergraph convolution. The key of HGIVul is to derive the syntax-semantic characteristic from multiple procedures in a suitable code information space, which brings more balanced detection.
Methods:
Firstly, the potential vulnerability-related code trace across multiple procedures is located via static analyzer Infer. Then, HGIVul reconstructs the soft inter-procedural control flow graph (ICFG) from the trace to restore the complex relationship between multiple-procedural codes. Next, HGIVul performs multi-level graph convolution on the soft ICFG to grasp holistic code characteristics within multiple procedures. Finally, a classifier is applied to the extracted code features for vulnerability detection.
Results:
The experimental results show that HGIVul outperforms in detecting vulnerabilities and identifying vulnerability types, with the F1-measure of 66.33% and 79.58% for detection and identification, respectively. Moreover, the experiment on cross-projects indicates HGIVul has a better detection ability.
Conclusion:
The proposed HGIVul achieves a balanced detection performance than the related state-of-the-art methods, which proves that fusing syntactic–semantic information from multiple procedures benefits inter-procedural vulnerability detection. In addition, the results applied to five actual projects indicate that HGIVul has the feasibility of detection in practical.
Keywords: Vulnerability detection; Inter-procedural vulnerability; Hypergraph neural network; Software security engineering; Static analysis

Laura Wartschinski, Yannic Noller, Thomas Vogel, Timo Kehrer, Lars Grunske,
VUDENC: Vulnerability Detection with Deep Learning on a Natural Codebase for Python,
Information and Software Technology,
Volume 144,
2022,
106809,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2021.106809.
(https://www.sciencedirect.com/science/article/pii/S0950584921002421)
Abstract: Context:
Identifying potential vulnerable code is important to improve the security of our software systems. However, the manual detection of software vulnerabilities requires expert knowledge and is time-consuming, and must be supported by automated techniques.
Objective:
Such automated vulnerability detection techniques should achieve a high accuracy, point developers directly to the vulnerable code fragments, scale to real-world software, generalize across the boundaries of a specific software project, and require no or only moderate setup or configuration effort.
Method:
In this article, we present Vudenc (Vulnerability Detection with Deep Learning on a Natural Codebase), a deep learning-based vulnerability detection tool that automatically learns features of vulnerable code from a large and real-world Python codebase. Vudenc applies a word2vec model to identify semantically similar code tokens and to provide a vector representation. A network of long-short-term memory cells (LSTM) is then used to classify vulnerable code token sequences at a fine-grained level, highlight the specific areas in the source code that are likely to contain vulnerabilities, and provide confidence levels for its predictions.
Results:
To evaluate Vudenc, we used 1,009 vulnerability-fixing commits from different GitHub repositories that contain seven different types of vulnerabilities (SQL injection, XSS, Command injection, XSRF, Remote code execution, Path disclosure, Open redirect) for training. In the experimental evaluation, Vudenc achieves a recall of 78%–87%, a precision of 82%–96%, and an F1 score of 80%–90%. Vudenc’s code, the datasets for the vulnerabilities, and the Python corpus for the word2vec model are available for reproduction.
Conclusions:
Our experimental results suggest that Vudenc is capable of outperforming most of its competitors in terms of vulnerably detection capabilities on real-world software. Comparable accuracy was only achieved on synthetic benchmarks, within single projects, or on a much coarser level of granularity such as entire source code files.
Keywords: Static analysis; Vulnerability detection; Deep learning; Long-short-term memory network; Natural codebase; Software repository mining

Guodong Ye, Xin Liu, Siqi Fan, Yuan Tan, Qingguo Zhou, Rui Zhou, Xiaokang Zhou,
Novel supply chain vulnerability detection based on heterogeneous-graph-driven hash similarity in IoT,
Future Generation Computer Systems,
Volume 148,
2023,
Pages 201-210,
ISSN 0167-739X,
https://doi.org/10.1016/j.future.2023.06.006.
(https://www.sciencedirect.com/science/article/pii/S0167739X23002194)
Abstract: Supply chain vulnerability (SCV) exists in third-party components (operating systems, basic libraries, etc.). These vulnerabilities do not exist in code written by ordinary developers, who unknowingly introduce them due to the use of third-party components, resulting in the software they developed being affected by these vulnerabilities. Compared with traditional devices, IoT devices have various architectures, and the security issues introduced by code reuse are prominent. This paper proposes PhG-vNet, an effective and efficient SCV detection approach for IoT devices based on heterogeneous-graph-driven hash similarity. PhG-vNet uses customized graph embedding to feature the pseudo-code and uses the heterogeneous graph neural network to extract the graph structure to binary hash embeddings. Then, PhG-vNet detects SCVs based on self-designed bit similarity with Bayesian weighted. Experiments show that PhG-vNet does not need expensive hardware requirements and has impressive low overhead and acceptable detection performance.
Keywords: Binary code similarity; Supply chain vulnerability; Heterogeneous graph; Vulnerability detection

Xue Yuan, Guanjun Lin, Huan Mei, Yonghang Tai, Jun Zhang,
Software vulnerable functions discovery based on code composite feature,
Journal of Information Security and Applications,
Volume 81,
2024,
103718,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2024.103718.
(https://www.sciencedirect.com/science/article/pii/S2214212624000218)
Abstract: Vulnerability identification is crucial to protecting software systems from attacks. Although numerous learning-based solutions have been suggested to assist in vulnerability identification, these approaches often face challenges due to the scarcity of real-world vulnerability data. To extract as much vulnerability information as possible from limited data, we consider obtaining the characteristics of vulnerabilities from different forms of code by leveraging two distinct deep neural models. First, source code functions are considered to be textual sequences, and Gated Recurrent Unit (GRU) is applied to extract serialized features. Then, Abstract Syntax Trees (ASTs) of these functions, which reflects the code structure, are fed to a Gated Graph Recurrent Network (GGRN) to obtain structural features indicative of software vulnerability. To better handle data imbalance issues in real-world scenarios, we employ Random Forest (RF) to construct a predictive model to learn the concatenation of serialized and structural features extracted by GRU and GGRN. To evaluate the proposed approach, we collected 12 open-source projects containing function-level samples and compared the proposed method with a series of baselines, including popular learning-based methods and static analysis tools. The empirical results demonstrate that our proposed approach outperforms the baselines and can identify more vulnerabilities.
Keywords: Vulnerability detection; Source code; Deep learning; Deep representation learning

Hariharan M., Sathish Kumar C., Anshul Tanwar, Krishna Sundaresan, Prasanna Ganesan, Sriram Ravi, R. Karthik,
Proximal Instance Aggregator networks for explainable security vulnerability detection,
Future Generation Computer Systems,
Volume 134,
2022,
Pages 303-318,
ISSN 0167-739X,
https://doi.org/10.1016/j.future.2022.04.008.
(https://www.sciencedirect.com/science/article/pii/S0167739X22001315)
Abstract: Security vulnerabilities in software are the root cause of cyberattacks. Considering that these defects have huge associated costs, they should be proactively detected and resolved before shipping the software. Data-driven approaches like Artificial Intelligence (AI) are vastly explored for automatic vulnerability detection, given their potential to leverage large-scale vulnerability data feeds and learn from these scenarios. This work introduces a novel Proximal Instance Aggregator (PIA) neural network for accurately capturing insecure C code patterns from Abstract Syntax Tree (AST). It is built upon the concept of Multiple Instance Learning (MIL), which treats the AST representation of the code as a ‘bag’ of tree path ‘instances’. The security vulnerability can manifest in one or multiple such AST path instances. The PIA model dynamically learns a set of abstract concepts to describe the patterns associated with the AST paths. Specifically, the vulnerable nature of an AST path is characterized by its proximity to these concepts. The model also employs the attention mechanism to generate deep representations. By drawing cross-correlation of features between the path instances, the self-attention robustly weighs the relevance of each AST path towards vulnerability classification. The MIL utilizes these deep feature sets to construct the concept space. Thus, even without explicit supervision for localizing the line of defect, the AI automatically learns AST instance classification in a weakly supervised manner. Since AST-level prediction is formed as an aggregation of instance classifications, the AI is inherently explainable. The model outperforms state-of-the-art methods by a fair margin. It achieves 95.63% detection accuracy and 95.65% F1-score on the benchmarked NIST SARD, NVD datasets for a range of vulnerabilities.
Keywords: Multiple-Instance learning; Interpretability; Deep learning; Vulnerability detection; Abstract Syntax Tree; Weakly supervised learning

Wanqing Jie, Qi Chen, Jiaqi Wang, Arthur Sandor Voundi Koe, Jin Li, Pengfei Huang, Yaqi Wu, Yin Wang,
A novel extended multimodal AI framework towards vulnerability detection in smart contracts,
Information Sciences,
Volume 636,
2023,
118907,
ISSN 0020-0255,
https://doi.org/10.1016/j.ins.2023.03.132.
(https://www.sciencedirect.com/science/article/pii/S0020025523004565)
Abstract: Current automatic data-driven vulnerability detection in smart contracts selects and processes features of interest under black box settings without empirical justification. In this paper, we propose a smart contract testing methodology that bestows developers with flexible, practical and customizable strategies to detect vulnerabilities. Our work enforces strong whitebox knowledge to a series of supervised multimodal tasks under static analysis. Each task encapsulates a vulnerability detection branch test and pipelines feature selection, dimension unification, feature fusion, model training and decision-making. We exploit multiple features made up of code and graph embeddings at the single modality level (intramodal settings) and across individual modalities (intermodal settings). We assign each task to either intramodal or intermodal settings, and show how to train state-of-the-art self-attentive bi-LSTM, textCNN, and random forest (RF) models to extract a joint multimodal feature representation per task. We evaluate our framework over 101,082 functions extracted from the SmartEmbed dataset, and rank each multimodal vulnerability mining strategy in terms of detection performance. Extensive experiments show that our work outperforms existing schemes, and the highest performance reaches 99.71%.
Keywords: Smart contract; Vulnerability detection; Multimodal; AI approach; White box

Jinfu Chen, Chi Zhang, Saihua Cai, Lin Zhang, Liang Ma,
A memory-related vulnerability detection approach based on vulnerability model with Petri Net,
Journal of Logical and Algebraic Methods in Programming,
Volume 132,
2023,
100859,
ISSN 2352-2208,
https://doi.org/10.1016/j.jlamp.2023.100859.
(https://www.sciencedirect.com/science/article/pii/S2352220823000135)
Abstract: With the continuous development of information technology, software vulnerabilities have become a critical threat to information security. Post-release detection of memory leaks, double free and use after free is one of the most challenging research problems in software vulnerability analysis. To tackle this challenge, we introduce a vulnerability model based on Petri Net. We consider the characteristics and causes of vulnerabilities, modeling is conducted from the subject and environment of vulnerabilities. Based on this vulnerability model, we propose a memory-related vulnerability detection framework based on vulnerability model (MRVD-VM) and its vulnerability detection algorithm based on vulnerability mode (VDA-VM). The results of experiments on Juliet Test Suite 1.2 for C_CPP show that MRVD-VM significantly outperforms three state-of-the-art baseline tools, including Cppcheck, Flawfinder, and Splint, in detecting memory leaks, double free and use after free.
Keywords: Vulnerability model; Vulnerability detection; Memory leak; Double free; Use after free

Francesco Lomio, Emanuele Iannone, Andrea De Lucia, Fabio Palomba, Valentina Lenarduzzi,
Just-in-time software vulnerability detection: Are we there yet?,
Journal of Systems and Software,
Volume 188,
2022,
111283,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2022.111283.
(https://www.sciencedirect.com/science/article/pii/S0164121222000437)
Abstract: Background:
Software vulnerabilities are weaknesses in source code that might be exploited to cause harm or loss. Previous work has proposed a number of automated machine learning approaches to detect them. Most of these techniques work at release-level, meaning that they aim at predicting the files that will potentially be vulnerable in a future release. Yet, researchers have shown that a commit-level identification of source code issues might better fit the developer’s needs, speeding up their resolution.
Objective:
To investigate how currently available machine learning-based vulnerability detection mechanisms can support developers in the detection of vulnerabilities at commit-level.
Method:
We perform an empirical study where we consider nine projects accounting for 8991 commits and experiment with eight machine learners built using process, product, and textual metrics.
Results:
We point out three main findings: (1) basic machine learners rarely perform well; (2) the use of ensemble machine learning algorithms based on boosting can substantially improve the performance; and (3) the combination of more metrics does not necessarily improve the classification capabilities.
Conclusion:
Further research should focus on just-in-time vulnerability detection, especially with respect to the introduction of smart approaches for feature selection and training strategies.
Keywords: Software vulnerabilities; Machine learning; Empirical SE

Hieu Dinh Vo, Son Nguyen,
Can an old fashioned feature extraction and a light-weight model improve vulnerability type identification performance?,
Information and Software Technology,
Volume 164,
2023,
107304,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107304.
(https://www.sciencedirect.com/science/article/pii/S0950584923001581)
Abstract: Recent advances in automated vulnerability detection have achieved potential results in helping developers determine vulnerable components. However, after detecting vulnerabilities, investigating to fix vulnerable code is a non-trivial task. In fact, the types of vulnerability, such as buffer overflow or memory corruption, could help developers quickly understand the nature of the weaknesses and localize vulnerabilities for security analysis. In this work, we investigate the problem of vulnerability type identification (VTI). The problem is modeled as the multi-label classification task, which could be effectively addressed by “pre-training, then fine-tuning” framework with deep pre-trained embedding models. We evaluate the performance of the well-known and advanced pre-trained models for VTI on a large set of vulnerabilities. Surprisingly, their performance is not much better than that of the classical baseline approach with an old-fashioned bag-of-word, TF-IDF. Meanwhile, these deep neural network approaches cost much more resources and require GPU. We also introduce a lightweight independent component to refine the predictions of the baseline approach. Our idea is that the types of vulnerabilities could strongly correlate to certain code tokens (distinguishing tokens) in several crucial parts of programs. The distinguishing tokens for each vulnerability type are statistically identified based on their prevalence in the type versus the others. Our results show that the baseline approach enhanced by our component can outperform the state-of-the-art deep pre-trained approaches while retaining very high efficiency. Furthermore, the proposed component could also improve the neural network approaches by up to 92.8% in macro-average F1.
Keywords: Vulnerability type identification; Vulnerability resolution; Software vulnerability

Sicong Cao, Xiaobing Sun, Lili Bo, Ying Wei, Bin Li,
BGNN4VD: Constructing Bidirectional Graph Neural-Network for Vulnerability Detection,
Information and Software Technology,
Volume 136,
2021,
106576,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2021.106576.
(https://www.sciencedirect.com/science/article/pii/S0950584921000586)
Abstract: Context:
Previous studies have shown that existing deep learning-based approaches can significantly improve the performance of vulnerability detection. They represent code in various forms and mine vulnerability features with deep learning models. However, the differences of code representation forms and deep learning models make various approaches still have some limitations. In practice, their false-positive rate (FPR) and false-negative rate (FNR) are still high.
Objective:
To address the limitations of existing deep learning-based vulnerability detection approaches, we propose BGNN4VD (Bidirectional Graph Neural Network for Vulnerability Detection), a vulnerability detection approach by constructing a Bidirectional Graph Neural-Network (BGNN).
Method:
In Phase 1, we extract the syntax and semantic information of source code through abstract syntax tree (AST), control flow graph (CFG), and data flow graph (DFG). Then in Phase 2, we use vectorized source code as input to Bidirectional Graph Neural-Network (BGNN). In Phase 3, we learn the different features between vulnerable code and non-vulnerable code by introducing backward edges on the basis of traditional Graph Neural-Network (GNN). Finally in Phase 4, a Convolutional Neural-Network (CNN) is used to further extract features and detect vulnerabilities through a classifier.
Results:
We evaluate BGNN4VD on four popular C/C++ projects from NVD and GitHub, and compare it with four state-of-the-art (Flawfinder, RATS, SySeVR, and VUDDY) vulnerab ility detection approaches. Experiment results show that, when compared these baselines, BGNN4VD achieves 4.9%, 11.0%, and 8.4% improvement in F1-measure, accuracy and precision, respectively.
Conclusion:
The proposed BGNN4VD achieves a higher precision and accuracy than the state-of-the-art methods. In addition, when applied on the latest vulnerabilities reported by CVE, BGNN4VD can still achieve a precision at 45.1%, which demonstrates the feasibility of BGNN4VD in practical application.
Keywords: Vulnerability detection; Bidirectional Graph Neural-Network; Code representation

Clemens-Alexander Brust, Tim Sonnekalb, Bernd Gruner,
ROMEO: A binary vulnerability detection dataset for exploring Juliet through the lens of assembly language,
Computers & Security,
Volume 128,
2023,
103165,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103165.
(https://www.sciencedirect.com/science/article/pii/S0167404823000755)
Abstract: Context
Automatic vulnerability detection on C/C++ source code has benefitted from the introduction of machine learning to the field, with many recent publications targeting this combination. In contrast, assembly language or machine code artifacts receive less attention, although there are compelling reasons to study them. They are more representative of what is executed, more easily incorporated in dynamic analysis, and in the case of closed-source code, there is no alternative.
Objective
We evaluate the representative capability of assembly language compared to C/C++ source code for vulnerability detection. Furthermore, we investigate the role of call graph context in detecting function-spanning vulnerabilities. Finally, we verify whether compiling a benchmark dataset compromises an experiment’s soundness by inadvertently leaking label information.
Method
We propose ROMEO, a publicly available, reproducible and reusable binary vulnerability detection benchmark dataset derived from the synthetic Juliet test suite. Alongside, we introduce a simple text-based assembly language representation that includes context for function-spanning vulnerability detection and semantics to detect high-level vulnerabilities. It is constructed by disassembling the .text segment of the respective binaries.
Results
We evaluate an x86 assembly language representation of the compiled dataset, combined with an off-the-shelf classifier. It compares favorably to state-of-the-art methods, including those operating on the full C/C++ code. Including context information using the call graph improves detection of function-spanning vulnerabilities. There is no label information leaked during the compilation process.
Conclusion
Performing vulnerability detection on a compiled program instead of the source code is a worthwhile tradeoff. While certain information is lost, e.g., comments and certain identifiers, other valuable information is gained, e.g., about compiler optimizations.

Qianchong Zhao, Cheng Huang, Liuhu Dai,
VULDEFF: Vulnerability detection method based on function fingerprints and code differences,
Knowledge-Based Systems,
Volume 260,
2023,
110139,
ISSN 0950-7051,
https://doi.org/10.1016/j.knosys.2022.110139.
(https://www.sciencedirect.com/science/article/pii/S0950705122012357)
Abstract: The significant increase in Open Source Software has led to a sharp increase in code cloning vulnerabilities. Code similarity detection methods are usually used to detect these vulnerabilities. However, cloned code often modifies the original code to varying degrees, and the difference between vulnerable code and patch code can be very small. Traditional code similarity detection methods cannot effectively detect common mutation patterns in code cloning and distinguish vulnerable code from patch code. The paper proposes a vulnerability detection method named VULDEFF based on function fingerprints and code differences. This paper designs a lightweight function fingerprint method based on the Context Triggered Piecewise Hashing algorithm, which can characterize the basic syntax features of function source code. In particular, the fingerprint of the vulnerable function contains the syntax features, vulnerability features, and patch features of the vulnerable function. VULDEFF detects whether target function has vulnerabilities by searching target function fingerprint in the vulnerable function fingerprint library. Compared with five advanced software vulnerability detection tools, VULDEFF significantly reduces the false positive and false negative rates while ensuring the scalability of vulnerability detection. VULDEFF discovered 111 new vulnerabilities in 10 open source projects.
Keywords: Open source software; Vulnerability detection; Code similarity detection; Function fingerprint

Wei Zheng, Peiran Deng, Kui Gui, Xiaoxue Wu,
An Abstract Syntax Tree based static fuzzing mutation for vulnerability evolution analysis,
Information and Software Technology,
Volume 158,
2023,
107194,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107194.
(https://www.sciencedirect.com/science/article/pii/S0950584923000484)
Abstract: Context:
Zero-day vulnerabilities are highly destructive and sudden. However, traditional static and dynamic testing methods cannot efficiently detect them.
Objective:
In this paper, a static fuzzy mutation method for program code is studied. This method can improve the efficiency of mutation sample generation according to the vulnerability evolution law, thus promoting the development of zero-day vulnerability detection methods based on deep learning techniques.
Method:
A static fuzzy mutation method based on the Abstract Syntax Tree (AST) is proposed. Under the guidance of software vulnerability evolution law, potential evolution paths that threaten program security are detected, and mutation samples containing vulnerabilities are generated at the syntax tree level based on the paths. To verify the effectiveness of static fuzzy mutation based on ASTs, this paper starts with Concurrent Use After Free (CUAF) homologous vulnerability. It uses multi-threaded programs to perform vulnerability feature statement insertion processing to infer the optimal mutation operator execution sequence corresponding to CUAF vulnerabilities triggered by data competition. The Linux kernel code is used to verify whether it can effectively reduce the number of invalid mutation samples.
Results:
In this paper, we filter the code fragments in the Linux kernel public code containing CUAF vulnerability fix commits and perform static fuzzy mutation on the fix versions of the vulnerabilities to reproduce the vulnerabilities of this type triggered by these code fragments on the timeline. We compare the process with the execution of the random mutation operator in traditional detection methods horizontally and improve the efficiency by 42.4% on average.
Conclusion:
The static fuzzy mutation based on the AST is effective in stages. When this method is explored in more vulnerability-type evolution laws, it is expected to promote the development of the zero-day vulnerability active detection technology framework.
Keywords: Static fuzzy mutation; Abstract Syntax Tree; Potential evolution paths; Concurrent Use After Free; Multi-threaded programs

Zixian Zhen, Xiangfu Zhao, Jinkai Zhang, Yichen Wang, Haiyue Chen,
DA-GNN: A smart contract vulnerability detection method based on Dual Attention Graph Neural Network,
Computer Networks,
Volume 242,
2024,
110238,
ISSN 1389-1286,
https://doi.org/10.1016/j.comnet.2024.110238.
(https://www.sciencedirect.com/science/article/pii/S1389128624000707)
Abstract: A smart contract is an automated computer program based on blockchain technology. In recent years, the security incidents of smart contracts have caused serious economic losses. However, existing smart contract vulnerability detection methods rely on fixed expert rules, resulting in reduced detection accuracy and scalability. Therefore, addressing the issues of low accuracy in traditional smart contract vulnerability detection methods and the insufficient feature extraction in neural network-based approaches for smart contracts, this paper introduces an intelligent contract vulnerability identification method, Dual Attention Graph Neural Network (DA-GNN). Firstly, DA-GNN transforms the operation code sequence of nodes in the smart contract Control Flow Graph (CFG) into a feature matrix of semantic features and relationships between nodes based on the five types of instructions we propose. Secondly, our proposed dual attention mechanism introduces node semantic features and relationship features between nodes into the GAT to achieve node embedding updates. The updated graph node information is fused through self-attention mechanism to obtain the graph features. Then, the classification and prediction of vulnerabilities are achieved through the classification module. Finally, we evaluated our method on 17,670 real smart contracts. The experimental results show that the precision in detecting integer overflow vulnerabilities, self-destruct vulnerabilities, and transaction sequence dependency vulnerabilities reaches 72.17%, 67.03%, and 73.66%, respectively.
Keywords: Smart contract; Vulnerability detection; Graph neural networks; Attention mechanisms; Opcodes

Chunyong Zhang, Yang Xin,
Static vulnerability detection based on class separation,
Journal of Systems and Software,
Volume 206,
2023,
111832,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111832.
(https://www.sciencedirect.com/science/article/pii/S0164121223002273)
Abstract: Software vulnerability detection is a key step to prevent the system from being attacked. However, tens of thousands of codes have brought great challenges to engineers, so we urgently need an automatic and intelligent vulnerability detection method. The existing vulnerability detection model based on deep learning has the problem that it is difficult to separate the features of vulnerable and neutral code. Based on the code data drive, this paper proposes a static vulnerability detection method SDV(Statically Detecting Vulnerability) for C∖C++ programs. SDV is a function-level vulnerability code detection method. This paper uses a code property graph to represent the code and decouples the feature extractor and the classifier. In the graph feature extraction stage, we use Jump Graph Attention Network layers and convolutional pooling layers. Their combination can not only prevent the over-smoothing problem but also separate the sample classes deeply. Finally, on the chrdeb dataset, SDV outperforms state-of-the-art function-level vulnerability detection methods by 52.3%, 15.9%, and 39.6% in Precision, Recall, and F1-Score, respectively. On the real project sard, the number of vulnerabilities detected by SDV is 10.7 times more than Reveal.
Keywords: Vulnerability detection; Code property graph; Jump structure; Graph attention network; Class separation

Huijiang Liu, Shuirou Jiang, Xuexin Qi, Yang Qu, Hui Li, Tingting Li, Cheng Guo, Shikai Guo,
Detect software vulnerabilities with weight biases via graph neural networks,
Expert Systems with Applications,
Volume 238, Part B,
2024,
121764,
ISSN 0957-4174,
https://doi.org/10.1016/j.eswa.2023.121764.
(https://www.sciencedirect.com/science/article/pii/S0957417423022662)
Abstract: Code vulnerabilities are common in software systems and may cause many problems, including Stack Overflow, memory leaks, and so on. Public reports show that code vulnerabilities are increasing year by year, which brings greater threats to the security of software systems. Thus a variety of neural network models have been developed to detect code vulnerabilities. However, the previous neural network models cannot fully express the semantics and structure of the code with as little overhead as possible, and they also cannot enhance learning of difficult samples. Addressing to this issue, we designed a model built upon GGNN for Detecting Software Vulnerabilities (GDSV), which contains three components. Specifically, Graph Embedding component extracts the semantic and structural features, and generates a graph representation of the code; GGNN component learns these features and detects vulnerabilities in the code; weighted component improves the learning ability of Vulnerable samples through the Focal Loss function. A serial of experiments on the datasets of FFmpeg and QEMU were conducted, and the results show that GDSV performs better than the state-of-the-art efforts based on various widely used evaluations.
Keywords: Software vulnerabilities; Weight biases; Gated Graph Neural Network

Zhonglin Liu, Yong Fang, Cheng Huang, Yijia Xu,
MFXSS: An effective XSS vulnerability detection method in JavaScript based on multi-feature model,
Computers & Security,
Volume 124,
2023,
103015,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.103015.
(https://www.sciencedirect.com/science/article/pii/S0167404822004072)
Abstract: The widespread use of web applications has also made them more vulnerable to hackers, resulting in the leakage of large amounts of application and personal privacy data. Cross-site scripting (XSS) attacks are one of the most significant threats to web applications. Attackers can inject scripts to control the victim’s browser to send data or execute commands, leading to the theft of privacy or the hijacking of login tokens. Therefore, we proposed a multi-feature fusion-based neural network vulnerability detection model for detecting XSS vulnerabilities in the JavaScript source code of websites (We termed our implementation of this approach MFXSS). We combine abstract syntax tree (AST) and code control flow graph (CFG) to convert the generalized sample data into graph structure and code string structure. Then, through the graph convolutional neural network, weighted aggregation, and the bidirectional recurrent neural network, the logical call features and the context execution relationship features of the source code are extracted and fused respectively. Finally, the fused feature vectors are used to detect and predict XSS vulnerabilities in JavaScript. In the experiment, we designed multiple control experiments to verify that the model construction is optimal, and the accuracy rates in the standard and variant datasets are 0.997 and 0.986. Moreover, in comparing similar detection schemes, MFXSS also performs better. Applying the model to an actual web environment, we successfully detected the presence of XSS vulnerabilities in websites.
Keywords: Cross-site scripting; Multi-feature fusion; Graph convolutional network; Weighted aggregation; Vulnerability detection

Weina Niu, Xiaosong Zhang, Xiaojiang Du, Lingyuan Zhao, Rong Cao, Mohsen Guizani,
A deep learning based static taint analysis approach for IoT software vulnerability location,
Measurement,
Volume 152,
2020,
107139,
ISSN 0263-2241,
https://doi.org/10.1016/j.measurement.2019.107139.
(https://www.sciencedirect.com/science/article/pii/S026322411931005X)
Abstract: Computer system vulnerabilities, computer viruses, and cyber attacks are rooted in software vulnerabilities. Reducing software defects, improving software reliability and security are urgent problems in the development of software. The core content is the discovery and location of software vulnerability. However, traditional human experts-based approaches are labor-consuming and time-consuming. Thus, some automatic detection approaches are proposed to solve the problem. But, they have a high false negative rate. In this paper, a deep learning based static taint analysis approach is proposed to automatically locate Internet of Things (IoT) software vulnerability, which can relieve tedious manual analysis and improve detection accuracy. Deep learning is used to detect vulnerability since it considers the program context. Firstly, the taint from the difference file between the source program and its patched program selection rules are designed. Secondly, the taint propagation paths are got using static taint analysis. Finally, the detection model based on two-stage Bidirectional Long Short Term Memory (BLSTM) is applied to discover and locate software vulnerabilities. The Code Gadget Database is used to evaluate the proposed approach, which includes two types of vulnerabilities in C/C++ programs, buffer error vulnerability (CWE-119) and resource management error vulnerability (CWE-399). Experimental results show that our proposed approach can achieve an accuracy of 0.9732 for CWE-119 and 0.9721 for CWE-399, which is higher than that of the other three models (the accuracy of RNN, LSTM, and BLSTM is under than 0.97) and achieve a lower false negative rate and false positive rate than the other approaches.
Keywords: IoT software vulnerability location; Deep learning; Software patching; Static taint analysis

Xiaobing Sun, Liangqiong Tu, Jiale Zhang, Jie Cai, Bin Li, Yu Wang,
ASSBert: Active and semi-supervised bert for smart contract vulnerability detection,
Journal of Information Security and Applications,
Volume 73,
2023,
103423,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2023.103423.
(https://www.sciencedirect.com/science/article/pii/S221421262300008X)
Abstract: With the popularity of blockchain, the amount of smart contracts has increased very fast, and the safety of smart contracts has come to more extensive notice. Recently, machine learning technology has been widely applied in vulnerability detection for smart contracts. However, it implements effective smart contract vulnerability detection still faces a major challenge, that is, there is a problem of insufficient labeled data in the current field. Active learning can label data more efficiently. Nevertheless, classical active learning only uses limited labeled data for model training, contrary to the deep learning of a large amount of data required for model training. Because of the above, we provide a new framework, called ASSBert, that leverages active and semi-supervised bidirectional encoder representation from transformers network, which is dedicated to completing the task of smart contract vulnerability classification with a little amount of labeled code data and a large number of unlabeled code data. In our framework, active learning is responsible for selecting highly uncertain code data from unlabeled sol files and putting them into the training set after manual labeling. Besides, semi-supervised learning is charged to continuously pick a certain number of high-confidence unlabeled code data from unlabeled sol files, and put them into the training dataset behind pseudo-labeling. Intuitively, by combining active learning and semi-supervised learning, we are able to get more valuable data to increase the performance of our detection model. In our experiments, we collect our benchmark dataset included 6 vulnerabilities in about 20829 smart contracts. The result of the experiment demonstrates that our framework is superior to the baseline methods with a little amount of labeled code data and a large number of unlabeled code data.
Keywords: Smart contract; Vulnerability detection; Active learning; Semi-supervised learning

Chunyong Zhang, Tianxiang Yu, Bin Liu, Yang Xin,
Vulnerability detection based on federated learning,
Information and Software Technology,
Volume 167,
2024,
107371,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107371.
(https://www.sciencedirect.com/science/article/pii/S0950584923002264)
Abstract: Context:
Detecting potential vulnerabilities is a key step in defending against network attacks. However, manual detection is time-consuming and requires expertise. Therefore, vulnerability detection must require automated techniques.
Objective:
Vulnerability detection methods based on deep learning need to rely on sufficient vulnerable code samples. However, the problem of code islands has not been extensively researched. For example, in the case of multi-party vulnerability data, how to securely combine multi-party data to improve vulnerability detection performance. From the perspectives of data augmentation and data security, we propose a vulnerability detection framework based on federated learning (VDBFL). VDBFL is a new model for vulnerability code detection that combines multi-party data.
Method:
Firstly, VDBFL utilizes the code property graph as a code representation. The code property graph contains various semantic dependencies of the code. Secondly, VDBFL utilizes graph neural networks and convolutional neural networks as the code feature extractor. VDBFL utilizes the jump-structured graph attention network to aggregate node information of important neighbors. Finally, VDBFL utilizes horizontal federated learning to train a local vulnerability detection model for the client.
Result:
In the real world, VDBFL improves F1-Score by 37.4% compared to the vulnerability detection method Reveal. Among the 5401 vulnerability samples, VDBFL detected 11.8 times more vulnerabilities than Reveal.
Conclusion:
Under different datasets, VDBFL has shown better performance than advanced vulnerability detection methods in multiple metrics. In addition, the federated learning stage of VDBFL can be expanded on top of the feature extraction stage of any vulnerable detection method.
Keywords: Vulnerability detection; Code property graph; Graph neural network; Horizontal federated learning; Data security

Hao Sun, Lei Cui, Lun Li, Zhenquan Ding, Siyuan Li, Zhiyu Hao, Hongsong Zhu,
VDTriplet: Vulnerability detection with graph semantics using triplet model,
Computers & Security,
Volume 139,
2024,
103732,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103732.
(https://www.sciencedirect.com/science/article/pii/S0167404824000336)
Abstract: This study presents VDTriplet, a novel learning framework for building vulnerability detection models. VDTriplet is the first attempt using deep learning to avoid the potential known vulnerability function misjudgment due to the small difference between vulnerability and its fixed vulnerability function. Unlike prior work that treats the program as sequential tokens or randomly initialized graphs for supervised binary classification detection tasks, our model not only fuses rich syntactic and semantic information to obtain the most accurate program representation, but also utilizes the TripletNN model to reduce misjudgment of potential known vulnerabilities. VDTriplet first extracts the subgraphs that causes the vulnerability through the typical programming errors to reduce redundant code. Then, it uses the pre-trained model and unsupervised model for the graph encoding of subgraphs, thereby minimizing the influence of randomly initialized graph nodes and avoiding the need for supervised labeling. Finally, TripletNN model minimizes the distance between potential vulnerabilities and vulnerabilities with the same vulnerability type, and maximizes the distance between potential vulnerabilities and fixed vulnerabilities to reduce false positives. The results show that the performance of VDTriplet is significantly better than the studied baselines. Compared with the best performing model in the literature, our model achieves a total of 4.89%, 4.23%, 4.56% and 5.34% improvement in Accuracy, Precision, Recall and F1-Score in the test results respectively. Moreover, it exhibits well generalization in detecting new eight applications, demonstrating that it is potentially valuable in practical usage. Overall, this is indeed an outstanding improvement.
Keywords: Vulnerability detection; Deep learning; Extracting subgraphs; Encoding subgraphs; TripletNN model

Guilong Lu, Xiaolin Ju, Xiang Chen, Wenlong Pei, Zhilong Cai,
GRACE: Empowering LLM-based software vulnerability detection with graph structure and in-context learning,
Journal of Systems and Software,
Volume 212,
2024,
112031,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2024.112031.
(https://www.sciencedirect.com/science/article/pii/S0164121224000748)
Abstract: Software vulnerabilities inflict considerable economic and societal harm. Therefore, timely and accurate detection of these flaws has become vital. Large language models (LLMs) have emerged as a promising tool for vulnerability detection in recent studies. However, their effectiveness suffers when limited to plain text source code, which may ignore the syntactic and semantic information of the code. To address this limitation, we propose a novel vulnerability detection approach GRACE that empowers LLM-based software vulnerability detection by incorporating graph structural information in the code and in-context learning. We also design an effective demonstration retrieval approach that identifies highly relevant code examples by considering semantic, lexical, and syntactic similarities for the target code to provide better demonstrations for in-context learning. To evaluate the effectiveness of GRACE, we conducted an empirical study on three vulnerability detection datasets (i.e., Devign, Reveal, and Big-Vul). The results demonstrate that GRACE outperforms six state-of-the-art vulnerability detection baselines by at least 28.65% in terms of the F1 score across these three datasets. Therefore, our study highlights the effectiveness of integrating graph structural information and in-context learning in LLMs for vulnerability detection. These findings motivate further investigation into tailoring such approaches for specific vulnerability types or adapting them to other security tasks.
Keywords: Vulnerability detection; Large language model; In-context learning; Source code representation; Graph structure

M. Naghavi, K. Gul, T. O’Brien, S. Siadaty, M. Madjid, R.M. Mohammadi, T. Tewatia, J.T. Willerson, W. Casscells,
SAI-15: Coronary thermosensor basket catheter with thermographic imaging software for thermal detection of vulnerable atherosclerotic plaques,
The American Journal of Cardiology,
Volume 88, Issue 2, Supplement 1,
2001,
Pages 80-81,
ISSN 0002-9149,
https://doi.org/10.1016/S0002-9149(01)01770-2.
(https://www.sciencedirect.com/science/article/pii/S0002914901017702)

Cristina Cifuentes, François Gauthier, Behnaz Hassanshahi, Padmanabhan Krishnan, Davin McCall,
The role of program analysis in security vulnerability detection: Then and now,
Computers & Security,
Volume 135,
2023,
103463,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103463.
(https://www.sciencedirect.com/science/article/pii/S0167404823003735)
Abstract: Program analysis techniques play an important role in detecting security vulnerabilities. In this paper we describe our experiences in developing a variety of tools that detect security vulnerabilities in an industrial setting. The main driving forces for adoption of program analysis tools by a development organisation are low false positive rate, ease of integration in the developer's workflow, scalability to handle industrial size systems and results that are easy to understand. Even if one the above dimensions is not supported, the tool will not be used in practice. We show how the analyses of program analysis tools have changed over more than a decade due to differences in languages, e.g., code written in systems-level languages like C tend to focus on memory-related vulnerabilities, in contrast to languages like Java, JavaScript and Python where the focus is more on injection vulnerabilities in web or cloud applications. Based on language, static or dynamic analysis approaches are needed, including hybrid approaches. We conclude with our vision on Intelligent Application Security – how program analysis tools will keep changing to enable the DevSecOps model given the fertile ground that the DevOps model provides today. We foresee different program analysis tools working together by sharing information, including the results they produce, while addressing newer security issues such as those related to supply chain issues. In this way, program analysis tools would be extended with relevant machine learning techniques and be integrated in all different phases of the code development, building, testing, deployment and monitoring cycle.
Keywords: Static analysis; Dynamic analysis; Industrial scale application; DevOps

Fredrik Heiding, Sotirios Katsikeas, Robert Lagerström,
Research communities in cyber security vulnerability assessments: A comprehensive literature review,
Computer Science Review,
Volume 48,
2023,
100551,
ISSN 1574-0137,
https://doi.org/10.1016/j.cosrev.2023.100551.
(https://www.sciencedirect.com/science/article/pii/S1574013723000187)
Abstract: Ethical hacking and vulnerability assessments are gaining rapid momentum as academic fields of study. Still, it is sometimes unclear what research areas are included in the categories and how they fit into the traditional academic framework. Previous studies have reviewed literature in the field, but the attempts use manual analysis and thus fail to provide a comprehensive view of the domain. To better understand how the area is treated within academia, 537,629 related articles from the Scopus database were analyzed. A Python script was used for data mining as well as analysis of the data, and 23,459 articles were included in the final synthesis. The publication dates of the articles ranged from 1975 to 2022. They were authored by 53,495 authors and produced an aggregated total of 836,956 citations. Fifteen research communities were detected using the Louvain community detection algorithm: (smart grids, attack graphs, security testing, software vulnerabilities, Internet of Things (IoT), network vulnerability, vulnerability analysis, Android, cascading failures, authentication, Software-Defined Networking (SDN), spoofing attacks, malware, trust models, and red teaming). In addition, each community had several individual subcommunities, constituting a total of 126. From the trends of the analyzed studies, it is clear that research interest in ethical hacking and vulnerability assessment is increasing.
Keywords: Systematic literature review; SLR; Vulnerability assessment; Ethical hacking; Cybersecurity; Scopus; Penetration testing

Daogui Tang, Yi-Ping Fang, Enrico Zio,
Vulnerability analysis of demand-response with renewable energy integration in smart grids to cyber attacks and online detection methods,
Reliability Engineering & System Safety,
Volume 235,
2023,
109212,
ISSN 0951-8320,
https://doi.org/10.1016/j.ress.2023.109212.
(https://www.sciencedirect.com/science/article/pii/S0951832023001278)
Abstract: The two-way information exchange between customers and the utility in smart grids enables demand-response programs of customers and the integration of distributed renewable energy resources. However, this also makes the demand-response programs vulnerable to cyber attacks. In this paper, we study cyber attacks that target customers’ demand-response programs in smart grids by injecting false consumption and generation information. Then, as a countermeasure, an online detector based on convolutional neural networks is designed to detect the cyber attacks and mitigate impacts. The vulnerability of power distribution systems with and without the proposed detector is analyzed with reference to a case study concerning the IEEE 34 bus test feeder. The results show that the power distribution systems is vulnerable to the studied cyber attack and the proposed detector can achieve high accuracy and mitigate the impact of cyber attacks with fixed change rates, whereas the attacks with variable change rates are inherently challenging to detect.
Keywords: Smart grids; Distributed renewable energy resources; Demand-response; Cyber attacks detector; Convolutional neural network

Dazhi Zhang, Donggang Liu, Christoph Csallner, David Kung, Yu Lei,
A distributed framework for demand-driven software vulnerability detection,
Journal of Systems and Software,
Volume 87,
2014,
Pages 60-73,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2013.08.033.
(https://www.sciencedirect.com/science/article/pii/S0164121213002288)
Abstract: Security testing aims at detecting program security flaws through a set of test cases and has become an active area of research. The challenge is how to efficiently produce test cases that are highly effective in detecting security flaws. This paper presents a novel distributed demand-driven security testing system to address this challenge. It leverages how end users use the software to increase the coverage of essential paths for security testing. The proposed system consists of many client sites and one testing site. The software under test is installed at each client site. Whenever a new path is about to be exercised by a user input, it will be sent to the testing site for security testing. At the testing site, symbolic execution is used to check any potential vulnerability on this new path. If a vulnerability is detected, a signature is automatically generated and updated to all client sites for protection. The benefits are as follows. First, it allows us to focus testing on essential paths, i.e., the paths that are actually being explored by users or attackers. Second, it stops an attacker from exploiting an unreported vulnerability at the client site. A prototype system has been implemented to evaluate the performance of the proposed system. The results show that it is both effective and efficient in practice.
Keywords: Software vulnerability; Security testing; Test decomposition

Yukun Dong, Yeer Tang, Xiaotong Cheng, Yufei Yang,
DeKeDVer: A deep learning-based multi-type software vulnerability classification framework using vulnerability description and source code,
Information and Software Technology,
Volume 163,
2023,
107290,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107290.
(https://www.sciencedirect.com/science/article/pii/S0950584923001441)
Abstract: Context:
Software vulnerabilities have confused software developers for a long time. Vulnerability classification is thus crucial, through which we can know the specific type of vulnerability and then conduct targeted repair. Stack of papers have looked into deep learning-based multi-type vulnerability classification, among which most are based on vulnerability descriptions and some are based on source code. While vulnerability descriptions can sometimes mislead vulnerability classification and source code-based approaches have been rarely explored in multi-type vulnerability classification.
Objective:
We design DeKeDVer (Vulnerability Descriptions and Key Domain based Vulnerability Classifier) with two objectives: (i) to extract more useful information from vulnerability descriptions; (ii) to better utilize the information source code can reflect.
Method:
In this work, we propose a multi-type vulnerability classifier which combine vulnerability descriptions and source code together. We process vulnerability descriptions and source code of each project separately. For the vulnerability description of a sample, we preprocess it using a specified way we design based on our observations on numerous descriptions and then select text features. After that, Text Recurrent Convolutional Neural Network (TextRCNN) is applied to learn text information. For source code, we leverage its Code Property Graph (CPG) and extract key domain from it which are then embedded. Acquired feature vectors are then fed into Relational Graph Attention Network (RGAT). Result vectors gained from TextRCNN and RGAT are combined together as the feature vector of the current sample. A Multi-Layer Perceptron (MLP) layer is further added to undertake classification.
Results:
We conduct our experiments on C/C++ projects from NVD. Experimental results show that our work achieves 84.49% in weighted F1-measure which proves our work to be more effective.
Conclusion:
Our work utilizes information reflected both from vulnerability descriptions and source code to facilitate vulnerability classification and achieves higher weighted F1-measure than existing vulnerability classification tools.
Keywords: Multi-type vulnerability classification; Vulnerability description; Source code; Text Recurrent Convolutional Neural Network; Relational graph attention network

Junfeng Tian, Wenjing Xing, Zhen Li,
BVDetector: A program slice-based binary code vulnerability intelligent detection system,
Information and Software Technology,
Volume 123,
2020,
106289,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2020.106289.
(https://www.sciencedirect.com/science/article/pii/S0950584920300392)
Abstract: Context
Software vulnerability detection is essential to ensure cybersecurity. Currently, most software is published in binary form, thus researchers can only detect vulnerabilities in these software by analysing binary programs. Although existing research approaches have made a substantial contribution to binary vulnerability detection, there are still many deficiencies, such as high false positive rate, detection with coarse granularity, and dependence on expert experience.
Objective
The goal of this study is to perform fine-grained intelligent detection on the vulnerabilities in binary programs. This leads us to propose a fine-grained representation of binary programs and introduce deep learning techniques to intelligently detect the vulnerabilities.
Method
We use program slices of library/API function calls to represent binary programs. Additionally, we design and construct a Binary Gated Recurrent Unit (BGRU) network model to intelligently learn vulnerability patterns and automatically detect vulnerabilities in binary programs.
Results
This approach yields the design and implementation of a program slice-based binary code vulnerability intelligent detection system called BVDetector. We show that BVDetector can effectively detect vulnerabilities related to library/API function calls in binary programs, which reduces the false positive rate and false negative rate of vulnerability detection.
Conclusion
This paper proposes a program slice-based binary code vulnerability intelligent detection system called BVDetector. The experimental results show that BVDetector can effectively reduce the false negative rate and false positive rate of binary vulnerability detection.
Keywords: Binary program; Vulnerability detection; Deep learning; Program slice; Library/API function call

Jinfu Chen, Weijia Wang, Bo Liu, Saihua Cai, Dave Towey, Shengran Wang,
Hybrid semantics-based vulnerability detection incorporating a Temporal Convolutional Network and Self-attention Mechanism,
Information and Software Technology,
Volume 171,
2024,
107453,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2024.107453.
(https://www.sciencedirect.com/science/article/pii/S0950584924000582)
Abstract: Context:
Desirable characteristics in vulnerability-detection (VD) systems (VDSs) include both good detection capability (high accuracy, low false positive rate, low false negative rate, etc.) and low time overheads. The widely used VDSs based on models such as Recurrent Neural Networks (RNNs) have some problems, such as low time efficiency, failing to learn the vulnerability features better, and insufficient amounts of vulnerability features. Therefore, it is very important to construct an automatic detection model with high detection accuracy.
Objective:
This paper reports on training based on the source code to analyze and learn from the code’s patterns and structures by deep-learning techniques to generate an efficient VD model that does not require manual feature design.
Method:
We propose a software VD model based on multi-feature fusion and deep neural networks called AIdetectorX-SP. It first uses a Temporal Convolutional Network (TCN) and adds a Self-attention Mechanism (SaM) to the TCN to build a model for extracting vulnerability logic features, then transforms the source code into an image input to a Convolutional Neural Network (CNN) to extract structural and semantic information. Finally, we use feature-fusion technology to design and implement an improved deep-learning-based VDS, called AIdetectorX Sequence with Picturization (AIdetectorX-SP).
Results:
We report on experiments conducted using publicly-available and widely-used datasets to evaluate the effectiveness of AIdetectorX-SP, with results indicating that AIdetectorX-SP is an effective VDS; that the combination of TCN and SaM can effectively extract vulnerability logic features; and that the pictorial code can extract code structure features, which can further improve the VD capability.
Conclusion:
In this paper, we propose a novel detection model for software vulnerability based on TCNs, SaM, and software picturization. The proposed model solves some shortcomings and limitations of existing VDSs, and obtains a high software-VD accuracy with a high degree of stability.
Keywords: Deep learning; Software vulnerability detection; Temporal Convolutional Network; Self-attention Mechanism; Source-code picturization; Feature fusion

Hanting Chu, Pengcheng Zhang, Hai Dong, Yan Xiao, Shunhui Ji, Wenrui Li,
A survey on smart contract vulnerabilities: Data sources, detection and repair,
Information and Software Technology,
Volume 159,
2023,
107221,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107221.
(https://www.sciencedirect.com/science/article/pii/S0950584923000757)
Abstract: Smart contracts contain many built-in security features, such as non-immutability once being deployed and non-involvement of third parties for contract execution. These features reduce security risks and enhance users’ trust towards smart contracts. However, smart contract security issues still persist, resulting in huge financial losses. Contract publishers cannot fully cover contract vulnerabilities through contract version updating. These security issues affect further development of blockchain technologies. So far, there are many related studies focusing on smart contract security issues and tend to discuss from a particular perspective (e.g., development cycle, vulnerability attack methods, security detection tools, etc.). However, smart contract security is a complicated issue that needs to be explored from a multi-dimensional perspective. In this paper, we explore smart contract security from the perspectives of vulnerability data sources, vulnerability detection, and vulnerability defense. We first analyze the existing security issues and challenges of smart contracts, investigate the existing vulnerability classification frameworks and common security vulnerabilities, followed by reviewing the existing contract vulnerability injection, detection, and repair methods. We then analyze the performance of existing security methods. Next, we summarize the current status of smart contract security-related research. Finally, we summarize the state of the art and future trends of smart contract security-related research. This paper aims to provide systematic knowledge and references to this research field.
Keywords: Blockchains; Smart contracts; Vulnerability detection; Vulnerability repair; Information security

C. Thyagarajan, S. Vijay Bhanu, S. Suthir,
A secure network path of implantable medical devices for detecting the vulnerabilities using hybrid DBNF network,
Biomedical Signal Processing and Control,
Volume 92,
2024,
105968,
ISSN 1746-8094,
https://doi.org/10.1016/j.bspc.2024.105968.
(https://www.sciencedirect.com/science/article/pii/S1746809424000260)
Abstract: IoT is complicated as it contains a huge number of devices which saves data and promotes functionality of each device. Generally, such models include real-time functioning as it is a strong hurdle to specific corporal processes. Instantaneous functioning is threatened due to security issues which are forwarded to alleviate the emerging attacks in IoT. The aim is to develop a vulnerability detection framework using a hybrid deep model by adding regression functionality. Initially, the information from the target host and network is collected in real-time. The vulnerability detection technology actively explores the target host and network host for collecting the related information and the status of working and accumulates information about the network in real-time. The information model obtains the feedback through the target host and compares it using data contained in the vulnerability dataset and if it matches then it concludes that the target model poses a security hole else the model sends suggestions regarding disposal. Here, the vulnerability detection is based on the Deep belief cascade-neuro fuzzy (DBNF) network, which is an amalgamation of deep belief network (DBN) and cascade Neuro–fuzzy network, where the regression layer is added. The DBNF outperformed with a better accuracy of 90.8%, sensitivity of 94.7%, specificity of 92.7%, and F-measure of 93.7%.
Keywords: Vulnerability detection; Deep learning; Internet of Things; Intelligent early warning; Security; Deep belief cascade-neuro fuzzy network; Deep belief network

Wenbo Guo, Yong Fang, Cheng Huang, Haoran Ou, Chun Lin, Yongyan Guo,
HyVulDect: A hybrid semantic vulnerability mining system based on graph neural network,
Computers & Security,
Volume 121,
2022,
102823,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.102823.
(https://www.sciencedirect.com/science/article/pii/S0167404822002176)
Abstract: In recent years, software programs tend to be large and complex, software has become the infrastructure of modern society, but software security issues can not be ignored. software vulnerabilities have become one of the main threats to computer security. There are countless cases of exploiting source code vulnerabilities to launch attacks. At the same time, the development of open source software has made source code vulnerability detection more and more critical. Traditional vulnerability mining methods have been unable to meet the security analysis needs of complex software because of the high false-positive rate and false-negative rate. To resolve the existing problems, we propose a graph neural network vulnerability mining system named HyVulDect based on hybrid semantics, which constructs a composite semantic code property graph for code representation based on the causes of vulnerabilities. A gated graph neural network is used to extract deep semantic information. Since most of the vulnerabilities are data flow associated, we use taint analysis to extract the taint propagation chain, use the BiLSTM model to extract the token-level features of the context, and finally use the classifier to classify the fusion features. We introduce a dual-attention mechanism that allows the model to focus on vulnerability-related code, making it more suitable for vulnerability mining tasks. The experimental results show that HyVulDect outperforms existing state-of-the-art methods and can achieve an accuracy rate of 92% on the benchmark dataset. Compared with the rule-based static mining tools Flawfinder, RATS, and Cppcheck, it has better performance and can effectively detect the actual CVE source code vulnerabilities.
Keywords: Program analysis; Vulnerability mining; Graph neural network; Taint analysis; Code representation,

Wei Zheng, Jialiang Gao, Xiaoxue Wu, Fengyu Liu, Yuxing Xun, Guoliang Liu, Xiang Chen,
The impact factors on the performance of machine learning-based vulnerability detection: A comparative study,
Journal of Systems and Software,
Volume 168,
2020,
110659,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2020.110659.
(https://www.sciencedirect.com/science/article/pii/S0164121220301229)
Abstract: Machine learning-based Vulnerability detection is an active research topic in software security. Different traditional machine learning-based and deep learning-based vulnerability detection methods have been proposed. To our best knowledge, we are the first to identify four impact factors and conduct a comparative study to investigate the performance influence of these factors. In particular, the quality of datasets, classification models and vectorization methods can directly affect the detection performance, in contrast function/variable name replacement can affect the features of vulnerability detection and indirectly affect the performance. We collect three different vulnerability code datasets from two various sources (i.e., NVD and SARD). These datasets can correspond to different types of vulnerabilities. Moreover, we extract and analyze the features of vulnerability code datasets to explain some experimental results. Our findings based on the experimental results can be summarized as follows: (1) Deep learning models can achieve better performance than traditional machine learning models. Of all the models, BLSTM can achieve the best performance. (2) CountVectorizer can significantly improve the performance of traditional machine learning models. (3) Features generated by the random forest algorithm include system-related functions, syntax keywords, and user-defined names. Different vulnerability types and code sources will generate different features. (4) Datasets with user-defined variable and function name replacement will decrease the performance of vulnerability detection. (5) As the proportion of code from SARD increases, the performance of vulnerability detection will increase.
Keywords: Vulnerability detection; Machine learning; Comparative study; Deep learning; Feature extraction

Maoyuan Qin, Jiacheng Zhu, Baolei Mao, Wei Hu,
Hardware/software security co-verification and vulnerability detection: An information flow perspective,
Integration,
Volume 94,
2024,
102089,
ISSN 0167-9260,
https://doi.org/10.1016/j.vlsi.2023.102089.
(https://www.sciencedirect.com/science/article/pii/S0167926023001311)
Abstract: Security vulnerabilities provide attackers unauthorized access to critical resources and effective attack surfaces to compromise a system. Security verification is an emerging technique for detecting and locating such threats. However, existing security verification methods are typically restricted within the hardware or software boundary and incapable of meeting cross-layer verification requirements due to the differences in design semantics and the lack of a security model that fits both hardware and software. We attempt to address such a limitation from the perspective of information flow analysis and propose a hardware/software security co-verification method, which can check information flow security properties on fine-grained hardware information flow models. The proposed method can pinpoint security vulnerabilities by capturing information flow security property violations under clues of malicious information flows. Our information flow security model and properties are described using standard hardware design and verification languages, which allows our method to be seamlessly integrated with electronics design automation flows. Experimental results using RISC-V hardware/software designs show that the proposed method detects software, hardware and system-level security vulnerabilities, effectively.
Keywords: Hardware and software security co-verification; Information flow security; Security model; Security property; Vulnerability detection

Melanie Ehrenberg, Shahram Sarkani, Thomas A. Mazzuchi,
Python source code vulnerability detection with named entity recognition,
Computers & Security,
Volume 140,
2024,
103802,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103802.
(https://www.sciencedirect.com/science/article/pii/S0167404824001032)
Abstract: Vulnerabilities within source code have grown over the last 20 years to become a common threat to systems and networks. As the implementation of open-source software continues to develop, more unknown vulnerabilities will exist throughout system networks. This research proposes an enhanced vulnerability detection method specific to Python source code that utilizes pre-trained, BERT-based transformer models to apply tokenization, embedding, and named entity recognition (a natural language processing technique). The use of named entity recognition not only allows for the detection of potential vulnerabilities, but also for the classification of different vulnerability types. This research uses the publicly available CodeBERT, RoBERTa, and DistilBERT models to fine-tune for the downstream task of token classification for six different common weakness enumeration specifications. The results achieved in this research outperform previous Python-based vulnerability detection methods and demonstrate the effectiveness of applying named entity recognition to enhance the overall research into Python source code vulnerabilities.
Keywords: Vulnerability detection; Natural language processing; Machine learning; Named entity recognition; Transformer; Python; BERT; Programming language; Common weakness enumeration; CWE

Anjana Wijekoon, Nirmalie Wiratunga,
A user-centred evaluation of DisCERN: Discovering counterfactuals for code vulnerability detection and correction,
Knowledge-Based Systems,
Volume 278,
2023,
110830,
ISSN 0950-7051,
https://doi.org/10.1016/j.knosys.2023.110830.
(https://www.sciencedirect.com/science/article/pii/S0950705123005804)
Abstract: Counterfactual explanations highlight actionable knowledge which helps to understand how a machine learning model outcome could be altered to a more favourable outcome. Understanding actionable corrections in source code analysis can be critical to proactively mitigate security attacks that are caused by known vulnerabilities. In this paper, we present the DisCERN explainer for discovering counterfactuals for code vulnerability correction. Given a vulnerable code segment, DisCERN finds counterfactual (i.e. non-vulnerable) code segments and recommends actionable corrections. DisCERN uses feature attribution knowledge to identify potentially vulnerable code statements. Subsequently, it applies a substitution-focused correction, suggesting suitable fixes by analysing the nearest-unlike neighbour. Overall, DisCERN aims to identify vulnerabilities and correct them while preserving both the code syntax and the original functionality of the code. A user study evaluated the utility of counterfactuals for vulnerability detection and correction compared to more commonly used feature attribution explainers. The study revealed that counterfactuals foster positive shifts in mental models, effectively guiding users towards making vulnerability corrections. Furthermore, counterfactuals significantly reduced the cognitive load when detecting and correcting vulnerabilities in complex code segments. Despite these benefits, the user study showed that feature attribution explanations are still more widely accepted than counterfactuals, possibly due to the greater familiarity with the former and the novelty of the latter. These findings encourage further research and development into counterfactual explanations, as they demonstrate the potential for acceptability over time among developers as a reliable resource for both coding and training.
Keywords: Counterfactual explanations; Vulnerability detection; Explainable AI

Yiran Cheng, Shouguo Yang, Zhe Lang, Zhiqiang Shi, Limin Sun,
VERI: A Large-scale Open-Source Components Vulnerability Detection in IoT Firmware,
Computers & Security,
Volume 126,
2023,
103068,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.103068.
(https://www.sciencedirect.com/science/article/pii/S0167404822004606)
Abstract: IoT device manufacturers integrate open-source components (OSCs) to serve necessary and common functions for facilitating firmware development. However, outdated versions of OSC conceal N-day vulnerabilities and continue to function on IoT devices. The security risks can be predicted once we can identify the OSC versions employed in the firmware. Existing works make attempts at OSC version identification but fail to perform vulnerability detection on a large-scale IoT firmware due to i) unsuitable version identification method for IoT firmware scenario. ii) the lack of a large-scale version-vulnerability relation database. To this end, we propose a system VERI for large-scale vulnerability detection based on lightweight version identification. First, for OSC version identification, VERI leverages symbolic execution with static analysis to identify exact OSC versions even though there are many version-like strings in OSC. Second, VERI employs a deep learning-based method to extract OSC names and vulnerable version ranges from vulnerability descriptions, constructs and maintains an OSC version-vulnerability relation database to serve the vulnerability detection. Finally, VERI polls the relation database to confirm the N-day security risk of the OSC with identified version. The evaluation results show that VERI achieves 96.43% accuracy with high efficiency in OSC version identification. Meanwhile, the deep learning model accurately extracts the OSC names and versions from vulnerability descriptions dataset with 97.19% precision and 96.56% recall. Based on the model, we build a large-scale version-vulnerability relation database. Furthermore, we utilize VERI to conduct a large-scale analysis on 28,890 firmware and find 38,654 vulnerable OSCs with 266,109 N-day vulnerabilities, most of which are with high risks. From the detection results, we find that after the official patch for the vulnerability is released, manufacturers delay an average of 473 days to patch the firmware.
Keywords: IoT Firmware; Open-source component; Vulnerability detection; Version identification

Chongyang Liu, Xiang Chen, Xiangwei Li, Yinxing Xue,
Making vulnerability prediction more practical: Prediction, categorization, and localization,
Information and Software Technology,
Volume 171,
2024,
107458,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2024.107458.
(https://www.sciencedirect.com/science/article/pii/S0950584924000636)
Abstract: Context:
Due to the prevalence of software vulnerabilities, vulnerability detection becomes a fundamental problem in system security.
Objective:
To solve this problem, academics and industries have made great efforts to propose deep-learning-based (DL-based) approaches but these attempts have three main limitations: (1) perform poorly on real-world projects (e.g., Accuracy below 74.33% and F1 below 73.55%); (2) perform poorly in catching vulnerable patterns due to incomplete code representations; (3) mostly perform coarse-grained function-level prediction and lack interpretability analysis.
Methods:
In this paper, we propose VulPCL, a BLSTM and CodeBERT based approach, which makes the first attempt to perform vulnerability prediction, categorization, and localization automatically within a framework. To alleviate the above-mentioned limitations, our VulPCL considers multi-dimension (i.e., text-based, sequence-based, and graph-based) representations to catch latent vulnerable patterns and multi-model training to learn high-level semantics.
Results:
Through experiments on four real-world datasets containing 114+ CWE (Common Weakness Enumeration) types spanning from 2005 to 2022, we find that our VulPCL outperforms the baselines by (1) 13.51%∼60.64% and 14.34%∼180.23% on Accuracy, and F1 respectively on vulnerability prediction; (2) 10.32%∼46.79%, and 10.71%∼127.80% on Accuracy, and macro-F1 respectively on vulnerability categorization; (3) 9.23%∼36.54% on Top-10 Accuracy on vulnerability localization.
Conclusion:
These results indicate that our VulPCL is considerably more accurate, effective, fine-grained, and practical than previous studies. Besides, our further analyses show that VulPCL is indeed capable of capturing all vulnerability lines, and the result of line-level vulnerability localization is consistent with the function-level vulnerability prediction as the increase of predicted lines. Thus making VulPCL more interpretable than previous studies. Our additional investigation also shows that VulPCL effectively detects the Most Dangerous 25 CWEs in 2022, which is instructive for security researchers.
Keywords: Deep learning; Pre-trained language model; Semantic analysis; Vulnerability detection

Thu-Trang Nguyen, Hieu Dinh Vo,
Context-based statement-level vulnerability localization,
Information and Software Technology,
Volume 169,
2024,
107406,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2024.107406.
(https://www.sciencedirect.com/science/article/pii/S0950584924000119)
Abstract: Context:
The number of attacks exploring software vulnerabilities has dramatically increased, which has caused various severe damages. Thus, early and accurately detecting vulnerabilities becomes essential to guarantee software quality and prevent the systems from malicious attacks. Multiple automated vulnerability detection approaches have been proposed and obtained promising results. However, most studies detect vulnerabilities at a coarse-grained, i.e., file or method level. Thus, developers still have to spend significant investigation efforts on localizing vulnerable statements.
Objective:
In this paper, we introduce COSTA, a novel context-based approach to localize vulnerable statements.
Method:
In particular, given a vulnerable function, COSTA identifies vulnerable statements based on their suspiciousness scores. Specifically, the suspiciousness of each statement is measured according to its semantics captured by four contexts, including operation context, dependence context, surrounding context, and vulnerability type.
Results:
Our experimental results on a large vulnerability dataset show that COSTA outperforms the state-of-the-art approaches up to 96% in F1-score and 167% in Accuracy. COSTA also surpasses these approaches up to two times in Top-1 Accuracy. Especially, COSTA obtains about 80% at Top-3 Recall. In other words, developers can find about 80% of the vulnerable statements by investigating only three first-ranked statements in each function.
Conclusion:
COSTA effectively addresses the challenge of statement-level vulnerability localization by leveraging multiple contextual features. Our experimental results show that COSTA outperforms existing state-of-the-art approaches. With the ability to accurately and efficiently identify vulnerable statements, developers can better allocate their investigation efforts, reduce the risk of potential security threats, and ensure software quality and security in real-world applications.
Keywords: Vulnerable statement; Vulnerability detection; Vulnerability localization; Context representation; COSTA

Ahmed Alzahrani, Muhammad Zubair Asghar,
Cyber vulnerabilities detection system in logistics-based IoT data exchange,
Egyptian Informatics Journal,
Volume 25,
2024,
100448,
ISSN 1110-8665,
https://doi.org/10.1016/j.eij.2024.100448.
(https://www.sciencedirect.com/science/article/pii/S1110866524000112)
Abstract: Modern-day digitalization has a profound impact on business and society, revolutionizing logistics. Supply chain digitalization improves transparency, speed, and cost-effectiveness, increasingtech adoption—transportationbenefits from IoT-driven shipment tracking and web data storage. However, cyber threats target IoT data by exploiting cyber vulnerabilities. Although ML/DL approaches have showed potential in finding IoT vulnerabilities, the difficulty of selecting appropriate features remains. Existing research has produced surprising outcomes, and deep neural networks have been utilised to extract characteristics without taking sequence information into account. To address this, the paper presents a unique approach for accurate IoT vulnerability identification that combines deep learning and better feature selection. On the BoT-IoT dataset, the LSTM + CNN model achieved 95.73 % accuracy. This approach has the ability to successfully anticipate IoT based vulnerabilities by leveraging benchmark data, selecting relevant features, and enhancing overall system performance.
Keywords: Hybrid deep learning; Feature selection; IoT-based vulnerabilities; Logistics

Xueshuo Xie, Haolong Wang, Zhaolong Jian, Yaozheng Fang, Zichun Wang, Tao Li,
Block-gram: Mining knowledgeable features for efficiently smart contract vulnerability detection,
Digital Communications and Networks,
2023,
,
ISSN 2352-8648,
https://doi.org/10.1016/j.dcan.2023.07.009.
(https://www.sciencedirect.com/science/article/pii/S2352864823001347)
Abstract: Smart contracts are widely used on the blockchain to implement complex transactions, such as decentralized applications on Ethereum. Effective vulnerability detection of large-scale smart contracts is critical, as attacks on smart contracts often cause huge economic losses. Since it is difficult to repair and update smart contracts, it is necessary to find the vulnerabilities before they are deployed. However, code analysis, which requires traversal paths, and learning methods, which require many features to be trained, are too time-consuming to detect large-scale on-chain contracts. Learning-based methods will obtain detection models from a feature space compared to code analysis methods such as symbol execution. But the existing features lack the interpretability of the detection results and training model, even worse, the large-scale feature space also affects the efficiency of detection. This paper focuses on improving the detection efficiency by reducing the dimension of the features, combined with expert knowledge. In this paper, a feature extraction model Block-gram is proposed to form low-dimensional knowledge-based features from bytecode. First, the metadata is separated and the runtime code is converted into a sequence of opcodes, which are divided into segments based on some instructions (jumps, etc.). Then, scalable Block-gram features, including 4-dimensional block features and 8-dimensional attribute features, are mined for the learning-based model training. Finally, feature contributions are calculated from SHAP values to measure the relationship between our features and the results of the detection model. In addition, six types of vulnerability labels are made on a dataset containing 33,885 contracts, and these knowledge-based features are evaluated using seven state-of-the-art learning algorithms, which show that the average detection latency speeds up 25× to 650×, compared with the features extracted by N-gram, and also can enhance the interpretability of the detection model.
Keywords: Smart contract; Bytecode & opcode; Knowledgeable features; Vulnerability detection; Feature contribution

Jinfu Chen, Wei Lin, Saihua Cai, Yemin Yin, Haibo Chen, Dave Towey,
BiTCN_DRSN: An effective software vulnerability detection model based on an improved temporal convolutional network,
Journal of Systems and Software,
Volume 204,
2023,
111772,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111772.
(https://www.sciencedirect.com/science/article/pii/S016412122300167X)
Abstract: The detection of software vulnerabilities is a challenging task in the field of security. With the increasing scale of software and the rapid development of artificial intelligence technology, deep learning has been extensively applied to automatic vulnerability detection. Temporal Convolutional Networks (TCNs) have been shown to perform well in tasks that can be processed in parallel; they can adaptively learn complex structures (including in-time series data); and they have exhibited stable gradients — they are relatively easier to train, and can quickly converge to an optimal solution. However, TCNs cannot simultaneously capture the bidirectional semantics of the source code, since they do not have a bidirectional network structure. Furthermore, because of the weak noise resistance of residual TCN connections, TCNs are also susceptible to learning features that are not related to vulnerabilities when learning the source code features. To overcome the limitations of the traditional TCN, we propose a bidirectional TCN model based on the Deep Residual Shrinkage Network (DRSN), namely BiTCN_DRSN. BiTCN_DRSN combines TCN and DRSN to enhance the noise immunity and make the network model more attentive to the features associated with vulnerabilities. In addition, addressing the limitation that the TCN is a unidirectional network structure, the forward and backward sequences are utilized for bidirectional source-code feature learning. The experimental results show that the proposed BiTCN_DRSN model can effectively improve the accuracy of source-code vulnerability detection, compared with some existing neural-network models. Compared with the traditional TCN, our model increases the accuracy by 4.22%, 2.42% and 2.66% on the BE-ALL, RM-ALL and HY-ALL datasets, respectively. The proposed BiTCN_DRSN model also exhibits improved detection stability.
Keywords: Software security; Vulnerability detection; Deep learning; Deep residual shrinkage network

Wei Xiao, Zhengzhang Hou, Tao Wang, Chengxian Zhou, Chao Pan,
MSGVUL: Multi-semantic integration vulnerability detection based on relational graph convolutional neural networks,
Information and Software Technology,
Volume 170,
2024,
107442,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2024.107442.
(https://www.sciencedirect.com/science/article/pii/S0950584924000478)
Abstract: Software security has drawn extensive attention as software projects have grown increasingly large and complex. Since the traditional manual or equipment vulnerability detection technology cannot meet today's software development needs, there is a recognized need to create more effective techniques to address security issues. Although various vulnerability detection systems have been proposed, most are based only on serialization or graph representation, to inadequate effect. We propose a system, MSGVUL, that provides superior vulnerability detection using a new multi-semantic approach. MSGVUL uses versatile and efficient code slicing employing a search algorithm based on sensitive data and functions and innovatively constructs an SSVEC model to fully integrate the semantic and structural information into the code. We also developed a novel BAG model, made up of BAP and PAG frameworks, that enables the hierarchical extraction of code vulnerability representations from the graph and sequence levels. The MSGVUL model is evaluated on slice-level and function-level vulnerability datasets, and the results demonstrate that the MSGVUL method outperforms other state-of-the-art methods.
Keywords: Vulnerability detection; Code representation; Program slicing; Graph convolutional neural networks

Longtao Guo, Huakun Huang, Lingjun Zhao, Peiliang Wang, Shan Jiang, Chunhua Su,
Reentrancy vulnerability detection based on graph convolutional networks and expert patterns under subspace mapping,
Computers & Security,
Volume 142,
2024,
103894,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103894.
(https://www.sciencedirect.com/science/article/pii/S0167404824001962)
Abstract: Smart contracts with automatic execution capability provide a vast development space for transactions in Blockchain. However, due to the vulnerabilities in smart contracts, Blockchain has suffered huge economic losses, which greatly undermines people’s trust in Blockchain and smart contracts. In this paper, we explore a vulnerability detection method based on graph neural networks and combine both contract source code and opcode. The structure of the method consists of four modules, i.e., preprocessing, subspace mapping, feature extraction, and detection modules. In the feature mapping module, we use a multi-subspace mapping approach to explore the impact of different subspace mappings on the detection method. For reentrancy vulnerability, we conducted extensive experiments. The experiments prove that our method achieves 95% accuracy and 94% F1-Score on average.
Keywords: Blockchain; Smart contract; Vulnerability detection; Graph neural network; Subspace mapping

Xiaojun Ren, Yongtang Wu, Jiaqing Li, Dongmin Hao, Muhammad Alam,
Smart contract vulnerability detection based on a semantic code structure and a self-designed neural network,
Computers and Electrical Engineering,
Volume 109, Part B,
2023,
108766,
ISSN 0045-7906,
https://doi.org/10.1016/j.compeleceng.2023.108766.
(https://www.sciencedirect.com/science/article/pii/S0045790623001908)
Abstract: Smart contracts are riddled with vulnerabilities due to flaws in programming languages and the inexperience of developers, causing damage. Nonetheless, the current research on smart contract vulnerability detection is insufficient. In this study, we propose a novel approach, namely, Blass, based on a semantic code structure and a self-designed neural network. Blass constructs program slices with complete semantic structure information (CPSs) and uses an abstract syntax tree and a depth-first traversal algorithm to convert CPSs into code chains during the process of CPS vectorization, which increases its ability to express vulnerability features. Blass also uses a self-designed neural network, Bi-LSTM-Att, as the classification model, which introduces an attention mechanism to capture the key features of vulnerabilities and effectively achieve improved smart contract vulnerability detection performance. The CPSs and the Bi-LSTM-Att can improve the vulnerability detection effectiveness of Blass, and Blass can be applied to malicious contract detection with satisfactory precision, recall, and F1 values.
Keywords: Smart contract; Vulnerability; Semantic code structure; Code chain; Bi-LSTM-Att classification model

Yuanhai Fan, Chuanhao Wan, Cai Fu, Lansheng Han, Hao Xu,
VDoTR: Vulnerability detection based on tensor representation of comprehensive code graphs,
Computers & Security,
Volume 130,
2023,
103247,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103247.
(https://www.sciencedirect.com/science/article/pii/S0167404823001578)
Abstract: Code vulnerability detection has long been a critical issue due to its potential threat to computer systems. It is imperative to detect source code vulnerabilities in software and remediate them to avoid cyber attacks. To automate detection and reduce labor costs, many deep learning-based methods have been proposed. However, these approaches have been found to be either ineffective in detecting multiple classes of vulnerabilities or limited by treating original source code as a natural language sequence without exploiting the structural information of code. In this paper, we propose VDoTR, a model that leverages a new tensor representation of comprehensive code graphs, including AST, CFG, DFG, and NCS, to detect multiple types of vulnerabilities. Firstly, a tensor structure is introduced to represent the structured information of code, which deeply captures code features. Secondly, a new Circle Gated Graph Neural Network (CircleGGNN) is designed based on tensor for hidden state embedding of nodes. CircleGGNN can perform heterogeneous graph information fusion more directly and effectively. Lastly, a 1-D convolution-based output layer is applied to hidden embedding features for classification. The experimental results demonstrate that the detection performance of VDoTR is superior to other approaches with higher accuracy, precision, recall, and F1-measure on multiple datasets for vulnerability detection. Moreover, we illustrate which code graph contributes the most to the performance of VDoTR and which code graph is more sensitive to represent vulnerability features for different types of vulnerabilities through ablation experiments.
Keywords: Source code vulnerability detection; Tensor-based feature; GGNN; Code graphs; Heterogeneous information fusion

Hongyu Sun, Guoliang Ou, Ziqiu Zheng, Lei Liao, He Wang, Yuqing Zhang,
Inconsistent measurement and incorrect detection of software names in security vulnerability reports,
Computers & Security,
Volume 135,
2023,
103477,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103477.
(https://www.sciencedirect.com/science/article/pii/S0167404823003875)
Abstract: As the number of vulnerability databases established by various nations continues to grow, they have accumulated hundreds of thousands of security vulnerability reports, which play a crucial role in protecting system security. However, many databases are found to lack essential information, contain inaccuracies, or are inconsistent with others. Despite these challenges, the importance of vulnerability databases continues to grow. Current research on vulnerability databases is limited to software version and vulnerability reproduction, but the software names, an essential component of vulnerability databases, have not been extensively studied. Understanding the consistency of software names in different vulnerability databases is crucial for improving the accuracy of vulnerability databases. The paper introduces VERNIER, an automated method for measuring inconsistencies in 789,954 sets of software names from nine security vulnerability databases (including CVE and NVD) from 1999 to 2019. We utilized a named entity recognition (NER) model with exceptional accuracy (99.5%) and F1 score (95.1%) to extract software names from unstructured Chinese and English vulnerability reports. VERNIER assesses software names' inconsistency at character and semantic levels. The results indicate that inconsistent software names are prevalent in vulnerability databases. The average of the exact matching rate between NVD and other mainstream databases, such as CVE, is only 20.3% at the character-level and 43.3% at the semantic-level. We also discover internal inconsistencies between the structured and unstructured software names inside the same vulnerability database (e.g., NVD). To mitigate the inconsistency, we implement an alert tool using inconsistencies to detect incorrect software names. This tool can effectively warn and correct software names.
Keywords: Inconsistency measurement; NER; Software name; Vulnerability databases; Artificial intelligence

Son Nguyen, Thu-Trang Nguyen, Thanh Trong Vu, Thanh-Dat Do, Kien-Tuan Ngo, Hieu Dinh Vo,
Code-centric learning-based just-in-time vulnerability detection,
Journal of Systems and Software,
Volume 214,
2024,
112014,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2024.112014.
(https://www.sciencedirect.com/science/article/pii/S0164121224000578)
Abstract: Attacks against computer systems exploiting software vulnerabilities can cause substantial damage to the cyber infrastructure of our modern society and economy. To minimize the consequences, it is vital to detect and fix vulnerabilities as soon as possible. Just-in-time vulnerability detection (JIT-VD) discovers vulnerability-prone (“dangerous”) commits to prevent them from being merged into source code and causing vulnerabilities. By JIT-VD, the commits’ authors, who understand the commits properly, can review these dangerous commits and fix them if necessary while the relevant modifications are still fresh in their minds. In this paper, we propose CodeJIT, a novel graph-based code-centric learning-based approach for just-in-time vulnerability detection. The key idea of CodeJIT is that the meaning of the code changes of a commit is the direct and deciding factor for determining if the commit is dangerous for the code. Based on that idea, we design a novel graph-based representation, Code Transformation Graph (CTG) to represent the semantics of code changes in terms of both code syntactic structure and program dependencies. A graph neural network (GNN) model is developed to capture the meaning of the code changes represented by our graph-based representation and learn to discriminate between dangerous and safe commits. We conducted experiments to evaluate the JIT-VD performance of CodeJIT on a dataset of 20K+ dangerous and safe commits in 506 real-world projects from 1998 to 2022. Our results show that CodeJIT significantly improves the state-of-the-art JIT-VD methods by up to 66% in Recall, 136% in Precision, and 68% in F1. Moreover, CodeJIT correctly classifies nearly 9/10 of dangerous/safe (benign) commits and even detects 69 commits that fix a vulnerability yet produce other issues in source code.
Keywords: Just-in-time vulnerability detection; Code-centric; Code change representation; Graph-based model; Commit-level bugs

Ilias Kalouptsoglou, Miltiadis Siavvas, Apostolos Ampatzoglou, Dionysios Kehagias, Alexander Chatzigeorgiou,
Software vulnerability prediction: A systematic mapping study,
Information and Software Technology,
Volume 164,
2023,
107303,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107303.
(https://www.sciencedirect.com/science/article/pii/S095058492300157X)
Abstract: Context:
Software security is considered a major aspect of software quality as the number of discovered vulnerabilities in software products is growing. Vulnerability prediction is a mechanism that helps engineers to prioritize their inspection efforts focusing on vulnerable parts. Despite the recent advancements, current literature lacks a systematic mapping study on vulnerability prediction.
Objective:
This paper aims to analyze the state-of-the-art of vulnerability prediction focusing on: (a) the goals of vulnerability prediction-related studies; (b) the data collection processes and the types of datasets that exist in the literature; (c) the mostly examined techniques for the construction of the prediction models and their input features; and (d) the utilized evaluation techniques.
Method:
We collected 180 primary studies following a broad search methodology across four popular digital libraries. We mapped these studies to the variables of interest and we identified trends and relationships between the studies.
Results:
The main findings suggest that: (i) there are two major study types, prediction of vulnerable software components and forecasting of the evolution of vulnerabilities in software; (ii) most studies construct their own vulnerability-related dataset retrieving information from vulnerability databases for real-world software; (iii) there is a growing interest for deep learning models along with a trend on textual source code representation; and (iv) F1-score was found to be the most widely used evaluation metric.
Conclusions:
The results of our study indicate that there are several open challenges in the domain of vulnerability prediction. One of the major conclusions, is the fact that most studies focus on within-project prediction, neglecting the real-world scenario of cross-project prediction.
Keywords: Systematic mapping study; Software security; Vulnerability prediction; Machine learning

Katarzyna Filus, Joanna Domańska,
Software vulnerabilities in TensorFlow-based deep learning applications,
Computers & Security,
Volume 124,
2023,
102948,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.102948.
(https://www.sciencedirect.com/science/article/pii/S0167404822003406)
Abstract: Usage of Deep Learning (DL) methods is ubiquitous. It is common in the DL/Artificial Intelligence domain to use 3rd party software. TensorFlow is one of the most popular Machine Learning (ML) platforms. Every software product is a subject to security failures which often result from software vulnerabilities. In this paper, we focus on threats related to 6 common types of threats in TensorFlow implementation. We identify them using Common Weakness Enumeration. We analyze more than 100 vulnerability instances. We focus on vulnerabilities’ severity, impact on confidentiality, integrity and availability, as well as possible results of exploitation. We also use Orthogonal Defect Classification (ODC). The results show that a majority of vulnerabilities are caused by missing/incorrect checking statements, however some fixes require more advanced algorithmic changes. Static Analysis Tools tested in our study show low effectiveness in detecting known vulnerabilities in TensorFlow, but we provide some recommendations based on the obtained alerts to improve overall code quality. Further analysis of vulnerabilities helped us to understand and characterize different vulnerability types and provide a set of observations. We believe that these observations can be useful for the creators of new static analysis tools as a source of inspiration and to build the test cases. We also aim to draw the programmers’ attention to the prevalence of vulnerabilities in deep learning applications and a low effectiveness of automatic tools to find software vulnerabilities in such products.
Keywords: Software vulnerability; TensorFlow; Deep learning; Security; Static analysis

Akashdeep Bhardwaj, Salil Bharany, Anas W. Abulfaraj, Ashraf Osman Ibrahim, Wamda Nagmeldin,
Fortifying home IoT security: A framework for comprehensive examination of vulnerabilities and intrusion detection strategies for smart cities,
Egyptian Informatics Journal,
Volume 25,
2024,
100443,
ISSN 1110-8665,
https://doi.org/10.1016/j.eij.2024.100443.
(https://www.sciencedirect.com/science/article/pii/S1110866524000069)
Abstract: Smart home devices have brought in a disruptive, revolutionary Internet-based ecosystem that enhanced our daily lives but has pushed private data from inside our homes to external public sources. Threats and attacks mounted against IoT deployments have only increased in recent times. There have been several proposals to secure home automation environments, but there is no full protection against Cybersecurity threats for our home IoT platforms. This research investigates attack attempts on smart home environments, focusing on firmware, brute force, and DoS attacks on the Internet of Things (IoT) network which were successful in bringing down the device in less than a minute. Weak passwords were cracked using Brute Force techniques related to HTTP, SSH, Telnet, and FTP protocols, and an unknown service port to reveal backdoor access. Cross-site scripting vulnerability was detected on IoT devices that could allow running malicious scripts on the devices. The authors also exploited the unknown services to reveal backdoors and access sensitive device details and potentially exploited them to add new ports or rules to turn the IoT devices into a router to attack other devices. To detect and mitigate such attacks, the authors present an IoT-based intrusion detection and prevention system to secure smart home network devices. The authors compared the proposed framework with other similar research based on Precision, Accuracy, F-measure, and Recall. The proposed model outperforms all the other known models reporting a high of 95% for identifying malicious attack packets, while others reported 58% and 71% detection percentage.
Keywords: IoT; Firmware attack; XSS; Brute Force; Cross-site scripting; UPnP; IDS

Prabith GS, Rohit Narayanan M, Arya A, Aneesh Nadh R, Binu PK,
BiT5: A Bidirectional NLP Approach for Advanced Vulnerability Detection in Codebase,
Procedia Computer Science,
Volume 233,
2024,
Pages 812-821,
ISSN 1877-0509,
https://doi.org/10.1016/j.procs.2024.03.270.
(https://www.sciencedirect.com/science/article/pii/S1877050924006306)
Abstract: In this research paper, a detailed investigation presents the utilization of the BiT5 Bidirectional NLP model for detecting vulnerabilities within codebases. The study addresses the pressing need for techniques enhancing software security by effectively identifying vulnerabilities. Methodologically, the paper introduces BiT5, specifically designed for code analysis and vulnerability detection, encompassing dataset collection, preprocessing steps, and model fine-tuning. The key findings underscore BiT5’s efficacy in pinpointing vulnerabilities within code snippets, notably reducing both false positives and false negatives. This research contributes by offering a methodology for leveraging BiT5 in vulnerability detection, thus significantly bolstering software security and mitigating risks associated with code vulnerabilities.
Keywords: Bidirectional Transformer; BiT5 Model; Code Analysis; Code Vulnerabilities; Machine Learning; Natural Language Processing (NLP); Software Security; Vulnerability Detection

Wei Tang, Mingwei Tang, Minchao Ban, Ziguo Zhao, Mingjun Feng,
CSGVD: A deep learning approach combining sequence and graph embedding for source code vulnerability detection,
Journal of Systems and Software,
Volume 199,
2023,
111623,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111623.
(https://www.sciencedirect.com/science/article/pii/S0164121223000183)
Abstract: In order to secure software, it is critical to detect potential vulnerabilities. The performance of traditional static vulnerability detection methods is limited by predefined rules, which rely heavily on the expertise of developers. Existing deep learning-based vulnerability detection models usually use only a single sequence or graph embedding approach to extract vulnerability features. Sequence embedding-based models ignore the structured information inherent in the code, and graph embedding-based models lack effective node and graph embedding methods. As a result, we propose a novel deep learning-based approach, CSGVD (Combining Sequence and Graph embedding for Vulnerability Detection), which considers function-level vulnerability detection as a graph binary classification task. Firstly, we propose a PE-BL module, which inherits and enhances the knowledge from the pre-trained language model. It extracts the code’s local semantic features as node embedding in the control flow graph by using sequence embedding. Secondly, CSGVD uses graph neural networks to extract the structured information of the graph. Finally, we propose a mean biaffine attention pooling, M-BFA, to better aggregate node information as a graph’s feature representation. The experimental results show that CSGVD outperforms the existing state-of-the-art models and obtains 64.46% accuracy on the real-world benchmark dataset from CodeXGLUE for vulnerability detection.
Keywords: Graph neural networks; Vulnerability detection; Sequence embedding; Graph embedding; Pre-trained language model; Attention pooling

Solmaz Salimi, Mehdi Kharrazi,
VulSlicer: Vulnerability detection through code slicing,
Journal of Systems and Software,
Volume 193,
2022,
111450,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2022.111450.
(https://www.sciencedirect.com/science/article/pii/S0164121222001443)
Abstract: There has been a multitude of techniques proposed for identifying vulnerabilities in software. Forcing a program into a vulnerable state has become increasingly unscalable, given the size of the programs and the number of possible execution states. At the same time, techniques that are looking for vulnerability signatures are marred with weak and incomplete signatures. This is not to say that such techniques have failed to identify previously unknown vulnerabilities in the code. However, they have inherent weaknesses, which result in identifying vulnerabilities that are limited in type and complexity. We propose a novel technique to extract succinct vulnerability-relevant statements representing the self-contained nature of vulnerabilities and reproduce the vulnerable behavior independently of the rest of the program. We also introduce an innovative technique to slice target programs and search for similar vulnerability-relevant statements in them. We developed VulSlicer, a prototype system capable of extracting vulnerability-relevant statements from vulnerable programs and searching for them on target programs at scale. Furthermore, we have examined four candidate open-source projects and have been able to identify 118 potential vulnerabilities, out of which 94 were found to be silently patched, and from the remaining reported cases, three were confirmed by obtaining a CVE designation.
Keywords: Code slicing; Static analysis; Vulnerability detection

Xinghua Li, Zhongyuan Hu, Mengfan Xu, Yunwei Wang, Jianfeng Ma,
Transfer learning based intrusion detection scheme for Internet of vehicles,
Information Sciences,
Volume 547,
2021,
Pages 119-135,
ISSN 0020-0255,
https://doi.org/10.1016/j.ins.2020.05.130.
(https://www.sciencedirect.com/science/article/pii/S0020025520305569)
Abstract: As a new type of network, the types of attack in the Internet of Vehicles (IoV) are constantly emerging and changing. Consequently, the machine learning based intrusion detection model has to update to cope with new attacks. However, existing machine learning based IoV intrusion detection schemes require large amounts of labeled data to complete model updates. For new attacks, the IoV cloud is also difficult to identify in time, which requires a lot of labor and time cost in IoV. To solve above issue, this paper employs transfer learning and proposes two model update schemes based on whether the IoV cloud can timely provide a small amount of labeled data for a new attack. The first one is the cloud-assisted update scheme where the IoV cloud can provide a small amount of data. And the second one is the local update scheme where the IoV cloud cannot provide any labeled data timely. In this paper, the local update scheme obtains pseudo label of the unlabeled data in new attacks via pre-classifies and uses the pseudo-labeled data for multiple rounds of transfer learning. Then the vehicle can complete the update without obtaining any labeled data through the IoV cloud. The experimental results show that compared with the existing method, our two schemes have improved the detection accuracy by at least 23%.
Keywords: Transfer learning; Intrusion detection; Internet of Vehicles

Chao Liu, Di Liu,
Deep reinforcement learning algorithm based on multi-agent parallelism and its application in game environment,
Entertainment Computing,
Volume 50,
2024,
100670,
ISSN 1875-9521,
https://doi.org/10.1016/j.entcom.2024.100670.
(https://www.sciencedirect.com/science/article/pii/S1875952124000387)
Abstract: Deep reinforcement learning has become a prominent area of research in artificial intelligence in recent years. Its application in solving complex tasks and game environments has garnered significant attention. This study aims to develop a deep reinforcement learning algorithm based on multi-agent parallelism to enhance intelligent decision-making in game environments. The algorithm combines a deep Q-network with a multi-agent cooperation strategy. Through parallel training of multiple agents, the learning process is accelerated, and decision accuracy is improved. The experimental results indicated that the Actor-Critic algorithm, when combined with precision rate, recall rate, and average fitness of multi-agent parallel, achieves a relatively high accuracy rate index, which stabilizes above 0.95. The recall rate index was also above 0.8, and the average fitness was in a relatively high range. The research shows that the deep reinforcement learning algorithm based on multi-agent parallelism performs better and is more effective in game environments. It can learn the optimal strategy faster and obtain higher rewards. This not only provides a new technical means for game development but also offers a useful reference for the application of multi-agent systems in complex environments.
Keywords: Multi-agent parallelism; Deep reinforcement learning; Game environment; Convolutional neural network; Policy gradient

Ziyuan Wang, Dexin Bu, Nannan Wang, Sijie Yu, Shanyi Gou, Aiyue Sun,
An empirical study on bugs in JavaScript engines,
Information and Software Technology,
Volume 155,
2023,
107105,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2022.107105.
(https://www.sciencedirect.com/science/article/pii/S0950584922002142)
Abstract: Context:
JavaScript is a prototype-based dynamic type scripting language. The correct running of a JavaScript program depends on the correctness of both the program and the JavaScript engine.
Objective:
An in-depth understanding of the characteristics of bugs in JavaScript engines can help detect and fix them.
Methods:
We conduct an empirical study on the bugs in three mainstream JavaScript engines: V8, SpiderMonkey, and Chakra. Such an empirical study involves 19,019 bug reports, 16,437 revisions, 805 test cases, and root causes of randomly selected 540 bugs.
Results:
(1) The Compiler and the DOM are the most buggy component in V8 and SpiderMonkey, respectively. Most of the source files contain only one bug. (2) The scales of the testing programs that reveal bugs are usually small. Most bug fixes involve only limited modifications since the number of modified source files and lines of code modified are small. (3) Most bugs can be fixed within half a year (80.33% for V8 and 91.9% for SpiderMonkey). Only 4.33% of SpiderMonkey bugs need more than a year to fix. Bugs in SpiderMonkey are usually fixed faster than bugs in V8. (4) High priority tends to be assigned to Infrastructure bugs in V8 and Release Automation bugs in SpiderMonkey. The duration of bugs is not strictly correlated with their priorities. (5) Semantic bugs are the most common root causes of bugs. And among semantic bugs, the processing bugs, missing features bugs and function call bugs are more than others.
Conclusion:
This study deepens our understanding of bugs in JavaScript engines, and empirical results could indicate some potential problems during the detecting and fixing of bugs in JavaScript engines, assist developers of JavaScript engines in improving their development quality, assist maintainers in detecting and fixing bugs more effectively, and suggest users of JavaScript evade potential risks.
Keywords: Empirical study; JavaScript engine; Software bug; SpiderMonkey; Chakra; V8

Zuhaira Muhammad Zain, Sapiah Sakri, Nurul Halimatul Asmak Ismail,
Application of Deep Learning in Software Defect Prediction: Systematic Literature Review and Meta-analysis,
Information and Software Technology,
Volume 158,
2023,
107175,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107175.
(https://www.sciencedirect.com/science/article/pii/S0950584923000290)
Abstract: Context
Despite recent attention given to Software Defect Prediction (SDP), the lack of any systematic effort to assess existing empirical evidence on the application of Deep Learning (DL) in SDP indicates that it is still relatively under-researched.
Objective
To synthesize literature on SDP using DL, pertaining to measurements, models, techniques, datasets, and achievements; to obtain a full understanding of current SDP-related methodologies using DL; and to compare the DL models’ performances with those of Machine Learning (ML) models in classifying software defects.
Method
We completed a thorough review of the literature in this domain. To answer the research issues, results from primary investigations were synthesized. The preliminary findings for DL vs. ML in SDP were verified by using meta-analysis (MA).
Result
We discovered 63 primary studies that passed the systematic literature review quality evaluation. However, only 19 primary studies passed the MA quality evaluation. The five most popular performance measurements employed in SDP were f-measure, recall, accuracy, precision, and Area Under the Curve (AUC). The top five DL techniques used in building SDP models were Convolutional Neural Network (CNN), Deep Neural Network (DNN), Long Short-Term Memory (LSTM), Deep Belief Network (DBN), and Stacked Denoising Autoencoder (SDAE). PROMISE and NASA datasets were found to be used more frequently to train and test DL models in SDP. The MA results show that DL was favored over ML in terms of study and dataset across accuracy, f-measure, and AUC.
Conclusion
The application of DL in SDP remains a challenge, but it has the potential to achieve better predictive performance when the performance-influencing parameters are optimized. We provide a reference point for future research which could be used to improve research quality in this domain.
Keywords: Deep Learning; Software Defect Prediction; Systematic Literature Review; Meta-Analysis

Yuteng Lu, Kaicheng Shao, Jia Zhao, Weidi Sun, Meng Sun,
Mutation testing of unsupervised learning systems,
Journal of Systems Architecture,
Volume 146,
2024,
103050,
ISSN 1383-7621,
https://doi.org/10.1016/j.sysarc.2023.103050.
(https://www.sciencedirect.com/science/article/pii/S1383762123002291)
Abstract: Unsupervised learning (UL) is one of the most important areas in artificial intelligence. UL systems are capable of learning patterns from unlabeled data and playing an increasingly critical role in many fields. Therefore, more and more attention has been paid to the security and stability of UL systems. Testing has achieved great success in ensuring the safety of traditional software systems and been gradually applied to supervised learning. However, UL is not in the consideration of most current testing methods. To fill this gap, we propose a novel mutation testing technique specific to UL systems. We design a series of mutation operators to simulate the unstable situations and possible errors that UL systems may encounter, and define corresponding mutation scores. Further, we combine the proposed technique with autoencoder for generating adversarial samples. In the evaluation phase, we demonstrate the practicability of the proposed technique based on three datasets. We have also developed an open-source tool MTGAN, which incorporates the functionality of mutation testing for GANs, to evaluate their stability and assess their capacity to address given issues.
Keywords: Mutation testing; Unsupervised learning; Cluster analysis; Autoencoder

Xiaofang Qi, Tiangang Zhu, Yanhui Li,
Coverage-enhanced fault diagnosis for Deep Learning programs: A learning-based approach with hybrid metrics,
Information and Software Technology,
2024,
107488,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2024.107488.
(https://www.sciencedirect.com/science/article/pii/S0950584924000934)
Abstract: Context:
Given the data-driven paradigm inherent to Deep Learning (DL), it is inevitable that DL software will exhibit incorrect behavior in real-world applications. DL programs have been identified as a primary source of DL faults. To tackle this, researchers have devised a unique framework that approaches fault diagnosis as a learning task, which leverages runtime data as metrics to construct predictive models, enabling effective fault diagnosis.
Object:
In this paper, we aim to propose new metrics, especially from the coverage view, to enhance the performance of fault diagnosis models.
Method:
We combine coverage criteria and statistical operators to propose 80 coverage metrics, which summarize the trend of coverage values in the model training procedure. We construct hybrid prediction models by combining our new coverage metrics and existing runtime metrics under four widely used classifiers.
Results:
To examine whether adding our new coverage metrics performs well in DL program fault diagnosis, we conduct our experiments on six widely used datasets under four indicators (i.e., accuracy, F1 score, AUC, and MCC). Through the experiments, we observe that (a) coverage metrics are not redundant with respect to the original runtime metrics, and (b) adding extra coverage metrics can significantly enhance the performance of fault diagnosis models.
Conclusions:
Our study shows that our proposed coverage metrics are helpful in constructing effective fault diagnosis models for DL programs.
Keywords: Deep Learning; Coverage; metrics; Fault diagnosis

Sandra Kumi, Dylan Kelly, Jonathan Woodstuff, Richard K. Lomotey, Rita Orji, Ralph Deters,
Cocoa Companion: Deep Learning-Based Smartphone Application for Cocoa Disease Detection,
Procedia Computer Science,
Volume 203,
2022,
Pages 87-94,
ISSN 1877-0509,
https://doi.org/10.1016/j.procs.2022.07.013.
(https://www.sciencedirect.com/science/article/pii/S1877050922006184)
Abstract: The use of machine learning (ML) in crop disease detection has gain significant attention from both academia and industry lately. This paper posits that ML techniques can be employed for early detection and diagnosis of the two (2) major diseases that affect cocoa production namely – Swollen Shoot and Black Pod. In this regard, a mobile application is designed with ML techniques integrated to enable cocoa farmers take a picture of the cocoa pod and upload for the diagnosis, which takes place on a backend cloud service. The automatic detection and diagnosis of diseases is based on the Convolutional Neural Networks (CNN) for image analysis and classification. In the paper, four (4) CNN models are built and trained. The best performing model is SSD MobileNet V2 with over 80% confidence detection score.
Keywords: Cocoa; Mobile; Deep Learning; Machine Learning; Convolutional Neural Networks (CNN); Detection

Samuel Akwasi Danso, Shang Liping, Deng Hu, Samuel Afoakwa, Eugene Louis Badzongoly, Justice Odoom, Owais Muhammad, Muhammad Umer Mushtaq, Abdul Qayoom, Wenqing Zhou,
An optimal defect recognition security-based terahertz low resolution image system using deep learning network,
Egyptian Informatics Journal,
Volume 24, Issue 3,
2023,
100384,
ISSN 1110-8665,
https://doi.org/10.1016/j.eij.2023.05.009.
(https://www.sciencedirect.com/science/article/pii/S1110866523000324)
Abstract: The physics of Terahertz (THz) technology is the electromagnetic (EM) spectrum band between the infrared and the microwave band with frequencies of about 0.1 to 30 THz. THz signals have gained adoption in medicine, telecommunications, security monitoring and imaging. THz imaging technology has the advantages of rapid imaging, strong penetration, and harmless to the human body hence widely used in a variety of security environments and has become an alternative technology for X-ray imaging. However, THz is characterized by low resolution of THz images of which noise is an integral factor constituting a defect. Clarity of THz image is therefore essential at various security checkpoints to avoid life’s dangers and treats. In this paper, we propose an efficient and high-performance defect detection model based on RetinaNet to recognize defects from captured images. The strategy of transfer learning is introduced to improve detection performance accuracy, which enhances the average precision (AP) by 19.2%. Contrary to existing THz image detection techniques on image recognition pertaining to the whole region of the image, we adopt a different approach via differential evolution search algorithm for optimization given the small proportion of defect area which improves the AP by 9.9% comparing with the fine-tuned model. For the problem of the lack of defect data samples, image augmentation is adopted to enrich our training samples, which improves the AP by 9.5%. As for the problem of low precision and recall in detecting blurred images, we firstly manually generate clear-blurred image pairs to train a GAN. Then, the blurred images are deblurred using a trained generator. We get 5.5% AP improvement on the testset using our approach. Compared with existing works, the optimized model based on RetinaNet has better detection performance, subsequently, proving the practicability and effectiveness of the proposed method.
Keywords: Defect recognition; Differential evolution search algorithm; Feature pyramid network; Generative adversarial network; Low resolution; Terahertz image

Jiayi Zhao, Aldo Lipani, Calogero Schillaci,
Fallen apple detection as an auxiliary task: Boosting robotic apple detection performance through multi-task learning,
Smart Agricultural Technology,
Volume 8,
2024,
100436,
ISSN 2772-3755,
https://doi.org/10.1016/j.atech.2024.100436.
(https://www.sciencedirect.com/science/article/pii/S2772375524000418)
Abstract: In modern agricultural practices, advanced machine learning techniques play a pivotal role in optimizing yields and management. A significant challenge in orchard management is detecting apples on trees, which is essential for effective harvest planning and yield estimation. The YOLO series, especially the YOLOv8 model, stands out as a state-of-the-art solution for object detection, but its potential in orchards remains untapped. Addressing this, our study evaluates YOLOv8’s capability in orchard apple detection, aiming to set a benchmark. By employing image augmentation techniques like exposure, rotation, mosaic, and cutout, we lifted the model's performance to a state-of-the-art level. We further integrated multi-task learning, enhancing tree apple detection by also identifying apples on the ground. This approach resulted in a model with robust accuracy across evaluation metrics. Our results underscore that the YOLOv8 model achieves a leading standard in orchard apple detection. When trained for both tree and fallen apple detection, it outperformed the one when trained exclusively for the former. Recognizing fallen apples not only reduces waste but could also indicate pest activity, influencing strategic orchard decisions and potentially boosting economic returns. Merging cutting-edge tech with agricultural needs, our research showcases the promise of multi-task learning in fruit detection with deep learning.
Keywords: Automatic agriculture; Deep learning; Detection of orchard apple; YOLOv8 model; Data augmentation techniques

Naresh Kumar Nagwani, Jasjit S. Suri,
An artificial intelligence framework on software bug triaging, technological evolution, and future challenges: A review,
International Journal of Information Management Data Insights,
Volume 3, Issue 1,
2023,
100153,
ISSN 2667-0968,
https://doi.org/10.1016/j.jjimei.2022.100153.
(https://www.sciencedirect.com/science/article/pii/S2667096822000969)
Abstract: The timely release of defect-free software and the optimization of development costs depend on efficient software bug triaging (SBT) techniques. SBT can also help in managing the vast information available in software bug repositories. Recently, Artificial Intelligence (AI)-based emerging technologies have been utilized excessively, however, it is not clear how it is shaping the design, development, and performance in the field of SBT. It is therefore important to write this well-planned, comprehensive, and timely needed AI-based SBT review, establishing clear findings. For selecting the key studies in SBT, Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) analysis was carried out, and 123 studies were selected for the AI-based review, addressing key research questions. Further, Cochrane protocol was applied for risk-of-bias computations for selecting AI techniques. We studied the six types of software bug triaging techniques (SBTT) that were analyzed. AI has provided the possibility of automating the time-consuming manual SBT process. Our study shows that AI-based architectures, developers for newly reported bugs can be identified more accurately and quickly. Deep learning (DL)-based approaches demonstrate capabilities for developing SBT systems having improved (i) learning rate, (ii) scalability, and (iii) performance as compared to conventional approaches. For evaluating the SBT techniques, apart from the accuracy, precision, and recall, the mean average precision (mAP) is suggested to be an effective metric. In the future, more work is expected in the direction of SBT considering additional information from developer's networks, other repositories, and modern AI technologies.
Keywords: Software bug triaging; Bug assignment; Expert developer; AI; Recommender systems; Tossing graphs; Performance; and accuracy

Zaher Shuraym M. Alharthi, Ravi Rastogi,
An efficient classification of secure and non-secure bug report material using machine learning method for cyber security,
Materials Today: Proceedings,
Volume 37, Part 2,
2021,
Pages 2507-2512,
ISSN 2214-7853,
https://doi.org/10.1016/j.matpr.2020.08.311.
(https://www.sciencedirect.com/science/article/pii/S2214785320361836)
Abstract: In the field of software development, the main problem is to recognize the security-oriented issues within the reported bugs due to its inacceptable rate to provide the satisfied reliability on customer and software dataset. The objective is to propose a novel machine learning approach for multiclass supervised classification named Bug Severity classification to overcome these challenges with the use of supervised Artificial Neural Network and stacking based Navies Bayes classifier. This proposed approach directly examines the latent and highly descriptive features. Primarily, using the natural language programming approaches bug report text is preprocessed. After then, N gram is employed for extracting features by overcoming data sparsity problems. Further, the supervised Artificial Neural Network extracts the salient feature patterns of the corresponding severity classes. Finally, the stacking-based Navies Bayes classifier is employed for classifying multiple bug severity classes.
Keywords: Cyber security; Machine learning; Classification; Bug report; Data sparsity

Veronica Ferrari, Rosalba Calvini, Bas Boom, Camilla Menozzi, Aravind Krishnaswamy Rangarajan, Lara Maistrello, Peter Offermans, Alessandro Ulrici,
Evaluation of the potential of near infrared hyperspectral imaging for monitoring the invasive brown marmorated stink bug,
Chemometrics and Intelligent Laboratory Systems,
Volume 234,
2023,
104751,
ISSN 0169-7439,
https://doi.org/10.1016/j.chemolab.2023.104751.
(https://www.sciencedirect.com/science/article/pii/S0169743923000011)
Abstract: The brown marmorated stink bug (BMSB), Halyomorpha halys, is an invasive insect pest of global importance that damages several crops, compromising agri-food production. Field monitoring procedures are fundamental to perform risk assessment operations, in order to promptly face crop infestations and avoid economical losses. To improve pest management, spectral cameras mounted on Unmanned Aerial Vehicles (UAVs) and other Internet of Things (IoT) devices, such as smart traps or unmanned ground vehicles, could be used as an innovative technology allowing fast, efficient and real-time monitoring of insect infestations. The present study consists in a preliminary evaluation at the laboratory level of Near Infrared Hyperspectral Imaging (NIR-HSI) as a possible technology to detect BMSB specimens on different vegetal backgrounds, overcoming the problem of BMSB mimicry. Hyperspectral images of BMSB were acquired in the 980–1660 nm range, considering different vegetal backgrounds selected to mimic a real field application scene. Classification models were obtained following two different chemometric approaches. The first approach was focused on modelling spectral information and selecting relevant spectral regions for discrimination by means of sparse-based variable selection coupled with Soft Partial Least Squares Discriminant Analysis (s-Soft PLS-DA) classification algorithm. The second approach was based on modelling spatial and spectral features contained in the hyperspectral images using Convolutional Neural Networks (CNN). Finally, to further improve BMSB detection ability, the two strategies were merged, considering only the spectral regions selected by s-Soft PLS-DA for CNN modelling.
Keywords: Halyomorpha halys; Hyperspectral imaging; Pest management; Precision agriculture; Multivariate image analysis

Eloy Peña-Asensio, Josep M. Trigo-Rodríguez, Pau Grèbol-Tomàs, David Regordosa-Avellana, Albert Rimola,
Deep machine learning for meteor monitoring: Advances with transfer learning and gradient-weighted class activation mapping,
Planetary and Space Science,
Volume 238,
2023,
105802,
ISSN 0032-0633,
https://doi.org/10.1016/j.pss.2023.105802.
(https://www.sciencedirect.com/science/article/pii/S003206332300171X)
Abstract: In recent decades, the use of optical detection systems for meteor studies has increased dramatically, resulting in huge amounts of data being analyzed. Automated meteor detection tools are essential for studying the continuous meteoroid incoming flux, recovering fresh meteorites, and achieving a better understanding of our Solar System. Concerning meteor detection, distinguishing false positives between meteor and non-meteor images has traditionally been performed by hand, which is significantly time-consuming. To address this issue, we developed a fully automated pipeline that uses Convolutional Neural Networks (CNNs) to classify candidate meteor detections. Our new method is able to detect meteors even in images that contain static elements such as clouds, the Moon, and buildings. To accurately locate the meteor within each frame, we employ the Gradient-weighted Class Activation Mapping (Grad-CAM) technique. This method facilitates the identification of the region of interest by multiplying the activations from the last convolutional layer with the average of the gradients across the feature map of that layer. By combining these findings with the activation map derived from the first convolutional layer, we effectively pinpoint the most probable pixel location of the meteor. We trained and evaluated our model on a large dataset collected by the Spanish Meteor Network (SPMN) and achieved a precision of 98%. Our new methodology presented here has the potential to reduce the workload of meteor scientists and station operators and improve the accuracy of meteor tracking and classification.
Keywords: Meteorites; Meteors; Meteoroids; Machine learning; Convolutional neural networks; Transfer learning

Xue Han, Daniel Carroll, Tingting Yu,
Reproducing performance bug reports in server applications: The researchers’ experiences,
Journal of Systems and Software,
Volume 156,
2019,
Pages 268-282,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2019.06.100.
(https://www.sciencedirect.com/science/article/pii/S0164121219301438)
Abstract: Performance is one of the key aspects of non-functional qualities as performance bugs can cause significant performance degradation and lead to poor user experiences. While bug reports are intended to help developers to understand and fix bugs, they are also extensively used by researchers for finding benchmarks to evaluate their testing and debugging approaches. Although researchers spend a considerable amount of time and effort in finding usable performance bugs from bug repositories, they often get only a few. Reproducing performance bugs is difficult even for performance bugs that are confirmed by developers with domain knowledge. The amount of information disclosed in a bug report may not always be sufficient to reproduce the performance bug for researchers, and thus hinders the usability of bug repository as the resource for finding benchmarks. In this paper, we study the characteristics of confirmed performance bugs by reproducing them using only informations available from the bug report to examine the challenges of bug reproduction from the perspective of researchers. We spent more than 800 h over the course of six months to study and to try to reproduce 93 confirmed performance bugs, which are randomly sampled from two large-scale open-source server applications. We (1) studied the characteristics of the reproduced performance bug reports; (2) summarized the causes of failed-to-reproduce performance bug reports from the perspective of researchers by reproducing bugs that have been solved in bug reports; (3) shared our experience on suggesting workarounds to improve the bug reproduction success rate; (4) delivered a virtual machine image that contains a set of 17 ready-to-execute performance bug benchmarks. The findings of our study provide guidance and a set of suggestions to help researchers to understand, evaluate, and successfully replicate performance bugs.
Keywords: Performance bug reproduction; Bug characteristics study; Experience report

Jalaj Pachouly, Swati Ahirrao, Ketan Kotecha, Ganeshsree Selvachandran, Ajith Abraham,
A systematic literature review on software defect prediction using artificial intelligence: Datasets, Data Validation Methods, Approaches, and Tools,
Engineering Applications of Artificial Intelligence,
Volume 111,
2022,
104773,
ISSN 0952-1976,
https://doi.org/10.1016/j.engappai.2022.104773.
(https://www.sciencedirect.com/science/article/pii/S0952197622000616)
Abstract: Delivering high-quality software products is a challenging task. It needs proper coordination from various teams in planning, execution, and testing. Many software products have high numbers of defects revealed in a production environment. Software failures are costly regarding money, time, and reputation for a business and even life-threatening if utilized in critical applications. Identifying and fixing software defects in the production system is costly, which could be a trivial task if detected before shipping the product. Binary classification is commonly used in existing software defect prediction studies. With the advancements in Artificial Intelligence techniques, there is a great potential to provide meaningful information to software development teams for producing quality software products. An extensive survey for Software Defect Prediction is necessary for exploring datasets, data validation methods, defect detection, and prediction approaches and tools. The survey infers standard datasets utilized in early studies lack adequate features and data validation techniques. According to the finding of the literature survey, the standard datasets has few labels, resulting in insufficient details regarding defects. Systematic Literature Reviews (SLR) on Software Defect Prediction are limited. Hence this SLR presents a comprehensive analysis of defect datasets, dataset validation, detection, prediction approaches, and tools for Software Defect Prediction. The survey exhibits the futuristic recommendations that will allow researchers to develop a tool for Software Defect Prediction. The survey introduces the architecture for developing a software prediction dataset with adequate features and statistical data validation techniques for multi-label classification for software defects.
Keywords: Software defect prediction; Classification; Artificial intelligence; Machine learning

TianTian Wang, HaiLong Yu, KeChao Wang, XiaoHong Su,
Fault localization based on wide & deep learning model by mining software behavior,
Future Generation Computer Systems,
Volume 127,
2022,
Pages 309-319,
ISSN 0167-739X,
https://doi.org/10.1016/j.future.2021.09.026.
(https://www.sciencedirect.com/science/article/pii/S0167739X21003721)
Abstract: Many learning based fault localization approaches haven been proposed to improve the effectiveness by fusing various dimension of fault diagnosis features. However, method calls behavior has been neglected, and the interaction between features has not been fully explored. To solve this problem, firstly, a fault localization method by mining software behavior graphs has been proposed to improve the effectiveness of localizing function call related faults. Then, a fault localization approach by wide & deep learning on multi-feature groups has been proposed. Not only the spectrum based and mutation based suspiciousness features have been analyzed, but also the behavior based and invariants based suspiciousness, the static metrics, as well as the combined features of crash stack trace with the invariants change features have been integrated. Wide & Deep model is adopted as the ranking model, to explore the relationships between these features, so as to improve the effectiveness of fault localization. Experiments on practical software defects benchmark Defects4J have shown that our model outperforms the traditional spectrum-based and mutation-based approaches, it also outperforms the state-art-of learning-based approaches on the capability of early fault detection.
Keywords: Fault localization; Learning to rank; Wide & deep learning; Software behavior

Zied Ben Houidi, Dario Rossi,
Neural language models for network configuration: Opportunities and reality check,
Computer Communications,
Volume 193,
2022,
Pages 118-125,
ISSN 0140-3664,
https://doi.org/10.1016/j.comcom.2022.06.035.
(https://www.sciencedirect.com/science/article/pii/S0140366422002377)
Abstract: Boosted by deep learning, natural language processing (NLP) techniques have recently seen spectacular progress, mainly fueled by breakthroughs both in representation learning with word embeddings (e.g. word2vec) as well as novel architectures (e.g. transformers). This success quickly invited researchers to explore the use of NLP techniques to other field, such as computer programming languages, with the promise to automate tasks in software programming (bug detection, code synthesis, code repair, cross language translation etc.). By extension, NLP has potential for application to network configuration languages as well, for instance considering tasks such as network configuration verification, synthesis, and cross-vendor translation. In this paper, we survey recent advances in deep learning applied to programming languages, for the purpose of code verification, synthesis and translation: in particularly, we review their training requirements and expected performance, and qualitatively assess whether similar techniques can benefit corresponding use-cases in networking.
Keywords: Natural language processing; Code verification; Synthesis; Translation; Network configuration verification; Synthesis translation

Meng-Jie Lin, Cheng-Zen Yang, Chao-Yuan Lee, Chun-Chang Chen,
Enhancements for duplication detection in bug reports with manifold correlation features,
Journal of Systems and Software,
Volume 121,
2016,
Pages 223-233,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2016.02.022.
(https://www.sciencedirect.com/science/article/pii/S0164121216000546)
Abstract: In software maintenance activities, bug report processing is a major task in deriving crucial information for bug fixing. Because a considerable fraction of bug reports comprises duplicates in many projects, the duplicate reports must be identified for processing efficiency. Various text mining schemes have been proposed to handle this detection problem. This paper proposes an enhanced support vector machines (SVM) model (SVM-SBCTC) by considering the manifold textual and semantic correlation features based on a previous SVM-based discriminative scheme (SVM-54). We conducted empirical studies on three open source software projects: Apache, ArgoUML, and SVN. Compared with the SVM-54 scheme, SVM-SBCTC demonstrates promising detection performance in achieving relative improvements ranging 2.79%–28.97% in the top-5 recall rates among three projects. Furthermore, SVM-SBCTC demonstrates the top performance among various other weighting schemes in most cases.
Keywords: Duplication detection; Bug reports; Correlation features

L.L. Minku,
Which machine learning method do you need?,
Editor(s): Tim Menzies, Laurie Williams, Thomas Zimmermann,
Perspectives on Data Science for Software Engineering,
Morgan Kaufmann,
2016,
Pages 155-159,
ISBN 9780128042069,
https://doi.org/10.1016/B978-0-12-804206-9.00030-1.
(https://www.sciencedirect.com/science/article/pii/B9780128042069000301)
Abstract: Machine learning can be used for several different software data analytics tasks, providing useful insights into software processes and products. For example, it can reveal what software modules are most likely to contain bugs, what amount of effort is likely to be required to develop new software projects, what commits are most likely to induce crashes, how the productivity of a company changes over time, how to improve productivity, etc. The right machine learning algorithm depends on the data and the environment being modeled. Therefore, in order to create good data models, it is important to investigate the data analytics problem in hand before choosing the type of machine learning algorithm to be used. This chapter discusses questions that software engineers can ask about their data analytics problem in order to choose an appropriate machine learning algorithm.
Keywords: Machine learning; Machine learning styles; Software effort estimation; Software bug prediction; Crash-inducing commits

Madhura Jayaratne, Damminda Alahakoon, Daswin de Silva,
Unsupervised skill transfer learning for autonomous robots using distributed Growing Self Organizing Maps,
Robotics and Autonomous Systems,
Volume 144,
2021,
103835,
ISSN 0921-8890,
https://doi.org/10.1016/j.robot.2021.103835.
(https://www.sciencedirect.com/science/article/pii/S0921889021001202)
Abstract: A persistent challenge in the cognitive development of autonomous robotics is the unsupervised and unstructured nature of skill transfer learning where the Self Organizing Map (SOM) has been used as the enabling technology. The Growing Self-Organizing Map (GSOM) algorithm is an unsupervised, structure-adapting machine learning algorithm conventionally used for data exploration, clustering, visualization, outlier detection and dimensionality reduction. In this paper, we present the design and development of a new distributed algorithm based on the GSOM for unsupervised skill transfer learning in autonomous robotics settings which overcomes the key limitations of the SOM in real-life scenarios. We posit this new algorithm will be directly applicable to skill transfer learning scenarios that require unsupervised, incremental and on-going self-learning of multi-tasks and knowledge transfer. The distributed and scalable properties of the proposed algorithm handle large volumes of data required for unsupervised skill transfer learning, based on data parallelization. It generates multiple maps representing diverse skill knowledge, which are then projected together to a single embedding. The new algorithm is positioned within an autonomous developmental robotics framework for knowledge acquisition and skill transfer learning. This framework was further adapted to three contemporary distributed computing platforms, Hadoop, Spark and Hama. Empirical evaluation of these three adaptations using several benchmark and real-life datasets demonstrates its practical value and computational efficiency for unsupervised skill transfer learning in autonomous robots.
Keywords: Autonomous robots; Skill transfer learning; Distributed self-organizing map; Knowledge transfer; Growing Self-Organizing Map; MapReduce; Resilient Distributed Dataset; Bulk Synchronous Parallel; Developmental robotics; Unsupervised machine learning; Artificial intelligence

O.O. Büyük, A. Nizam,
Deep learning with class-level abstract syntax tree and code histories for detecting code modification requirements,
Journal of Systems and Software,
Volume 206,
2023,
111851,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111851.
(https://www.sciencedirect.com/science/article/pii/S0164121223002467)
Abstract: Improving code quality is one of the most significant issues in the software industry. Deep learning is an emerging area of research for detecting code smells and addressing refactoring requirements. The aim of this study is to develop a deep learning-based system for code modification analysis to predict the locations and types of code modifications, while significantly reducing the need for manual labeling. We created an experimental dataset by collecting historical code data from open-source project repositories on the Internet. We introduce a novel class-level abstract syntax tree-based code embedding method for code analysis. A recurrent neural network was employed to effectively identify code modification requirements. Our system achieves an average accuracy of approximately 83% across different repositories and 86% for the entire dataset. These findings indicate that our system provides higher performance than the method-based and text-based code embedding approaches. In addition, we performed a comparative analysis with a static code analysis tool to justify the readiness of the proposed model for deployment. The correlation coefficient between the outputs demonstrates a significant correlation of 67%. Consequently, this research highlights that the deep learning-based analysis of code histories empowers software teams in identifying potential code modification requirements.
Keywords: Refactoring; Code smell; Recurrent neural network; Abstract syntax tree; Code embedding

Yang Zhang, Chuyan Ge, Shuai Hong, Ruili Tian, Chunhao Dong, Jingjing Liu,
DeleSmell: Code smell detection based on deep learning and latent semantic analysis,
Knowledge-Based Systems,
Volume 255,
2022,
109737,
ISSN 0950-7051,
https://doi.org/10.1016/j.knosys.2022.109737.
(https://www.sciencedirect.com/science/article/pii/S0950705122008796)
Abstract: The presence of code smells will increase the risk of failure, make software difficult to maintain, and introduce potential technique debt in the future. Although many deep-learning-based approaches have been proposed to detect code smells, most existing works suffer from the problem of incomplete feature extraction and unbalanced distribution between positive samples and negative samples. Furthermore, the accuracy of existing works can be further improved. This paper proposes a novel approach named DeleSmell to detect code smells based on a deep learning model. The dataset is built by extracting samples from 24 real-world projects. To improve the imbalance in the dataset, a refactoring tool is developed to automatically transform good source code into smelly code and to generate positive samples based on real cases. DeleSmell collects both structural features through iPlasma and semantic features via latent semantic analysis and word2vec. DeleSmell’s model includes a convolutional neural network(CNN) branch and gate recurrent unit(GRU)-attention branch. The final classification is conducted by an support vector machine(SVM). In the experimentation, the effectiveness of DeleSmell is evaluated by answering seven research questions. The experimental results show that DeleSmell improves the accuracy of brain class (BC) and brain method (BM) code smells detection by up to 4.41% compared with existing approaches, demonstrating the effectiveness of our approach.
Keywords: Code smell; Deep learning; Refactoring; Latent semantic analysis

Yue Yu, Huaimin Wang, Gang Yin, Tao Wang,
Reviewer recommendation for pull-requests in GitHub: What can we learn from code review and bug assignment?,
Information and Software Technology,
Volume 74,
2016,
Pages 204-218,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2016.01.004.
(https://www.sciencedirect.com/science/article/pii/S0950584916000069)
Abstract: Context: The pull-based model, widely used in distributed software development, offers an extremely low barrier to entry for potential contributors (anyone can submit of contributions to any project, through pull-requests). Meanwhile, the project’s core team must act as guardians of code quality, ensuring that pull-requests are carefully inspected before being merged into the main development line. However, with pull-requests becoming increasingly popular, the need for qualified reviewers also increases. GitHub facilitates this, by enabling the crowd-sourcing of pull-request reviews to a larger community of coders than just the project’s core team, as a part of their social coding philosophy. However, having access to more potential reviewers does not necessarily mean that it’s easier to find the right ones (the “needle in a haystack” problem). If left unsupervised, this process may result in communication overhead and delayed pull-request processing. Objective: This study aims to investigate whether and how previous approaches used in bug triaging and code review can be adapted to recommending reviewers for pull-requests, and how to improve the recommendation performance. Method: First, we extend three typical approaches used in bug triaging and code review for the new challenge of assigning reviewers to pull-requests. Second, we analyze social relations between contributors and reviewers, and propose a novel approach by mining each project’s comment networks (CNs). Finally, we combine the CNs with traditional approaches, and evaluate the effectiveness of all these methods on 84 GitHub projects through both quantitative and qualitative analysis. Results: We find that CN-based recommendation can achieve, by itself, similar performance as the traditional approaches. However, the mixed approaches can achieve significant improvements compared to using either of them independently. Conclusion: Our study confirms that traditional approaches to bug triaging and code review are feasible for pull-request reviewer recommendations on GitHub. Furthermore, their performance can be improved significantly by combining them with information extracted from prior social interactions between developers on GitHub. These results prompt for novel tools to support process automation in social coding platforms, that combine social (e.g., common interests among developers) and technical factors (e.g., developers’ expertise).
Keywords: Pull-request; Reviewer recommendation; Social network analysis

Li Jia, Hao Zhong, Xiaoyin Wang, Linpeng Huang, Xuansheng Lu,
The symptoms, causes, and repairs of bugs inside a deep learning library,
Journal of Systems and Software,
Volume 177,
2021,
110935,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2021.110935.
(https://www.sciencedirect.com/science/article/pii/S0164121221000327)
Abstract: In recent years, deep learning has become a hot research topic. Although it achieves incredible positive results in some scenarios, bugs inside deep learning software can introduce disastrous consequences, especially when the software is used in safety-critical applications. To understand the bug characteristic of deep learning software, researchers have conducted several empirical studies on bugs in deep learning applications. Although these studies present useful findings, we notice that none of them analyze the bug characteristic inside a deep learning library like TensorFlow. We argue that some fundamental questions of bugs in deep learning libraries are still open. For example, what are the symptoms and the root causes of bugs inside TensorFlow, and where are they? As the underlying library of many deep learning projects, the answers to these questions are useful and important, since its bugs can have impacts on many deep learning projects. In this paper, we conduct the first empirical study to analyze the bugs inside a typical deep learning library, i.e., TensorFlow. Based on our results, we summarize 8 findings, and present our answers to 4 research questions. For example, we find that the symptoms and root causes of TensorFlow bugs are more like ordinary projects (e.g., Mozilla) than other machine learning libraries (e.g., Lucene). As another example, we find that most TensorFlow bugs reside in its interfaces (26.24%), learning algorithms (11.79%), and how to compile (8.02%), deploy (7.55%), and install (4.72%) TensorFlow across platforms.
Keywords: Deep learning; Bug analysis; TensorFlow; Empirical study

Thiago S. Alves, M. Alice Pinto, Paulo Ventura, Cátia J. Neves, David G. Biron, Arnaldo C. Junior, Pedro L. De Paula Filho, Pedro J. Rodrigues,
Automatic detection and classification of honey bee comb cells using deep learning,
Computers and Electronics in Agriculture,
Volume 170,
2020,
105244,
ISSN 0168-1699,
https://doi.org/10.1016/j.compag.2020.105244.
(https://www.sciencedirect.com/science/article/pii/S0168169919307690)
Abstract: In a scenario of worldwide honey bee decline, assessing colony strength is becoming increasingly important for sustainable beekeeping. Temporal counts of number of comb cells with brood and food reserves offers researchers data for multiple applications, such as modelling colony dynamics, and beekeepers information on colony strength, an indicator of colony health and honey yield. Counting cells manually in comb images is labour intensive, tedious, and prone to error. Herein, we developed a free software, named DeepBee©, capable of automatically detecting cells in comb images and classifying their contents into seven classes. By distinguishing cells occupied by eggs, larvae, capped brood, pollen, nectar, honey, and other, DeepBee© allows an unprecedented level of accuracy in cell classification. Using Circle Hough Transform and the semantic segmentation technique, we obtained a cell detection rate of 98.7%, which is 16.2% higher than the best result found in the literature. For classification of comb cells, we trained and evaluated thirteen different convolutional neural network (CNN) architectures, including: DenseNet (121, 169 and 201); InceptionResNetV2; InceptionV3; MobileNet; MobileNetV2; NasNet; NasNetMobile; ResNet50; VGG (16 and 19) and Xception. MobileNet revealed to be the best compromise between training cost, with ~9 s for processing all cells in a comb image, and accuracy, with an F1-Score of 94.3%. We show the technical details to build a complete pipeline for classifying and counting comb cells and we made the CNN models, source code, and datasets publicly available. With this effort, we hope to have expanded the frontier of apicultural precision analysis by providing a tool with high performance and source codes to foster improvement by third parties (https://github.com/AvsThiago/DeepBee-source).
Keywords: Cell classification; Apis mellifera L.; Semantic segmentation; Machine learning; Deep learning; DeepBee software

Moi Hoon Yap, Ryo Hachiuma, Azadeh Alavi, Raphael Brüngel, Bill Cassidy, Manu Goyal, Hongtao Zhu, Johannes Rückert, Moshe Olshansky, Xiao Huang, Hideo Saito, Saeed Hassanpour, Christoph M. Friedrich, David B. Ascher, Anping Song, Hiroki Kajita, David Gillespie, Neil D. Reeves, Joseph M. Pappachan, Claire O'Shea, Eibe Frank,
Deep learning in diabetic foot ulcers detection: A comprehensive evaluation,
Computers in Biology and Medicine,
Volume 135,
2021,
104596,
ISSN 0010-4825,
https://doi.org/10.1016/j.compbiomed.2021.104596.
(https://www.sciencedirect.com/science/article/pii/S0010482521003905)
Abstract: There has been a substantial amount of research involving computer methods and technology for the detection and recognition of diabetic foot ulcers (DFUs), but there is a lack of systematic comparisons of state-of-the-art deep learning object detection frameworks applied to this problem. DFUC2020 provided participants with a comprehensive dataset consisting of 2,000 images for training and 2,000 images for testing. This paper summarizes the results of DFUC2020 by comparing the deep learning-based algorithms proposed by the winning teams: Faster R–CNN, three variants of Faster R–CNN and an ensemble method; YOLOv3; YOLOv5; EfficientDet; and a new Cascade Attention Network. For each deep learning method, we provide a detailed description of model architecture, parameter settings for training and additional stages including pre-processing, data augmentation and post-processing. We provide a comprehensive evaluation for each method. All the methods required a data augmentation stage to increase the number of images available for training and a post-processing stage to remove false positives. The best performance was obtained from Deformable Convolution, a variant of Faster R–CNN, with a mean average precision (mAP) of 0.6940 and an F1-Score of 0.7434. Finally, we demonstrate that the ensemble method based on different deep learning methods can enhance the F1-Score but not the mAP.
Keywords: Diabetic foot ulcers; Object detection; Machine learning; Deep learning; DFUC2020

Dawei Yuan, Xiaohui Wang, Yao Li, Tao Zhang,
Optimizing smart contract vulnerability detection via multi-modality code and entropy embedding,
Journal of Systems and Software,
Volume 202,
2023,
111699,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111699.
(https://www.sciencedirect.com/science/article/pii/S0164121223000948)
Abstract: Smart contracts have been widely used in the blockchain world these years, and simultaneously vulnerability detection has gained more and more attention due to the staggering economic losses caused by the attacker. Existing tools that analyze vulnerabilities for smart contracts heavily rely on rules predefined by experts, which are labour-intense and require domain knowledge. Moreover, predefined rules tend to be misconceptions and increase the risk of crafty potential back-doors in the future. Recently, researchers mainly used static and dynamic execution analysis to detect the vulnerabilities of smart contracts and have achieved acceptable results. However, the dynamic method cannot cover all the program inputs and execution paths, which leads to some vulnerabilities that are hard to detect. The static analysis method commonly includes symbolic execution and theorem proving, which requires using constraints to detect vulnerability. These shortcomings show that traditional methods are challenging to apply and expand on a large scale. This paper aims to detect vulnerabilities via the Bug Injection framework and transfer learning techniques. First, we train a Transformer encoder using multi-modality code, which contains source code, intermediate representation, and assembly code. The input code consists separately of Solidity source code, intermediate representation, and assembly code. Specifically, we translate source code into the intermediate representation and decompile the byte code into assembly code by the EVM compiler. Then, we propose a novel entropy embedding technique, which combines token embedding, segment embedding, and positional embedding of the Transformer encoder in our approach. After that, we utilize the Bug Injection framework to automatically generate specific types of buggy code for fine-tuning and evaluating the performance of vulnerability detection. The experimental results show that our proposed approach improves the performance in detecting reentrancy vulnerabilities and timestamp dependence. Moreover, our approach is more flexible and scalable than static and dynamic analysis approaches in detecting smart contract vulnerabilities. Our approach improves the baseline approaches by an average of 11.89% in term of F1 score.
Keywords: Smart contract; Bug injection; Transfer learning; Vulnerability detection

Yilin Yang, Tianxing He, Zhilong Xia, Yang Feng,
A comprehensive empirical study on bug characteristics of deep learning frameworks,
Information and Software Technology,
Volume 151,
2022,
107004,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2022.107004.
(https://www.sciencedirect.com/science/article/pii/S0950584922001306)
Abstract: Context:
Deep Learning (DL) frameworks enable developers to build DNN models without learning the underlying algorithms and models. While some of these DL-based software systems have been deployed in safety-critical areas, such as self-driving cars and medical diagnostics, for DL frameworks, characterizing their bugs and thus helping researchers to design specific quality assurance techniques become desperately needed.
Objective:
Our research aims to characterize bugs typical of DL frameworks at the source code level for an in-depth analysis of bug symptoms, root causes, and bug fixes. In this way, we hope to provide insights for researchers to design automatic quality assurance techniques, such as automatic repair techniques and fault location techniques, applicable to DL frameworks and DL-based software systems.
Method:
We started by summarizing the DL framework reference architecture and proposing the DL framework bug taxonomy. Then, we mined 1,127 DL framework bug reports from eight popular DL frameworks and labeled the bug types, root causes, and symptoms. Finally, we discussed the bug characteristics and explored how developers could possibly deal with these bugs.
Results:
Our main findings are: (i) DNN model building bugs and general type bugs accounted for one-third of the total defects. (ii) DNN model building bugs are more prone to algorithm logic constraints, internal API errors, and data/numerical errors. (iii) Fifteen bug-fixing patterns are summarized, providing reference for common DL framework bug repair and future research on the development of automatic DL framework bug detection tools.
Conclusion:
By analyzing the bug-fixing changes, we characterize the occurrences, root causes, symptoms, and fixing of these bugs. The study results have provided researchers with insights into how to ensure DL framework quality and presented actionable suggestions for DL framework developers to improve their code quality.
Keywords: Bug characteristics; Deep learning framework; Empirical study; Bug detection

Xi Xiao, Renjie Xiao, Qing Li, Jianhui Lv, Shunyan Cui, Qixu Liu,
BugRadar: Bug localization by knowledge graph link prediction,
Information and Software Technology,
Volume 162,
2023,
107274,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107274.
(https://www.sciencedirect.com/science/article/pii/S0950584923001283)
Abstract: Context
: Information Retrieval-based Bug Localization (IRBL) aims to design automatic systems that find buggy files according to bug reports, which can reduce the time consumption to fix bugs for programmers. There has been extensive research on IRBL techniques in recent years. However, these methods cannot make full use of the structure information in bug reports and source files.
Objective
: In this paper, we propose a novel scheme BugRadar. It combines text features and structure features from bug reports and source files for bug localization. Especially, BugRadar leverages a knowledge graph to make use of structure features.
Method
: We originally propose a knowledge graph named TriGraph based on structure features and apply hyperbolic attention embedding to get the link prediction scores. For text features, we propose Partial Text Similarity which improves traditional Text Similarity and Method Level Text Similarity. We also propose Word Collaborative Filtering Score which leverages historical bug reports with more attention on important terms. Finally, we calculate the final suspicious scores based on the structure features, text features, and fixing time information from bug fixing history with a neural network.
Results
: We apply our scheme to four projects (Tomcat, SWT, JDT, and Birt) in a popular dataset and get approving results. BugRadar gets better results than other state-of-the-art methods on three projects out of the four. It achieves a relative improvement of 8.8% in SWT and 9.8% in JDT for Mean Average Precision compared to the previous best scheme KGBugLocator and 11.4% in Birt compared to Adaptive Regression.
Conclusions
: BugRadar can achieve approving performance on large-scale projects with enough historical bug reports. It verifies that knowledge graphs are capable of representing the structure features for bug localization. The novel Partial Text Similarity and Word Collaborative Filtering Score are both effective improvements for using text features.
Keywords: Bug localization; Knowledge graph; Collaborative filtering

Juliana Alves Pereira, Mathieu Acher, Hugo Martin, Jean-Marc Jézéquel, Goetz Botterweck, Anthony Ventresque,
Learning software configuration spaces: A systematic literature review,
Journal of Systems and Software,
Volume 182,
2021,
111044,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2021.111044.
(https://www.sciencedirect.com/science/article/pii/S0164121221001412)
Abstract: Most modern software systems (operating systems like Linux or Android, Web browsers like Firefox or Chrome, video encoders like ffmpeg, x264 or VLC, mobile and cloud applications, etc.) are highly configurable. Hundreds of configuration options, features, or plugins can be combined, each potentially with distinct functionality and effects on execution time, security, energy consumption, etc. Due to the combinatorial explosion and the cost of executing software, it is quickly impossible to exhaustively explore the whole configuration space. Hence, numerous works have investigated the idea of learning it from a small sample of configurations’ measurements. The pattern “sampling, measuring, learning” has emerged in the literature, with several practical interests for both software developers and end-users of configurable systems. In this systematic literature review, we report on the different application objectives (e.g., performance prediction, configuration optimization, constraint mining), use-cases, targeted software systems, and application domains. We review the various strategies employed to gather a representative and cost-effective sample. We describe automated software techniques used to measure functional and non-functional properties of configurations. We classify machine learning algorithms and how they relate to the pursued application. Finally, we also describe how researchers evaluate the quality of the learning process. The findings from this systematic review show that the potential application objective is important; there are a vast number of case studies reported in the literature related to particular domains or software systems. Yet, the huge variant space of configurable systems is still challenging and calls to further investigate the synergies between artificial intelligence and software engineering.
Keywords: Systematic literature review; Software product lines; Machine learning; Configurable systems

Padma Jayaraman, Ranjani Parthasarathi,
Performance counter based online pipeline bugs detection using machine learning techniques,
Microprocessors and Microsystems,
Volume 84,
2021,
104262,
ISSN 0141-9331,
https://doi.org/10.1016/j.micpro.2021.104262.
(https://www.sciencedirect.com/science/article/pii/S0141933121004300)
Abstract: The growing complexity of new features in multicore processors imposes significant pressure towards functional verification. Although a large amount of time and effort are spent on it, functional design bugs escape into the products and cause catastrophic effects. Hence, online design bug detection is needed to detect the functional bugs in the field. In this work, we propose a novel approach by leveraging Performance Monitoring Counters (PMC) and machine learning to detect and locate pipeline bugs in a processor. We establish the correlation between PMC events and pipeline bugs in order to extract the features to build and train machine learning models. We design and implement a synthetic bug injection framework to obtain datasets for our simulation. To evaluate the proposal, Multi2Sim simulator is used to simulate the x86 architecture model. An x86 fault model is developed to synthetically inject bugs in x86 pipeline stages. PMC event values are collected by executing the SPEC CPU2006 and MiBench benchmarks for both bug and no-bug scenarios in the x86 simulator. This training data obtained through simulation is used to build a Bug Detection Model (BDM) that detects a pipeline bug and a Bug Location Model (BLM) that locates the pipeline unit where the bug occurred. Simulation results show that both BDM and BLM provide an accuracy of 97.3% and 91.6% using Decision tree and Random forest, respectively. When compared against other state of art approaches, our solution can locate the pipeline unit where the bug occurred with a high accuracy and without using additional hardware.
Keywords: Performance monitoring counters; Bug detection; Machine learning; Online design bug detection

Zhuo Zhang, Ya Li, Sha Yang, Zhanjun Zhang, Yan Lei,
Code-aware fault localization with pre-training and interpretable machine learning,
Expert Systems with Applications,
Volume 238, Part A,
2024,
121689,
ISSN 0957-4174,
https://doi.org/10.1016/j.eswa.2023.121689.
(https://www.sciencedirect.com/science/article/pii/S0957417423021917)
Abstract: Following the rapid development of deep learning, many studies in the field of fault localization (FL) have utilized deep learning to analyze statements’ coverage information (i.e., executed or not executed) and test cases’ results (i.e., failing or passing), which have shown dramatic ability in identifying suspicious statements potentially responsible for failures. However, they mainly pay attention to the binary information of executing test cases but ignore incorporating code snippets and their inner relationships into the learning process. Furthermore, how a complex deep learning model for FL achieves a particular decision is not transparent. These drawbacks may limit the effectiveness of FL. Recently, graph-based pre-training techniques have dramatically improved the state-of-the-art in a variety of code-related tasks such as natural language code search, clone detection, code translation, code refinement, etc. And interpretable machine learning tackles the problem of non-transparency and enables learning models to explain or present their behaviors to humans in an understandable way. In this paper, our insight is to select a candidate solution that leverages the promising learning ability of graph-based pre-training techniques to learn a feasible model for incorporating code snippets as well as their inner relationships into fault localization, and then uses interpretable machine learning to localize faulty statements. Thus, we propose CodeAwareFL, a code-aware fault localization technique with pre-training and interpretable machine learning. Concretely, CodeAwareFL constructs a variety of code snippets through executing test cases. Next, CodeAwareFL utilizes the code snippets to extract propagation chains which could show a set of variables interact with each other to cause a failure. After that, a graph-based pre-trained model is customized for fault localization. CodeAwareFL takes the code snippets and their corresponding propagation chains as inputs with test results as labels to conduct the training process. Finally, CodeAwareFL evaluates the suspiciousness of statements with interpretable machine learning techniques. In the experimental study, we choose 12 large-sized programs to conduct the comparison. The results show that CodeAwareFL achieves promising results (e.g., 32.43% faults are ranked within top 5), and is significantly better than 12 state-of-the-art baselines.
Keywords: Fault localization; Pre-training; Interpretable machine learning

Ayoub Si-Ahmed, Mohammed Ali Al-Garadi, Narhimene Boustia,
Survey of Machine Learning based intrusion detection methods for Internet of Medical Things,
Applied Soft Computing,
Volume 140,
2023,
110227,
ISSN 1568-4946,
https://doi.org/10.1016/j.asoc.2023.110227.
(https://www.sciencedirect.com/science/article/pii/S1568494623002454)
Abstract: The Internet of Medical Things (IoMT) has revolutionized the healthcare industry by enabling physiological data collection using sensors, which are transmitted to remote servers for continuous analysis by physicians and healthcare professionals. This technology offers numerous benefits, including early disease detection and automatic medication for patients with chronic illnesses. However, IoMT technology also presents significant security risks, such as violating patient privacy or exposing sensitive data to interception attacks due to wireless communication, which could be fatal for the patient. Additionally, traditional security measures, such as cryptography, are challenging to implement in medical equipment due to the heterogeneous communication and their limited computation, storage, and energy capacity. These protection methods are also ineffective against new and zero-day attacks. It is essential to adopt robust security measures to ensure data integrity, confidentiality, and availability during data collection, transmission, storage, and processing. In this context, using Intrusion Detection Systems (IDS) based on Machine Learning (ML) can bring a complementary security solution adapted to the unique characteristics of IoMT systems. Therefore, this paper investigates how IDS based on ML can address security and privacy issues in IoMT systems. First, the generic three-layer architecture of IoMT is provided, and the security requirements of IoMT systems are outlined. Then, the various threats that can affect IoMT security are identified, and the advantages, disadvantages, methods, and datasets used in each solution based on ML at the three layers that make up IoMT are presented. Finally, the paper discusses the challenges and limitations of applying IDS based on ML at each layer of IoMT, which can serve as a future research direction.
Keywords: Internet of Medical Things; Intrusion Detection System; Machine Learning; Privacy; Security

Khaldoon Dhou, Christopher Cruzen,
An innovative chain coding mechanism for information processing and compression using a virtual bat-bug agent-based modeling simulation,
Engineering Applications of Artificial Intelligence,
Volume 113,
2022,
104888,
ISSN 0952-1976,
https://doi.org/10.1016/j.engappai.2022.104888.
(https://www.sciencedirect.com/science/article/pii/S0952197622001282)
Abstract: The continuous changes in the size of data create new challenges to design new techniques to reduce its size and encode it in a way that changes its original representation. In this article, we develop a bat-bug agent-based modeling simulation for chain coding and employ it in compressing bi-level image information. The system consists of agents that are classified into static and dynamic depending on their movements. Bugs are considered static agents, and they are distributed over the virtual environment according to the allocation of pixels in the original image. On the other hand, bats are dynamic agent, and their role is to move around to consume bugs while the algorithm tracks their movements. Bats are designed in a way to move within certain boundaries to avoid crashing into each other. Bats employ specific movements that allow them to move in relative directions. Therefore, the frequency of their movements can follow a certain pattern that can help in further size reduction. In other words, the integration of relative movements into our design proved to be advantageous because there is an observable pattern of repeated movements, which allows getting higher compression results. Finally, arithmetic coding is applied to the final strings that represent the movements of bats while searching for bugs to eat. To assess the performance of the algorithm, we compared the findings against standardized benchmarks used in the image processing community: G3, G4, JBIG1, and JBIG2. The outcomes show that we could outperform all these benchmarks using all the images we used for testing. Additionally, we conducted a series of paired samples t-tests, and they revealed that the mean differences between our results and those obtained from other benchmarks are statistically significant.
Keywords: Agent-based modeling; Chain code; Bi-level image; Compression; Bats; Simulation; Virtual environment; Arithmetic coding; JBIG

Zhuo Zhang, Yan Lei, Xiaoguang Mao, Meng Yan, Ling Xu, Xiaohong Zhang,
A study of effectiveness of deep learning in locating real faults,
Information and Software Technology,
Volume 131,
2021,
106486,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2020.106486.
(https://www.sciencedirect.com/science/article/pii/S0950584920302287)
Abstract: Context: The recent progress of deep learning has shown its promising learning ability in making sense of data, and many fields have utilized this learning ability to learn an effective model, successfully solving their problems. Fault localization has explored and used deep learning to server an aid in debugging, showing the promising results on fault localization. However, as far as we know, there is no detailed studies on evaluating the benefits of using deep learning for locating real faults present in programs. Objective: To understand the benefits of deep learning in locating real faults, this paper explores more about deep learning by studying the effectiveness of fault localization using deep learning for a set of real bugs reported in the widely used programs. Method: We use three representative deep learning architectures (i.e. convolutional neural network, recurrent neural network and multi-layer perceptron) for fault localization, and conduct large-scale experiments on 8 real-world programs equipped with all real faults to evaluate their effectiveness on fault localization. Results: We observe that the localization effectiveness varies considerably among three neural networks in the context of real faults. Specifically, convolutional neural network performs the best in locating real faults, showing an average of 38.97% and 26.22% saving over multi-layer perceptron and recurrent neural network respectively; recurrent neural network and multi-layer perceptron yield comparable effectiveness even if the effectiveness of recurrent neural network is marginally higher than multi-layer perceptron. Conclusion: In context of real faults, convolutional neural network is the most effective for fault localization among the investigated architectures, and we suggest potential factors of deep learning for improving fault localization.
Keywords: Fault localization; Debugging; Neural networks; Deep learning; Suspiciousness

Guoyun Duan, Yuanzhi Fu, Minjie Cai, Hao Chen, Jianhua Sun,
DongTing: A large-scale dataset for anomaly detection of the Linux kernel,
Journal of Systems and Software,
Volume 203,
2023,
111745,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111745.
(https://www.sciencedirect.com/science/article/pii/S0164121223001401)
Abstract: Host-based intrusion detection systems (HIDS) can automatically identify adversarial applications by learning models from system events that represent normal system behaviors. The system call is the only way for applications to interact with the operating system (OS). Thus, system call sequences are traditionally used in HIDS to train models to detect novel attacks, and a wide range of datasets has been proposed for this task. However, existing datasets are either built for user-level applications (not for OS kernels), or completely outdated (proposed more than 20 years ago). To address this issue, this paper presents the first large-scale dataset specifically assembled for anomaly detection of the Linux kernel. The task of creating such a dataset is challenging due to the difficulty both in collecting a diversified set of programs that can trigger bugs in the kernel and in tracing events that may crash the kernel at runtime. In this paper, we describe in detail how to collect the data through an automated and efficient framework. The raw dataset is 85 GB in size, and contains 18,966 system call sequences that are labeled with normal and abnormal attributes. Our dataset covers more than 200 kernel versions (including major/minor releases and revisions) and 3,600 bug-triggering programs in the past five years. In addition, we conduct cross-dataset evaluation to demonstrate that training on our dataset enables superior generalization ability than other related datasets, and provide benchmark results for anomaly detection of Linux kernel on our dataset. Our extensive dataset is both useful for machine learning researchers focusing on algorithmic optimizations and practitioners in kernel development who are interested in deploying deep learning models in OS kernels.
Keywords: Anomaly detection; Dataset; Linux kernel; System calls; Kernel BUG; Deep learning

Amin Kargar, Dimitrios Zorbas, Salvatore Tedesco, Michael Gaffney, Brendan O’Flynn,
Detecting Halyomorpha halys using a low-power edge-based monitoring system,
Computers and Electronics in Agriculture,
Volume 221,
2024,
108935,
ISSN 0168-1699,
https://doi.org/10.1016/j.compag.2024.108935.
(https://www.sciencedirect.com/science/article/pii/S0168169924003260)
Abstract: Smart monitoring systems in orchards can automate agriculture monitoring processes and provide useful information about the presence of insects, such as the Brown Marmorated Stink Bug (BMSB), that threaten the production quantity and quality of fruit such as pears. Unlike other approaches in the literature, we propose a low-cost image monitoring system which exhibits a very low power consumption without compromising much of the accuracy that existing expensive systems incorporating significant computing and processing capability can achieve in such applications. The proposed system relies on a microcontroller unit and a camera which can take pictures of a double-sided sticky insect trap which, with the help of novel machine learning algorithms, can report on the presence of BMSB via a long-range communication link. The Internet of Things data capture and analysis system has recently been deployed in a real orchard in Italy which is subject to BMSB infestation and the first images have been analysed. This paper presents how the system works, the image processing, detection and classification algorithms, as well as a demonstration of the memory and energy consumption associated with the processing algorithms. The system achieves an accuracy of over 90% with multiple times less memory and energy consumption compared to other similar approaches in the literature.
Keywords: Halyomorpha halys; Edge computing; Machine learning; Deep learning

Zhengfa Li, Chuanhe Huang, Shuhua Deng, Wanyu Qiu, Xieping Gao,
A soft actor-critic reinforcement learning algorithm for network intrusion detection,
Computers & Security,
Volume 135,
2023,
103502,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103502.
(https://www.sciencedirect.com/science/article/pii/S0167404823004121)
Abstract: Network intrusion detection plays a very important role in network security. Although current deep learning-based intrusion detection algorithms have achieved good detection performance, there are still limitations in dealing with unbalanced datasets and identifying minority attacks and unknown attacks. In this paper, we propose an intrusion detection model AE-SAC based on adversarial environment learning and soft actor-critic reinforcement learning algorithm. First, this paper introduces an environmental agent for training data resampling to solve the imbalance problem of the original data. Second, rewards are redefined in reinforcement learning. In order to improve the recognition rate of few categories of network attacks, we set different reward values for different categories of attacks. The environment agent and classifier agent are trained adversarially around maximizing their respective reward values. Finally, a multi-classification experiment is conducted on the NSL-KDD and AWID datasets to compare with the existed excellent intrusion detection algorithms. AE-SAC achieves excellent classification performance with an accuracy of 84.15% and a f1-score of 83.97% on the NSL-KDD dataset, and an accuracy and a f1-score over 98.9% on the AWID dataset.
Keywords: Network security; Anomaly detection; Network intrusion detection; Deep reinforcement learning; Soft actor-critic

Thomas Hirsch, Birgit Hofer,
Using textual bug reports to predict the fault category of software bugs,
Array,
Volume 15,
2022,
100189,
ISSN 2590-0056,
https://doi.org/10.1016/j.array.2022.100189.
(https://www.sciencedirect.com/science/article/pii/S259000562200042X)
Abstract: Debugging is a time-consuming and expensive process. Developers have to select appropriate tools, methods and approaches in order to efficiently reproduce, localize and fix bugs. These choices are based on the developers’ assessment of the type of fault for a given bug report. This paper proposes a machine learning (ML) based approach that predicts the fault type for a given textual bug report. We built a dataset from 70+ projects for training and evaluation of our approach. Further, we performed a user study to establish a baseline for non-expert human performance on this task. Our models, incorporating our custom preprocessing approaches, reach up to 0.69% macro average F1 score on this bug classification problem. We demonstrate inter-project transferability of our approach. Further, we identify and discuss issues and limitations of ML classification approaches applied on textual bug reports. Our models can support researchers in data collection efforts, as for example bug benchmark creation. In future, such models could aid inexperienced developers in debugging tool selection, helping save time and resources.
Keywords: Bug report; Bug benchmark; Fault type prediction

Tushar Sharma, Vasiliki Efstathiou, Panos Louridas, Diomidis Spinellis,
Code smell detection by deep direct-learning and transfer-learning,
Journal of Systems and Software,
Volume 176,
2021,
110936,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2021.110936.
(https://www.sciencedirect.com/science/article/pii/S0164121221000339)
Abstract: Context:
An excessive number of code smells make a software system hard to evolve and maintain. Machine learning methods, in addition to metric-based and heuristic-based methods, have been recently applied to detect code smells; however, current methods are considered far from mature.
Objective:
First, explore the feasibility of applying deep learning models to detect smells without extensive feature engineering. Second, investigate the possibility of applying transfer-learning in the context of detecting code smells.
Methods:
We train smell detection models based on Convolution Neural Networks and Recurrent Neural Networks as their principal hidden layers along with autoencoder models. For the first objective, we perform training and evaluation on C# samples, whereas for the second objective, we train the models from C# code and evaluate the models over Java code samples and vice-versa.
Results:
We find it feasible to detect smells using deep learning methods though the models’ performance is smell-specific. Our experiments show that transfer-learning is definitely feasible for implementation smells with performance comparable to that of direct-learning. This work opens up a new paradigm to detect code smells by transfer-learning especially for the programming languages where the comprehensive code smell detection tools are not available.
Keywords: Code smells; Smell detection tools; Deep learning; Transfer-learning

Hazim Hanif, Mohd Hairul Nizam Md Nasir, Mohd Faizal Ab Razak, Ahmad Firdaus, Nor Badrul Anuar,
The rise of software vulnerability: Taxonomy of software vulnerabilities detection and machine learning approaches,
Journal of Network and Computer Applications,
Volume 179,
2021,
103009,
ISSN 1084-8045,
https://doi.org/10.1016/j.jnca.2021.103009.
(https://www.sciencedirect.com/science/article/pii/S1084804521000369)
Abstract: The detection of software vulnerability requires critical attention during the development phase to make it secure and less vulnerable. Vulnerable software always invites hackers to perform malicious activities and disrupt the operation of the software, which leads to millions in financial losses to software companies. In order to reduce the losses, there are many reliable and effective vulnerability detection systems introduced by security communities aiming to detect the software vulnerabilities as early as in the development or testing phases. To summarise the software vulnerability detection system, existing surveys discussed the conventional and data mining approaches. These approaches are widely used and mostly consist of traditional detection techniques. However, they lack discussion on the newly trending machine learning approaches, such as supervised learning and deep learning techniques. Furthermore, existing studies fail to discuss the growing research interest in the software vulnerability detection community throughout the years. With more discussion on this, we can predict and focus on what are the research problems in software vulnerability detection that need to be urgently addressed. Aiming to reduce these gaps, this paper presents the research interests’ taxonomy in software vulnerability detection, such as methods, detection, features, code and dataset. The research interest categories exhibit current trends in software vulnerability detection. The analysis shows that there is considerable interest in addressing methods and detection problems, while only a few are interested in code and dataset problems. This indicates that there is still much work to be done in terms of code and dataset problems in the future. Furthermore, this paper extends the machine learning approaches taxonomy, which is used to detect the software vulnerabilities, like supervised learning, semi-supervised learning, ensemble learning and deep learning. Based on the analysis, supervised learning and deep learning approaches are trending in the software vulnerability detection community as these techniques are able to detect vulnerabilities such as buffer overflow, SQL injection and cross-site scripting effectively with a significant detection performance, up to 95% of F1 score. Finally, this paper concludes with several discussions on potential future work in software vulnerability detection in terms of datasets, multi-vulnerabilities detection, transfer learning and real-world applications.
Keywords: Software vulnerability detection; Software security; Computer security; Machine learning; Deep learning

Szymon Stradowski, Lech Madeyski,
Industrial applications of software defect prediction using machine learning: A business-driven systematic literature review,
Information and Software Technology,
Volume 159,
2023,
107192,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107192.
(https://www.sciencedirect.com/science/article/pii/S0950584923000460)
Abstract: Context:
Machine learning software defect prediction is a promising field of software engineering, attracting a great deal of attention from the research community; however, its industry application tents to lag behind academic achievements.
Objective:
This study is part of a larger project focused on improving the quality and minimising the cost of software testing of the 5G system at Nokia, and aims to evaluate the business applicability of machine learning software defect prediction and gather lessons learnt.
Methods:
The systematic literature review was conducted on journal and conference papers published between 2015 and 2022 in popular online databases (ACM, IEEE, Springer, Scopus, Science Direct, and Google Scholar). A quasi-gold standard procedure was used to validate the search, and SEGRESS guidelines were used for transparency, reporting, and replicability.
Results:
We have selected and analysed 32 publications out of 397 found by our automatic search (and seven by snowballing). We have identified highly relevant evidence of methods, features, frameworks, and datasets used. However, we found a minimal emphasis on practical lessons learnt and cost consciousness — both vital from a business perspective.
Conclusion:
Even though the number of machine learning software defect prediction studies validated in the industry is increasing (and we were able to identify several excellent papers on studies performed in vivo), there is still not enough practical focus on the business aspects of the effort that would help bridge the gap between the needs of the industry and academic research.
Keywords: Software defect prediction; Machine learning; Systematic literature review; Effort and cost minimisation; Real-world; Industry

Dapeng Yan, Kui Liu, Yuqing Niu, Li Li, Zhe Liu, Zhiming Liu, Jacques Klein, Tegawendé F. Bissyandé,
Crex: Predicting patch correctness in automated repair of C programs through transfer learning of execution semantics,
Information and Software Technology,
Volume 152,
2022,
107043,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2022.107043.
(https://www.sciencedirect.com/science/article/pii/S0950584922001562)
Abstract: A significant body of automated program repair literature relies on test suites to assess the validity of generated patches. Because such oracles are weak, state-of-the-art repair tools can validate some patches that overfit the test cases but are actually incorrect. This situation has become a prime concern in APR, hindering its adoption by the industry. This work investigates execution semantic features based on micro-traces, a form of under-constrained dynamic traces. We build on transfer learning to explore function code representations that are amenable to semantic similarity computation and can therefore be leveraged for classifying patch correctness. Our Crex prototype implementation is based on the Trex framework. Experimental results on patches generated by the CoCoNut APR tool on CodeFlaws programs indicate that our approach can yield high accuracy in predicting patch correctness. The learned embeddings were proven to capture semantic similarities between functions, which was instrumental in training a classifier that identifies patch correctness by learning to discriminate between correctly patched code and incorrectly patched code based on their semantic similarity with the buggy function.
Keywords: Program repair; Patch correctness; Semantic feature; Transfer learning

Hamza Kheddar, Yassine Himeur, Ali Ismail Awad,
Deep transfer learning for intrusion detection in industrial control networks: A comprehensive review,
Journal of Network and Computer Applications,
Volume 220,
2023,
103760,
ISSN 1084-8045,
https://doi.org/10.1016/j.jnca.2023.103760.
(https://www.sciencedirect.com/science/article/pii/S1084804523001790)
Abstract: Globally, the external internet is increasingly being connected to industrial control systems. As a result, there is an immediate need to protect these networks from a variety of threats. The key infrastructure of industrial activity can be protected from harm using an intrusion detection system (IDS), a preventive mechanism that seeks to recognize new kinds of dangerous threats and hostile activities. This review examines the most recent artificial-intelligence techniques that are used to create IDSs in many kinds of industrial control networks, with a particular emphasis on IDS-based deep transfer learning (DTL). DTL can be seen as a type of information-fusion approach that merges and/or adapts knowledge from multiple domains to enhance the performance of a target task, particularly when labeled data in the target domain is scarce. Publications issued after 2015 were considered. These selected publications were divided into three categories: DTL-only and IDS-only works are examined in the introduction and background section, and DTL-based IDS papers are considered in the core section of this review. By reading this review paper, researchers will be able to gain a better grasp of the current state of DTL approaches used in IDSs in many different types of network. Other useful information, such as the datasets used, the type of DTL employed, the pre-trained network, IDS techniques, the evaluation metrics including accuracy/F-score and false-alarm rate, and the improvements gained, are also covered. The algorithms and methods used in several studies are presented, and the principles of DTL-based IDS subcategories are presented to the reader and illustrated deeply and clearly.
Keywords: Intrusion detection system; Industrial control network; Deep transfer learning; Fine-tuning; Domain adaptation; Cybersecurity

Sahithi Tummalapalli, Lov Kumar, Lalita Bhanu Murthy Neti, Aneesh Krishna,
Detection of web service anti-patterns using weighted extreme learning machine,
Computer Standards & Interfaces,
Volume 82,
2022,
103621,
ISSN 0920-5489,
https://doi.org/10.1016/j.csi.2022.103621.
(https://www.sciencedirect.com/science/article/pii/S0920548922000022)
Abstract: ‘Anti-Pattern’ is a term often used by software engineers and practitioners nowadays. An anti-pattern is a supplement of the design pattern. Similar to design patterns, an anti-pattern is a template and a repeatable way of solving a specific problem, but in a non-optimal and ineffective way. Therefore, there is a requirement for the timely identification and modification of anti-patterns to increase software systems performance and efficiency. Anti-pattern detection using the source code metric can be used as an initial step in the software development life cycle, both to reduce the maintenance of the software system and to improve the quality of the software. The work in this paper empirically investigates the effectiveness of two machine learning algorithms, i.e., Extreme Learning Machine (ELM) and Weighted Extreme Learning Machine (WELM), with four different kernels in detecting web service anti-patterns. This work also investigates the application of different aggregation techniques and data sampling techniques to handle imbalanced data in predicting five different anti-patterns. The inference of this research is studied over 226 WSDL (Web Service Description Language) files. The experimental findings reveal that the model developed by WELM has superior prediction accuracy compared to the model developed by ELM.
Keywords: Anti-Pattern; Weighted extreme learning machine (WELM); Extreme learning machine (ELM); Service-Oriented architecture; Web service; Source code metric

Yael Mathov, Tal Ben Senior, Asaf Shabtai, Yuval Elovici,
Stop bugging me! Evading modern-day wiretapping using adversarial perturbations,
Computers & Security,
Volume 121,
2022,
102841,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.102841.
(https://www.sciencedirect.com/science/article/pii/S0167404822002358)
Abstract: Mass surveillance systems for voice over IP (VoIP) conversations pose a great risk to privacy. These automated systems use learning models to analyze conversations, and calls that involve specific topics are routed to a human agent for further examination. In this study, we present an adversarial-learning-based framework for privacy protection for VoIP conversations. We present a novel method that finds a universal adversarial perturbation (UAP), which, when added to the audio stream, prevents an eavesdropper from automatically detecting the conversation’s topic. As shown in our experiments, the UAP is agnostic to the speaker or audio length, and its volume can be changed in real time, as needed. Our real-world solution uses a Teensy microcontroller that acts as an external microphone and adds the UAP to the audio in real time. We examine different speakers, VoIP applications (Skype, Zoom, Slack, Google Meet, and Microsoft Teams), and audio lengths. Our results in the real world suggest that our approach is a feasible solution for privacy protection.
Keywords: Adversarial examples; Privacy protection

Fangyun Qin, Zheng Zheng, Yulei Sui, Siqian Gong, Zhiping Shi, Kishor S. Trivedi,
Cross-project concurrency bug prediction using domain-adversarial neural network,
Journal of Systems and Software,
Volume 214,
2024,
112077,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2024.112077.
(https://www.sciencedirect.com/science/article/pii/S0164121224001225)
Abstract: In recent years, software bug prediction has shown to be effective in narrowing down the potential bug modules and boosting the efficiency and precision of existing testing and analysis tools. However, due to its non-deterministic nature and low presence, concurrency bug labeling is a challenging task, which limits the implementation of within-project concurrency bug prediction. This paper proposes DACon, a Domain-Adversarial neural network-based cross-project Concurrency bug prediction approach to tackle this problem by leveraging information from another related project. By combining a set of designed concurrency code metrics with widely used sequential code metrics, DACon uses SMOTE (Synthetic Minority Over-sampling TEchnique) and domain-adversarial neural network to mitigate two challenges including the severe class imbalance between concurrency bug-prone samples and concurrency bug-free samples, and shift between source and target distribution during bug prediction implementation. Our evaluation on 20 pair-wise groups of experiments constructed from 5 real-world projects indicates that cross-project concurrency bug prediction is feasible, and DACon can effectively predict concurrency bugs across different projects.
Keywords: Software bug prediction; Cross-project bug prediction; Concurrency bug; Domain adaptation

Wei Zheng, Yunfan Li, Xiaoxue Wu, Jingyuan Cheng,
Duplicate Bug Report detection using Named Entity Recognition,
Knowledge-Based Systems,
Volume 284,
2024,
111258,
ISSN 0950-7051,
https://doi.org/10.1016/j.knosys.2023.111258.
(https://www.sciencedirect.com/science/article/pii/S0950705123010079)
Abstract: Software bugs pose significant challenges in management. The Bug Tracking System (BTS) serves as a standard platform to chronicle, oversee, and manage bugs throughout software development and maintenance. While BTS aggregates numerous bug reports for tracking purposes, identical bugs often get reported by various individuals. This redundancy leads to excessive duplicate reports, straining manual inspection efforts, risking repeated bug assignment tasks, and diminishing the efficiency of bug resolution. Notably, many contemporary DBR detection techniques tend to overlook the structured data abundant in descriptive information about bug report behaviors. To mitigate this oversight, this study introduces a groundbreaking method named CorNER. This technique enhances DBR detection precision by converting unstructured textual content into structured data via named entity recognition (NER). Specifically, CorNER employs Random Forest with context (RNER) to annotate entities in the title and description sections of bug reports and subsequently harnesses Text Convolutional Neural Networks (TextCNN) for feature extraction. Empirical evidence indicates a commendable improvement in CorNER’s F1-Score by 6.24% and 4.96% on average, surpassing the benchmarks of two prevalent DBR detection methods across five datasets.
Keywords: Duplicate Bug Report detection; Named Entity Recognition; Context-aware random forest; Convolutional neural networks

Xue Yuan, Guanjun Lin, Huan Mei, Yonghang Tai, Jun Zhang,
Software vulnerable functions discovery based on code composite feature,
Journal of Information Security and Applications,
Volume 81,
2024,
103718,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2024.103718.
(https://www.sciencedirect.com/science/article/pii/S2214212624000218)
Abstract: Vulnerability identification is crucial to protecting software systems from attacks. Although numerous learning-based solutions have been suggested to assist in vulnerability identification, these approaches often face challenges due to the scarcity of real-world vulnerability data. To extract as much vulnerability information as possible from limited data, we consider obtaining the characteristics of vulnerabilities from different forms of code by leveraging two distinct deep neural models. First, source code functions are considered to be textual sequences, and Gated Recurrent Unit (GRU) is applied to extract serialized features. Then, Abstract Syntax Trees (ASTs) of these functions, which reflects the code structure, are fed to a Gated Graph Recurrent Network (GGRN) to obtain structural features indicative of software vulnerability. To better handle data imbalance issues in real-world scenarios, we employ Random Forest (RF) to construct a predictive model to learn the concatenation of serialized and structural features extracted by GRU and GGRN. To evaluate the proposed approach, we collected 12 open-source projects containing function-level samples and compared the proposed method with a series of baselines, including popular learning-based methods and static analysis tools. The empirical results demonstrate that our proposed approach outperforms the baselines and can identify more vulnerabilities.
Keywords: Vulnerability detection; Source code; Deep learning; Deep representation learning

Fábio Lopes, João Agnelo, César A. Teixeira, Nuno Laranjeiro, Jorge Bernardino,
Automating orthogonal defect classification using machine learning algorithms,
Future Generation Computer Systems,
Volume 102,
2020,
Pages 932-947,
ISSN 0167-739X,
https://doi.org/10.1016/j.future.2019.09.009.
(https://www.sciencedirect.com/science/article/pii/S0167739X19308283)
Abstract: Software systems are increasingly being used in business or mission critical scenarios, where the presence of certain types of software defects, i.e., bugs, may result in catastrophic consequences (e.g., financial losses or even the loss of human lives). To deploy systems in which we can rely on, it is vital to understand the types of defects that tend to affect such systems. This allows developers to take proper action, such as adapting the development process or redirecting testing efforts (e.g., using a certain set of testing techniques, or focusing on certain parts of the system). Orthogonal Defect Classification (ODC) has emerged as a popular method for classifying software defects, but it requires one or more experts to categorize each defect in a quite complex and time-consuming process. In this paper, we evaluate the use of machine learning algorithms (k-Nearest Neighbors, Support Vector Machines, Naïve Bayes, Nearest Centroid, Random Forest and Recurrent Neural Networks) for automatic classification of software defects using ODC, based on unstructured textual bug reports. Experimental results reveal the difficulties in automatically classifying certain ODC attributes solely using reports, but also suggest that the overall classification accuracy may be improved in most of the cases, if larger datasets are used.
Keywords: Software defects; Bug reports; Orthogonal defect classification; Machine learning; Text classification

Hariharan M., Sathish Kumar C., Anshul Tanwar, Krishna Sundaresan, Prasanna Ganesan, Sriram Ravi, R. Karthik,
Proximal Instance Aggregator networks for explainable security vulnerability detection,
Future Generation Computer Systems,
Volume 134,
2022,
Pages 303-318,
ISSN 0167-739X,
https://doi.org/10.1016/j.future.2022.04.008.
(https://www.sciencedirect.com/science/article/pii/S0167739X22001315)
Abstract: Security vulnerabilities in software are the root cause of cyberattacks. Considering that these defects have huge associated costs, they should be proactively detected and resolved before shipping the software. Data-driven approaches like Artificial Intelligence (AI) are vastly explored for automatic vulnerability detection, given their potential to leverage large-scale vulnerability data feeds and learn from these scenarios. This work introduces a novel Proximal Instance Aggregator (PIA) neural network for accurately capturing insecure C code patterns from Abstract Syntax Tree (AST). It is built upon the concept of Multiple Instance Learning (MIL), which treats the AST representation of the code as a ‘bag’ of tree path ‘instances’. The security vulnerability can manifest in one or multiple such AST path instances. The PIA model dynamically learns a set of abstract concepts to describe the patterns associated with the AST paths. Specifically, the vulnerable nature of an AST path is characterized by its proximity to these concepts. The model also employs the attention mechanism to generate deep representations. By drawing cross-correlation of features between the path instances, the self-attention robustly weighs the relevance of each AST path towards vulnerability classification. The MIL utilizes these deep feature sets to construct the concept space. Thus, even without explicit supervision for localizing the line of defect, the AI automatically learns AST instance classification in a weakly supervised manner. Since AST-level prediction is formed as an aggregation of instance classifications, the AI is inherently explainable. The model outperforms state-of-the-art methods by a fair margin. It achieves 95.63% detection accuracy and 95.65% F1-score on the benchmarked NIST SARD, NVD datasets for a range of vulnerabilities.
Keywords: Multiple-Instance learning; Interpretability; Deep learning; Vulnerability detection; Abstract Syntax Tree; Weakly supervised learning

Golam Mostaeen, Banani Roy, Chanchal K. Roy, Kevin Schneider, Jeffrey Svajlenko,
A machine learning based framework for code clone validation,
Journal of Systems and Software,
Volume 169,
2020,
110686,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2020.110686.
(https://www.sciencedirect.com/science/article/pii/S0164121220301394)
Abstract: A code clone is a pair of code fragments, within or between software systems that are similar. Since code clones often negatively impact the maintainability of a software system, several code clone detection techniques and tools have been proposed and studied over the last decade. However, the clone detection tools are not always perfect and their clone detection reports often contain a number of false positives or irrelevant clones from specific project management or user perspective. To detect all possible similar source code patterns in general, the clone detection tools work on the syntax level while lacking user-specific preferences. This often means the clones must be manually inspected before analysis in order to remove those false positives from consideration. This manual clone validation effort is very time-consuming and often error-prone, in particular for large-scale clone detection. In this paper, we propose a machine learning approach for automating the validation process. First, a training dataset is built by taking code clones from several clone detection tools for different subject systems and then manually validating those clones. Second, several features are extracted from those clones to train the machine learning model by the proposed approach. The trained algorithm is then used to automatically validate clones without human inspection. Thus the proposed approach can be used to remove the false positive clones from the detection results, automatically evaluate the precision of any clone detectors for any given set of datasets, evaluate existing clone benchmark datasets, or even be used to build new clone benchmarks and datasets with minimum effort. In an experiment with clones detected by several clone detectors in several different software systems, we found our approach has an accuracy of up to 87.4% when compared against the manual validation by multiple expert judges. The proposed method also shows better results in several comparative studies with the existing related approaches for clone classification.
Keywords: Code clones; Validation; Machine learning; Clone management

ShiJie Wang, JianFeng Tao, QinCheng Jiang, Wei Chen, ChengLiang Liu,
Manipulator joint fault localization for intelligent flexible manufacturing based on reinforcement learning and robot dynamics,
Robotics and Computer-Integrated Manufacturing,
Volume 86,
2024,
102684,
ISSN 0736-5845,
https://doi.org/10.1016/j.rcim.2023.102684.
(https://www.sciencedirect.com/science/article/pii/S073658452300159X)
Abstract: This article proposes a new method to address the challenge of remote monitoring in intelligent flexible manufacturing systems. Specifically, we propose a multi working condition fault localization algorithm for robotic arms, which eliminates the need for additional sensors and is based on the classic sliding window algorithm. We use reinforcement learning technology to learn detection parameter debugging experience under different working conditions, and combine the dynamics of the robot to achieve fault detection and fault source localization in a flexible environment. Through the robot's own programmable logic controller system, the remote monitoring system can sense the operating status of each link. To evaluate the effectiveness of our proposed method, we conducted experimental equipment simulations and real-world industrial operations. The results show that under multiple operating conditions, the accuracy of fault detection reaches 86%, and the accuracy of localization reaches 81.35%. The deviation of results under different robot operating conditions is significantly lower than other algorithms. This study explores the potential and implementation approaches of reinforcement learning in intelligent manufacturing systems, with a particular focus on applications in flexible scenarios. These findings reveal the prospects of reinforcement learning technology in improving the sustainable operation of intelligent manufacturing systems.
Keywords: Remote monitoring; Fault localization; Reinforcement learning; Variable operating condition

Anshuman Nayak, Somsubhra Chakraborty, Dillip Kumar Swain,
Application of smartphone-image processing and transfer learning for rice disease and nutrient deficiency detection,
Smart Agricultural Technology,
Volume 4,
2023,
100195,
ISSN 2772-3755,
https://doi.org/10.1016/j.atech.2023.100195.
(https://www.sciencedirect.com/science/article/pii/S2772375523000254)
Abstract: The earliest detection of plant disease is the primary concern of the farming community. The availability of advanced digital cameras and smartphones with improved image acquisition modes and deep learning methods like convolutional neural networks (CNN) can detect plant disease with high accuracy. This study used 2259 smartphone images of various rice (Oryza sativa) plant parts under various classes and 250 real-time validation images for classifying 12 rice diseases and nutrient deficiency symptoms. Different image segmentation techniques like foreground extraction were used to segment affected portions. Additionally, optimization of models and procedures to use them in smartphones with offline working capabilities have been described. Furthermore, a dynamic framework has been developed and demonstrated where the server trains on unseen image data to improve the classification performance and updates the model on falling below a certain threshold level. A comparison was made across different models used for image classification with many supporting metrics to select the best model for transfer learning. The top four performing models were DenseNet201, Xception, MobileNetV2, and ResNet50, with validation accuracies of 0.9803, 0.9778, 0.9756, and 0.9718, respectively. The ResNet50 model was found to best among all for cloud architectures, while MobileNetV2 appeared as the best model for the smartphone application. Finally, the android application, “Rice Disease Detector” compiled with the MobileNetV2 model was tested for multiple disease occurrences in a single capture. More research is warranted to test the application for smartphones with variable configurations.
Keywords: Image processing; Smartphone; Application; Rice disease detection; Rice nutrient deficiency detection; Transfer learning

Zekai Zhang, Mingle Zhou, Honglin Wan, Min Li, Gang Li, Delong Han,
IDD-Net: Industrial defect detection method based on Deep-Learning,
Engineering Applications of Artificial Intelligence,
Volume 123, Part B,
2023,
106390,
ISSN 0952-1976,
https://doi.org/10.1016/j.engappai.2023.106390.
(https://www.sciencedirect.com/science/article/pii/S0952197623005742)
Abstract: Detecting defects in industrial products is one of the most widespread applications of industrial automation. Various product defects, large similarities, and drastic changes in scale in industrial scenarios pose challenges to existing industrial inspection networks. This paper proposes a deep learning-based industrial defect detection method (IDD-Net) to address the above challenges. Specifically, IDD-Net has three distinct features. First, for the defects of diversity and similarity (rolled-in_scale, crazing in steel defects), IDD-Net designed a novel local–global backbone feature network (LGB-Net). Second, IDD-Net proposes a novel Three-Layer Feature Aggregation network (TFLA-Net) to solve the problem of drastic scale changes. TFLA-Net adopts a novel three-layer descending method to aggregate semantic and fine-grained features effectively. At the same time, the dense connection of adjacent nodes of TFLA-Net ensures the efficient fusion of features of different scales in the network. In particular, this paper proposes a novel IoU loss (Defect-IoU loss) for the problem of object loss deviation at different scales. The novelty of Defect-IoU Loss is that the loss value is scaled by the difference in the area of different scale objects, which is more conducive to the balance of multi-scale object loss. The experimental results show that the calculation amount of IDD-Net is only 24.9 Gflops, and the mAP@.5 of 79.66%, 99.5%, and 95.9% in the steel defect, aluminium defect, and PCB defect datasets were respectively obtained, surpassing all comparison models. In addition, the test in the actual industrial scene also demonstrates the feasibility of the application of IDD-Net.
Keywords: Industrial defect detection; Lightweight self attention; Local–global feature; Feature fusion; IoU loss

Arghavan Moradi Dakhel, Amin Nikanjam, Vahid Majdinasab, Foutse Khomh, Michel C. Desmarais,
Effective test generation using pre-trained Large Language Models and mutation testing,
Information and Software Technology,
Volume 171,
2024,
107468,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2024.107468.
(https://www.sciencedirect.com/science/article/pii/S0950584924000739)
Abstract: Context:
One of the critical phases in the software development life cycle is software testing. Testing helps with identifying potential bugs and reducing maintenance costs. The goal of automated test generation tools is to ease the development of tests by suggesting efficient bug-revealing tests. Recently, researchers have leveraged Large Language Models (LLMs) of code to generate unit tests. While the code coverage of generated tests was usually assessed, the literature has acknowledged that the coverage is weakly correlated with the efficiency of tests in bug detection.
Objective:
To improve over this limitation, in this paper, we introduce MuTAP (Mutation Test case generation using Augmented Prompt) for improving the effectiveness of test cases generated by LLMs in terms of revealing bugs by leveraging mutation testing.
Methods:
Our goal is achieved by augmenting prompts with surviving mutants, as those mutants highlight the limitations of test cases in detecting bugs. MuTAP is capable of generating effective test cases in the absence of natural language descriptions of the Program Under Test (PUTs). We employ different LLMs within MuTAP and evaluate their performance on different benchmarks.
Results:
Our results show that our proposed method is able to detect up to 28% more faulty human-written code snippets. Among these, 17% remained undetected by both the current state-of-the-art fully-automated test generation tool (i.e., Pynguin) and zero-shot/few-shot learning approaches on LLMs. Furthermore, MuTAP achieves a Mutation Score (MS) of 93.57% on synthetic buggy code, outperforming all other approaches in our evaluation.
Conclusion:
Our findings suggest that although LLMs can serve as a useful tool to generate test cases, they require specific post-processing steps to enhance the effectiveness of the generated test cases which may suffer from syntactic or functional errors and may be ineffective in detecting certain types of bugs and testing corner cases in PUTs.
Keywords: Test generation; Large language model; Mutation testing

Mohammadreza Razavi, Samira Mavaddati, Ziad Kobti, Hamidreza Koohi,
Rice-ResNet: Rice classification and quality detection by transferred ResNet deep model,
Software Impacts,
2024,
100654,
ISSN 2665-9638,
https://doi.org/10.1016/j.simpa.2024.100654.
(https://www.sciencedirect.com/science/article/pii/S2665963824000423)
Abstract: Efficient classification and quality assessment of rice varieties are essential for market pricing, food safety, and consumer satisfaction in the global rice sector. Leveraging pre-trained ResNet architectures, Rice-ResNet significantly enhances feature extraction, ensuring accurate classification and quality detection of rice cultivars. This system, accessible in Python repositories, promises improved crop management and yield. Despite requiring real-world implementation, Rice-ResNet marks a significant advancement in rice classification, fostering enriched digital experiences.
Keywords: Rice quality detection; ResNet Model; Transfer learning; Python; Open-source

Karthik Chandra Swarna, Noble Saji Mathews, Dheeraj Vagavolu, Sridhar Chimalakonda,
On the impact of multiple source code representations on software engineering tasks — An empirical study,
Journal of Systems and Software,
Volume 210,
2024,
111941,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111941.
(https://www.sciencedirect.com/science/article/pii/S0164121223003369)
Abstract: Efficiently representing source code is crucial for various software engineering tasks such as code classification and clone detection. Existing approaches primarily use Abstract Syntax Tree (AST), and only a few focus on semantic graphs such as Control Flow Graph (CFG) and Program Dependency Graph (PDG), which contain information about source code that AST does not. Even though some works tried to utilize multiple representations, they do not provide any insights about the costs and benefits of using multiple representations. The primary goal of this paper is to discuss the implications of utilizing multiple source code representations, specifically AST, CFG, and PDG. We modify an AST path-based approach to accept multiple representations as input to an attention-based model. We do this to measure the impact of additional representations (such as CFG and PDG) over AST. We evaluate our approach on three tasks: Method Naming, Program Classification, and Clone Detection. Our approach increases the performance on these tasks by 11% (F1), 15.7% (Accuracy), and 9.3% (F1), respectively, over the baseline. In addition to the effect on performance, we discuss timing overheads incurred with multiple representations. We envision that this work can provide a base for researchers to explore and experiment with a variety of source code representations for software engineering tasks.
Keywords: Source code representation; Abstract Syntax Tree; Control Flow Graph; Program Dependence Graph; Code embedding; Method naming

Zhide Zhou, Zhilei Ren, Guojun Gao, He Jiang,
An empirical study of optimization bugs in GCC and LLVM,
Journal of Systems and Software,
Volume 174,
2021,
110884,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2020.110884.
(https://www.sciencedirect.com/science/article/pii/S0164121220302740)
Abstract: Optimizations are the fundamental component of compilers. Bugs in optimizations have significant impacts, and can cause unintended application behavior and disasters, especially for safety-critical domains. Thus, an in-depth analysis of optimization bugs should be conducted to help developers understand and test the optimizations in compilers. To this end, we conduct an empirical study to investigate the characteristics of optimization bugs in two mainstream compilers, GCC and LLVM. We collect about 57K and 22K bugs of GCC and LLVM, and then exhaustively examine 8,771 and 1,564 optimization bugs of the two compilers, respectively. The results reveal the following five characteristics of optimization bugs: (1) Optimizations are the buggiest component in both compilers except for the C++ component; (2) the value range propagation optimization and the instruction combine optimization are the buggiest optimizations in GCC and LLVM, respectively; the loop optimizations in both GCC and LLVM are more bug-prone than other optimizations; (3) most of the optimization bugs in both GCC and LLVM are misoptimization bugs, accounting for 57.21% and 61.38% respectively; (4) on average, the optimization bugs live over five months, and developers take 11.16 months for GCC and 13.55 months for LLVM to fix an optimization bug; in both GCC and LLVM, many confirmed optimization bugs have lived for a long time; (5) the bug fixes of optimization bugs involve no more than two files and three functions on average in both compilers, and around 99% of them modify no more than 100 lines of code, while 90% less than 50 lines of code. Our study provides a deep understanding of optimization bugs for developers and researchers. This could provide useful guidance for the developers and researchers to better design the optimizations in compilers. In addition, the analysis results suggest that we need more effective techniques and tools to test compiler optimizations. Moreover, our findings are also useful to the research of automatic debugging techniques for compilers, such as automatic compiler bug isolation techniques.
Keywords: Empirical study; Compiler reliability; Bug characteristics; Compiler optimization bugs; Compiler testing

Francesco Betti Sorbelli, Lorenzo Palazzetti, Cristina M. Pinotti,
YOLO-based detection of Halyomorpha halys in orchards using RGB cameras and drones,
Computers and Electronics in Agriculture,
Volume 213,
2023,
108228,
ISSN 0168-1699,
https://doi.org/10.1016/j.compag.2023.108228.
(https://www.sciencedirect.com/science/article/pii/S0168169923006166)
Abstract: This paper explores the utilization of innovative technologies such as RGB cameras, drones, and computer vision algorithms, for monitoring pests in orchards, with a specific focus on detecting the Halyomorpha halys (HH), commonly known as the “brown marmorated stink bug”. The integration of drones and machine learning (ML) into integrated pest management shows promising potential for effectively combating HH infestations. However, challenges arise from relying on vision models solely trained using high-quality images from public datasets. To address this issue, we create an ad hoc dataset of on-site images mainly captured with the help of a drone as well as other devices. We initially conduct an in-depth analysis of the captured images, considering factors such as blurriness and brightness, to possibly improve the performance of the ML algorithms. Afterwards, we undertake the training and evaluation of diverse ML models using distinct approaches within the YOLO framework. We employ a range of metrics to compare their performance and ultimately achieve a satisfactory outcome. Through the optimization of ML models and the correction of image imperfections, we contribute to advancing automated decision-making processes in pest insect monitoring and management, specifically in HH monitoring.
Keywords: Unmanned aerial vehicles; Insect detection; Halyomorpha halys; Brown marmorated stink bug; Computer vision algorithms; YOLO

Kajal Tameswar, Geerish Suddul, Kumar Dookhitram,
A hybrid deep learning approach with genetic and coral reefs metaheuristics for enhanced defect detection in software,
International Journal of Information Management Data Insights,
Volume 2, Issue 2,
2022,
100105,
ISSN 2667-0968,
https://doi.org/10.1016/j.jjimei.2022.100105.
(https://www.sciencedirect.com/science/article/pii/S2667096822000489)
Abstract: Early detection and correction of software defects is essential in the software development process. In the production stage, software with defects negatively impacts on operational costs and ultimately affects customer satisfaction. Although different approaches exist to predict software defects, two essential factors are timely and accurate detection. This paper presents a hybrid Deep Neural Network model for enhanced prediction of software bugs . Different Nature-Inspired Algorithms have been applied to improve the exploration of the hyperparameter solution space to optimize the Deep Neural Network architecture. Experimental investigations have been conducted using NASA dataset to predict software defects and evaluation measures like accuracy, computational time and F1 score have been used for performance comparison. The approach based on the combination of Genetic and Coral Reef metaheuristics outperformed all other models, achieving highest accuracy of around 96% and average F1-score of 0.92.
Keywords: Software bug prediction; Deep learning; Neural networks; Genetic algorithm; Coral reefs optimization algorithm; Nature inspired optimization techniques; Metaheuristic algorithms

Yao Tong, Xiaofang Zhang,
Crowdsourced test report prioritization considering bug severity,
Information and Software Technology,
Volume 139,
2021,
106668,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2021.106668.
(https://www.sciencedirect.com/science/article/pii/S0950584921001300)
Abstract: In crowdsourced testing, a large number of test reports will be generated in a short time. How to efficiently inspect these reports becomes one of the critical steps in the testing process. In recent years, many automated techniques like clustering, classification, and prioritization have emerged to provide an automated inspection order over test reports. Even though these methods have achieved good performance, they did not consider the priority to image and text information. Simultaneously, existing prioritization approaches only focus on the rate of detecting faults but ignore the severity of the faults. In fact, bug severity is a vital indicator that the users provide to flag the criticality of a bug, so developers can then use it to set their priority for the resolution process. For these reasons, this paper presents a novel prioritization approach for crowdsourcing test reports. It extracts features from text and screenshot information of the test reports, uses the hash technique to index test reports, and finally designs a prioritization algorithm. To validate our approach, we conducted experiments on six industrial projects. The results and the hypotheses analysis show that our approach can detect all faults faster in a limited time and can prioritize reports that have higher severity faults compared with the existing methods.
Keywords: Crowdsourced testing; Test report processing; Prioritization; Bug severity; Textual description

Abdul Qadir, Rabbia Mahum, Mohammed A. El-Meligy, Adham E. Ragab, Abdulmalik AlSalman, Muhammad Awais,
An efficient deepfake video detection using robust deep learning,
Heliyon,
Volume 10, Issue 5,
2024,
e25757,
ISSN 2405-8440,
https://doi.org/10.1016/j.heliyon.2024.e25757.
(https://www.sciencedirect.com/science/article/pii/S2405844024017882)
Abstract: The creation and manipulation of synthetic images have evolved rapidly, causing serious concerns about their effects on society. Although there have been various attempts to identify deep fake videos, these approaches are not universal. Identifying these misleading deepfakes is the first step in preventing them from spreading on social media sites. We introduce a unique deep-learning technique to identify fraudulent clips. Most deepfake identifiers currently focus on identifying face exchange, lip synchronous, expression modification, puppeteers, and other factors. However, exploring a consistent basis for all forms of fake videos and images in real-time forensics is challenging. We propose a hybrid technique that takes input from videos of successive targeted frames, then feeds these frames to the ResNet-Swish-BiLSTM, an optimized convolutional BiLSTM-based residual network for training and classification. This proposed method helps identify artifacts in deepfake images that do not seem real. To assess the robustness of our proposed model, we used the open deepfake detection challenge dataset (DFDC) and Face Forensics deepfake collections (FF++). We achieved 96.23% accuracy when using the FF++ digital record. In contrast, we attained 78.33% accuracy using the aggregated records from FF++ and DFDC. We performed extensive experiments and believe that our proposed method provides more significant results than existing techniques.
Keywords: Video deepfakes; Multimedia forensics; Swish; Visual manipulation

Guilong Lu, Xiaolin Ju, Xiang Chen, Wenlong Pei, Zhilong Cai,
GRACE: Empowering LLM-based software vulnerability detection with graph structure and in-context learning,
Journal of Systems and Software,
Volume 212,
2024,
112031,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2024.112031.
(https://www.sciencedirect.com/science/article/pii/S0164121224000748)
Abstract: Software vulnerabilities inflict considerable economic and societal harm. Therefore, timely and accurate detection of these flaws has become vital. Large language models (LLMs) have emerged as a promising tool for vulnerability detection in recent studies. However, their effectiveness suffers when limited to plain text source code, which may ignore the syntactic and semantic information of the code. To address this limitation, we propose a novel vulnerability detection approach GRACE that empowers LLM-based software vulnerability detection by incorporating graph structural information in the code and in-context learning. We also design an effective demonstration retrieval approach that identifies highly relevant code examples by considering semantic, lexical, and syntactic similarities for the target code to provide better demonstrations for in-context learning. To evaluate the effectiveness of GRACE, we conducted an empirical study on three vulnerability detection datasets (i.e., Devign, Reveal, and Big-Vul). The results demonstrate that GRACE outperforms six state-of-the-art vulnerability detection baselines by at least 28.65% in terms of the F1 score across these three datasets. Therefore, our study highlights the effectiveness of integrating graph structural information and in-context learning in LLMs for vulnerability detection. These findings motivate further investigation into tailoring such approaches for specific vulnerability types or adapting them to other security tasks.
Keywords: Vulnerability detection; Large language model; In-context learning; Source code representation; Graph structure

C Jackulin, S. Murugavalli,
A comprehensive review on detection of plant disease using machine learning and deep learning approaches,
Measurement: Sensors,
Volume 24,
2022,
100441,
ISSN 2665-9174,
https://doi.org/10.1016/j.measen.2022.100441.
(https://www.sciencedirect.com/science/article/pii/S2665917422000757)
Abstract: Agriculture plays a significant part in India due to their population growth and increased food demands. Hence, there is a need to enhance the yield of crop. One of these important effects on low crop yields is diseases caused by bacteria, fungi and viruses. This can be prevented and handled by means of applying plant disease detection approaches. Machine learning techniques will be employed in the process of disease identification on plants as it mostly applies information themselves and offers fabulous techniques for detection of plant diseases. Methods based on Machine learning can be employed for the identification of diseases because it mainly applies on data superiority outcomes for specified task. In this approach, a comprehensive review has been made on the various techniques employed in plant disease detection using artificial intelligence (AI) based machine learning and deep learning techniques. Likewise, deep learning has also gained a great deal of significance in offering better performance outcome for detecting plant disease in the computer vision field. The deep learning advancements were employed to a range of domains that leads to great attainment in the machine learning and computer vision areas. The comparative study is made in terms of machine and deep learning techniques and their performance and usage in various research papers is related to show the effectiveness of deep learning model over machine learning model. In order to prevent major crop losses, the deep learning technique can be used to detect the leaf diseases from captured images.
Keywords: Agriculture; Plant diseases detection; Machine learning methods; Artificial intelligence; And deep learning

Manpreet Kaur, Dhavleesh Rattan,
A systematic literature review on the use of machine learning in code clone research,
Computer Science Review,
Volume 47,
2023,
100528,
ISSN 1574-0137,
https://doi.org/10.1016/j.cosrev.2022.100528.
(https://www.sciencedirect.com/science/article/pii/S1574013722000624)
Abstract: Context:
Research related to code clones includes detection of clones in software systems, analysis, visualization and management of clones. Detection of semantic clones and management of clones have attracted use of machine learning techniques in code clone related research.
Objective:
The aim of this study is to report the extent of machine learning usage in code clone related research areas.
Method:
The paper uses a systematic review method to report the use of machine learning in research related to code clones. The study considers a comprehensive set of 57 articles published in leading conferences, workshops and journals.
Results:
Code clone related research using machine learning techniques is classified into different categories. Machine learning and deep learning algorithms used in the code clone research are reported. The datasets, features used to train machine learning models and metrics used to evaluate machine learning algorithms are reported. The comparative results of various machine learning algorithms presented in primary studies are reported.
Conclusion:
The research will help to identify the status of using machine learning in different code clone related research areas. We identify the need of more empirical studies to assess the benefits of machine learning in code clone research and give recommendations for future research.
Keywords: Software clone; Code clone; Machine learning; Deep learning; Semantic clone detection; Systematic literature review

Wen-Yao Wang, Chen-Hao Wu, Jie He,
CLeBPI: Contrastive Learning for Bug Priority Inference,
Information and Software Technology,
Volume 164,
2023,
107302,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107302.
(https://www.sciencedirect.com/science/article/pii/S0950584923001568)
Abstract: Context:
Automated bug priority inference (BPI) can reduce the time overhead of bug triagers for priority assignments, improving the efficiency of software maintenance.
Objective:
There are two orthogonal lines for this task, i.e., traditional machine learning based (TML-based) and neural network based (NN-based) approaches. Although these approaches achieve competitive performance, our observation finds that existing approaches face the following two issues: 1) TML-based approaches require much manual feature engineering and cannot learn the semantic information of bug reports; 2) Both TML-based and NN-based approaches cannot effectively address the label imbalance problem because they are difficult to distinguish the semantic difference between bug reports with different priorities.
Method:
We propose CLeBPI (Contrastive Learning for Bug Priority Inference), which leverages pre-trained language model and contrastive learning to tackle the above-mentioned two issues. Specifically, CLeBPI is first pre-trained on a large-scale bug report corpus in a self-supervised way, thus it can automatically learn contextual representations of bug reports without manual feature engineering. Afterward, it is further pre-trained by a contrastive learning objective, which enables it to distinguish semantic differences between bug reports, learning more precise contextual representations for each bug report. When finishing pre-training, we can connect a classification layer to CLeBPI and fine-tune it for BPI in a supervised way.
Results:
We choose four baseline approaches and conduct comparison experiments on a public dataset. The experimental results show that CLeBPI outperforms all baseline approaches by 23.86%–77.80% in terms of weighted average F1-score, showing its effectiveness.
Conclusion:
This paper propose CLeBPI, a pre-trained model combining contrastive learning that can automatically predict bug priority. Experimental results show that It achieves new result in BPI and can effectively alleviate label imbalance problem.
Keywords: Contrastive learning; Bug report; Bug priority inference; Software maintenance

Iqra Batool, Tamim Ahmed Khan,
Software fault prediction using data mining, machine learning and deep learning techniques: A systematic literature review,
Computers and Electrical Engineering,
Volume 100,
2022,
107886,
ISSN 0045-7906,
https://doi.org/10.1016/j.compeleceng.2022.107886.
(https://www.sciencedirect.com/science/article/pii/S0045790622001744)
Abstract: Software fault/defect prediction assists software developers to identify faulty constructs, such as modules or classes, early in the software development life cycle. There are data mining, machine learning, and deep learning techniques used for software fault prediction. We perform analysis of previously published reviews, surveys, and related studies to distill a list of questions. These questions were either answered in the past but needed a fresh look or they were not considered at all. We justify why answers to newly added questions are important and divide previous work based on data mining, machine learning, and deep learning and compare their performance. We study which datasets were commonly used and what comparison criteria were mostly adopted for software fault prediction. We select 68 primary studies from a wide list of initially selected set following our quality assessment criteria and present answers to our research questions.
Keywords: Software fault prediction; Defect prediction; Machine learning techniques; Data mining techniques; Deep learning techniques; Performance measures

Xiangping Chen, Furen Xu, Yuan Huang, Xiaocong Zhou, Zibin Zheng,
An empirical study of code reuse between GitHub and stack overflow during software development,
Journal of Systems and Software,
Volume 210,
2024,
111964,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2024.111964.
(https://www.sciencedirect.com/science/article/pii/S0164121224000074)
Abstract: With the rise of programming Q&A websites (e.g., Stack Overflow) and the open-source movement, code reuse has become a common phenomenon. Our study aims to provide a comprehensive study of the code reuse behavior of programmers during software development, i.e., we mainly focus on the code reuse between the code snippets in the commits of open-source projects and the code snippets on Stack Overflow (SO). The open-source java project code dataset we construct contains 793 projects which include 342,148 modified code snippets, and the SO code dataset includes 1,355,617 posts. Then, we employ a code clone detection tool to identify the instances of code reuse between the modified code snippets of commits and the code snippets of the SO posts. We find that the average code reuse ratio of the projects is 6.32%, which will have a significant upward trend in the future. Additionally, we find that experienced developers seem to be more likely to reuse the code on SO, and prefer to reuse posts with more favorites and higher scores. We combine deep learning and topic analysis algorithms to fully exploit the semantic information of SO posts. The result shows a certain difference in the distribution of post types reused by bug-related commits and non-bug-related commits. We also discover that the code reuse ratio (14.44%) in java class files that have undergone multiple modifications is more than double the overall code reuse ratio (6.32%). Finally, we discuss the reuse habits of programmers and find that they may refer to multiple posts in one reuse, and these posts are related to a certain extent. From these results, our study provides multiple practical insights for different stakeholders: researchers, developers, and the SO platform.
Keywords: Stack overflow; Code reuse; Code clone; Semantic analysis

Eman Abdullah AlOmar, Anthony Peruma, Mohamed Wiem Mkaouer, Christian Newman, Ali Ouni, Marouane Kessentini,
How we refactor and how we document it? On the use of supervised machine learning algorithms to classify refactoring documentation,
Expert Systems with Applications,
Volume 167,
2021,
114176,
ISSN 0957-4174,
https://doi.org/10.1016/j.eswa.2020.114176.
(https://www.sciencedirect.com/science/article/pii/S095741742030912X)
Abstract: Refactoring is the art of improving the structural design of a software system without altering its external behavior. Today, refactoring has become a well-established and disciplined software engineering practice that has attracted a significant amount of research presuming that refactoring is primarily motivated by the need to improve system structures. However, recent studies have shown that developers may incorporate refactoring strategies in other development-related activities that go beyond improving the design especially with the emerging challenges in contemporary software engineering. Unfortunately, these studies are limited to developer interviews and a reduced set of projects. To cope with the above-mentioned limitations, we aim to better understand what motivates developers to apply a refactoring by mining and automatically classifying a large set of 111,884 commits containing refactoring activities, extracted from 800 open source Java projects. We trained a multi-class classifier to categorize these commits into three categories, namely, Internal Quality Attribute, External Quality Attribute, and Code Smell Resolution, along with the traditional Bug Fix and Functional categories. This classification challenges the original definition of refactoring, being exclusive to improving software design and fixing code smells. Furthermore, to better understand our classification results, we qualitatively analyzed commit messages to extract textual patterns that developers regularly use to describe their refactoring activities. The results of our empirical investigation show that (1) fixing code smells is not the main driver for developers to refactoring their code bases. Refactoring is solicited for a wide variety of reasons, going beyond its traditional definition; (2) the distribution of refactoring operations differs between production and test files; (3) developers use a variety of patterns to purposefully target refactoring-related activities; (4) the textual patterns, extracted from commit messages, provide better coverage for how developers document their refactorings.
Keywords: Refactoring; Software quality; Software engineering; Machine learning

H.T. Manjula,  Neha Mangla,
An approach to on-stream DDoS blitz detection using machine learning algorithms,
Materials Today: Proceedings,
Volume 80, Part 3,
2023,
Pages 3492-3499,
ISSN 2214-7853,
https://doi.org/10.1016/j.matpr.2021.07.280.
(https://www.sciencedirect.com/science/article/pii/S2214785321051397)
Abstract: Distributed Denial of service (DDoS) attacks is an enormous threat to today’s cyber world, cyber networks are compromised by the attackers to distribute attacks in a large volume by denying the service to legitimate users. The toughest and challenging task in today’s network and network security engineers is to identify compromised traffic (attacked) and legitimate (normal) traffic. The main goal of the paper is to detect DDos attacks using classification algorithms. To achieve the goal the proposed system uses attacking tool to initiate attacks using Loic attacking tool with the data set extracted from open source tool Wireshark and transferring the dataset to apache Spark for detection analysis. The system also uses Apache spark machine learning algorithms (MLib), classification algorithms to classify the dataset. We use Naive Bayes, KNN and Random forest classification algorithms to classify normal traffic and attacked traffic. Our system is capable of detecting attacks with respect to any traffic protocols ICMP, TCP, or UDP. The accuracy of detection is compared on three classification algorithms and noted that random forest gives the accuracy of 96.75%.
Keywords: Loic; Apache spark; Wireshark; ICMP; TCP; UDP

Shirin Akbarinasaji, Can Kavaklioglu, Ayşe Başar, Adam Neal,
Partially observable Markov decision process to generate policies in software defect management,
Journal of Systems and Software,
Volume 163,
2020,
110518,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2020.110518.
(https://www.sciencedirect.com/science/article/pii/S0164121220300017)
Abstract: Bug repositories are dynamic in nature and as new bugs arrive, the old ones are closed. In a typical software project, bugs and their dependencies are reported manually and gradually using a issue tracking system. Thus, not all of the bugs in the system are available at any time, creating uncertainty in the dependency structure of the bugs. In this research, we propose to construct a dependency graph based on the reported dependency-blocking information in a issue tracking system. We use two graph metrics, depth and degree, to measure the extent of blocking bugs. Due to the uncertainty in the dependency structure, simply ordering bugs in the descending order of depth and/or degree may not be the best policy to prioritize bugs. Instead, we propose a Partially Observable Markov Decision Process model for sequential decision making and Partially Observable Monte Carlo Planning to identify the best policy for this sequential decision-making process. We validated our proposed approach by mining the data from two open source projects, and a commercial project. We compared our proposed framework with three baseline policies. The results on all datasets show that our proposed model significantly outperforms the other policies with respect to average discounted return.
Keywords: Defect management; Policy; Reinforcement learning; Partially observable Markov decision Process; Partially observable Monte Carlo Planning

Sushant Kumar Pandey, Ravi Bhushan Mishra, Anil Kumar Tripathi,
Machine learning based methods for software fault prediction: A survey,
Expert Systems with Applications,
Volume 172,
2021,
114595,
ISSN 0957-4174,
https://doi.org/10.1016/j.eswa.2021.114595.
(https://www.sciencedirect.com/science/article/pii/S0957417421000361)
Abstract: Several prediction approaches are contained in the arena of software engineering such as prediction of effort, security, quality, fault, cost, and re-usability. All these prediction approaches are still in the rudimentary phase. Experiments and research are conducting to build a robust model. Software Fault Prediction (SFP) is the process to develop the model which can be utilized by software practitioners to detect faulty classes/module before the testing phase. Prediction of defective modules before the testing phase will help the software development team leader to allocate resources more optimally and it reduces the testing effort. In this article, we present a Systematic Literature Review (SLR) of various studies from 1990 to June 2019 towards applying machine learning and statistical method over software fault prediction. We have cited 208 research articles, in which we studied 154 relevant articles. We investigated the competence of machine learning in existing datasets and research projects. To the best of our knowledge, the existing SLR considered only a few parameters over SFP’s performance, and they partially examined the various threats and challenges of SFP techniques. In this article, we aggregated those parameters and analyzed them accordingly, and we also illustrate the different challenges in the SFP domain. We also compared the performance between machine learning and statistical techniques based on SFP models. Our empirical study and analysis demonstrate that the prediction ability of machine learning techniques for classifying class/module as fault/non-fault prone is better than classical statistical models. The performance of machine learning-based SFP methods over fault susceptibility is better than conventional statistical purposes. The empirical evidence of our survey reports that the machine learning techniques have the capability, which can be used to identify fault proneness, and able to form well-generalized result. We have also investigated a few challenges in fault prediction discipline, i.e., quality of data, over-fitting of models, and class imbalance problem. We have also summarized 154 articles in a tabular form for quick identification.
Keywords: Machine learning; Fault proneness; Statistical techniques; Fault prediction; Systematic literature review

Anil V Turukmane, Ramkumar Devendiran,
M-MultiSVM: An efficient feature selection assisted network intrusion detection system using machine learning,
Computers & Security,
Volume 137,
2024,
103587,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103587.
(https://www.sciencedirect.com/science/article/pii/S0167404823004972)
Abstract: The intrusions are increasing daily, so there is a huge amount of privacy violations, financial loss, illegal transferring of information, etc. Various forms of intrusion occur in networks, such as menacing networks, computer resources and network information. Each type of intrusion focuses on specified tasks, whereas the hackers may focus on stealing confidential data, industrial secrets and personal information, which is then leaked to others for illegal gains. Due to the false detection of attacks in the security and changing environmental fields, limitations like data lagging on actual attacks and sustaining financial harms occur. To resolve this, automatic abnormality detection systems are required to secure the required computing ability and to analyze the attacks. Hence, an efficient automated intrusion detection system using machine learning methodology is proposed in this research paper. Initially, the data are gathered from CSE-CIC-IDS 2018 and UNSW-NB15 datasets. The acquired data are pre-processed using Null value handling and Min-Max normalization. Null value handling is used to remove missing values and irrelevant parameters. Min-Max normalization adjusted the unnormalized data in the pre-processing stage. After pre-processing, the class imbalance problem is reduced by using the Advanced Synthetic Minority Oversampling Technique (ASmoT). ASmoT aims to balance the class and reduce imbalance class problems and overfitting issues. The next phase is feature extraction, which is performed by Modified Singular Value Decomposition (M-SvD). M-SvD extracts essential features such as basic features, content features and traffic features from the input. The extracted features are optimized by the Opposition-based Northern Goshawk Optimization algorithm (ONgO). These optimal features are able to produce optimal output. After feature selection, the different types of attacks are classified by a hybrid machine learning model called Mud Ring assisted multilayer support vector machine (M-MultiSVM) and finally, the hyperparameters are tuned by the Mud Ring optimization algorithm. Thus, the proposed M-MultiSVM model can efficiently detect intrusion in the network. The performance metrics show that the proposed system achieved 99.89 % accuracy by using the CSE-CIC-IDS 2018 dataset; also, the proposed system achieved 97.535 % accuracy by using the UNSW-NB15 dataset.
Keywords: Null value handling; Min-max normalization; Synthetic minority oversampling; Singular value decomposition; Northern Goshawk Optimization; Multilayer SVM; Mud ring

Hengyan Zhang, Weizhe Zhang, Yuming Feng, Yang Liu,
SVScanner: Detecting smart contract vulnerabilities via deep semantic extraction,
Journal of Information Security and Applications,
Volume 75,
2023,
103484,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2023.103484.
(https://www.sciencedirect.com/science/article/pii/S2214212623000686)
Abstract: Blockchain is a significant advancement in technology recently, transforming the traditional centralized system into a decentralized one. Smart contracts, as one of the best applications of blockchain, show great potential in various fields, such as finance, supply chain, and the Internet of Things (IoT). As the world’s first blockchain platform to support turing complete smart contracts, Ethereum has become the most critical infrastructure for the digital world. However, with the vigorous development of smart contracts, malicious attacks against smart contracts have frequently occurred in recent years. The issue of smart contract security has attracted widespread attention due to the huge financial losses caused by smart contract vulnerabilities. Although researchers have made some progress in detecting smart contract vulnerabilities through symbolic execution and fuzzing-based methods, existing methods mainly rely on expert knowledge and hand-crafted features, leading to many detection errors. Even worse, existing methods take tens of seconds or even minutes to detect each smart contract on average, which is extremely time-consuming. In this work, we present SVScanner, the new method combining two features of heterogeneous patterns to detect smart contract vulnerabilities in the blockchain. Specifically, we first extract global semantic features from the sequence of contract code tokens. Then we further use the attention mechanism to capture deep structural semantics from the Abstract Syntax Tree (AST) of smart contracts. Finally, we combine these two features from different patterns and use a text convolutional neural network (TextCNN) to detect contract bugs. Experimental results show that SVScanner has the ability to detect vulnerabilities effectively in real-world smart contract datasets. SVScanner achieves a 7.33% improvement in accuracy compared with other traditional methods. Moreover, our method requires significantly less detection time.
Keywords: Blockchain; Smart contract; Vulnerability detection; Deep learning; Deep semantic extraction

Amreen Abbas, Sweta Jain, Mahesh Gour, Swetha Vankudothu,
Tomato plant disease detection using transfer learning with C-GAN synthetic images,
Computers and Electronics in Agriculture,
Volume 187,
2021,
106279,
ISSN 0168-1699,
https://doi.org/10.1016/j.compag.2021.106279.
(https://www.sciencedirect.com/science/article/pii/S0168169921002969)
Abstract: Plant diseases and pernicious insects are a considerable threat in the agriculture sector. Therefore, early detection and diagnosis of these diseases are essential. The ongoing development of profound deep learning methods has greatly helped in the detection of plant diseases, granting a vigorous tool with exceptionally precise outcomes but the accuracy of deep learning models depends on the volume and the quality of labeled data for training. In this paper, we have proposed a deep learning-based method for tomato disease detection that utilizes the Conditional Generative Adversarial Network (C-GAN) to generate synthetic images of tomato plant leaves. Thereafter, a DenseNet121 model is trained on synthetic and real images using transfer learning to classify the tomato leaves images into ten categories of diseases. The proposed model has been trained and tested extensively on publicly available PlantVillage dataset. The proposed method achieved an accuracy of 99.51%, 98.65%, and 97.11% for tomato leaf image classification into 5 classes, 7 classes, and 10 classes, respectively. The proposed approach shows its superiority over the existing methodologies.
Keywords: Deep learning; Tomato plant disease detection; Conditional Generative Adversarial Network; Data augmentation; Pre-trained DesnseNet121 network; Synthetic Images

Sushant Kumar Pandey, Anil Kumar Tripathi,
BCV-Predictor: A bug count vector predictor of a successive version of the software system,
Knowledge-Based Systems,
Volume 197,
2020,
105924,
ISSN 0950-7051,
https://doi.org/10.1016/j.knosys.2020.105924.
(https://www.sciencedirect.com/science/article/pii/S0950705120302604)
Abstract: Predicting the number of bugs in a software system intensifies the software quality and turns down the testing effort required in software development. It reduces the overall cost of software development. The evolution of hardware, platform, and user requirements leads to develop the next version of a software system. In this article, we formulate a problem and its novel solution, i.e., we are considering the prediction of the bug count vector of a successive version of a software system. After predicting the bug count vector in the next version of a software, the developer team leader can adequately allocate the developers in respective fault dense modules, in a more faulty dense module, more number of developers required. We have conducted our experiment over seven PROMISE repository datasets of different versions. We build metadata using a concatenation of different versions of the same software system for conducting experiments. We proposed a novel architecture using deep learning called BCV-Predictor. BCV-Predictor predicts the bug count vector of the next version software system; it is trained using metadata. To the best of our knowledge, no such work has been done in these aspects. We also address overfitting and class imbalance problem using random oversampling method and dropout regularization techniques. We conclude that BCV-Predictor is conducive to predicting the bug count vector of the next version of the software. We found five out of seven meta datasets reaches to more than 80% accuracy. In all seven meta datasets, Mean Squared Error (MSE) lies from 0.71 to 4.715, Mean Absolute Error (MAE) lies from 0.22 to 1.679, MSE and MAE over validation set lie between 0.84 to 4.865, and 0.22 to 1.709 respectively. We also compared the performance of BCV-Predictor with eleven baselines techniques and found the proposed approach outperform on most of the meta-datasets.
Keywords: Number of bugs prediction; Bug count vector; Deep learning; Regression; Long short term memory (LSTM)

Xin Dong, Yan Liang, Shoichiro Miyamoto, Shingo Yamaguchi,
Ensemble learning based software defect prediction,
Journal of Engineering Research,
Volume 11, Issue 4,
2023,
Pages 377-391,
ISSN 2307-1877,
https://doi.org/10.1016/j.jer.2023.10.038.
(https://www.sciencedirect.com/science/article/pii/S2307187723002997)
Abstract: Currently, the cost to detect and solve software defects is a heavy burden on software projects. So, it is significant to predict software defects at the earlier stages of the software development lifecycle. In this study, seven commonly-used machine learning and deep learning algorithms were studied and the performance of defect classification on 4 representative public datasets from NASA and the PROMISE repository was demonstrated. Furthermore, three classical ensemble learning methods (Bagging, Boosting, and Stacking) were used to improve the prediction performance. Six metrics, including accuracy, precision, f1-score, recall, the area under the receiver operating characteristic curve (AUC), and G-Mean were utilized to evaluate the performance. It was noted that ensemble learning exceeded all the other seven algorithms. Ensemble learning achieved the highest AUC of 0.99, the highest G-Mean of 0.96, and an average F1-score of 0.97. Under a time-sensitive scenario, the Boosting method was a good choice as it spent less runtime and had a similar performance to the other two ensemble learning methods in most cases.
Keywords: Software defect prediction; MLP; CNN; Ensemble learning

Bowen Li, Jianxun Zhang, Jie Cao, Jie Zhang, Linfeng Gao,
PMST: A parallel and miniature Swin transformer for logo detection,
Digital Signal Processing,
Volume 140,
2023,
104102,
ISSN 1051-2004,
https://doi.org/10.1016/j.dsp.2023.104102.
(https://www.sciencedirect.com/science/article/pii/S1051200423001975)
Abstract: With the popularity of online shopping and the rise of various brands, logo detection is gradually coming to the forefront of researchers' minds. However, accurately detecting multiscale, similar, diverse and shape-shifting logos poses a challenge for this technology. The Swin transformer has created a milestone as a high-performance deep learning method across modalities, domains and tasks in various tasks of computer vision. We improve the Swin transformer for better image feature extraction and enhance the robustness for its application to logo detection. In this paper, we propose the PMST as the backbone of logo detection, and design a bypass-parallelizable shift module and a miniature window tandem shift strategy to further enhance image feature fusion and transfer between windows. The PMST achieves a 79.2 box AP on the LogoData dataset, surpassing most detection models. According to existing known methods, in logo detection, the PMST is the first backbone to put transformer to the detection. The results achieved state-of-the-art on the FlickrLogos-32 and FoodLogoDet-1500 datasets. It also achieves excellent efficiency on the ImageNet-1K, OpenBrands-80 and MS-COCO datasets. The code is available at https://github.com/blowhen/PMST.
Keywords: Logo detection; Deep learning; Improved Swin transformer; Object detection; Transfer learning

Albert Salim,  Juliandry, Louis Raymond, Jurike V Moniaga,
General pattern recognition using machine learning in the cloud,
Procedia Computer Science,
Volume 216,
2023,
Pages 565-570,
ISSN 1877-0509,
https://doi.org/10.1016/j.procs.2022.12.170.
(https://www.sciencedirect.com/science/article/pii/S1877050922022487)
Abstract: Machine learning (ML) and cloud computing are two subjects that mix very well. The existence of cloud computing enables data scientists to create their machine learning models with the benefits of cloud computing which are very low cost, high performance, and high availability. This opens a new opportunity of allowing students and other people to utilize powerful machines for daily use with the help of appropriate cloud service. On the other hand, machine learning is usually perfect for recognizing patterns in our daily life. This article discusses the possibility and the benefit of creating a user-friendly general-purpose pattern recognition that can be played around by anyone using software as a service.
Keywords: cloud computing; machine learning; software as a service; machine learning as a service; pattern recognition

Görkem Giray,
A software engineering perspective on engineering machine learning systems: State of the art and challenges,
Journal of Systems and Software,
Volume 180,
2021,
111031,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2021.111031.
(https://www.sciencedirect.com/science/article/pii/S016412122100128X)
Abstract: Context:
Advancements in machine learning (ML) lead to a shift from the traditional view of software development, where algorithms are hard-coded by humans, to ML systems materialized through learning from data. Therefore, we need to revisit our ways of developing software systems and consider the particularities required by these new types of systems.
Objective:
The purpose of this study is to systematically identify, analyze, summarize, and synthesize the current state of software engineering (SE) research for engineering ML systems.
Method:
I performed a systematic literature review (SLR). I systematically selected a pool of 141 studies from SE venues and then conducted a quantitative and qualitative analysis using the data extracted from these studies.
Results:
The non-deterministic nature of ML systems complicates all SE aspects of engineering ML systems. Despite increasing interest from 2018 onwards, the results reveal that none of the SE aspects have a mature set of tools and techniques. Testing is by far the most popular area among researchers. Even for testing ML systems, engineers have only some tool prototypes and solution proposals with weak experimental proof. Many of the challenges of ML systems engineering were identified through surveys and interviews. Researchers should conduct experiments and case studies, ideally in industrial environments, to further understand these challenges and propose solutions.
Conclusion:
The results may benefit (1) practitioners in foreseeing the challenges of ML systems engineering; (2) researchers and academicians in identifying potential research questions; and (3) educators in designing or updating SE courses to cover ML systems engineering.
Keywords: Software engineering; Software development; Software process; Machine learning; Deep learning; Systematic literature review

Victor Chang, Vallabhanent Rupa Bhavani, Ariel Qianwen Xu, MA Hossain,
An artificial intelligence model for heart disease detection using machine learning algorithms,
Healthcare Analytics,
Volume 2,
2022,
100016,
ISSN 2772-4425,
https://doi.org/10.1016/j.health.2022.100016.
(https://www.sciencedirect.com/science/article/pii/S2772442522000016)
Abstract: The paper focuses on the construction of an artificial intelligence-based heart disease detection system using machine learning algorithms. We show how machine learning can help predict whether a person will develop heart disease. In this paper, a python-based application is developed for healthcare research as it is more reliable and helps track and establish different types of health monitoring applications. We present data processing that entails working with categorical variables and conversion of categorical columns. We describe the main phases of application developments: collecting databases, performing logistic regression, and evaluating the dataset’s attributes. A random forest classifier algorithm is developed to identify heart diseases with higher accuracy. Data analysis is needed for this application, which is considered significant according to its approximately 83% accuracy rate over training data. We then discuss the random forest classifier algorithm, including the experiments and the results, which provide better accuracies for research diagnoses. We conclude the paper with objectives, limitations and research contributions.
Keywords: Artificial intelligence; Heart disease detection system; Machine learning; Predictive analytics; Random forest classifier algorithm

Laanaoui My Driss, Aatila Mustapha, Lachgar Mohamed, Hrimech Hamid, Okacha Najia, Assouma Roukéya, Abou Elkhir Mohamed,
Version [1.1.0]- [DLDiagnosis: A mobile and web application for diseases classification using Deep Learning],
SoftwareX,
Volume 26,
2024,
101745,
ISSN 2352-7110,
https://doi.org/10.1016/j.softx.2024.101745.
(https://www.sciencedirect.com/science/article/pii/S235271102400116X)
Abstract: This paper presents version 1.1.0 of the DLDiagnosis software, which serves as an automated decision support tool for disease detection and classification through imaging analysis using deep learning. The latest update of DLDiagnosis includes significant enhancements, expanding the system to manage a total of eight different diseases. Three new diseases have been added: keratoconus, breast cancer, and pneumonia. This update focuses on refining user interface elements, identifying gaps in code logic, and improving mobile and web interface elements. Additionally, various functionalities have been improved, including reduced diagnostic latency, faster results, enhanced responsiveness, and a more consistent and intuitive diagnostic experience.
Keywords: Decision-making support; Images classification; Deep learning; Mobile application; Diagnosis

Aleksandar Kovačević, Jelena Slivka, Dragan Vidaković, Katarina-Glorija Grujić, Nikola Luburić, Simona Prokić, Goran Sladić,
Automatic detection of Long Method and God Class code smells through neural source code embeddings,
Expert Systems with Applications,
Volume 204,
2022,
117607,
ISSN 0957-4174,
https://doi.org/10.1016/j.eswa.2022.117607.
(https://www.sciencedirect.com/science/article/pii/S0957417422009186)
Abstract: Code smells are structures in code that often harm its quality. Manually detecting code smells is challenging, so researchers proposed many automatic detectors. Traditional code smell detectors employ metric-based heuristics, but researchers have recently adopted a Machine-Learning (ML) based approach. This paper compares the performance of multiple ML-based code smell detection models against multiple metric-based heuristics for detection of God Class and Long Method code smells. We assess the effectiveness of different source code representations for ML: we evaluate the effectiveness of traditionally used code metrics against code embeddings (code2vec, code2seq, and CuBERT). This study is the first to evaluate the effectiveness of pre-trained neural source code embeddings for code smell detection to the best of our knowledge. This approach helped us leverage the power of transfer learning – our study is the first to explore whether the knowledge mined from code understanding models can be transferred to code smell detection. A secondary contribution of our research is the systematic evaluation of the effectiveness of code smell detection approaches on the same large-scale, manually labeled MLCQ dataset. Almost every study that proposes a detection approach tests this approach on the dataset unique for the study. Consequently, we cannot directly compare the reported performances to derive the best-performing approach.
Keywords: Code smell detection; Neural source code embeddings; Code metrics; Machine learning; Software engineering

Fernando G. Soley,
Predatory flexibility of an araneophagic assassin bug derives from a few behavioural rules,
Animal Behaviour,
2024,
,
ISSN 0003-3472,
https://doi.org/10.1016/j.anbehav.2024.02.013.
(https://www.sciencedirect.com/science/article/pii/S0003347224000630)
Abstract: The assassin bug Stenolemus giraffa preys upon various web-building spiders, which are themselves dangerous predators. Here I review several aspects of the predatory behaviour of S. giraffa to argue that, unlike many web-invading araneophagic species, its primary predatory strategy is based on stealth. Going unnoticed in a spider web is a difficult task for an insect because the web acts as an extension of the spider's sensory system. Despite encountering substantial variation in web type and spider behaviour, S. giraffa can successfully adjust its behaviour to prey upon several distinct spider species. This supports the idea that dangerous prey can act as selective factors that favour flexibility in predators. Further, I suggest that the complex behaviour of S. giraffa can emerge from a simple set of seemingly ‘hardwired’ yet flexible rules that are principally guided by sensory systems. Still, other details in the behaviour of S. giraffa suggest that its ability for flexible problem solving could also involve cognitive processes that can fine-tune an innate predatory strategy. As part of this special issue honouring Bill Eberhard and Mary Jane West-Eberhard, I also briefly illustrate how detailed observations of behaviour are essential in disentangling hypotheses about the predatory strategy of araneophagic species.
Keywords: araneophagy; behavioural plasticity; decision making; flexibility; predator–prey interaction; Stenolemus giraffa

R. Sujatha, Jyotir Moy Chatterjee, NZ Jhanjhi, Sarfraz Nawaz Brohi,
Performance of deep learning vs machine learning in plant leaf disease detection,
Microprocessors and Microsystems,
Volume 80,
2021,
103615,
ISSN 0141-9331,
https://doi.org/10.1016/j.micpro.2020.103615.
(https://www.sciencedirect.com/science/article/pii/S0141933120307626)
Abstract: Plants are recognized as essential as they are the primary source of humanity's energy production since they are having nutritious, medicinal, etc. values. At any time between crop farming, plant diseases can affect the leaf, resulting in enormous crop production damages and economic market value. Therefore, in the farming industry, identification of leaf disease plays a crucial role. It needs, however, enormous labor, greater preparation time, and comprehensive plant pathogen knowledge. For the identification of plant disease detection various machine learning (ML) as well as deep learning (DL) methods are developed & examined by various researchers, and many of the times they also got significant results in both cases. Motivated by those existing works, here in this article we are comparing the performance of ML (Support Vector Machine (SVM), Random Forest (RF), Stochastic Gradient Descent (SGD)) & DL (Inception-v3, VGG-16, VGG-19) in terms of citrus plant disease detection. The disease classification accuracy (CA) we received by experimentation is quite impressive as DL methods perform better than that of ML methods in case of disease detection as follows: RF-76.8% > SGD-86.5% > SVM-87% > VGG-19–87.4% > Inception-v3–89% > VGG-16–89.5%. From the result, we can tell that RF is giving the least CA whereas VGG-16 is giving the best in terms of CA.
Keywords: Plant disease; ML; DL; SVM; RF; SGD; Inception-v3; VGG-16; VGG-19; CA

Fanny E. Eberhard, Sven Klimpel, Alessandra A. Guarneri, Nicholas J. Tobias,
Metabolites as predictive biomarkers for Trypanosoma cruzi exposure in triatomine bugs,
Computational and Structural Biotechnology Journal,
Volume 19,
2021,
Pages 3051-3057,
ISSN 2001-0370,
https://doi.org/10.1016/j.csbj.2021.05.027.
(https://www.sciencedirect.com/science/article/pii/S2001037021002087)
Abstract: Trypanosoma cruzi, the causative agent of Chagas disease (American trypanosomiasis), colonizes the intestinal tract of triatomines. Triatomine bugs act as vectors in the life cycle of the parasite and transmit infective parasite stages to animals and humans. Contact of the vector with T.cruzi alters its intestinal microbial composition, which may also affect the associated metabolic patterns of the insect. Earlier studies suggest that the complexity of the triatomine fecal metabolome may play a role in vector competence for different T. cruzi strains. Using high-resolution mass spectrometry and supervised machine learning, we aimed to detect differences in the intestinal metabolome of the triatomine Rhodnius prolixus and predict whether the insect had been exposed to T. cruzi or not based solely upon their metabolic profile. We were able to predict the exposure status of R. prolixus to T. cruzi with accuracies of 93.6%, 94.2% and 91.8% using logistic regression, a random forest classifier and a gradient boosting machine model, respectively. We extracted the most important features in producing the models and identified the major metabolites which assist in positive classification. This work highlights the complex interactions between triatomine vector and parasite including effects on the metabolic signature of the insect.
Keywords: Trypanosoma cruzi; Metabolomics; Chagas disease; Host-parasite interaction; Rhodnius prolixus; Supervised machine learning

Yilin Wang, Xiangping Chen, Yuan Huang, Hao-Nan Zhu, Jing Bian, Zibin Zheng,
An empirical study on real bug fixes from solidity smart contract projects,
Journal of Systems and Software,
Volume 204,
2023,
111787,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111787.
(https://www.sciencedirect.com/science/article/pii/S0164121223001826)
Abstract: Smart contracts are pieces of code that reside inside the blockchains and can be triggered to execute any transaction when specifically predefined conditions are satisfied. Being commonly used for commercial transactions in blockchain makes the security of smart contracts particularly important. Over the last few years, we have seen a great deal of academic and practical interest in detecting and fixing the bugs in smart contracts written by Solidity. But little is known about the real bug fixes in Solidity smart contract projects. To understand the bug fixes and enrich the knowledge of bug fixes in real-world projects, we conduct an empirical study on historical bug fixes from 46 real-world Solidity smart contract projects in this paper. We provide a multi-faceted discussion and mainly explore the following four questions: File Type and Amount, Fix Complexity, Bug distribution, and Fix Patches. We distill four findings during the process to explore these four questions. Finally, based on these findings, we provide actionable implications to improve the current approaches to fixing bugs in Solidity smart contracts from three aspects: Automatic repair techniques, Analysis tools, and Solidity developers.
Keywords: Bug fix; Empirical study; Smart contract; Solidity

Tal Tsafrir, Aviad Cohen, Etay Nir, Nir Nissim,
Efficient feature extraction methodologies for unknown MP4-Malware detection using Machine learning algorithms,
Expert Systems with Applications,
Volume 219,
2023,
119615,
ISSN 0957-4174,
https://doi.org/10.1016/j.eswa.2023.119615.
(https://www.sciencedirect.com/science/article/pii/S0957417423001161)
Abstract: We are living in an era in which daily interaction between individuals and businesses involves sending, uploading, and sharing videos as a means of communication and advertising. However, many users are unaware of the risks associated with opening a malicious video file, it is thus no surprise that cyber-criminals have taken advantage of this situation and adopted this attack vector in recent years. MP4 is one of the most commonly used video formats, and its properties make it well-suited for software vulnerability exploitation across multiple platforms, which can ultimately lead to a cyberattack. Due to their deterministic, signature-based technique, antivirus software solutions are limited in their ability to detect unknown malware, let alone zero-day attacks. Machine learning (ML) algorithms have been effective in detecting known and unknown malware across various file formats, domains, and platforms. ML algorithms’ performance relies heavily on the feature extraction methodology. However, to the best of our knowledge, there is no designated and specialized feature extraction methodology for MP4 files which generates a set of features for the task of unknown MP4 file malware detection. In this paper, we present three innovative and efficient feature extraction methodologies for unknown MP4 file malware detection. Two of them are file structure-based and one is knowledge-based. The methodologies are evaluated in a series of five experiments using six ML algorithms and 177 different datasets which represent different configurations of feature extraction, representation, and selection. The datasets are based on a representative collection of 6,229 files − 5,066 benign (∼81.3 %) files and 1,163 malicious files (∼18.7 %). The first three experiments demonstrate the methodologies’ discrimination and generalization capabilities across multiple configurations, in terms of known and unknown MP4 file malware detection. The fourth experiment shows that applying principal component analysis (PCA) on the features suggested by the methodologies can improve time and space complexity and feature resilience while maintaining strong detection and generalization capabilities. In the fifth experiment, the methodologies’ best performing configuration is compared to state-of-the-art, generic feature extraction methodologies, such as n-grams, MinHash, and representation and transfer learning (using a CNN), in the task of unknown MP4 file malware detection. The results show that our best performing configuration outperforms all other state-of-the-art feature extraction methodologies with an AUC, TPR, and FPR of 0.9951, 0.976, and 0.0 respectively.
Keywords: Feature Extraction; MP4; Media; Non-Executable; Malware; Detection; Machine Learning

Tushar Sharma, Maria Kechagia, Stefanos Georgiou, Rohit Tiwari, Indira Vats, Hadi Moazen, Federica Sarro,
A survey on machine learning techniques applied to source code,
Journal of Systems and Software,
Volume 209,
2024,
111934,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111934.
(https://www.sciencedirect.com/science/article/pii/S0164121223003291)
Abstract: The advancements in machine learning techniques have encouraged researchers to apply these techniques to a myriad of software engineering tasks that use source code analysis, such as testing and vulnerability detection. Such a large number of studies hinders the community from understanding the current research landscape. This paper aims to summarize the current knowledge in applied machine learning for source code analysis. We review studies belonging to twelve categories of software engineering tasks and corresponding machine learning techniques, tools, and datasets that have been applied to solve them. To do so, we conducted an extensive literature search and identified 494 studies. We summarize our observations and findings with the help of the identified studies. Our findings suggest that the use of machine learning techniques for source code analysis tasks is consistently increasing. We synthesize commonly used steps and the overall workflow for each task and summarize machine learning techniques employed. We identify a comprehensive list of available datasets and tools useable in this context. Finally, the paper discusses perceived challenges in this area, including the availability of standard datasets, reproducibility and replicability, and hardware resources. Editor’s note: Open Science material was validated by the Journal of Systems and Software Open Science Board.
Keywords: Machine learning for software engineering; Source code analysis; Deep learning; Datasets; Tools

Manishankar Mondal, Banani Roy, Chanchal K. Roy, Kevin A. Schneider,
An empirical study on bug propagation through code cloning,
Journal of Systems and Software,
Volume 158,
2019,
110407,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2019.110407.
(https://www.sciencedirect.com/science/article/pii/S0164121219301815)
Abstract: Code clones are identical or nearly similar code fragments in a code-base. According to the existing studies, code clones are directly related to bugs. Code cloning, creating code clones, is suspected to propagate temporarily hidden bugs from one code fragment to another. However, there is no study on the intensity of bug-propagation through code cloning. In this paper, we define two clone evolutionary patterns that reasonably indicate bug propagation through code cloning. By analyzing software evolution history, we identify those code clones that evolved following the bug propagation patterns. According to our study on thousands of commits of seven subject systems, overall 18.42% of the clone fragments that experience bug-fixes contain propagated bugs. Type-3 clones are primarily involved with bug-propagation. Bug propagation is more likely to occur in the clone fragments that are created in the same commit rather than in different commits. Moreover, code clones residing in the same file have a higher possibility of containing propagated bugs compared to those residing in different files. Severe bugs can sometimes get propagated through code cloning. Automatic support for immediately identifying occurrences of bug-propagation can be beneficial for software maintenance. Our findings are important for prioritizing code clones for management.
Keywords: Code clones; Clone-types; Bug propagation; Software maintenance

Rongze Xu, Zhanyong Tang, Guixin Ye, Huanting Wang, Xin Ke, Dingyi Fang, Zheng Wang,
Detecting code vulnerabilities by learning from large-scale open source repositories,
Journal of Information Security and Applications,
Volume 69,
2022,
103293,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2022.103293.
(https://www.sciencedirect.com/science/article/pii/S221421262200148X)
Abstract: Machine learning methods are widely used to identify common, repeatedly occurring bugs and code vulnerabilities. The performance of a machine-learned model is bounded by the quality and quantity of training data and the model’s capability in extracting and capturing the essential information of the problem domain. Unfortunately, there is a storage of high-quality samples for training code vulnerability detection models, and existing machine learning methods are inadequate in capturing code vulnerability patterns. We present Developer,11Developer = Detecting codE VulnerabilitiEs at the Large scale by learning from OPen sourcE Repositories. a novel learning framework for building code vulnerability detection models. To address the data scarcity challenge, Developer automatically gathers training samples from open-source projects and applies constraints rules to the collected data to filter out noisy data to improve the quality of the collected samples. The collected data provides many real-world vulnerable code training samples to complement the samples available in standard vulnerable databases. To build an effective code vulnerability detection model, Developer employs a convolutional neural network architecture with attention mechanisms to extract code representation from the program abstract syntax tree. The extracted program representation is then fed to a downstream network – a bidirectional long–short term memory architecture – to predict if the target code contains a vulnerability or not. We apply Developer to identify vulnerabilities at the program source-code level. Our evaluation shows that Developer outperforms state-of-the-art methods by uncovering more vulnerabilities with a lower false-positive rate.
Keywords: Code vulnerability detection; Deep learning; Attention mechanism; Software vulnerability

Sofien Boutaib, Maha Elarbi, Slim Bechikh, Carlos A. Coello Coello, Lamjed Ben Said,
Uncertainty-wise software anti-patterns detection: A possibilistic evolutionary machine learning approach,
Applied Soft Computing,
Volume 129,
2022,
109620,
ISSN 1568-4946,
https://doi.org/10.1016/j.asoc.2022.109620.
(https://www.sciencedirect.com/science/article/pii/S156849462200669X)
Abstract: Context:
Code smells (a.k.a. anti-patterns) are manifestations of poor design solutions that can deteriorate software maintainability and evolution.
Research gap:
Existing works did not take into account the issue of uncertain class labels, which is an important inherent characteristic of the smells detection problem. More precisely, two human experts may have different degrees of uncertainty about the smelliness of a particular software class not only for the smell detection task but also for the smell type identification one. Unluckily, existing approaches usually reject and/or ignore uncertain data that correspond to software classes (i.e. dataset instances) with uncertain labels. Throwing away and/or disregarding the uncertainty factor could considerably degrade the detection/identification process effectiveness. From a solution approach viewpoint, there is no work in the literature that proposed a method that is able to detect and/or identify code smells while preserving the uncertainty aspect.
Objective:
The main goal of our research work is to handle the uncertainty factor, issued from human experts, in detecting and/or identifying code smells by proposing an evolutionary approach that is able to deal with anti-patterns classification with uncertain labels.
Method:
We suggest Bi-ADIPOK, as an effective search-based tool that is capable to tackle the previously mentioned challenge for both detection and identification cases. The proposed method corresponds to an EA (Evolutionary Algorithm) that optimizes a set of detectors encoded as PK-NNs (Possibilistic K-nearest neighbors) based on a bi-level hierarchy, in which the upper level role consists on finding the optimal PK-NNs parameters, while the lower level one is to generate the PK-NNs. A newly fitness function has been proposed fitness function PomAURPC-OVA_dist (Possibilistic modified Area Under Recall Precision Curve One-Versus-All_distance, abbreviated PAURPC_d in this paper). Bi-ADIPOK is able to deal with label uncertainty using some concepts stemming from the Possibility Theory. Furthermore, the PomAURPC-OVA_dist is capable to process the uncertainty issue even with imbalanced data. We notice that Bi-ADIPOK is first built and then validated using a possibilistic base of smell examples that simulates and mimics the subjectivity of software engineers opinions.
Results:
The statistical analysis of the obtained results on a set of comparative experiments with respect to four relevant state-of-the-art methods shows the merits of our proposal. The obtained detection results demonstrate that, for the uncertain environment, the PomAURPC-OVA_dist of Bi-ADIPOK ranges between 0.902 and 0.932 and its IAC lies between 0.9108 and 0.9407, while for the certain environment, the PomAURPC-OVA_dist lies between 0.928 and 0.955 and the IAC ranges between 0.9477 and 0.9622. Similarly, the identification results, for the uncertain environment, indicate that the PomAURPC-OVA_dist of Bi-ADIPOK varies between 0.8576 and 0.9273 and its IAC is between 0.8693 and 0.9318. For the certain environment, the PomAURPC-OVA_dist lies between 0.8613 and 0.9351 and the IAC values are between 0.8672 and 0.9476. With uncertain data, Bi-ADIPOK can find 35% more code smells than the second best approach (i.e., BLOP). Furthermore, Bi-ADIPOK has succeeded to reduce the number of false alarms (i.e., misclassified smelly instances) by 12%. In addition, our proposed approach can identify 43% more smell types than BLOP and reduces the number of false alarms by 32%. The same results have been obtained for the certain environment, demonstrating Bi-ADIPOK’s ability to deal with such environment.
Keywords: Code smells detection; Data uncertainty; Possibility theory; Evolutionary Algorithm; Possibilistic K-NN

Ilias Kalouptsoglou, Miltiadis Siavvas, Apostolos Ampatzoglou, Dionysios Kehagias, Alexander Chatzigeorgiou,
Software vulnerability prediction: A systematic mapping study,
Information and Software Technology,
Volume 164,
2023,
107303,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107303.
(https://www.sciencedirect.com/science/article/pii/S095058492300157X)
Abstract: Context:
Software security is considered a major aspect of software quality as the number of discovered vulnerabilities in software products is growing. Vulnerability prediction is a mechanism that helps engineers to prioritize their inspection efforts focusing on vulnerable parts. Despite the recent advancements, current literature lacks a systematic mapping study on vulnerability prediction.
Objective:
This paper aims to analyze the state-of-the-art of vulnerability prediction focusing on: (a) the goals of vulnerability prediction-related studies; (b) the data collection processes and the types of datasets that exist in the literature; (c) the mostly examined techniques for the construction of the prediction models and their input features; and (d) the utilized evaluation techniques.
Method:
We collected 180 primary studies following a broad search methodology across four popular digital libraries. We mapped these studies to the variables of interest and we identified trends and relationships between the studies.
Results:
The main findings suggest that: (i) there are two major study types, prediction of vulnerable software components and forecasting of the evolution of vulnerabilities in software; (ii) most studies construct their own vulnerability-related dataset retrieving information from vulnerability databases for real-world software; (iii) there is a growing interest for deep learning models along with a trend on textual source code representation; and (iv) F1-score was found to be the most widely used evaluation metric.
Conclusions:
The results of our study indicate that there are several open challenges in the domain of vulnerability prediction. One of the major conclusions, is the fact that most studies focus on within-project prediction, neglecting the real-world scenario of cross-project prediction.
Keywords: Systematic mapping study; Software security; Vulnerability prediction; Machine learning

Yang Zhang, Chuyan Ge, Haiyang Liu, Kun Zheng,
Code smell detection based on supervised learning models: A survey,
Neurocomputing,
Volume 565,
2024,
127014,
ISSN 0925-2312,
https://doi.org/10.1016/j.neucom.2023.127014.
(https://www.sciencedirect.com/science/article/pii/S0925231223011372)
Abstract: Supervised learning-based code smell detection has become one of the dominant approaches to identify code smell. Existing works optimize the process of code smell detection from multiple aspects, such as high-quality dataset, feature selection, and model, etc. Although the accuracy is improved continuously, researchers are confused about what model are the most suitable ones to detect code smell when considering dataset construction and feature selection. Furthermore, existing surveys for code smell mainly analyze the impact of code smell, categorize the concerns of code smell, and repair code smell. There is a lack of systematic analysis and classification of code smell detection based on supervised learning. To this end, we collect 86 papers of code smell detection based on supervised learning ranging from January 2010 to April 2023. A total of 7 research questions is empirically evaluated from different aspects, such as datasets construction, data pre-processing, feature selection, and model training, etc. We conclude that existing works suffer from issues such as sample imbalance, different attention to types of code smell, and limited feature selection. Finally, we suggest possible future research directions.
Keywords: Code smell; Supervised learning; Feature selection; Dataset; Data balancing

Feisal Alaswad, E. Poovammal,
Software quality prediction using machine learning,
Materials Today: Proceedings,
Volume 62, Part 7,
2022,
Pages 4714-4720,
ISSN 2214-7853,
https://doi.org/10.1016/j.matpr.2022.03.165.
(https://www.sciencedirect.com/science/article/pii/S2214785322014936)
Abstract: Background
The demand for software is increasing every day in various fields. Software developers put more effort to develop and test the quality of the software and verify its reliability before it is released. High-quality software modules were developed to allow others to reuse the components. Purpose: This paper provides information to researchers in the software quality prediction field based on machine learning algorithms. Methodology: Most of the machine learning techniques and the relevant software metrics used in many high-quality papers published between 2010 and the end of 2021 have been analysed. Findings: Machine learning techniques are the most suitable for predicting software quality. Most of the researchers' interest was to predict the reliability of software. The detailed analysis enables researchers to choose the best way to plan their research and to make a good contribution in the field of software quality prediction.
Keywords: Software Engineering; Software Metrics; Deep learning; Transfer learning; Trend analysis

Omar Dib, Zhenghan Nan, Jinkua Liu,
Machine learning-based ransomware classification of Bitcoin transactions,
Journal of King Saud University - Computer and Information Sciences,
Volume 36, Issue 1,
2024,
101925,
ISSN 1319-1578,
https://doi.org/10.1016/j.jksuci.2024.101925.
(https://www.sciencedirect.com/science/article/pii/S1319157824000144)
Abstract: Ransomware presents a significant threat to the security and integrity of cryptocurrency transactions. This research paper explores the intricacies of ransomware detection in cryptocurrency transactions using the Bitcoinheist dataset. The dataset encompasses 28 distinct families classified into three ransomware categories: Princeton, Montreal, and Padua, along with a white category representing legitimate transactions. We propose a novel hybrid supervised and semi-supervised multistage machine learning framework to tackle this challenge. Our framework effectively classifies known ransomware families by leveraging ensemble learning techniques such as Decision Tree, Random Forest, XGBoost, and Stacking. Additionally, we introduce a novel semi-supervised approach to accurately identify previously unseen ransomware instances within the dataset. Through rigorous evaluation employing comprehensive classification metrics, including accuracy, precision, recall, F1 score, RoC score, and prediction time, our proposed approach demonstrates promising results in ransomware detection within cryptocurrency transactions.
Keywords: Ransomware detection; Cryptocurrency transactions; BitcoinHeist dataset; Machine learning methods; Anomaly detection

Görkem Giray, Kwabena Ebo Bennin, Ömer Köksal, Önder Babur, Bedir Tekinerdogan,
On the use of deep learning in software defect prediction,
Journal of Systems and Software,
Volume 195,
2023,
111537,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2022.111537.
(https://www.sciencedirect.com/science/article/pii/S0164121222002138)
Abstract: Context:
Automated software defect prediction (SDP) methods are increasingly applied, often with the use of machine learning (ML) techniques. Yet, the existing ML-based approaches require manually extracted features, which are cumbersome, time consuming and hardly capture the semantic information reported in bug reporting tools. Deep learning (DL) techniques provide practitioners with the opportunities to automatically extract and learn from more complex and high-dimensional data.
Objective:
The purpose of this study is to systematically identify, analyze, summarize, and synthesize the current state of the utilization of DL algorithms for SDP in the literature.
Method:
We systematically selected a pool of 102 peer-reviewed studies and then conducted a quantitative and qualitative analysis using the data extracted from these studies.
Results:
Main highlights include: (1) most studies applied supervised DL; (2) two third of the studies used metrics as an input to DL algorithms; (3) Convolutional Neural Network is the most frequently used DL algorithm.
Conclusion:
Based on our findings, we propose to (1) develop more comprehensive DL approaches that automatically capture the needed features; (2) use diverse software artifacts other than source code; (3) adopt data augmentation techniques to tackle the class imbalance problem; (4) publish replication packages.
Keywords: Software defect prediction; Deep learning; Quality assurance; Systematic literature review

Phillip Garrad, Saritha Unnikrishnan,
Reinforcement learning in VANET penetration testing,
Results in Engineering,
Volume 17,
2023,
100970,
ISSN 2590-1230,
https://doi.org/10.1016/j.rineng.2023.100970.
(https://www.sciencedirect.com/science/article/pii/S259012302300097X)
Abstract: The recent popularity of Connected and Autonomous Vehicles (CAV) corresponds with an increase in the risk of cyber-attacks. These cyber-attacks are instigated by white-coat hackers, and cyber-criminals. As Connected Vehicles move towards full autonomy the impact of these cyber-attacks also grows. The current research highlights challenges faced in cybersecurity testing of CAV, including access, the cost of representative test setup and the lack of experts in the field. Possible solutions of how these challenges can be overcome are reviewed and discussed. From these findings a software simulated Vehicular Ad Hoc NETwork (VANET) is established as a cost-effective representative testbed. Penetration tests are then performed on this simulation, demonstrating a cyber-attack in CAV. Studies have shown Artificial Intelligence (AI) to improve runtime, increase efficiency and comprehensively cover all the typical test aspects, in penetration testing in other industries. In this research a Reinforcement Learning model, called Q-Learning, is applied to automate the software simulation. The expectation from this implementation is to see improvements in runtime and efficiency for the VANET model. The results show this approach to be promising and using AI in penetration testing for VANET to improve efficiency in most cases. Each case is reviewed in detail before discussing possible ways to improve the implementation and get a truer reflection of the real-world application.
Keywords: Cybersecurity; Connected vehicles; Software simulation; Artificial intelligence; Penetration testing

Zijie Huang, Huiqun Yu, Guisheng Fan, Zhiqing Shao, Mingchen Li, Yuguo Liang,
Aligning XAI explanations with software developers’ expectations: A case study with code smell prioritization,
Expert Systems with Applications,
Volume 238, Part A,
2024,
121640,
ISSN 0957-4174,
https://doi.org/10.1016/j.eswa.2023.121640.
(https://www.sciencedirect.com/science/article/pii/S0957417423021425)
Abstract: EXplainable Artificial Intelligence (XAI) aims at improving users’ trust in black-boxed models by explaining their predictions. However, XAI techniques produced unreasonable explanations for software defect prediction since expected outputs (e.g., causes of bugs) were not captured by features used to build models. To set aside feature engineering limitations and evaluate whether XAI could adapt to developers, we exploit XAI for code smell prioritization (i.e., predicting criticalities of sub-optimal coding practices and design choices), whose features could capture developers’ major expectations. We assess the gap between XAI explanations and developers’ expectations in terms of (1) the accuracy of prediction, (2) the coverage of explanations on expectations, and (3) the complexity of explanations. We also narrow the gap by preserving the features related to developers’ expectations as much as possible in feature selection. We find that XAI can explain smells with simpler causes in top 3 to 5 features. Complex smells can be explained in around 10 features, which need more expertise to interpret. Selecting features adapting to the developers’ expectations improves coverage by 5% to 29%, with almost no negative impact on accuracy and complexity. Results also highlight the need of dividing coarse-grained prediction targets and developing fine-grained feature engineering.
Keywords: Code smell; Software quality assurance; Explainable artificial intelligence; Empirical software engineering

Ying Xing, Hui Shu, Fei Kang,
PeerRemove: An adaptive node removal strategy for P2P botnet based on deep reinforcement learning,
Computers & Security,
Volume 128,
2023,
103129,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103129.
(https://www.sciencedirect.com/science/article/pii/S0167404823000391)
Abstract: Botnets have become one of the major intrusion threats to cybersecurity. P2P botnets have high concealment and resilience because of their distributed structure, which are difficult to be completely dismantled and destroyed. Existing methods based on traffic statistics and vulnerability tracing cannot effectively solve the problem of P2P botnet disintegration. Although P2P networks emphasize that each node is peer-to-peer, the difference in processing power, resource distribution, and node bandwidth can lead to a certain heterogeneity. The critical nodes bridge the underlying bot nodes and the upper control server. Traditional methods for ranking the importance of nodes mainly relies on classical graph-theoretic feature statistics method, such as degree, betweenness, clustering coefficient, feature vector centrality, PageRank, etc. In this paper, botnet defense strategies are investigated from the perspective of complex network graph theory, and graph embedding and deep reinforcement learning combination optimization methods are adopted to handle the critical nodes identification problem of P2P botnets. Then, a novel adaptive node removal model called PeerRemove is proposed. The model uses Structure2vec graph embedding to characterize the network structure information as a low-dimensional embedding space, and it uses n-step Q-learning to train the model to learn complex topological patterns to find the critical nodes that effectively disintegrate the network. To evaluate the effectiveness of the proposed method, the Area Under the Curve (AUC) of the Largest Connected Component (LCC) size during node removal is used as an evaluation indicator, and six different types real or synthetic P2P botnets are selected, namely Sality, ZeroAccess, NSIS, Mozi, Gnutella, and Peer sampling service. Experiments are conducted on many real and model networks with node sizes reaching thousands and tens of thousands, and our method is compared with five classical static or dynamic node attack methods of HAD, PageRank, CI, BPD, and HPRA. The experimental results show that the overall AUC curve of the PeerRemove method is lower than that of the benchmark method, which can minimize botnet resiliency at a small cost. The proposed method is superior to the existing node removal methods and shows good robustness and feasibility. To demonstrate the generality of this method, it is tested on a centralized topological dataset and good experimental results are obtained.
Keywords: Botnet; Critical node; Network dismantling; Deep reinforcement learning; Adaptive

Oleksandr Kuznetsov, Dmytro Zakharov, Emanuele Frontoni, Andrea Maranesi,
AttackNet: Enhancing biometric security via tailored convolutional neural network architectures for liveness detection,
Computers & Security,
Volume 141,
2024,
103828,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103828.
(https://www.sciencedirect.com/science/article/pii/S0167404824001299)
Abstract: Biometric security is the cornerstone of modern identity verification and authentication systems, where the integrity and reliability of biometric samples is of paramount importance. This paper introduces AttackNet, a bespoke Convolutional Neural Network architecture, meticulously designed to combat spoofing threats in biometric systems. Rooted in deep learning methodologies, this model offers a layered defense mechanism, seamlessly transitioning from low-level feature extraction to high-level pattern discernment. Three distinctive architectural phases form the crux of the model, each underpinned by judiciously chosen activation functions, normalization techniques, and dropout layers to ensure robustness and resilience against adversarial attacks. Benchmarking our model across diverse datasets affirms its prowess, showcasing superior performance metrics in comparison to contemporary models. Furthermore, a detailed comparative analysis accentuates the model's efficacy, drawing parallels with prevailing state-of-the-art methodologies. Through iterative refinement and an informed architectural strategy, AttackNet underscores the potential of deep learning in safeguarding the future of biometric security.
Keywords: Biometric authentication; Convolutional neural networks; Liveness detection; Spoofing attacks; Deep learning architectures; Security and robustness

Gaigai Tang, Lin Yang, Long Zhang, Hongyu Kuang, Huiqiang Wang,
MRC-VulLoc: Software source code vulnerability localization based on multi-choice reading comprehension,
Computers & Security,
Volume 141,
2024,
103816,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103816.
(https://www.sciencedirect.com/science/article/pii/S0167404824001172)
Abstract: Recently, automatic vulnerability detection approaches based on machine learning (ML) have outperformed traditional rule-based approaches in terms of detection performance. Existing ML-based approaches typically concentrate on function or line granularity, which fail to realize accurate vulnerability localization and are insufficient to support effective root cause analysis of vulnerability. To address this issue, we propose a new approach that maps the multi-choice reading comprehension (MRC) task to the vulnerability localization task at the granularity of vulnerability triggering path named MRC-VulLoc. Initially, we design six large datasets (including C/C++ and Java languages) in the form of MRC. Subsequently, we introduce a novel pre-trained vulnerability localization model, combining the effective code semantic comprehension ability of pre-trained model with the advantages of Bidirectional Short-Term Memory Network (Bi-LSTM) and Convolutional Neural Network (CNN) models. Lastly, we conduct experiments to evaluate the vulnerability localization with several state-of-the-art MRC approaches and vulnerability detectors. Experimental results demonstrate the effectiveness of the proposed datasets in evaluating MRC approaches for vulnerability localization. Furthermore, MRC-VulLoc achieves higher precision on vulnerability localization compared to comparative vulnerability detectors.
Keywords: Source code; Vulnerability localization; Machine learning; MRC

Zinniya Taffannum Pritee, Mehedi Hasan Anik, Saida Binta Alam, Jamin Rahman Jim, Md Mohsin Kabir, M.F. Mridha,
Machine learning and deep learning for user authentication and authorization in cybersecurity: A state-of-the-art review,
Computers & Security,
Volume 140,
2024,
103747,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103747.
(https://www.sciencedirect.com/science/article/pii/S0167404824000488)
Abstract: In the continuously developing field of cyber security, user authentication and authorization play a vital role in protecting personal information and digital assets from unauthorized use. As the field of cyber security expands, traditional user authentication and authorization approaches are not enough to prevent unauthorized access to personal information. Therefore, Machine Learning and Deep Learning models are introduced in cybersecurity. To assist researchers and cybersecurity experts in their research endeavours, a comprehensive and informative study is required covering the state-of-the-art advancements. Therefore, this research aimed to explore the field of Machine Learning and Deep Learning-based user authentication and authorization. More specifically, this paper intends to explore the diverse application domains of Machine Learning and Deep Learning-based user authentication and authorization. The paper also analyzes the commonly used datasets, pre-processing methods and Machine Learning and Deep Learning algorithms in user authentication and authorization. After that, this study conducts a thorough and detailed examination of some state-of-the-art articles' results and experimental details to enhance comprehension of the present advancements. Finally, the study engages in a comprehensive discussion concerning the various challenges encountered and outlines potential avenues for future research. This systematic review provides an all-encompassing overview of Machine Learning and Deep Learning-based user authentication and authorization, covering its application domains, models, analysis of state-of-the-art results, challenges, and research directions. It serves as a valuable resource for interdisciplinary studies.
Keywords: Cyber security; Network security; Cyber threats; Authentication; Authorization; Machine learning; Deep learning

Guangli Wu, Xingyue Wang, Jing Zhang,
PeerG: A P2P botnet detection method based on representation learning and graph contrastive learning,
Computers & Security,
Volume 140,
2024,
103775,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103775.
(https://www.sciencedirect.com/science/article/pii/S0167404824000762)
Abstract: P2P botnets are distributed with complex topology and communication behavior, making them harder to detect and remove. Individuals or organizations can effectively detect P2P botnets by analyzing abnormal behaviors in network traffic. Existing works focus on extracting deterministic traffic interaction features, which are highly dependent on statistical features. Moreover, these methods are mainly aimed at generalized botnet detection and lack specificity for detecting P2P botnets. They ignore the topological information of P2P botnets, resulting in unsatisfactory detection accuracy. Among the few existing methods targeting P2P botnets, they consider the topological information but mainly rely on classical graph theory statistical features, such as degree, feature vector centrality, etc. This limits the generalization ability of the detection model. In this paper, we delve into the topological features of P2P botnets from the perspective of complex graph theory. We propose a P2P botnet detection method that combines representation learning and graph contrastive learning, dubbed PeerG. Specifically, we construct the communication graphs based on the flow interaction behavior between components of the P2P botnets. The Line algorithm is employed to embed the nodes of the communication graph into a low-dimensional representation vector space. Subsequently, the graph contrastive learning approach is utilized to optimize the feature extractor, enabling it to capture more representative node features. PeerG serves as a benchmark detection model for identifying P2P botnet nodes. Additionally, we devise two optimized contrastive detection strategies (PeerG-PreG and PeerG-PreF) based on graph-level and feature-level to boost the performance of PeerG. Extensive experiments demonstrate that PeerG brings significant improvements in detection accuracy over state-of-art detection methods. Furthermore, compared with PeerG, the detection strategies PeerG-PreG and PeerG-PreF have further improved detection performance, and achieve the best detection accuracy among multiple filtered P2P botnet types.
Keywords: P2P botnet detection; Representation learning; Graph contrastive learning; Communication graph; Topology information

Md. Mamunur Rashid, Joarder Kamruzzaman, Mohammad Mehedi Hassan, Tasadduq Imam, Santoso Wibowo, Steven Gordon, Giancarlo Fortino,
Adversarial training for deep learning-based cyberattack detection in IoT-based smart city applications,
Computers & Security,
Volume 120,
2022,
102783,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.102783.
(https://www.sciencedirect.com/science/article/pii/S016740482200178X)
Abstract: Intrusion Detection Systems (IDS) based on deep learning models can identify and mitigate cyberattacks in IoT applications in a resilient and systematic manner. These models, which support the IDS’s decision, could be vulnerable to a cyberattack known as adversarial attack. In this type of attack, attackers create adversarial samples by introducing small perturbations to attack samples to trick a trained model into misclassifying them as benign applications. These attacks can cause substantial damage to IoT-based smart city models in terms of device malfunction, data leakage, operational outage and financial loss. To our knowledge, the impact of and defence against adversarial attacks on IDS models in relation to smart city applications have not been investigated yet. To address this research gap, in this work, we explore the effect of adversarial attacks on the deep learning and shallow machine learning models by using a recent IoT dataset and propose a method using adversarial retraining that can significantly improve IDS performance when confronting adversarial attacks. Simulation results demonstrate that the presence of adversarial samples deteriorates the detection accuracy significantly by above 70% while our proposed model can deliver detection accuracy above 99% against all types of attacks including adversarial attacks. This makes an IDS robust in protecting IoT-based smart city services.
Keywords: Smart city; Internet of things; Cyberattacks; Deep learning; Machine learning; Retraining

Saddam Hussain Khan, Tahani Jaser Alahmadi, Wasi Ullah, Javed Iqbal, Azizur Rahim, Hend Khalid Alkahtani, Wajdi Alghamdi, Alaa Omran Almagrabi,
A new deep boosted CNN and ensemble learning based IoT malware detection,
Computers & Security,
Volume 133,
2023,
103385,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103385.
(https://www.sciencedirect.com/science/article/pii/S016740482300295X)
Abstract: Security issues are threatened in various types of networks, especially in the Internet of Things (IoT) environment that requires early detection. IoT is the network of real-time devices like home automation systems and can be controlled by open-source android devices, which can be an open ground for attackers. Attackers can access the network credentials, initiate a different kind of security breach, and compromises network control. Therefore, timely detecting the increasing number of sophisticated malware attacks is the challenge to ensure the credibility of network protection. In this regard, we have developed a new malware detection framework, Deep Squeezed-Boosted and Ensemble Learning (DSBEL), comprised of novel Squeezed-Boosted Boundary-Region Split-Transform-Merge (SB-BR-STM) CNN and ensemble learning. The proposed STM block employs multi-path dilated convolutional, Boundary, and regional operations to capture the homogenous and heterogeneous global malicious patterns. Moreover, diverse feature maps are achieved using transfer learning and multi-path-based squeezing and boosting at initial and final levels to learn minute pattern variations. Finally, the boosted discriminative features are extracted from the developed deep SB-BR-STM CNN and provided to the ensemble classifiers (SVM, MLP, and AdabooSTM1) to improve the hybrid learning generalization. The performance analysis of the proposed DSBEL framework and SB-BR-STM CNN against the existing techniques have been evaluated by the IOT_Malware dataset on standard performance measures. Evaluation results show progressive performance as 98.50% accuracy, 97.12% F1-Score, 91.91% MCC, 95.97 % Recall, and 98.42 % Precision. The proposed malware analysis framework is robust and helpful for the timely detection of malicious activity and suggests future strategies.
Keywords: Malware; IoT; Ensemble learning; Deep learning; CNN; Detection

Han Yan, Senlin Luo, Limin Pan, Yifei Zhang,
HAN-BSVD: A hierarchical attention network for binary software vulnerability detection,
Computers & Security,
Volume 108,
2021,
102286,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2021.102286.
(https://www.sciencedirect.com/science/article/pii/S0167404821001103)
Abstract: Deep learning has shown effectiveness in binary software vulnerability detection due to its outstanding feature extraction capability independent of human expert experience. However, detection approaches such as Instruction2vec still have the following defects: (1) the context between an instruction’s elements (opcode, registers, etc.) is not fully incorporated when embedding a single instruction into its vector representation; (2) the crucial regions that related to vulnerability are not highlighted when extracting features of the vulnerable code. In this paper, we propose a hierarchical attention network for binary software vulnerability detection (HAN-BSVD). Through HAN-BSVD, the contextual information is first enriched by the preprocessor with unifying jump address and normalizing instruction, and then preserved by the instruction embedding network that composed of Bi-GRU and word-attention module; the local features are captured and the crucial regions are highlighted by the feature extraction network that composed of Text-CNN and spatial-attention module. The proposed approach is evaluated on the Juliet Test Suite dataset and the ICLR19 dataset, detection result performs better than the other compared approaches. Extensive ablation studies are also conducted to further prove the effectiveness of each design choice.
Keywords: Vulnerability detection; Static binary analysis; Hierarchical attention; Instruction embedding; Deep learning

Devrim Akgun, Selman Hizal, Unal Cavusoglu,
A new DDoS attacks intrusion detection model based on deep learning for cybersecurity,
Computers & Security,
Volume 118,
2022,
102748,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.102748.
(https://www.sciencedirect.com/science/article/pii/S0167404822001432)
Abstract: The data is exposed to many attacks during communication in the network environment. It is becoming increasingly essential to identify intrusions into network communications. Researchers use machine learning techniques to design effective intrusion detection systems. In this study, we proposed an intrusion detection system that includes preprocessing procedures and a deep learning model to detect DDoS attacks. For this purpose, various models based on Deep Neural Networks (DNN), Convolutional Neural Networks (CNN), and Long Short Term Memory (LSTM) have been evaluated in terms of detection performance and real-time performance. We tested the suggested model using the CIC-DDoS2019 dataset, which is frequently used in the literature. We applied preprocess techniques such as feature elimination, random subset selection, feature selection, duplication removal, and normalization to the CIC-DDoS2019 dataset. As a result, better recognition performance was obtained for the training and testing evaluations. According to the test results, 99.99% for binary and 99.30% for multiclass accuracy using the CNN-based inception like model gave the best results among the proposed models. Also, the inference time of the proposed model for various sizes of test data looks promising compared to baseline models with a smaller number of trainable parameters. The proposed IDS system, together with the preprocessing methods, provides better results when compared to state-of-the-art studies.
Keywords: Intrusion detection system; Deep learning; Cloud security; DDoS; Data preprocessing

Zhendong Wang, Yaodi Liu, Daojing He, Sammy Chan,
Intrusion detection methods based on integrated deep learning model,
Computers & Security,
Volume 103,
2021,
102177,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2021.102177.
(https://www.sciencedirect.com/science/article/pii/S0167404821000018)
Abstract: Intrusion detection system can effectively identify abnormal data in complex network environments, which is an effective method to ensure computer network security. Recently, deep neural networks have been widely used in image recognition, natural language processing, network security and other fields. For network intrusion detection, this paper designs an integrated deep intrusion detection model based on SDAE-ELM to overcome the long training time and low classification accuracy of existing deep neural network models, and to achieve timely response to intrusion behavior. For host intrusion detection, an integrated deep intrusion detection model based on DBN-Softmax is constructed, which effectively improves the detection accuracy of host intrusion data. At the same time, in order to improve the training efficiency and detection performance of the SDAE-ELM and DBN-Softmax models, a small batch gradient descent method is used for network training and optimization. Experiments on the KDD Cup99, NSL-KDD, UNSW-NB15, CIDDS-001, and ADFA-LD datasets show that SDAE-ELM and DBN-Softmax integrated deep inspection models have better performance than other classic machine learning models.
Keywords: Deep learning; Deep neural network; Feature learning; Mini-batch gradient descent; Intrusion detection

Yan Wang, Peng Jia, Xi Peng, Cheng Huang, Jiayong Liu,
BinVulDet: Detecting vulnerability in binary program via decompiled pseudo code and BiLSTM-attention,
Computers & Security,
Volume 125,
2023,
103023,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.103023.
(https://www.sciencedirect.com/science/article/pii/S0167404822004151)
Abstract: Static detection of security vulnerabilities in binary programs is an important research field in software supply chain security. However, existing vulnerability detection methods based on code similarity can only detect known vulnerabilities. Vulnerability features generated by vulnerability pattern-based detection methods are low robust due to the influence of manually defined patterns, compiler diversity, and irrelevant function instructions. In this paper, we propose BinVulDet, which is a binary level vulnerability detection tool for accurate known and unknown vulnerability detection. BinVulDet uses decompilation techniques to obtain pseudo code containing high-level semantic information against the impact of compilation diversity. Then the program slicing technique is used to extract the statements with data dependencies and control dependencies related to the vulnerability. A BiLSTM-attention neural network is used to extract rich contextual semantic information from slice codes to generate more robust vulnerability patterns to detect vulnerabilities. The experimental results show that BinVulDet outperforms the state-of-the-art binary vulnerability detection methods. The FPR and FNR of BinVulDet are 1.04% and 0.89% on average, respectively, which are 3.93% and 22.86% lower than the baseline model on average. BinVulDet can effectively against the influence of compilation diversity and successfully be used for real-world vulnerability detection by being evaluated in three CVE vulnerability projects.
Keywords: Binary program; Decompile; Vulnerability detection; Program slicing; BiLSTM-attention

Mingcan Cen, Xizhen Deng, Frank Jiang, Robin Doss,
Zero-Ran Sniff: A zero-day ransomware early detection method based on zero-shot learning,
Computers & Security,
Volume 142,
2024,
103849,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103849.
(https://www.sciencedirect.com/science/article/pii/S0167404824001500)
Abstract: Ransomware attacks, which blackmail victims into paying a ransom by locking their devices or encrypting their files, have become one of the major threats to network security. Conventional anti-ransomware tools often fail to detect zero-day ransomware attacks due to the inability to obtain zero-day ransomware signatures in advance to train detection models. In addition, zero-day ransomware attacks often use sophisticated encryption techniques to launch attacks on new vulnerabilities, and these encryption attacks cause irreversible damage to victims' digital files even if they choose to pay a ransom. Hence, it is imperative and urgent to detect unknown ransomware attacks at the earliest possible stage, ideally before the encryption phase. To this end, this paper proposes Zero-Ran Sniff (ZRS), an early zero-day ransomware detection method based on zero-shot learning, which can detect zero-day ransomware attacks in the early stage. ZRS leverages the portable executable header (PE header) feature from executable files to identify ransomware. It comprises two stages: an auto-encoding network-based core attribute learning (AE-CAL) stage and a self-attentive mechanism-based convolutional neural network inference Stage (SA-CNN-IS). During the AE-CAL stage, the core features of known and unknown classes of ransomware are extracted using self-encoding networks, and the SA-CNN-IS phase identifies ransomware. To the best of our knowledge, we are the first to explore the use of zero-shot learning for zero-day ransomware early detection. Experimental results demonstrate that the proposed ZRS outperforms traditional machine learning methods. Compared to previous zero-day detection work, ZRS achieves a recall of 98.47% and an accuracy of 96.31%
Keywords: Ransomware; Ransomware early detection; Cybersecurity; Malware; Encrypted attacks

Waheed G. Gadallah, Hosny M. Ibrahim, Nagwa M. Omar,
A deep learning technique to detect distributed denial of service attacks in software-defined networks,
Computers & Security,
Volume 137,
2024,
103588,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103588.
(https://www.sciencedirect.com/science/article/pii/S0167404823004984)
Abstract: Software-Defined Network (SDN) is an established networking paradigm that separates the control plane from the data plane. It has central network control, and programmability facilities, therefore SDN can improve network flexibility, management, performance, and scalability. The programmability and control centralization of SDN have improved network functions but also exposed it to security challenges such as Distributed Denial of Service (DDoS) attacks that target both control and data planes. This paper proposes an effective detection technique against DDoS attack in SDN control plane and data plane. For the control plane, the technique detects DDoS attacks through a Deep Learning (DL) model using new features extracted from traffic statistics. A DL method (AE-BGRU) for DDoS detection uses Autoencoder (AE) with Bidirectional Gated Recurrent Unit (BGRU). The proposed features for the control plane include unknown IP destination address, packets inter-arrival time, Transport layer protocol (TLP) header, and Type of service (ToS) header. For the data plane, the technique tracks the switch's average arrival bit rate with an unknown destination address in the data plane. Then, the technique detects DDoS attacks through a DL-based model which also uses AE with BGRU. The proposed features in the data plane include the switch's stored capacity, the average rate of packets with unknown destination addresses, the IP Options header, and the average number of flows. The dataset is generated from feature extraction and computations from normal and attack packets and used with the classifier. Also, additional Machine Learning (ML) methods are used to enhance the detection process. If the model detects an attack, the technique mitigates DDoS effects by updating the user's trust value and blocking suspicious senders based on the trust value. The experimental results proved that compared to related techniques, the suggested method had a higher accuracy and lower false alarm rate.
Keywords: Software-defined networking; Distributed denial of service; Deep learning; Autoencoder; Bidirectional gated recurrent unit; Trust value

Vanlalruata Hnamte, Ashfaq Ahmad Najar, Hong Nhung-Nguyen, Jamal Hussain, Manohar Naik Sugali,
DDoS attack detection and mitigation using deep neural network in SDN environment,
Computers & Security,
Volume 138,
2024,
103661,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103661.
(https://www.sciencedirect.com/science/article/pii/S0167404823005710)
Abstract: In the contemporary digital landscape, the escalating threat landscape of cyber attacks, particularly distributed denial-of-service (DDoS) attacks, has become a paramount concern for network security. This research introduces an innovative approach to DDoS detection leveraging a deep neural network (DNN) architecture rooted in deep learning (DL) principles. The proposed model exhibits a scalable and adaptable framework, enabling meticulous analysis of network traffic data to discern intricate patterns indicative of DDoS attacks. To validate the efficacy of our methodology, rigorous evaluations were conducted using authentic real-world traffic data. The results unequivocally establish the superiority of our DNN-based approach over traditional DDoS detection techniques. This research holds significant promise for bolstering network security, particularly within the dynamic landscape of software-defined network (SDN) environments. The study's findings contribute to the continual refinement and eventual deployment of advanced measures in fortifying digital infrastructure against the evolving threat landscape. Performance metrics, including detection accuracy and loss rates, further emphasize the effectiveness of our approach across different datasets. With detection accuracy rates of 99.98%, 100%, and 99.99% for the InSDN, CICIDS2018, and Kaggle DDoS datasets, respectively, coupled with low loss rates, our DNN-based model demonstrates robust capabilities in mitigating contemporary DDoS threats. This study not only presents a novel DDoS detection approach within SDN infrastructures but also offers insights into practical implications and challenges associated with deploying DNNs in real-world SDN environments. Network security professionals can benefit from the nuanced perspectives provided, contributing to the ongoing discourse on fortifying digital networks against evolving cyber threats.
Keywords: Deep learning; Deep neural network; SDN; DDoS detection; Distributed denial of service attack; Anomaly detection

Charles-Henry Bertrand Van Ouytsel, Khanh Huu The Dam, Axel Legay,
Analysis of machine learning approaches to packing detection,
Computers & Security,
Volume 136,
2024,
103536,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103536.
(https://www.sciencedirect.com/science/article/pii/S0167404823004467)
Abstract: Packing is a widely used obfuscation technique by which malware hides content and behavior. Much research explores how to detect a packed program via such varied approaches as entropy analysis, syntactic signatures, and, more recently, machine learning classifiers using various features. Yet no robust results indicate which algorithms perform best or which features are most significant. Reviews of these results highlight how accuracy, cost, generalization of capabilities, and other measures complicate evaluations. Our work addresses deficiencies by assessing nine different machine-learning approaches using 119 features to identify which features are most significant for packing detection, which algorithms offer the best performance, and which algorithms are most economical.
Keywords: Malware; Machine learning; Packing; Features analysis; SHAP values; Experimental comparison; Adversarial attack

Munan Li, Hongbo Liu, Xiangdong Jiang, Zheng Zhao, Tianhao Zhang,
SENSE: An unsupervised semantic learning model for cross-platform vulnerability search,
Computers & Security,
Volume 135,
2023,
103500,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103500.
(https://www.sciencedirect.com/science/article/pii/S0167404823004108)
Abstract: Binary Similarity Analysis (BSA) emerges as a vital approach for identifying homologous vulnerabilities. However, it is constrained by semantic incompleteness, structural differences, and false positives arising from variations in compilation environments. In this paper, we propose a novel Unsupervised Semantic Learning Model named SENSE for cross-platform vulnerability search. The model comprises two main components: semantic learner and graph learner. The semantic learner is pre-trained with a mask language task on a well-normalized binary corpus, enabling it to capture contextual semantic relations and generate block embedding that effectively encode the semantic features. In the graph learner, a gated graph neural network with a self-gating layer is adopted to eliminate redundant features and an adversarial loss is incorporated to enhance the robustness of function embedding across different compiler environments. Finally, SENSE is trained in an unsupervised manner using a batch-wise sampling strategy along with maximum mutual information loss. This encourages semantically similar functions to exhibit tighter embedding representations, thereby reducing false positives and improving search efficiency. Through extensive experiments, we have demonstrated that SENSE outperforms state-of-the-art methods in terms of binary search accuracy. Our results also reveal that SENSE is capable of generating robust function embedding that mitigate the differences arising from diverse architecture and optimization options.
Keywords: Binary similarity analysis; Gated graph neural network; Adversarial loss; Mutual information; Vulnerability search

Tianrong Chen, Jie Ling, Yuping Sun,
White-box content camouflage attacks against deep learning,
Computers & Security,
Volume 117,
2022,
102676,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.102676.
(https://www.sciencedirect.com/science/article/pii/S0167404822000748)
Abstract: Deep learning has achieved remarkable success in a wide range of computer vision tasks. However, recent researches suggest that deep learning systems are vulnerable to a variety of attacks. Security concerns have been raised regarding the training or inference phase of deep learning models in the last few years, and the research field about the vulnerability of the pre-processing components in these models is still developing. In this paper, we systematically examine white-box content camouflage attacks on five types of pre-processing modules in deep learning systems: scaling, sharpening, Gamma correction, contrast adjustment, and saturation adjustment. We assume that an attacker's goal is to generate camouflage examples that show inconsistent visual semantics before and after pre-processing. Under the white-box setting (where the pre-processing algorithms and their parameters are known), we formulate content camouflage attacks as an optimization problem in which perceptual losses in the source and target images are smoothly calculated by a multi-scale discriminator to improve the camouflaging effect of the attack example. We evaluate our content camouflage attacks by conducting a series of experiments on two example groups as well as two real-world datasets, i.e., CIFAR-10 and FER-2013. The experimental results show that with good camouflaging ability, our attacks are effective against deep learning systems, and outperform prevalent scaling camouflage attacks by generating examples with better quality and a higher attack success rate. The proposed camouflage attacks are also extended to the four commonly used pre-processing algorithms, and yield good results. Furthermore, we discuss the effect of varying the parameters of several image pre-processing algorithms under our attacks and analyze' the reasons for their vulnerability.
Keywords: Deep learning; White-box attack; Pre-processing; Content camouflage; Computer vision

Wanyu Li, Hailiang Tang, Hailin Zhu, Wenxiao Zhang, Chen Liu,
TS-Mal: Malware detection model using temporal and structural features learning,
Computers & Security,
Volume 140,
2024,
103752,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103752.
(https://www.sciencedirect.com/science/article/pii/S0167404824000531)
Abstract: The cyber ecosystem is facing severe threats from malware attacks, making it imperative to detect malware to safeguard a purified Internet environment. However, current studies primarily concentrate on examining the time-based correlation between APIs for malware detection while neglecting the contextual associations derived from API categories, resulting in inadequate detection performance. In this paper, we present TS-Mal, a novel Malware detection model incorporated Temporal and Structural features learning. Particularly, TS-Mal first designs a temporal vector learning method to automatically capture the evolving representation from the non-repetitive API sequences, which can efficiently pursue the attack preferences of malware. Then TS-Mal introduces heterogeneous graphs to model the interactive relationships between APIs and presents a dense-interactive structural embedding approach to generate the fine-grained API structural representation, which is capable of utilizing API category interaction information to boost detection effectiveness. Finally, TS-Mal simultaneously integrates temporal and structural attack features to accurately identify the unknown malware, effectively defending against new malware attacks. Experimental results on real-world datasets demonstrate that our proposed TS-Mal model outperforms existing state-of-the-art methods.
Keywords: Malware detection; Graph attention network; API call events; Temporal feature

Hongliang Liang, Zhuosi Xie, Yixiu Chen, Hua Ning, Jianli Wang,
FIT: Inspect vulnerabilities in cross-architecture firmware by deep learning and bipartite matching,
Computers & Security,
Volume 99,
2020,
102032,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2020.102032.
(https://www.sciencedirect.com/science/article/pii/S0167404820303059)
Abstract: Widely deployed IoT devices expose serious security threats because the firmware in them contains vulnerabilities, which are difficult to detect due to two main factors: 1) The firmware’s code is usually not available; 2) A same vulnerability often exists in multiple firmware with different architectures and/or release versions. In this paper, we propose a novel neural network-based staged approach to inspect vulnerabilities in firmware, which first learns semantics in binary code and utilizes neural network model to screen out the potential vulnerable functions, then performs bipartite graph matching upon three-level features between two binary functions. We implement the approach in a tool called FIT and evaluation results show that FIT outperforms state-of-the-art approaches, i.e., Gemini, CVSSA and discovRE, on both effectiveness and efficiency. FIT also detects vulnerabilities in real-world firmware of IoT devices, such as D-Link routers. Moreover, we make our tool and dataset publicly available in the hope of facilitating further researches in the firmware security field.
Keywords: firmware security; binary code; similarity detection; neural network; bipartite matching

Jingcheng Yang, Hongwei Li, Shuo Shao, Futai Zou, Yue Wu,
FS-IDS: A framework for intrusion detection based on few-shot learning,
Computers & Security,
Volume 122,
2022,
102899,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.102899.
(https://www.sciencedirect.com/science/article/pii/S0167404822002929)
Abstract: Due to the high dependency of traditional intrusion detection method on a fully-labeled large dataset, existing works can hardly be applied in real-world scenarios, especially facing zero-day attacks. In this paper we present a novel intrusion detection framework called “FS-IDS”, including flow data encoding method, feature fusion mechanism and architecture of intrusion detection system based on few-shot learning. We utilize task generator to split the dataset into separate tasks and train model in an episodic way, hoping model to learn general knowledge rather than those specific to a single class. The extraction module and distance metric module are responsible for learning and determining whether the traffic data are benign or not. We conduct three sets of experiments on “FS-IDS”, i.e., comparison study, ablation study and multiclass study. Comparison study firstly determines that the best measure metric for discrimination is Euclidean distance. Based on the optimal implementation, “FS-IDS” achieves comparable performance with existing works by using much fewer malicious samples. Ablation study sets two base models to explore how proposed encoding method and feature fusion mechanism improve detection capacity. Both the image representation and feature fusion achieve more than 2% improvement in accuracy and recall. Finally, to test whether “FS-IDS” can perform well under real-world scenario or not, we design network traffic containing various attacks to simulate complex malicious network environment. Experimental results show that “FS-IDS” maintains more than 90% detection accuracy and recall under the worst circumstances, which composes of various seen or unseen attacks with only a few malicious samples available.
Keywords: Network security; Intrusion detection system; Few-shot learning; Feature fusion; CNN; Deep learning

Sharmin Aktar, Abdullah Yasin Nur,
Towards DDoS attack detection using deep learning approach,
Computers & Security,
Volume 129,
2023,
103251,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103251.
(https://www.sciencedirect.com/science/article/pii/S016740482300161X)
Abstract: Due to the extensive use and evolution in the cyber world, different network attacks have recently increased significantly. Distributed Denial-of-Service (DDoS) attack has become one of the fatal threats to the Internet, where attackers send massive amounts of packets to the target system to make online systems unavailable to legitimate users. Proper attack detection measurement is crucial to defend against these attacks. This paper proposes a deep learning-based model using a contractive autoencoder to detect anomalies. We train our model to learn the normal traffic pattern from the compacted representation of the input data, and then apply a stochastic threshold method to detect the attack. Three renowned Intrusion Detection System datasets have been used for evaluationCIC-IDS2017, NSL-KDD, and CIC-DDoS2019. We have assessed the results against a basic autoencoder and other deep learning approaches to show our model efficacy. Our results indicate a successful intrusion detection of the proposed method with an accuracy ranging between 93.41% and 97.58% on the CIC-DDoS2019 dataset. Moreover, it achieved an accuracy of 96.08% and 92.45% on NSL-KDD and CIC-IDS2017 datasets, respectively.
Keywords: Denial of service attack; Distributed denial of service attack; Intrusion detection systems; Deep neural networks; Anomaly detection

Lingdi Kong, Senlin Luo, Limin Pan, Zhouting Wu, Xinshuai Li,
A multi-type vulnerability detection framework with parallel perspective fusion and hierarchical feature enhancement,
Computers & Security,
Volume 140,
2024,
103787,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103787.
(https://www.sciencedirect.com/science/article/pii/S0167404824000889)
Abstract: A core problem of vulnerability detection is to detect multi-type vulnerabilities simultaneously by characterizing vulnerabilities of high diversity and complexity in real program source code. Current methods mainly adjust and compromise multiple code representations such as code sequence and code graph based on composite graph. However, sequential features extracted by graph are hardly sufficient to model the contextual semantic associations of the token sequence. Meanwhile, structural features of the code graph extracted by models based on Euclidean Graph Neural Network are difficult to fit the tree-like calling relationships between code lines. These limitations make it difficult to detect diverse vulnerabilities. In addition, most of the existing models ignore the type of code statement, which is closely associated with some specific vulnerability types. In this paper, we propose a Parallelism Framework with Hierarchical feature Enhancement for Multi-type Vulnerability Detection (PFHE-MVD). PFHE-MVD models program code from three parallel perspectives, containing sequence, code graph, and Abstract Syntax Tree statistic. Hyperbolic Graph Convolutional Neural Network is integrated to model the top-down hierarchical calling structure in program code graph through hyperbolic space mapping. Besides, the statement type of code is embedded along with the code text to strengthen the identification ability for different types of vulnerabilities. Experimental results show that PFHE-MVD achieves new state-of-the-art results in multi-type vulnerability detection. PFHE-MVD captures tree-like hierarchical code structure feature and enhances the distinguishing ability for vulnerabilities by code statement type embedding.
Keywords: Vulnerability detection; Multiple types; Hyperbolic graph; Feature fusion

Michal Motylinski, Áine MacDermott, Farkhund Iqbal, Babar Shah,
A GPU-based machine learning approach for detection of botnet attacks,
Computers & Security,
Volume 123,
2022,
102918,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.102918.
(https://www.sciencedirect.com/science/article/pii/S0167404822003108)
Abstract: Rapid development and adaptation of the Internet of Things (IoT) has created new problems for securing these interconnected devices and networks. There are hundreds of thousands of IoT devices with underlying security vulnerabilities, such as insufficient device authentication/authorisation making them vulnerable to malware infection. IoT botnets are designed to grow and compete with one another over unsecure devices and networks. Once infected, the device will monitor a Command-and-Control (C&C) server indicating the target of an attack via Distributed Denial of Service (DDoS) attack. These security issues, coupled with the continued growth of IoT, presents a much larger attack surface for attackers to exploit in their attempts to disrupt or gain unauthorized access to networks, systems, and data. Large datasets available online provide good benchmarks for the development of accurate solutions for botnet detection, however model training is often a time-consuming process. Interestingly, significant advancement of GPU technology allows shortening the time required to train such large and complex models. This paper presents a methodology for the pre-processing of the IoT-Bot dataset and classification of various attack types included. We include descriptions of pre-processing actions conducted to prepare data for training and a comparison of results achieved with GPU accelerated versions of Random Forest, k-Nearest Neighbour, Support Vector Machine (SVM) and Logistic Regression classifiers from the cuML library. Using our methodology, the best-trained models achieved at least 0.99 scores for accuracy, precision, recall and f1-score. Moreover, the application of feature selection and training models on GPU significantly reduced the training and estimation times.
Keywords: Internet of Things; Machine learning; Random forest; Feature selection; Attack detection; Classification

Li Chen, Cong Tang, Junjiang He, Hui Zhao, Xiaolong Lan, Tao Li,
XSS adversarial example attacks based on deep reinforcement learning,
Computers & Security,
Volume 120,
2022,
102831,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.102831.
(https://www.sciencedirect.com/science/article/pii/S0167404822002255)
Abstract: Cross-site scripting (XSS) attack is one of the most serious security problems in web applications. Although deep neural network (DNN) has been used in XSS attack detection and achieved unprecedented success, it is vulnerable to adversarial example attacks because its input-output mapping is quite discontinuous to a large extent. The existence of adversarial examples have raised concerns in applying deep learning to key security fields. Therefore, to evaluate the effectiveness of these detection methods, a XSS adversarial example attack technique using Soft Actor-Critic (SAC) reinforcement learning algorithm is presented in the paper. A key aspect of our idea is to train an agent using SAC algorithm to build adversarial examples for several popular XSS detection models which have been proved can achieve very high accuracy rate by simulation experiments. We first design mutation strategies for different modules of XSS attack vectors to ensure the validity of the generated adversarial examples. Then, the agent selects an appropriate escape strategy according to the feedback of the detection model until it bypasses the detection model. The final experiment results show that our model can achieve an escape rate of more than 92% and outperforms the latest method by up to 6%. In other words, the effectiveness of these detection models needs to be improved, at least in terms of defense adversarial example attacks.
Keywords: Web security; Cross site scripting; Adversarial examples; Adversarial attack; SAC; Reinforcement learning

Damien Warren Fernando, Nikos Komninos,
FeSAD ransomware detection framework with machine learning using adaption to concept drift,
Computers & Security,
Volume 137,
2024,
103629,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103629.
(https://www.sciencedirect.com/science/article/pii/S0167404823005394)
Abstract: This paper proposes FeSAD, a framework that will allow a machine learning classifier to detect evolutionary ransomware. Ransomware is a critical player in the malware space that causes hundreds of millions of dollars of damage globally and evolves quickly. The evolution of ransomware in machine learning classifiers is often calculated as concept drift. Concept drift is dangerous as changes in the behavior of ransomware can easily lead to misclassifications, and misclassification can harm individuals and businesses. Our proposed framework consists of a feature selection layer, drift calibration layer and drift decision layer that allows a machine learning classifier to detect and classify concept drift samples reliably. We evaluate the FeSAD framework in various concept drift scenarios and observe its ability to detect drifting samples effectively. The FeSAD framework is also evaluated on its ability to extend the lifespan of a classifier. The results obtained by this research show that FeSAD can successfully and reliably classify ransomware and benign samples while under concept drift and can extend the time between retraining.
Keywords: Ransomware detection; Machine learning; Concept drift; Malware evolution; Genetic algorithm

Yeming Gu, Hui Shu, Fei Kang,
BinAIV: Semantic-enhanced vulnerability detection for Linux x86 binaries,
Computers & Security,
Volume 135,
2023,
103508,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103508.
(https://www.sciencedirect.com/science/article/pii/S0167404823004182)
Abstract: Binary code vulnerability detection is an important research direction in the field of network security. The extensive reuse of open-source code has led to the spread of vulnerabilities that originally only affected a small number of targets to other software. Existing vulnerability detection methods are mainly based on binary code similarity analysis, that is, by comparing the similarity of code embedding to detect vulnerabilities. However, existing methods lack semantic understanding of binary code and cannot distinguish between different functions with similar code structures, which reduces the accuracy of vulnerability detection. This paper proposes a binary vulnerability detection method BinAIV based on function semantics. BinAIV is based on a neural network model, which defines and constructs binary function semantics to achieve more accurate similarity analysis. Experimental results show that in terms of binary code similarity analysis performance, BinAIV has a significant improvement compared to traditional methods that only use function embedding. In cross-compiler function search, cross-optimization function search, and cross-obfuscation function search experiments, the average Recall@1 value of BinAIV compared to the best-performing baseline methods increased by 40.1 %, 99.8 %, and 184.0 %. In the real-world vulnerability detection experiment, BinAIV had the highest detection accuracy for all vulnerabilities, with an improvement of 155.1 % and 97.7 % compared to Asm2Vec and SAFE, respectively.
Keywords: Function semantic; Vulnerability detection; Code similarity; Binary code; Deep learning

Yali Wu, Yanghu Hu, Junhu Wang, Mengqi Feng, Ang Dong, Yanxi Yang,
An active learning framework using deep Q-network for zero-day attack detection,
Computers & Security,
Volume 139,
2024,
103713,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103713.
(https://www.sciencedirect.com/science/article/pii/S0167404824000142)
Abstract: Zero-day attacks from highly dynamic and complex cyberspace make severe threats to the existing network intrusion detection systems. Robust and intelligent solutions are required to handle the rapidly evolving threats from internet environment. In this paper, a novel active learning framework based on Deep Q-Network (DQN) is proposed for zero-day attacks detection. The framework is composed of network intrusion detection systems classifier, sample selection strategy and annotator. Deep Q-Network model serves as an intelligent control component to select the zero-day samples for labeling with the probability distribution. Moreover, the Bi-directional Long Short-Term Memory (BiLSTM) network is integrated into DQN model to form the selecting policy to analyze the temporal correlation within the static classification context. Meanwhile, Euclidean distance function is adopted for labeling the selected samples to achieve an accurate labeling result. Two famous datasets named NSL_KDD and UNSW_NB15 in intrusion detection field are tested for evaluate the performance of our proposed framework. Compared to other machine learning methods, the approach proposed in this paper demonstrates better universality and generalizability. This indicates that the method is more capable of reliably identifying and detecting network intrusion behaviors, which holds significant importance for further security research and practical applications.
Keywords: Network intrusion detection systems; Active learning; Deep Q-network; Annotator

Tommaso Zoppi, Andrea Ceccarelli, Tommaso Puccetti, Andrea Bondavalli,
Which algorithm can detect unknown attacks? Comparison of supervised, unsupervised and meta-learning algorithms for intrusion detection,
Computers & Security,
Volume 127,
2023,
103107,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103107.
(https://www.sciencedirect.com/science/article/pii/S0167404823000172)
Abstract: There is an astounding growth in the adoption of machine learners (MLs) to craft intrusion detection systems (IDSs). These IDSs model the behavior of a target system during a training phase, making them able to detect attacks at runtime. Particularly, they can detect known attacks, whose information is available during training, at the cost of a very small number of false alarms, i.e., the detector suspects attacks but no attack is actually threatening the system. However, the attacks experienced at runtime will likely differ from those learned during training and thus will be unknown to the IDS. Consequently, the ability to detect unknown attacks becomes a relevant distinguishing factor for an IDS. This study aims to evaluate and quantify such ability by exercising multiple ML algorithms for IDSs. We apply 47 supervised, unsupervised, deep learning, and meta-learning algorithms in an experimental campaign embracing 11 attack datasets, and with a methodology that simulates the occurrence of unknown attacks. Detecting unknown attacks is not trivial: however, we show how unsupervised meta-learning algorithms have better detection capabilities of unknowns and may even outperform classification performance of other ML algorithms when dealing with unknown attacks.
Keywords: Intrusion detection; Machine learning; Unknown attacks; Unsupervised; Meta-Learning; Zero-Day attacks

Muhammad Tayyab, Mohsen Marjani, N.Z. Jhanjhi, Ibrahim Abaker Targio Hashem, Raja Sher Afgun Usmani, Faizan Qamar,
A comprehensive review on deep learning algorithms: Security and privacy issues,
Computers & Security,
Volume 131,
2023,
103297,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103297.
(https://www.sciencedirect.com/science/article/pii/S0167404823002079)
Abstract: Machine Learning (ML) algorithms are used to train the machines to perform various complicated tasks that begin to modify and improve with experiences. It has become widely used for automated decisions. In particular, the applications which have a profound impact on society that rely on Deep Learning (DL) for autonomous decisions, such as Patient Health Record (PHR), Unmanned Aerial Vehicles (UAVs), etc. Such impacts have a vital concern about the potential vulnerabilities introduced by DL. Traditional attackers have powerful motives that can alter and modify DL algorithms to subvert the outcomes. In poisoning attacks, an attacker can consciously change training dataset, which is used to operate the outcomes of decision-based model. While in privacy and evasion attacks, an adversary can also misclassify new datasets to infer private information. Therefore, in this paper, we have provided a review of security and privacy issues of DL algorithms and analyzed their applications and challenges based on state-of-the-art literature. We have classified attacks, devised a taxonomy, and comprehensive analysis of defense techniques for the most common attacks such as poisoning, evasion, model extraction, and model inversion. We have also presented various privacy preserving techniques to ensure the privacy of dataset. We have proposed a secure cryptographic framework for dataset based on hash functions and Homomorphic Encryption (HE) scheme. Finally, we have provided recent research challenges and future studies concerning security and privacy issues. We believed that the highlighted limitations and weaknesses provide possible research questions and open matters for designing efficient future DL algorithms.
Keywords: Machine Learning (ML); Deep Learning (DL); Poisoning attacks; Privacy attacks; Evasion attacks; Adversarial settings

Hamid Bostani, Veelasha Moonsamy,
EvadeDroid: A practical evasion attack on machine learning for black-box Android malware detection,
Computers & Security,
Volume 139,
2024,
103676,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103676.
(https://www.sciencedirect.com/science/article/pii/S0167404823005862)
Abstract: Over the last decade, researchers have extensively explored the vulnerabilities of Android malware detectors to adversarial examples through the development of evasion attacks; however, the practicality of these attacks in real-world scenarios remains arguable. The majority of studies have assumed attackers know the details of the target classifiers used for malware detection, while in reality, malicious actors have limited access to the target classifiers. This paper introduces EvadeDroid, a problem-space adversarial attack designed to effectively evade black-box Android malware detectors in real-world scenarios. EvadeDroid constructs a collection of problem-space transformations derived from benign donors that share opcode-level similarity with malware apps by leveraging an n-gram-based approach. These transformations are then used to morph malware instances into benign ones via an iterative and incremental manipulation strategy. The proposed manipulation technique is a query-efficient optimization algorithm that can find and inject optimal sequences of transformations into malware apps. Our empirical evaluations, carried out on 1K malware apps, demonstrate the effectiveness of our approach in generating real-world adversarial examples in both soft- and hard-label settings. Our findings reveal that EvadeDroid can effectively deceive diverse malware detectors that utilize different features with various feature types. Specifically, EvadeDroid achieves evasion rates of 80%–95% against DREBIN, Sec-SVM, ADE-MA, MaMaDroid, and Opcode-SVM with only 1–9 queries. Furthermore, we show that the proposed problem-space adversarial attack is able to preserve its stealthiness against five popular commercial antiviruses with an average of 79% evasion rate, thus demonstrating its feasibility in the real world.
Keywords: Query-based evasion attacks; Android malware detection; Machine learning; Black-box adversarial attacks

Kashan Ahmed, Syed Khaldoon Khurshid, Sadaf Hina,
CyberEntRel: Joint extraction of cyber entities and relations using deep learning,
Computers & Security,
Volume 136,
2024,
103579,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103579.
(https://www.sciencedirect.com/science/article/pii/S0167404823004893)
Abstract: The cyber threat intelligence (CTI) knowledge graph is beneficial for making robust defense strategies for security professionals. These are built from cyber threat intelligence data based on relation triples where each relation triple contains two entities associated with one relation. The main problem is that the CTI data is increasing more rapidly than expected and existing techniques are becoming ineffective for extracting the CTI information. This work mainly focuses on the extraction of cyber relation triples in an effective way using the joint extraction technique, which resolves the issues in the classical pipeline technique. Firstly, the ‘BIEOS’ tagging scheme was applied to CTI data using the joint tagging technique and then the relation triples were jointly extracted. This study utilized the attention-based RoBERTa-BiGRU-CRF model for sequential tagging. Finally, the relation triples were extracted using the relation-matching technique after matching the best suitable relation for the two predicted entities. The experimental results showed that this technique outperformed the state-of-the-art models in knowledge triple extraction on CTI data. Furthermore, a 7% increase in the F1 score also proved the effectiveness of this technique for the information extraction task on CTI data.
Keywords: Cyber threat intelligence; Deep learning; Named entity recognition; Relation extraction; Knowledge graph

Hoang V. Vo, Hanh P. Du, Hoa N. Nguyen,
APELID: Enhancing real-time intrusion detection with augmented WGAN and parallel ensemble learning,
Computers & Security,
Volume 136,
2024,
103567,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103567.
(https://www.sciencedirect.com/science/article/pii/S0167404823004777)
Abstract: This paper proposes an AI-powered intrusion detection method that improves intrusion detection performance by increasing the quality of the training set and employing numerous potent AI models. Composed of the Augmented Wasserstein Generative Adversarial Networks (AWGAN) and Parallel Ensemble Learning-based Intrusion Detection (PELID) algorithms, it is referred to as APELID. First, to augment the training set quality, AWGAN combines a clustering algorithm to select representative samples from the majority classes and WGAN to generate more realistic samples from the minority classes. Second, PELID employs a weighted ensemble of multiple efficient AI models in parallel to improve the efficacy of AI-powered intrusion detection. In addition, APELID also incorporates a sandbox-based malware analyzer. It aims to enrich the indicators of compromise for preventing malicious files that have been transferred over the network. Rigorous experiments utilizing well-known datasets, such as CSE-CIC-IDS2018 and NSL-KDD, are conducted in order to evaluate APELID. Hence, it achieves an outstanding F1-score of 99.99% and 99.65% and a remarkably low false negative rate of 0.00% and 0.34%, respectively, which is superior to state-of-the-art methods. In addition, the average PELID-based detection time (i.e., 22.29μs/flow) for a single network traffic flow is fast enough to detect intrusions in real-time.
Keywords: AI-powered intrusion detection; Traffic deep analysis; Data augmentation; Wasserstein generative adversarial networks; Deep neural network; EXtreme gradient boosting; Gradient boosting on decision trees; Bagging meta-estimator; Parallel ensemble learning

Wenxin Tao, Xiaohong Su, Jiayuan Wan, Hongwei Wei, Weining Zheng,
Vulnerability detection through cross-modal feature enhancement and fusion,
Computers & Security,
Volume 132,
2023,
103341,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103341.
(https://www.sciencedirect.com/science/article/pii/S0167404823002511)
Abstract: Software vulnerability detection is critical to computer security. Most existing vulnerability detection methods use single modal-based vulnerability detection models, which cannot effectively extract cross-modal features. To solve this problem, we propose a new multimodal deep learning based vulnerability detection method through a cross-modal feature enhancement and fusion. Firstly, we utilize a special compilation and debugging method to obtain the alignment relationship between source code statements and assembly instructions, as well as between source code variables and assembly code registers. Based on this alignment relationship and program slicing technology, we propose a cross-slicing method to generate bimodal program slices. Then, we propose a cross-modal feature enhanced code representation learning model to capture the fine-grained semantic correlation between source code and assembly code by using the co-attention mechanisms. Finally, vulnerability detection is achieved by feature level fusion of semantic features captured in fine-grained aligned source code and assembly code. Extensive experiments show that our method improves the performance of vulnerability detection compared with state-of-the-art methods. Specifically, our method achieves an accuracy of 97.4% and an F1-measure of 93.4% on the SARD dataset. An average accuracy of 95.4% and an F1-measure of 89.1% on two real-world software projects (i.e., FFmpeg and OpenSSL) is also achieved by our method, improving over SOTA method 4.5% and 2.9%.
Keywords: Software security; Multimodal deep learning; Fine-grained cross modal alignment; Co-attention; Vulnerability detection

P. Malini, Dr. K.R. Kavitha,
An efficient deep learning mechanisms for IoT/Non-IoT devices classification and attack detection in SDN-enabled smart environment,
Computers & Security,
Volume 141,
2024,
103818,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103818.
(https://www.sciencedirect.com/science/article/pii/S0167404824001196)
Abstract: In recent years, the development of Internet of Things (IoT) applications has increased, resulting in higher demands for sufficient bandwidth, data rates, latency, and quality of service (QoS). In advanced communications, managing network resources for allocating IoT services and identifying the exact IoT devices connected to a network is a major concern. The existing studies have introduced various methods for classifying IoT devices in a network. However, the previous studies faced challenges like limited attributes, low efficiency, inappropriate features, and computational complexities. Also, the existing studies failed to concentrate on IoT/Non-IoT classification along with attack detection. Detecting attacks on IoT devices is critical for making network services more effective. Thus, the proposed study introduces an efficient IoT device classification and attack detection mechanism using software defined networking (SDN)-enabled fiber-wireless access networks internet of things (FiWi IoT) architecture. Initially, an effective resource allocation process is performed to mitigate the delay constraint issues by introducing a hybrid parallel neural network-based dynamic bandwidth allocation (DBA) method. Then, the input traffic information is gathered from the resource-efficient SDN-enabled FiWi IoT network, and the input data is pre-processed to eliminate unwanted noises using min-max normalization and standardization. Next, the essential attributes are extracted to attain enhanced classification performance. To reduce the feature dimensionality problem and thereby solve complexity issues, the most optimal features are selected by a new chaotic seagull optimization (CSO) approach. After that, IoT/non-IoT classification is performed using a transformer-driven deep intelligent model. Finally, the attacks are detected and classified by introducing a novel slice attention-based deep capsule autoencoder (SA_DCAE) model. For experimentation, the Python 3.7.0 tool is used in this work, and the performance of proposed classifiers is measured by evaluating varied matrices. Also, the comparison analysis proves the superiority of the proposed techniques to other existing methods.
Keywords: SDN-enabled FiWi IoT network; Dynamic resource allocation; Transformer-driven deep intelligent model; Slice attention mechanism; Deep learning; Chaotic seagull optimization capsule autoencoder model

Run Yang, Hui He, Yulong Wang, Yue Qu, Weizhe Zhang,
Dependable federated learning for IoT intrusion detection against poisoning attacks,
Computers & Security,
Volume 132,
2023,
103381,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103381.
(https://www.sciencedirect.com/science/article/pii/S0167404823002912)
Abstract: Network intrusion detection methods based on federated learning (FL) and edge computing have great potential for protecting the cybersecurity of the Internet of Things. It overcomes the disadvantages of the traditional centralized method, such as high latency, overloaded network, and privacy leakage. At the same time, it can combine private data from multiple participants to train models, and the rich data can train more effective models. However, the inherent security vulnerabilities of the FL framework do not ensure the robustness of the global models trained collaboratively. Towards FL, each participant has access to model parameters and training data, and malicious participants can affect the global model by tampering with data or weights. This paper studies label-flipping attacks in FL-based IoT intrusion detection. We propose a lightweight detection mechanism to mitigate the impact of poisoning attacks on FL-based intrusion detection methods in IoT networks. The detection mechanism on a central server filters anomalous participants and excludes their uploaded models from the global model aggregation. Specifically, we propose a scoring mechanism for evaluating participants based on the loss of the local model and the training dataset size. Afterwards, the Manhattan similarity between each participant will be calculated according to the scores. Finally, the anomalous participants will be found by clustering algorithm for similarity cluster analysis. The experimental results show that our proposed detection method can defend against label-flipping attacks in FL. On the CIC-IDS-2017 dataset, our method can improve the accuracy of the intrusion detection model trained based on FL from 84.3% to 97.1%, while enhancing the protection of IoT network security.
Keywords: Internet of thing; Cyber-physical systems; Network intrusion detection; Federated learning; Label-flipping attacks

Sara Aboukadri, Aafaf Ouaddah, Abdellatif Mezrioui,
Machine learning in identity and access management systems: Survey and deep dive,
Computers & Security,
Volume 139,
2024,
103729,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103729.
(https://www.sciencedirect.com/science/article/pii/S0167404824000300)
Abstract: The evolution of identity and access management (IAM) has been driven by the expansion of online services, cloud computing, and the Internet of Things (IoT). The proliferation of remote work, mobile applications, and interconnected devices has intensified the demand for robust identity protection and access control. As digital interactions and data sharing become more prevalent across industries, IAM has gained prominence, compelled by the need to safeguard sensitive information, prevent unauthorized access, and adhere to increasingly stringent regulatory frameworks. In parallel with IAM's evolution, the integration of artificial intelligence (AI) has emerged as a pivotal avenue for enhancing IAM effectiveness. This survey delves into the fusion of machine learning (ML) techniques to fortify IAM, with a specific focus on its core processes: authentication, authorization, and auditing. Addressing fundamental questions regarding ML's role in enhancing IAM processes, we begin by proposing a comprehensive definition of IAM within a unified layered-wise reference model, highlighting Authentication, Authorization, and Auditing functions (with focus on monitoring). Furthermore, our survey comprehensively explores ML-based solutions within IAM systems, presenting a taxonomy of state-of-the-art methodologies categorized by their application in IAM processes. Drawing from both qualitative and quantitative insights from cited references, we investigate how ML enhances the performance and security of IAM processes. Additionally, by investigating challenges in implementing ML in IAM systems, we shed light on issues such as data privacy concerns and the interpretability of ML-driven decisions. In conclusion, this paper makes a substantial contribution to the IAM landscape by providing comprehensive insights into the transformative role of ML. Addressing pivotal questions, our survey offers a roadmap to leverage ML's potential for enhancing the performance, security, and efficacy of IAM systems.
Keywords: Identity and access management; Authentication; Authorization; Monitoring; Machine learning; Privacy

Xiaoyu Wang, Xiaobo Yang, Xueping Liang, Xiu Zhang, Wei Zhang, Xiaorui Gong,
Combating alert fatigue with AlertPro: Context-aware alert prioritization using reinforcement learning for multi-step attack detection,
Computers & Security,
Volume 137,
2024,
103583,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103583.
(https://www.sciencedirect.com/science/article/pii/S0167404823004935)
Abstract: Alert fatigue problems can have serious consequences for the enterprise security. When analysts become overwhelmed by the sheer number of alerts, high-risk alerts may go unnoticed or receive delayed responses, exposing the organization to potential cyber threats or data breaches. While current research on alert triage primarily concentrates on reducing false positives, analysts still face a shortage of resources to investigate all true alerts. The key to resolving this issue lies in the prioritization of alerts based on their potential severity, allowing analysts to allocate their efforts effectively. This paper introduces AlertPro, an alert prioritization framework that facilitates the alert triage and validation stage of typical SOC workflow. The AlertPro framework extracts context features from alert sequences and history features from alerts previously investigated by analysts, besides basic features from raw alert data. By presenting analysts with only the top-ranked potentially high-risk alerts in each query and continually updating these rankings based on feedback, AlertPro significantly streamlines the alert investigation process. To evaluate AlertPro, we conducted experiments on five datasets that are chosen or prepared specifically because they all include multi-step attacks. The results reveal that AlertPro is able to discover a previously undisclosed attack concealed within the public dataset iscx, illustrating its potential in enhancing security posture. We also evaluate the feature importance in anomaly detection and conclude that employing context features yields better performance over basic features. The paper also explores the effectiveness of incorporating history features in active learning, achieving an average improvement of 30% in attack discovery rates. The processing time of AlertPro for re-ranking and selecting high-risk alerts is within 0.5 seconds, indicating that AlertPro can effectively work in real-time scenarios. AlertPro is limited to only using partial feedback and can be improved by incorporating richer feedback from experts. Overall, AlertPro mitigates alert fatigue, enabling security analysts to concentrate their efforts on high-priority threats.
Keywords: Alert fatigue; Multi-step attack; Intrusion detection; Reinforcement learning; Expert feedback; Active learning

Pedro H. Barros, Eduarda T.C. Chagas, Leonardo B. Oliveira, Fabiane Queiroz, Heitor S. Ramos,
Malware‐SMELL: A zero‐shot learning strategy for detecting zero‐day vulnerabilities,
Computers & Security,
Volume 120,
2022,
102785,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.102785.
(https://www.sciencedirect.com/science/article/pii/S0167404822001808)
Abstract: One of the most relevant security problems is inferring whether a program has malicious intent (malware software). Even though Antivirus is one of the most popular approaches for malware detection, new types of malware are released at a fast pace, making most techniques for detecting them quickly obsolete. Thus, regular Antivirus typically fails to detect new malware until their signature is incorporated into their database. Nevertheless, new techniques to identify unknown malware are necessary to protect systems even at the day zero of a malware release. Few-shot learning is an approach that consists of using a few examples from each class while training a model. A compelling case of this approach is classifying objects classes that have not yet been used in the training set, namely Zero-shot Learning. In the present work, we propose Malware-SMELL, a new Zero-shot learning method to classify malware using visual representation. In Malware-SMELL, we propose a new representation space to calculate the similarity between pairs of objects, called S-Space. This new representation enhances the class separability and, thus, makes such a challenging classification process more efficient. Malware-SMELL reached 80% of recall and outperforms other methods by a ratio of 9.58% in a classification model trained only with goodware code on real-world datasets in Generalized Zero-shot Learning paradigm.
Keywords: Similarity space; Latent feature space; Malware classification; Zero-day vulnerabilities

Sanghoon Jeon, Huy Kang Kim,
AutoVAS: An automated vulnerability analysis system with a deep learning approach,
Computers & Security,
Volume 106,
2021,
102308,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2021.102308.
(https://www.sciencedirect.com/science/article/pii/S0167404821001322)
Abstract: Owing to the advances in automated hacking and analysis technologies in recent years, numerous software security vulnerabilities have been announced. Software vulnerabilities are increasing rapidly, whereas methods to analyze and cope with them depend on manual analyses, which result in a slow response. In recent years, studies concerning the prediction of vulnerabilities or the detection of patterns of previous vulnerabilities have been conducted by applying deep learning algorithms in an automated vulnerability search based on source code. However, existing methods target only certain security vulnerabilities or make limited use of source code to compile information. Few studies have been conducted on methods that represent source code as an embedding vector. Thus, this study proposes a deep learning-based automated vulnerability analysis system (AutoVAS) that effectively represents source code as embedding vectors by using datasets from various projects in the National Vulnerability Database (NVD) and Software Assurance Reference Database (SARD). To evaluate AutoVAS, we present and share a dataset for deep learning models. Experimental results show that AutoVAS achieves a false negative rate (FNR) of 3.62%, a false positive rate (FPR) of 1.88%, and an F1-score of 96.11%, which represent lower FNR and FPR values than those achieved by other approaches. We further apply AutoVAS to nine open-source projects and detect eleven vulnerabilities, most of which are missed by the other approaches we experimented with. Notably, we discovered three zero-day vulnerabilities, two of which were patched after being informed by AutoVAS. The other vulnerability received the Common Vulnerabilities and Exposures (CVE) ID after being detected by AutoVAS.
Keywords: Vulnerability detection; Cybersecurity; Data-driven security; Static analysis; Program slicing

Hao Sun, Lei Cui, Lun Li, Zhenquan Ding, Zhiyu Hao, Jiancong Cui, Peng Liu,
VDSimilar: Vulnerability detection based on code similarity of vulnerabilities and patches,
Computers & Security,
Volume 110,
2021,
102417,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2021.102417.
(https://www.sciencedirect.com/science/article/pii/S0167404821002418)
Abstract: Vulnerability detection using machine learning is a hot topic in improving software security. However, existing works formulate detection as a classification problem, which requires a large set of labelled data while capturing semantical and syntactic similarity. In this work, we argue that similarity in the view of vulnerability is the key in detecting vulnerabilities. We prepare a relatively smaller data set composed of both vulnerabilities and associated patches, and attempt to realize security similarity from (i) the similarity between pair of vulnerabilities and (ii) the difference between a pair of vulnerability and patch. To achieve this, we setup the detection model using the Siamese network cooperated with BiLSTM and Attention to deal with source code, Attention network to improve the detection accuracy. On a data set of 876 vulnerabilities and patches of OpenSSL and Linux, the proposed model (VDSimilar) achieves about 97.17% in AUC value of OpenSSL (where the Attention network contributes 1.21% than BiLSTM in Siamese), which is more outstanding than the most advanced methods based on deep learning.
Keywords: Siamese network; BiLSTM; Attention; Vulnerability detection; Code similarity

Gustavo de Carvalho Bertoli, Lourenço Alves Pereira Junior, Osamu Saotome, Aldri Luiz dos Santos,
Generalizing intrusion detection for heterogeneous networks: A stacked-unsupervised federated learning approach,
Computers & Security,
Volume 127,
2023,
103106,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103106.
(https://www.sciencedirect.com/science/article/pii/S0167404823000160)
Abstract: The constantly evolving digital transformation imposes new requirements on our society. Aspects relating to reliance on the networking domain and the difficulty of achieving security by design pose a challenge today. As a result, data-centric and machine-learning approaches arose as feasible solutions for securing large networks. Although, in the network security domain, ML-based solutions face a challenge regarding the capability to generalize between different contexts. In other words, solutions based on specific network data usually do not perform satisfactorily on other networks. This paper describes the stacked-unsupervised federated learning (FL) approach to generalize on a cross-silo configuration for a flow-based network intrusion detection system (NIDS). The proposed approach we have examined comprises a deep autoencoder in conjunction with an energy flow classifier in an ensemble learning task. Our approach performs better than traditional local learning and naive cross-evaluation (training in one context and testing on another network data). Remarkably, the proposed approach demonstrates a sound performance in the case of non-IID data silos. In conjunction with an informative feature in an ensemble architecture for unsupervised learning, we advise that the proposed FL-based NIDS results in a feasible approach for generalization between heterogeneous networks.
Keywords: Network intrusion detection; Generalization; Unsupervised learning; Federated learning; Network flows

Zhengfa Li, Chuanhe Huang, Shuhua Deng, Wanyu Qiu, Xieping Gao,
A soft actor-critic reinforcement learning algorithm for network intrusion detection,
Computers & Security,
Volume 135,
2023,
103502,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103502.
(https://www.sciencedirect.com/science/article/pii/S0167404823004121)
Abstract: Network intrusion detection plays a very important role in network security. Although current deep learning-based intrusion detection algorithms have achieved good detection performance, there are still limitations in dealing with unbalanced datasets and identifying minority attacks and unknown attacks. In this paper, we propose an intrusion detection model AE-SAC based on adversarial environment learning and soft actor-critic reinforcement learning algorithm. First, this paper introduces an environmental agent for training data resampling to solve the imbalance problem of the original data. Second, rewards are redefined in reinforcement learning. In order to improve the recognition rate of few categories of network attacks, we set different reward values for different categories of attacks. The environment agent and classifier agent are trained adversarially around maximizing their respective reward values. Finally, a multi-classification experiment is conducted on the NSL-KDD and AWID datasets to compare with the existed excellent intrusion detection algorithms. AE-SAC achieves excellent classification performance with an accuracy of 84.15% and a f1-score of 83.97% on the NSL-KDD dataset, and an accuracy and a f1-score over 98.9% on the AWID dataset.
Keywords: Network security; Anomaly detection; Network intrusion detection; Deep reinforcement learning; Soft actor-critic

Xin Li, Yang Xin, Hongliang Zhu, Yixian Yang, Yuling Chen,
Cross-domain vulnerability detection using graph embedding and domain adaptation,
Computers & Security,
Volume 125,
2023,
103017,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.103017.
(https://www.sciencedirect.com/science/article/pii/S0167404822004096)
Abstract: Vulnerability detection is an effective means to maintain cyberspace security. Machine learning methods have risen much attention in software security due to their advantage of accuracy and automation. However, current researches mainly focus on in-domain vulnerability detection where the training data and test data belong to the same domain. Due to application scenarios, coding habits, and other factors, vulnerabilities in different software projects may obey different probability distributions. This discrepancy compromises the performance of machine learning methods when they are applied to a brand-new project. To address this cold start problem, we propose a cross-domain vulnerability detection framework using graph embedding and deep domain adaption (VulGDA). It works in a variety of cross-domain fashions, including the Zero-Shot fashion that no labeled data in the target domain is available for training. VulGDA is decomposed to graph embedding and domain adaptation. At the graph embedding stage, we transform the samples in source code into graph representations where elements are directly concatenated according to their syntactic and semantic relationships. Then, we aggregate information from neighbors and edges defined in the graph into real-valued vectors. By graph embedding, VulGDA extracts comprehensive vulnerability features and compromises the challenge of long-term dependency. Aiming at the discrepancy between training data and test data, domain adaption is used to train a feature generator. This feature generator maps the graph embedding to a “deep” feature that is discriminative for vulnerability detection, and invariant to the shift between domains. We perform a systematic experiment to validate the effectiveness of VulGDA. The results show that combining graph embedding and deep domain adaptation promotes VulGDA's performance in cross-domain vulnerability detection. Compared with the state-of-the-art methods, our method has better performance under the cold start condition.
Keywords: Cross-domain; Vulnerability detection; Graph embedding; Domain adaption; Software security

Muhammad Imran, Hafeez Ur Rehman Siddiqui, Ali Raza, Muhammad Amjad Raza, Furqan Rustam, Imran Ashraf,
A performance overview of machine learning-based defense strategies for advanced persistent threats in industrial control systems,
Computers & Security,
Volume 134,
2023,
103445,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103445.
(https://www.sciencedirect.com/science/article/pii/S0167404823003553)
Abstract: Cybersecurity incident response is a very crucial part of the cybersecurity management system. Adversaries emerge and evolve with new cybersecurity tactics, techniques, and procedures (TTPs). It is essential to detect the TTPs in a timely manner to respond effectively and mitigate the vulnerabilities to secure business operations. This research focuses on TTP identification and detection based on a machine learning approach. Early identification and detection are paramount in protecting, responding to, and recovering from such adversarial attacks. Analyzing use cases is a critical tool to ensure proper and in-depth evaluation of sector-specific cybersecurity challenges. In this regard, this study investigates existing known methodologies for cyber-attacks such as Mitre attacks, and developed a method for identifying threat cases. In addition, Windows-based threat cases are implemented, comprehensive datasets are generated, and supervised machine learning models are applied to detect threats effectively and efficiently. Random forest outperforms other models with the highest accuracy of 99%. Future work can be done for generating threat cases based on multiple log sources, including network security and endpoint protection device, and achieve high accuracy by removing false positives using machine learning. Similarly, real-time threat detection is also envisioned for future work.
Keywords: Cybersecurity; Mitre attack; Advance persistent threats; Industrial control; Machine learning; Feature engineering

Bolun Wu, Futai Zou, Ping Yi, Yue Wu, Liang Zhang,
SlicedLocator: Code vulnerability locator based on sliced dependence graph,
Computers & Security,
Volume 134,
2023,
103469,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103469.
(https://www.sciencedirect.com/science/article/pii/S0167404823003796)
Abstract: Machine learning-based fine-grained vulnerability detection is an important technique for locating vulnerable statements, which assists engineers in efficiently analyzing and fixing the vulnerabilities. However, due to insufficient code representations, code embeddings, and neural network design, current methods suffer low vulnerability localization performance. In this paper, we propose to address these shortcomings by presenting SlicedLocator, a novel fine-grained code vulnerability detection model that is trained in a dual-grained manner and can predict both program-level and statement-level vulnerabilities. We design the sliced dependence graph, a new code representation that not only preserves rich interprocedural relations but also eliminates vulnerability-irrelevant statements. We create attention-based code embedding networks that are trained with the entire model to extract vulnerability-aware code features. In addition, we present a new LSTM-GNN model as a fusion of semantic modeling and structural modeling. Experiment results on a large-scale C/C++ vulnerability dataset reveal that SlicedLocator outperforms state-of-the-art machine learning-based vulnerability detectors, especially in terms of localization metrics.
Keywords: Vulnerability detection; Localization; Program analysis; Program representation; Deep learning

Idris Zakariyya, Harsha Kalutarage, M. Omar Al-Kadri,
Towards a robust, effective and resource efficient machine learning technique for IoT security monitoring,
Computers & Security,
Volume 133,
2023,
103388,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103388.
(https://www.sciencedirect.com/science/article/pii/S0167404823002985)
Abstract: The application of Deep Neural Networks (DNNs) for monitoring cyberattacks in Internet of Things (IoT) systems has gained significant attention in recent years. However, achieving optimal detection performance through DNN training has posed challenges due to computational intensity and vulnerability to adversarial samples. To address these issues, this paper introduces an optimization method that combines regularization and simulated micro-batching. This approach enables the training of DNNs in a robust, efficient, and resource-friendly manner for IoT security monitoring. Experimental results demonstrate that the proposed DNN model, including its performance in Federated Learning (FL) settings, exhibits improved attack detection and resistance to adversarial perturbations compared to benchmark baseline models and conventional Machine Learning (ML) methods typically employed in IoT security monitoring. Notably, the proposed method achieves significant reductions of 79.54% and 21.91% in memory and time usage, respectively, when compared to the benchmark baseline in simulated virtual worker environments. Moreover, in realistic testbed scenarios, the proposed method reduces memory footprint by 6.05% and execution time by 15.84%, while maintaining accuracy levels that are superior or comparable to state-of-the-art methods. These findings validate the feasibility and effectiveness of the proposed optimization method for enhancing the efficiency and robustness of DNN-based IoT security monitoring.
Keywords: Internet of things; Deep neural networks; Cybersecurity; Resource constrained; Attack detection; Federated learning

Chunyong Zhang, Yang Xin,
VulGAI: vulnerability detection based on graphs and images,
Computers & Security,
Volume 135,
2023,
103501,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103501.
(https://www.sciencedirect.com/science/article/pii/S016740482300411X)
Abstract: Deep learning models have been widely used in the field of vulnerability detection. Deep learning-based vulnerability detection methods can automatically learn code patterns. Some methods consider processing codes as text sequences to achieve scalable vulnerability detection. They leverage natural language processing models to extract code features. These methods do not consider the code's semantic structure and treat code slices as text. Vulnerability detection methods based on graph structures and graph neural networks are more accurate than text-based methods. However, these methods lack scalability in practice. Both graph generation and graph neural network training are all time-consuming. We propose a vulnerability detection method based on graphs and images (VulGAI). VulGAI choose the more reasonable node centrality to generate the image. It can preserve program details and distinguish node importance from different perspectives. In addition, we design a more efficient CNN model, which reduces computational overhead and improves detection performance (Time and Accuracy). We implement VulGAI and evaluate six methods (VulDePecker, SySeVR, Devign, VulCNN, mVulPreter, and VulGAI) on 40,657 functions. Experimental results show that VulGAI achieves higher Accuracy, TPR, and F1-Score than the others. In addition, we compare VulGAI and VulCNN on 30270 real-world functions. VulGAI outperforms VulCNN by 1.48 times in the number of TP. VulGAI is about 3.9 times faster than VulCNN in detection time.
Keywords: Vulnerability detection; Program dependency graph; Node centrality; RGB image; CNN

Abdullahi Aishatu Wabi, Ismaila Idris, Olayemi Mikail Olaniyi, Joseph A. Ojeniyi,
DDOS attack detection in SDN: Method of attacks, detection techniques, challenges and research gaps,
Computers & Security,
Volume 139,
2024,
103652,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103652.
(https://www.sciencedirect.com/science/article/pii/S0167404823005618)
Abstract: The aim of a Software Defined Network is to provide flexibility and programmability towards ensuring network manageability and centralized control to deal with the growing users of future network. However, the advantages that SDN presents comes with security concerns arising from some vulnerabilities in its Architecture. Security concerns such as DDOS attack in SDN is growing in strength and sophistication trying to exploit the programmability and centralized control features of SDN Architecture. Although SDN is vulnerable to attack, SDN itself could be used to defeat attacks. This Article reviews DDOS Attack Detection and mitigation approaches and is further clustered into four as follows: Statistical based technique, techniques based on Machine Learning, Neural network and other detection approaches or Techniques. The capability and weakness of the detection techniques were pointed out. The metrics for the performance Evaluation of some of the various techniques as well as Data set repository were presented. Finally, some general research challenges and Gaps to guide future research in this area were discussed.
Keywords: SDN; DDOS attacks; Detection; Mitigation; Review; DDOS traffic features

Sydney Mambwe Kasongo, Yanxia Sun,
A deep learning method with wrapper based feature extraction for wireless intrusion detection system,
Computers & Security,
Volume 92,
2020,
101752,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2020.101752.
(https://www.sciencedirect.com/science/article/pii/S0167404820300365)
Abstract: In the past decade, wired and wireless computer networks have substantially evolved because of the rapid development of technologies such as the Internet of Things (IoT), wireless handled devices, vehicular networks, 4G and 5G, cyber-physical systems, etc. These technologies exchange large amount of data, and as a result, they are prone to several malicious actions, attacks and security threats that can compromise the availability and integrity of information or services. Therefore, the security and protection of the various communication infrastructures using an intrusion detection system (IDS) is of critical importance. In this research, we propose a Feed-Forward Deep Neural Network (FFDNN) wireless IDS system using a Wrapper Based Feature Extraction Unit (WFEU). The extraction method of the WFEU uses the Extra Trees algorithm in order to generate a reduced optimal feature vector. The effectiveness and efficiency of the WFEU-FFDNN is studied based on the UNSW-NB15 and the AWID intrusion detection datasets. Furthermore, the WFEU-FFDNN is compared to standard machine learning (ML) algorithms that include Random Forest (RF), Support Vector Machine (SVM), Naïve Bayes (NB), Decision Tree (DT) and k-Nearest Neighbor (kNN). The experimental studies include binary and multiclass types of attacks. The results suggested that the proposed WFEU-FFDNN has greater detection accuracy than other approaches. In the instance of the UNSW-NB15, the WFEU generated an optimal feature vector consisting of 22 attributes. Using this input vector; our approach achieved overall accuracies of 87.10% and 77.16% for the binary and multiclass classification schemes, respectively. In the instance of the AWID, a reduced input vector of 26 attributes was generated by the WFEU, and the experiments demonstrated that our method obtained overall accuracies of 99.66% and 99.77% for the binary and the multiclass classification configurations, respectively.
Keywords: Machine learning; Deep learning; Intrusion detection; Wireless networks; Feature extraction

Pascal Maniriho, Abdun Naser Mahmood, Mohammad Jabed Morshed Chowdhury,
MeMalDet: A memory analysis-based malware detection framework using deep autoencoders and stacked ensemble under temporal evaluations,
Computers & Security,
Volume 142,
2024,
103864,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103864.
(https://www.sciencedirect.com/science/article/pii/S0167404824001652)
Abstract: Malware attacks continue to evolve, making detection challenging for traditional static and dynamic analysis techniques. On the other hand, memory analysis provides valuable behavioral insights, but prior research lacks temporal evaluations which are critical for robust detection of new malware variants over time. This paper presents MeMalDet, a novel memory analysis-based malware detection technique using deep autoencoders and stacked ensemble learning. We introduce an improved dataset with temporal attributes enabling more realistic evaluations of memory-based malware detection techniques under concept drift (temporal data split). MeMalDet extracts optimal features from memory dumps using deep autoencoders in an unsupervised manner, avoiding manual feature engineering. A stacked ensemble of supervised classifiers then performs highly accurate malware detection. Extensive experiments on our improved large-scale public dataset demonstrate MeMalDet’s ability to maintain high performance when detecting obfuscated malware under temporal splits. We achieve up to 98.82% accuracy and 98.72% F1-score in detecting previously unseen advanced obfuscated malware, significantly improving upon state-of-the-art memory analysis-based malware detection techniques. The improved dataset enables temporally robust evaluations, which is a novel contribution. MeMalDet combines the benefits of representation learning and supervised machine learning ensemble classification for effective malware detection over time using memory analysis. This research provides a new capability for identifying evasive modern malware and combating evolving real-world threats.
Keywords: Malware detection; Malware obfuscation; Memory analysis; Windows malware; Machine learning; Deep learning

P.L.S. Jayalaxmi, Rahul Saha, Gulshan Kumar, Mamoun Alazab, Mauro Conti, Xiaochun Cheng,
PIGNUS: A Deep Learning model for IDS in industrial internet-of-things,
Computers & Security,
Volume 132,
2023,
103315,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103315.
(https://www.sciencedirect.com/science/article/pii/S0167404823002250)
Abstract: The heterogeneous nature of the Industrial Internet of Thing (IIoT) has a considerable impact on the development of an effective Intrusion Detection System (IDS). The proliferation of linked devices results in multiple inputs from industrial sensors. IDS faces challenges in analyzing the features of the traffic and identifying anonymous behavior. Due to the unavailability of a comprehensive feature mapping method, the present IDS solutions are non-usable to identify zero-day vulnerabilities. In this paper, we introduce the first comprehensive IDS framework that combines an efficient feature-mapping technique and cascading model to solve the above-mentioned problems. We call our proposed solution deeP learnIG model intrusioN detection in indUStrial internet-of things (PIGNUS). PIGNUS integrates Auto Encoders (AE) to select optimal features and Cascade Forward Back Propagation Neural Network (CFBPNN) for classification and attack detection. The cascading model uses interconnected links from the initial layer to the output layer and determines the normal and abnormal behavior patterns and produces a perfect classification. We execute a set of experiments on five popular IIoT datasets: gas pipeline, water storage tank, NSLKDD+, UNSW-NB15, and X-IIoTID. We compare PIGNUS to the state-of-the-art models in terms of accuracy, False Positive Ratio (FPR), precision, and recall. The results show that PIGNUS provides more than 95% accuracy, which is 25% better on average than the existing models. In the other parameters, PIGNUS shows 20% improved FPR, 10% better recall, and 10% better in precision. Overall, PIGNUS proves its efficiency as an IDS solution for IIoTs. Thus, PIGNUS is an efficient solution for IIoTs.
Keywords: IoT; Industry; Security; Intrusion; Detection

Xinjun Pei, Long Yu, Shengwei Tian,
AMalNet: A deep learning framework based on graph convolutional networks for malware detection,
Computers & Security,
Volume 93,
2020,
101792,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2020.101792.
(https://www.sciencedirect.com/science/article/pii/S0167404820300778)
Abstract: The increasing popularity of Android apps attracted widespread attention from malware authors. Traditional malware detection systems suffer from some shortcomings; computationally expensive, insufficient performance or not robust enough. To address this challenge, we (1) build a novel and highly reliable deep learning framework, named AMalNet, to learn multiple embedding representations for Android malware detection and family attribution, (2) introduce a version of Graph Convolutional Networks (GCNs) for modeling high-level graphical semantics, which automatically identifies and learns the semantic and sequential patterns, (3) use an Independently Recurrent Neural Network (IndRNN) to decode the deep semantic information, making full use of remote dependent information between nodes to independently extract features. The experimental results on multiple benchmark datasets indicated that the AMalNet framework outperforms other state-of-the-art techniques significantly.
Keywords: Word embedding; Graph convolutional networks; Independently recurrent neural networks; Android Malware detection; Static analysis

Zihan Ma, Tianchong Gao,
Federated learning backdoor attack detection with persistence diagram,
Computers & Security,
Volume 136,
2024,
103557,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103557.
(https://www.sciencedirect.com/science/article/pii/S0167404823004674)
Abstract: Federated learning (FL) is an emerging decentralized machine learning method that allows multiple clients to participate in a joint mission by merging the local models into a global model. While FL provides the ultimate data privacy for each participant, the service providers can hardly verify the validity of local datasets, which gives malicious clients an opportunity to undermine the functionality of the global model, i.e., perpetrate the backdoor attack. To find the potential attackers among the clients, we propose a topological data analysis tool called Persistence Homology (PH). PH reveals the correlation between topological properties and the neurons' status, which tells us whether the model is well generalized or overfits on some specific samples. We trained a classifier based on the PH features of neural network models, eventually composing a secure federated learning mechanism. The results illustrated that our method can detect malicious clients with different types of backdoor attacks with high accuracy, even under the highly unbalanced non-i.i.d. data distribution condition.
Keywords: Federated learning; Backdoor attack; Persistence homology; Topological data analysis; Neural network

Clemens-Alexander Brust, Tim Sonnekalb, Bernd Gruner,
ROMEO: A binary vulnerability detection dataset for exploring Juliet through the lens of assembly language,
Computers & Security,
Volume 128,
2023,
103165,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103165.
(https://www.sciencedirect.com/science/article/pii/S0167404823000755)
Abstract: Context
Automatic vulnerability detection on C/C++ source code has benefitted from the introduction of machine learning to the field, with many recent publications targeting this combination. In contrast, assembly language or machine code artifacts receive less attention, although there are compelling reasons to study them. They are more representative of what is executed, more easily incorporated in dynamic analysis, and in the case of closed-source code, there is no alternative.
Objective
We evaluate the representative capability of assembly language compared to C/C++ source code for vulnerability detection. Furthermore, we investigate the role of call graph context in detecting function-spanning vulnerabilities. Finally, we verify whether compiling a benchmark dataset compromises an experiment’s soundness by inadvertently leaking label information.
Method
We propose ROMEO, a publicly available, reproducible and reusable binary vulnerability detection benchmark dataset derived from the synthetic Juliet test suite. Alongside, we introduce a simple text-based assembly language representation that includes context for function-spanning vulnerability detection and semantics to detect high-level vulnerabilities. It is constructed by disassembling the .text segment of the respective binaries.
Results
We evaluate an x86 assembly language representation of the compiled dataset, combined with an off-the-shelf classifier. It compares favorably to state-of-the-art methods, including those operating on the full C/C++ code. Including context information using the call graph improves detection of function-spanning vulnerabilities. There is no label information leaked during the compilation process.
Conclusion
Performing vulnerability detection on a compiled program instead of the source code is a worthwhile tradeoff. While certain information is lost, e.g., comments and certain identifiers, other valuable information is gained, e.g., about compiler optimizations.

Daniel Gibert, Carles Mateu, Jordi Planes,
HYDRA: A multimodal deep learning framework for malware classification,
Computers & Security,
Volume 95,
2020,
101873,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2020.101873.
(https://www.sciencedirect.com/science/article/pii/S0167404820301462)
Abstract: While traditional machine learning methods for malware detection largely depend on hand-designed features, which are based on experts’ knowledge of the domain, end-to-end learning approaches take the raw executable as input, and try to learn a set of descriptive features from it. Although the latter might behave badly in problems where there are not many data available or where the dataset is imbalanced. In this paper we present HYDRA, a novel framework to address the task of malware detection and classification by combining various types of features to discover the relationships between distinct modalities. Our approach learns from various sources to maximize the benefits of multiple feature types to reflect the characteristics of malware executables. We propose a baseline system that consists of both hand-engineered and end-to-end components to combine the benefits of feature engineering and deep learning so that malware characteristics are effectively represented. An extensive analysis of state-of-the-art methods on the Microsoft Malware Classification Challenge benchmark shows that the proposed solution achieves comparable results to gradient boosting methods in the literature and higher yield in comparison with deep learning approaches.
Keywords: Malware classification; Machine learning; Deep learning; Feature fusion; Multimodal learning

Songyun Wu, Bo Wang, Zhiliang Wang, Shuhan Fan, Jiahai Yang, Jia Li,
Joint prediction on security event and time interval through deep learning,
Computers & Security,
Volume 117,
2022,
102696,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.102696.
(https://www.sciencedirect.com/science/article/pii/S0167404822000943)
Abstract: Recently, sophisticated attacks on cyberspace have occurred frequently, causing severe damage to the Internet. Predicting potential threats can assist security engineers in deploying corresponding defenses in advance to reduce the damage. Thus, threat prediction has drawn attention in communities recently. Previous works utilized merely historical security event sequences to predict the subsequent event through the recurrent neural network (RNN), yielding inaccurate results when the input sequence is corrupted by false reports from underlying detection logs. In this paper, we develop a joint predictor for security events and time intervals through attention-based LSTM (Long Short-Term Memory). To enhance the event predicting performance for corrupted input sequences, time intervals between events are incorporated into the input tuple, providing more distinguishing features. Moreover, a time discretization method is proposed to transform the skewed long-tail dwell time distribution into a predictable distribution of the time interval. In addition, the joint optimization function enables the model to predict the occurrence time of the next event simultaneously, which is supportive for security managers to select appropriate defenses. Our model is proved to be effective on four real-world datasets, outperforming previous methods on both event and time prediction. Moreover, the empirical results also validate the model’s stability.
Keywords: Security event; Attack prediction; Time prediction; Deep learning; Security management

Xabier Sáez-de-Cámara, Jose Luis Flores, Cristóbal Arellano, Aitor Urbieta, Urko Zurutuza,
Clustered federated learning architecture for network anomaly detection in large scale heterogeneous IoT networks,
Computers & Security,
Volume 131,
2023,
103299,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103299.
(https://www.sciencedirect.com/science/article/pii/S0167404823002092)
Abstract: There is a growing trend of cyberattacks against Internet of Things (IoT) devices; moreover, the sophistication and motivation of those attacks is increasing. The vast scale of IoT, diverse hardware and software, and being typically placed in uncontrolled environments make traditional IT security mechanisms such as signature-based intrusion detection and prevention systems challenging to integrate. They also struggle to cope with the rapidly evolving IoT threat landscape due to long delays between the analysis and publication of the detection rules. Machine learning methods have shown faster response to emerging threats; however, model training architectures like cloud or edge computing face multiple drawbacks in IoT settings, including network overhead and data isolation arising from the large scale and heterogeneity that characterizes these networks. This work presents an architecture for training unsupervised models for network intrusion detection in large, distributed IoT and Industrial IoT (IIoT) deployments. We leverage Federated Learning (FL) to collaboratively train between peers and reduce isolation and network overhead problems. We build upon it to include an unsupervised device clustering algorithm fully integrated into the FL pipeline to address the heterogeneity issues that arise in FL settings. The architecture is implemented and evaluated using a testbed that includes various emulated IoT/IIoT devices and attackers interacting in a complex network topology comprising 100 emulated devices, 30 switches and 10 routers. The anomaly detection models are evaluated on real attacks performed by the testbed’s threat actors, including the entire Mirai malware lifecycle, an additional botnet based on the Merlin command and control server and other red-teaming tools performing scanning activities and multiple attacks targeting the emulated devices.
Keywords: Anomaly detection; Botnet; Internet of things; Intrusion detection; Machine learning; Network security

Zhonglin Liu, Yong Fang, Cheng Huang, Yijia Xu,
MFXSS: An effective XSS vulnerability detection method in JavaScript based on multi-feature model,
Computers & Security,
Volume 124,
2023,
103015,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.103015.
(https://www.sciencedirect.com/science/article/pii/S0167404822004072)
Abstract: The widespread use of web applications has also made them more vulnerable to hackers, resulting in the leakage of large amounts of application and personal privacy data. Cross-site scripting (XSS) attacks are one of the most significant threats to web applications. Attackers can inject scripts to control the victim’s browser to send data or execute commands, leading to the theft of privacy or the hijacking of login tokens. Therefore, we proposed a multi-feature fusion-based neural network vulnerability detection model for detecting XSS vulnerabilities in the JavaScript source code of websites (We termed our implementation of this approach MFXSS). We combine abstract syntax tree (AST) and code control flow graph (CFG) to convert the generalized sample data into graph structure and code string structure. Then, through the graph convolutional neural network, weighted aggregation, and the bidirectional recurrent neural network, the logical call features and the context execution relationship features of the source code are extracted and fused respectively. Finally, the fused feature vectors are used to detect and predict XSS vulnerabilities in JavaScript. In the experiment, we designed multiple control experiments to verify that the model construction is optimal, and the accuracy rates in the standard and variant datasets are 0.997 and 0.986. Moreover, in comparing similar detection schemes, MFXSS also performs better. Applying the model to an actual web environment, we successfully detected the presence of XSS vulnerabilities in websites.
Keywords: Cross-site scripting; Multi-feature fusion; Graph convolutional network; Weighted aggregation; Vulnerability detection

Peng Zhou, Yuhan Gao,
Detecting prototype pollution for node.js: Vulnerability review and new fuzzing inputs,
Computers & Security,
Volume 137,
2024,
103625,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103625.
(https://www.sciencedirect.com/science/article/pii/S0167404823005357)
Abstract: Prototype pollution is a unique vulnerability originating from the JavaScript languages and has been found widely prevalent across the modern Node.js ecosystem. To detect this kind of vulnerability, state-of-the-art research either runs dynamic fuzzing on the function level to trigger the pollution in the run time or performs static analysis to look up the polluted objects in symbolic conditions. Despite succeeding to some extent, we find the current dynamic fuzzing highly relies on a very limited set of pre-defined function inputs for detection, and the static analysis cannot adapt well to large and complex Node.js modules, hence likely missing lots of potential detection possibilities. In this paper, to the best of our knowledge, we take the first review by re-detecting historical vulnerabilities of prototype pollution that have been disclosed and recorded in public databases. Surprisingly, we find out the current research can only cover some of these records. Our further analysis reveals that many cases cannot be detected because of the very limited code coverage of dynamic fuzzing and their incapability to parse large-scale code bases by static analysis. We thus can confirm the current research still has much room to improve and accordingly, we take dynamic fuzzing as a case study to show this possibility. Specifically, we have extended dynamic fuzzing by reusing new function inputs summarized from historical vulnerabilities and evaluated it over 60,000 Node.js packages. With this extension, we have discovered 65 new prototype pollution vulnerabilities in zero days, which cannot be covered by original dynamic fuzzing. Compared with static analysis, we also find 28 of the 65 new vulnerabilities that cannot be detected. Furthermore, for the vulnerabilities covered by both the approaches, our extended fuzzing runs more reliably and faster (with more than tens of times of speed) than its static counterpart. To the date we write this paper, we have received 6 CVE numbers and continuously negotiated with respective package maintainers (via Snyk and GitHub) for reporting and patching the remaining vulnerabilities.
Keywords: Prototype pollution; Node.js security; Dynamic fuzzing; Static taint analysis; Vulnerability review

Xiuzhen Chen, Weicheng Qiu, Lixing Chen, Yinghua Ma, Jin Ma,
Fast and practical intrusion detection system based on federated learning for VANET,
Computers & Security,
Volume 142,
2024,
103881,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103881.
(https://www.sciencedirect.com/science/article/pii/S0167404824001822)
Abstract: VANET facilitates communication between vehicles and roadside units, thereby enhancing traffic safety and efficiency. However, it also introduces several attack vectors, compromising security and privacy. To enhance the practicality and precision of existing VANET intrusion detection systems, we propose a novel hybrid algorithm named VAN-IDS. This algorithm combines packet analysis and physical feature analysis. Temporal properties of packets are analyzed using Bi-LSTM, while physical attributes of vehicles are evaluated using LightGBM. Predictive outputs from both models are merged using the Dempster–Shafer theory. Data is collected from the F2MD simulation environment, and experiments are conducted to evaluate the efficacy of VAN-IDS. Results show that VAN-IDS achieves an accuracy exceeding 98.5% in detecting DoS and Sybil attacks, surpassing existing VANET IDSs and meeting real-time detection requirements. Federated learning is introduced, with VAN-FED-IDS designed to accelerate model training and updates, while protecting the privacy of the model and dataset. Roadside units (RSUs) serve as edge computing nodes for local model training, while cloud services aggregate models for collaborative training of detection algorithms. In these experiments, the open-source federated learning frameworks Flower and FedTree are used to assess communication overhead and training duration in both single-machine simulation and multi-machine deployment scenarios. This demonstrates the viability of federated learning, which can protect local data privacy, expedite model training and updates within the IDS, and maintain the original model’s detection accuracy.
Keywords: VANET; Intrusion detection; Machine learning; DST; Federated learning

Ryusei Maeda, Mamoru Mimura,
Automating post-exploitation with deep reinforcement learning,
Computers & Security,
Volume 100,
2021,
102108,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2020.102108.
(https://www.sciencedirect.com/science/article/pii/S0167404820303813)
Abstract: In order to assess the risk of information systems, it is important to investigate the behavior of the attacker after successful exploitation (post-exploitation). However, the audit requires the experts, and to the best of our knowledge, there are no solutions to automate this process. This paper proposes a method of automating post-exploitation by combining deep reinforcement learning and the PowerShell Empire, which is famous as a post-exploitation framework. Our reinforcement learning agents select one of the PowerShell Empire modules as an action. The state of the agents is defined by 10 parameters such as type of account that was compromised by the agents. In the learning phase, we compared the learning progress of the 3 reinforcement learning models: A2C, Q-Learning, and SARSA. The result shows that the A2C could gain reward most efficiently. Moreover, the behavior of the trained agents are evaluated in a test domain network. The results show that the trained agent using A2C could obtain the administrative privileges to the domain controller.
Keywords: Reinforcement learning; Post-exploitation; A2C; Q-Learning; SARSA; Deep reinforcement learning; Lateral movement

Hao Sun, Lei Cui, Lun Li, Zhenquan Ding, Siyuan Li, Zhiyu Hao, Hongsong Zhu,
VDTriplet: Vulnerability detection with graph semantics using triplet model,
Computers & Security,
Volume 139,
2024,
103732,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103732.
(https://www.sciencedirect.com/science/article/pii/S0167404824000336)
Abstract: This study presents VDTriplet, a novel learning framework for building vulnerability detection models. VDTriplet is the first attempt using deep learning to avoid the potential known vulnerability function misjudgment due to the small difference between vulnerability and its fixed vulnerability function. Unlike prior work that treats the program as sequential tokens or randomly initialized graphs for supervised binary classification detection tasks, our model not only fuses rich syntactic and semantic information to obtain the most accurate program representation, but also utilizes the TripletNN model to reduce misjudgment of potential known vulnerabilities. VDTriplet first extracts the subgraphs that causes the vulnerability through the typical programming errors to reduce redundant code. Then, it uses the pre-trained model and unsupervised model for the graph encoding of subgraphs, thereby minimizing the influence of randomly initialized graph nodes and avoiding the need for supervised labeling. Finally, TripletNN model minimizes the distance between potential vulnerabilities and vulnerabilities with the same vulnerability type, and maximizes the distance between potential vulnerabilities and fixed vulnerabilities to reduce false positives. The results show that the performance of VDTriplet is significantly better than the studied baselines. Compared with the best performing model in the literature, our model achieves a total of 4.89%, 4.23%, 4.56% and 5.34% improvement in Accuracy, Precision, Recall and F1-Score in the test results respectively. Moreover, it exhibits well generalization in detecting new eight applications, demonstrating that it is potentially valuable in practical usage. Overall, this is indeed an outstanding improvement.
Keywords: Vulnerability detection; Deep learning; Extracting subgraphs; Encoding subgraphs; TripletNN model

Anee Sharma, Ningrinla Marchang,
A review on client-server attacks and defenses in federated learning,
Computers & Security,
Volume 140,
2024,
103801,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103801.
(https://www.sciencedirect.com/science/article/pii/S0167404824001020)
Abstract: Federated Learning (FL) offers decentralized machine learning (ML) capabilities while potentially safeguarding data privacy. However, this architecture introduces unique security challenges. This paper presents a comprehensive survey of these challenges, categorizing attacks based on their targets: client-side training data, local models, FL channel, server-side aggregated parameters, and global models. We further discuss defense mechanisms tailored for local and global models. Through our investigation, we illuminate the vulnerabilities inherent to FL and provide insights into countermeasures that ensure robustness. Our findings underscore the significance of a dual-focused strategy, addressing security concerns at both client and server levels.
Keywords: Security; Federated learning; Machine learning; Attacks; Defenses

Umesh Kumar Lilhore, Surjeet Dalal, Sarita Simaiya,
A cognitive security framework for detecting intrusions in IoT and 5G utilizing deep learning,
Computers & Security,
Volume 136,
2024,
103560,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103560.
(https://www.sciencedirect.com/science/article/pii/S0167404823004704)
Abstract: The fast growth of Internet of Things (IoT) gadgets and 5G networks has increased linkage and accessibility. However, growing interconnectivity poses new threat levels in these environments, making intrusion detection critical. In this article, we introduce a novel security framework that centres on deep learning and is tailored to support the particular risks posed by IoT channels and 5G networks. Deep neural networks are used in our proposed framework to effectively analyze network activity patterns and recognize any possible breaches in real-time communication. Deep learning autonomously learns complicated features and patterns, facilitating the proposed model's adaptability to changing threat vectors and traffic features. This research proposed a Hybrid model using enhanced light-weight CNNs architecture (MobileNetV3-SVM) and Transfer learning (TL) for intrusion detection in 5G communication. The proposed model utilizes the advantages of a multi-layered structure, which enables it to acquire knowledge from raw network information hierarchically. It provides the ability to distinguish between authentic and malicious behaviour efficiently. We have implemented several cutting-edge strategies to maximize the effectiveness of intrusion detection in environments characterized by limited availability of resources, such as those associated with the IoT and high-speed 5G networks. The proposed hybrid model processes network packets in real-time using light-weight MobileNet, reducing the computational overhead and making it suitable for IoT and 5G edge devices. In the proposed model, a MobileNetV3-SVM auto-classifies the network's intrusion images, enhancing the overall accuracy. In addition, to address the issue of limited labelled data in dynamic and constantly changing systems, we use a transfer learning strategy to deal with this issue. The proposed hybrid model and existing CNN- architectures, i.e., VGG-16, VGG-19, Efficient-Net and Inception-Net, are tested on CICIDS-2017, 2018 and UNSW-NB15 IoT 5G security datasets. During the experimental assessment, we demonstrated the strength of the proposed model by simulating a wide range of network settings and intrusion scenarios. Experimental findings show considerable improvements by the proposed hybrid model in accuracy, precision, false positive rates, Matthew's Correlation Coefficient (MCC) and AUC-ROC over existing approaches.
Keywords: Intrusion detection system; MobilenetV3; Deep learning; 5G security; IoT; Transfer learning

Cristina Cifuentes, François Gauthier, Behnaz Hassanshahi, Padmanabhan Krishnan, Davin McCall,
The role of program analysis in security vulnerability detection: Then and now,
Computers & Security,
Volume 135,
2023,
103463,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103463.
(https://www.sciencedirect.com/science/article/pii/S0167404823003735)
Abstract: Program analysis techniques play an important role in detecting security vulnerabilities. In this paper we describe our experiences in developing a variety of tools that detect security vulnerabilities in an industrial setting. The main driving forces for adoption of program analysis tools by a development organisation are low false positive rate, ease of integration in the developer's workflow, scalability to handle industrial size systems and results that are easy to understand. Even if one the above dimensions is not supported, the tool will not be used in practice. We show how the analyses of program analysis tools have changed over more than a decade due to differences in languages, e.g., code written in systems-level languages like C tend to focus on memory-related vulnerabilities, in contrast to languages like Java, JavaScript and Python where the focus is more on injection vulnerabilities in web or cloud applications. Based on language, static or dynamic analysis approaches are needed, including hybrid approaches. We conclude with our vision on Intelligent Application Security – how program analysis tools will keep changing to enable the DevSecOps model given the fertile ground that the DevOps model provides today. We foresee different program analysis tools working together by sharing information, including the results they produce, while addressing newer security issues such as those related to supply chain issues. In this way, program analysis tools would be extended with relevant machine learning techniques and be integrated in all different phases of the code development, building, testing, deployment and monitoring cycle.
Keywords: Static analysis; Dynamic analysis; Industrial scale application; DevOps

S. Manimaran, V.N. Sastry, N.P. Gopalan,
SBTDDL: A novel framework for sensor-based threats detection on Android smartphones using deep learning,
Computers & Security,
Volume 118,
2022,
102729,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.102729.
(https://www.sciencedirect.com/science/article/pii/S0167404822001249)
Abstract: Sensors in the smartphone play a vital role in various user-friendly mobile services. The mobile application requires user permission to access the permission imposed sensors and not for other sensors. The sensors in the smartphone are vulnerable to various attacks. The attackers can exploit these sensors to trigger malware, extract the sensitive information of users and other nearby devices, and expose users’ confidential information. We propose SBTDDL, a novel context-aware framework for detecting sensor-based threats on Android smartphones using deep learning. In our work, (a) we identify the sensor-based threats by using the state (on and off) of the sensors in the smartphone for different user activities, (b) binary classification is performed in the sequence prediction model to classify the benign and malicious activities on the device, (c) SBTDDL performs better in detecting the sensor-based threats compared to the state-of-art existing methods by attaining the accuracy of 99% in identifying benign and malicious activities, (d) SBTDDL also detects the malicious activity occurring like benign activity, and the performance is not affected when the total number of benign and malicious activities increases.
Keywords: Sensors; Threats; Smartphone; Benign activity; Malicious activity; Classification

Islam Obaidat, Meera Sridhar, Khue M. Pham, Phu H. Phung,
Jadeite: A novel image-behavior-based approach for Java malware detection using deep learning,
Computers & Security,
Volume 113,
2022,
102547,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2021.102547.
(https://www.sciencedirect.com/science/article/pii/S0167404821003710)
Abstract: Java malware exploiting language vulnerabilities has become increasingly prevalent in the recent past. Since Java is a platform-independent language, these security threats open up the opportunity for multi-platform exploitation. Although security researchers continuously develop different approaches for protecting against Java malware programs, the presence of complicated Java malware properties, such as code obfuscation, makes these malware programs fly under the radar. These challenges present the need to develop new approaches that are resilient to such properties. This article presents Jadeite, a novel approach for detecting Java bytecode malware programs using static analysis and recent advancements in the image-based, deep-learning classification space. In particular, Jadeite extracts the Interprocedural Control Flow Graph (ICFG) from a given Java bytecode file and then prunes the ICFG and converts it into an adjacency matrix. Finally, Jadeite constructs a grayscale image from this matrix. We leverage an object detection algorithm in a deep Convolutional Neural Network (CNN) classifier to determine maliciousness. Also, Jadeite extracts an additional set of features from the Java malware program to improve the accuracy of malware classification. These features are consolidated with the extracted images and used as inputs to the CNN classifier. Experimental results demonstrate that Jadeite achieves high accuracy (98.4%) compared to other Java malware detection approaches and is capable of detecting both known and previously-unseen real-world malicious Java programs.
Keywords: Bytecode; Malware; Deep learning; CNN; Classification

Ramkumar M .P . , P.V. Bhaskar Reddy, J.T. Thirukrishna, Ch. Vidyadhari,
Intrusion detection in big data using hybrid feature fusion and optimization enabled deep learning based on spark architecture,
Computers & Security,
Volume 116,
2022,
102668,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.102668.
(https://www.sciencedirect.com/science/article/pii/S0167404822000670)
Abstract: With the rapid expansion of Internet services and increasing intrusion issues, conventional intrusion detection techniques cannot work well with several difficult intrusions. Though several intrusion detection methods have been introduced in the past years, developing an Intrusion Detection Systems (IDS) with prevailing intrusion detection strategy is still very much desirable. Hence, a robust and effective intrusion detection approach, named RV coefficient+Exponential Sea Lion Optimization-enabled Deep Residual Network (ExpSLO-enabled DRN) using spark is devised for the intrusion detection. Here, the unique features are selected using proposed RV coefficient-based hybrid feature fusion, which is designed by the incorporation of wrapper, class-wise information gain (CIG), and Canberra distance in slave node. With the distinctive features selected, the process of data augmentation is done using oversampling for making the data more appropriate to perform the further process in the slave node. Moreover, DRN classifier is utilized for detecting the intrusions in the master node where the DRN training is done using devised ExpSLO algorithm, which is the hybridization of Exponentially Weighted Moving average (EWMA) and Sea Lion Optimization (SLnO). Furthermore, the devised method obtained better performance by considering the evaluation metrics, such as precision, recall, and F-measure with the higher values of 0.8800, 0.8845, and 0.8822 based on without attacks using dataset-2.
Keywords: Big data; Deep learning; Intrusion detection; Deep residual network; and Spark model

Roberto Doriguzzi-Corin, Domenico Siracusa,
FLAD: Adaptive Federated Learning for DDoS attack detection,
Computers & Security,
Volume 137,
2024,
103597,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103597.
(https://www.sciencedirect.com/science/article/pii/S0167404823005072)
Abstract: Federated Learning (FL) has been recently receiving increasing consideration from the cybersecurity community as a way to collaboratively train deep learning models with distributed profiles of cyber threats, with no disclosure of training data. Nevertheless, the adoption of FL in cybersecurity is still in its infancy, and a range of practical aspects have not been properly addressed yet. Indeed, the Federated Averaging algorithm at the core of the FL concept requires the availability of test data to control the FL process. Although this might be feasible in some domains, test network traffic of newly discovered attacks cannot be always shared without disclosing sensitive information. In this paper, we address the convergence of the FL process in dynamic cybersecurity scenarios, where the trained model must be frequently updated with new recent attack profiles to empower all members of the federation with the latest detection features. To this aim, we propose FLAD (adaptive Federated Learning Approach to DDoS attack detection), an FL solution for cybersecurity applications based on an adaptive mechanism that orchestrates the FL process by dynamically assigning more computation to those members whose attacks profiles are harder to learn, without the need of sharing any test data to monitor the performance of the trained model. Using a recent dataset of DDoS attacks, we demonstrate that FLAD outperforms state-of-the-art FL algorithms in terms of convergence time and accuracy across a range of unbalanced datasets of heterogeneous DDoS attacks. We also show the robustness of our approach in a realistic scenario, where we retrain the deep learning model multiple times to introduce the profiles of new attacks on a pre-trained model.
Keywords: Network security; Intrusion detection; Distributed denial of service; Federated Learning; Heterogeneous data

Daniel Gibert, Matt Fredrikson, Carles Mateu, Jordi Planes, Quan Le,
Enhancing the insertion of NOP instructions to obfuscate malware via deep reinforcement learning,
Computers & Security,
Volume 113,
2022,
102543,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2021.102543.
(https://www.sciencedirect.com/science/article/pii/S0167404821003679)
Abstract: Current state-of-the-art research for tackling the problem of malware detection and classification is centered on the design, implementation and deployment of systems powered by machine learning because of its ability to generalize to never-before-seen malware families and polymorphic mutations. However, it has been shown that machine learning models, in partidular deep neural networks, lack robustness against crafted inputs (adversarial examples). In this work, we have investigated the vulnerability of a state-of-the-art shallow convolutional neural network malware classifier against the deat code insertion technique. We propose a general framework powered by a Double Q-network to induce misclassification over malware families. The framework trains an agent through a convolutional neural network to select the optimal positions in a code sequence to insert dead code instructions so that the machine learning classifier mislabels the resulting executable. The experiments show that the proposed method significantly drops the classification accuracy of the classifier to 56.53% while having an evasion rate of 100% for the samples belonging to Kelihos_ver3, Simda, and Kelihos_ver1 families. In addition, the average number of instructions needed to mislabel malware in comparison to a random agent decreased by 33%.
Keywords: Malware classification; Assembly language source code; Obfuscation; Reinforcement learning; Deep Q-Network

Wenbo Guo, Yong Fang, Cheng Huang, Haoran Ou, Chun Lin, Yongyan Guo,
HyVulDect: A hybrid semantic vulnerability mining system based on graph neural network,
Computers & Security,
Volume 121,
2022,
102823,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.102823.
(https://www.sciencedirect.com/science/article/pii/S0167404822002176)
Abstract: In recent years, software programs tend to be large and complex, software has become the infrastructure of modern society, but software security issues can not be ignored. software vulnerabilities have become one of the main threats to computer security. There are countless cases of exploiting source code vulnerabilities to launch attacks. At the same time, the development of open source software has made source code vulnerability detection more and more critical. Traditional vulnerability mining methods have been unable to meet the security analysis needs of complex software because of the high false-positive rate and false-negative rate. To resolve the existing problems, we propose a graph neural network vulnerability mining system named HyVulDect based on hybrid semantics, which constructs a composite semantic code property graph for code representation based on the causes of vulnerabilities. A gated graph neural network is used to extract deep semantic information. Since most of the vulnerabilities are data flow associated, we use taint analysis to extract the taint propagation chain, use the BiLSTM model to extract the token-level features of the context, and finally use the classifier to classify the fusion features. We introduce a dual-attention mechanism that allows the model to focus on vulnerability-related code, making it more suitable for vulnerability mining tasks. The experimental results show that HyVulDect outperforms existing state-of-the-art methods and can achieve an accuracy rate of 92% on the benchmark dataset. Compared with the rule-based static mining tools Flawfinder, RATS, and Cppcheck, it has better performance and can effectively detect the actual CVE source code vulnerabilities.
Keywords: Program analysis; Vulnerability mining; Graph neural network; Taint analysis; Code representation,

Anil V Turukmane, Ramkumar Devendiran,
M-MultiSVM: An efficient feature selection assisted network intrusion detection system using machine learning,
Computers & Security,
Volume 137,
2024,
103587,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103587.
(https://www.sciencedirect.com/science/article/pii/S0167404823004972)
Abstract: The intrusions are increasing daily, so there is a huge amount of privacy violations, financial loss, illegal transferring of information, etc. Various forms of intrusion occur in networks, such as menacing networks, computer resources and network information. Each type of intrusion focuses on specified tasks, whereas the hackers may focus on stealing confidential data, industrial secrets and personal information, which is then leaked to others for illegal gains. Due to the false detection of attacks in the security and changing environmental fields, limitations like data lagging on actual attacks and sustaining financial harms occur. To resolve this, automatic abnormality detection systems are required to secure the required computing ability and to analyze the attacks. Hence, an efficient automated intrusion detection system using machine learning methodology is proposed in this research paper. Initially, the data are gathered from CSE-CIC-IDS 2018 and UNSW-NB15 datasets. The acquired data are pre-processed using Null value handling and Min-Max normalization. Null value handling is used to remove missing values and irrelevant parameters. Min-Max normalization adjusted the unnormalized data in the pre-processing stage. After pre-processing, the class imbalance problem is reduced by using the Advanced Synthetic Minority Oversampling Technique (ASmoT). ASmoT aims to balance the class and reduce imbalance class problems and overfitting issues. The next phase is feature extraction, which is performed by Modified Singular Value Decomposition (M-SvD). M-SvD extracts essential features such as basic features, content features and traffic features from the input. The extracted features are optimized by the Opposition-based Northern Goshawk Optimization algorithm (ONgO). These optimal features are able to produce optimal output. After feature selection, the different types of attacks are classified by a hybrid machine learning model called Mud Ring assisted multilayer support vector machine (M-MultiSVM) and finally, the hyperparameters are tuned by the Mud Ring optimization algorithm. Thus, the proposed M-MultiSVM model can efficiently detect intrusion in the network. The performance metrics show that the proposed system achieved 99.89 % accuracy by using the CSE-CIC-IDS 2018 dataset; also, the proposed system achieved 97.535 % accuracy by using the UNSW-NB15 dataset.
Keywords: Null value handling; Min-max normalization; Synthetic minority oversampling; Singular value decomposition; Northern Goshawk Optimization; Multilayer SVM; Mud ring

Antonio Paya, Sergio Arroni, Vicente García-Díaz, Alberto Gómez,
Apollon: A robust defense system against Adversarial Machine Learning attacks in Intrusion Detection Systems,
Computers & Security,
Volume 136,
2024,
103546,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103546.
(https://www.sciencedirect.com/science/article/pii/S016740482300456X)
Abstract: The rise of Adversarial Machine Learning (AML) attacks is presenting a significant challenge to Intrusion Detection Systems (IDS) and their ability to detect threats. To address this issue, we introduce Apollon, a novel defense system that can protect IDS against AML attacks. Apollon utilizes a diverse set of classifiers to identify intrusions and employs Multi-Armed Bandits (MAB) with Thompson sampling to dynamically select the optimal classifier or ensemble of classifiers for each input. This approach enables Apollon to prevent attackers from learning the IDS behavior and generating adversarial examples that can evade the IDS detection. We evaluate Apollon on several of the most popular and recent datasets, and show that it can successfully detect attacks without compromising its performance on traditional network traffic. Our results suggest that Apollon is a robust defense system against AML attacks in IDS.
Keywords: Adversarial Machine Learning; Intrusion Detection Systems; Artificial Intelligence; Cybersecurity; Multi-Armed Bandits

Melanie Ehrenberg, Shahram Sarkani, Thomas A. Mazzuchi,
Python source code vulnerability detection with named entity recognition,
Computers & Security,
Volume 140,
2024,
103802,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103802.
(https://www.sciencedirect.com/science/article/pii/S0167404824001032)
Abstract: Vulnerabilities within source code have grown over the last 20 years to become a common threat to systems and networks. As the implementation of open-source software continues to develop, more unknown vulnerabilities will exist throughout system networks. This research proposes an enhanced vulnerability detection method specific to Python source code that utilizes pre-trained, BERT-based transformer models to apply tokenization, embedding, and named entity recognition (a natural language processing technique). The use of named entity recognition not only allows for the detection of potential vulnerabilities, but also for the classification of different vulnerability types. This research uses the publicly available CodeBERT, RoBERTa, and DistilBERT models to fine-tune for the downstream task of token classification for six different common weakness enumeration specifications. The results achieved in this research outperform previous Python-based vulnerability detection methods and demonstrate the effectiveness of applying named entity recognition to enhance the overall research into Python source code vulnerabilities.
Keywords: Vulnerability detection; Natural language processing; Machine learning; Named entity recognition; Transformer; Python; BERT; Programming language; Common weakness enumeration; CWE

Giampaolo Bovenzi, Giuseppe Aceto, Domenico Ciuonzo, Antonio Montieri, Valerio Persico, Antonio Pescapé,
Network anomaly detection methods in IoT environments via deep learning: A Fair comparison of performance and robustness,
Computers & Security,
Volume 128,
2023,
103167,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103167.
(https://www.sciencedirect.com/science/article/pii/S0167404823000779)
Abstract: The Internet of Things (IoT) is a key enabler in closing the loop in Cyber-Physical Systems, providing “smartness” and thus additional value to each monitored/controlled physical asset. Unfortunately, these devices are more and more targeted by cyberattacks because of their diffusion and of the usually limited hardware and software resources. This calls for designing and evaluating new effective approaches for protecting IoT systems at the network level (Network Intrusion Detection Systems, NIDSs). These in turn are challenged by the heterogeneity of IoT devices and the growing volume of transmitted data. To tackle this challenge, we select a Deep Learning architecture to perform unsupervised early anomaly detection. With a data-driven approach, we explore in-depth multiple design choices and exploit the appealing structural properties of the selected architecture to enhance its performance. The experimental evaluation is performed on two recent and publicly available IoT datasets (IoT-23 and Kitsune). Finally, we adopt an adversarial approach to investigate the robustness of our solution in the presence of Label Flipping poisoning attacks. The experimental results highlight the improved performance of the proposed architecture, in comparison to both well-known baselines and previous proposals.
Keywords: Anomaly detection; Deep learning; Internet of things; Intrusion detection system; Network security; Robustness

Jesús F. Cevallos M., Alessandra Rizzardi, Sabrina Sicari, Alberto Coen Porisini,
NERO: NEural algorithmic reasoning for zeRO-day attack detection in the IoT: A hybrid approach,
Computers & Security,
2024,
103898,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103898.
(https://www.sciencedirect.com/science/article/pii/S0167404824002001)
Abstract: Anomaly detection approaches for network intrusion detection learn to identify deviations from normal behavior on a data-driven basis. However, current approaches strive to infer the degree of abnormality of out-of-distribution samples when these appertain to different zero-day attacks. Inspired by the successes of the neural algorithmic reasoning paradigm to leverage the generalization of rule-based behavior, this paper presents a deep learning strategy for solving zero-day network attack detection and categorization. Moreover, focusing on the particular scenario of the Internet of Things (IoT), the privacy preservation requirement may imply a low training data regime for any learning algorithm. To this respect, the presented framework uses metric-based meta-learning to achieve few-shot learning capabilities. The presented pipeline is called NERO, as it imports the encode-process-decode architecture from the NEural algorithmic reasoning blueprint to converge zeRO-day attack detection policies within constrained training data.
Keywords: Network intrusion detection systems; Internet of things; Neural algorithmic reasoning; Meta-learning

Yiran Cheng, Shouguo Yang, Zhe Lang, Zhiqiang Shi, Limin Sun,
VERI: A Large-scale Open-Source Components Vulnerability Detection in IoT Firmware,
Computers & Security,
Volume 126,
2023,
103068,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.103068.
(https://www.sciencedirect.com/science/article/pii/S0167404822004606)
Abstract: IoT device manufacturers integrate open-source components (OSCs) to serve necessary and common functions for facilitating firmware development. However, outdated versions of OSC conceal N-day vulnerabilities and continue to function on IoT devices. The security risks can be predicted once we can identify the OSC versions employed in the firmware. Existing works make attempts at OSC version identification but fail to perform vulnerability detection on a large-scale IoT firmware due to i) unsuitable version identification method for IoT firmware scenario. ii) the lack of a large-scale version-vulnerability relation database. To this end, we propose a system VERI for large-scale vulnerability detection based on lightweight version identification. First, for OSC version identification, VERI leverages symbolic execution with static analysis to identify exact OSC versions even though there are many version-like strings in OSC. Second, VERI employs a deep learning-based method to extract OSC names and vulnerable version ranges from vulnerability descriptions, constructs and maintains an OSC version-vulnerability relation database to serve the vulnerability detection. Finally, VERI polls the relation database to confirm the N-day security risk of the OSC with identified version. The evaluation results show that VERI achieves 96.43% accuracy with high efficiency in OSC version identification. Meanwhile, the deep learning model accurately extracts the OSC names and versions from vulnerability descriptions dataset with 97.19% precision and 96.56% recall. Based on the model, we build a large-scale version-vulnerability relation database. Furthermore, we utilize VERI to conduct a large-scale analysis on 28,890 firmware and find 38,654 vulnerable OSCs with 266,109 N-day vulnerabilities, most of which are with high risks. From the detection results, we find that after the official patch for the vulnerability is released, manufacturers delay an average of 473 days to patch the firmware.
Keywords: IoT Firmware; Open-source component; Vulnerability detection; Version identification

Peng Luo, Buhong Wang, Jiwei Tian,
TTSAD: TCN-Transformer-SVDD Model for Anomaly Detection in air traffic ADS-B data,
Computers & Security,
Volume 141,
2024,
103840,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103840.
(https://www.sciencedirect.com/science/article/pii/S016740482400141X)
Abstract: ADS-B (Automatic Dependent Surveillance-Broadcast) is a key technology in the new generation air traffic surveillance system. However, it is vulnerable to various cyber attacks because it broadcasts data in plaintext format and lacks authentication mechanism. Previous research has rarely considered the application scenarios of ATM (Air Traffic Management) in commercial air transport, and there are the problems of low anomaly detection rate and the non-lightweight model. This paper focuses on ADS-B anomaly detection under the background of ATM. We propose the TTSAD (TCN-Transformer-SVDD Model for Anomaly Detection) model, which aims to address the problems of existing ADS-B anomaly detection methods including inadequate considerations of long-term dependencies and distribution characteristic, the non-lightweight model and the poor adaptive threshold. First, ADS-B time series is input into TCN (Temporal Convolutional Network) prediction module which predicts data in an accurate and quick way using causal convolution and dilated convolution. Then, the predicted ADS-B time series is input into Transformer reconstruction module which reconstructs data accurately and quickly based on Self-Attention and Multi-Head Attention mechanism. Finally, the difference values between the reconstructed values and the real values are input into SVDD (Support Vector Data Description) threshold determination module for an optimal threshold. Experimental results show that the TTSAD model can detect ADS-B anomaly data generated from attacks such as altitude slow offset and DOS (Denial of Service). The TTSAD model is superior to other machine learning methods in terms of recall rate, detection rate, accuracy rate, missing detection rate and false alarm rate. Furthermore, compared with other deep learning methods including LSTM, GRU and LSTM-AE, the TTSAD model has a shorter training time and a lightweight characteristic. This approach guarantees the information security of ADS-B, thereby improving the operational security of ATM.
Keywords: ADS-B; Anomaly detection; Deep learning; TCN; Transformer

Zihao Wang, Kar Wai Fok, Vrizlynn L.L. Thing,
Machine learning for encrypted malicious traffic detection: Approaches, datasets and comparative study,
Computers & Security,
Volume 113,
2022,
102542,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2021.102542.
(https://www.sciencedirect.com/science/article/pii/S0167404821003667)
Abstract: As people’s demand for personal privacy and data security becomes a priority, encrypted traffic has become mainstream in the cyber world. However, traffic encryption is also shielding malicious and illegal traffic introduced by adversaries, from being detected. This is especially so in the post-COVID-19 environment where malicious traffic encryption is growing rapidly. Common security solutions that rely on plain payload content analysis such as deep packet inspection are rendered useless. Thus, machine learning based approaches have become an important direction for encrypted malicious traffic detection. In this paper, we formulate a universal framework of machine learning based encrypted malicious traffic detection techniques and provided a systematic review. Furthermore, current research adopts different datasets to train their models due to the lack of well-recognized datasets and feature sets. As a result, their model performance cannot be compared and analyzed reliably. Therefore, in this paper, we analyse, process and combine datasets from 5 different sources to generate a comprehensive and fair dataset to aid future research in this field. On this basis, we also implement and compare 10 encrypted malicious traffic detection algorithms. We then discuss challenges and propose future directions of research.
Keywords: encrypted malicious traffic detection; traffic classification; machine learning; deep learning

Yanchen Qiao, Weizhe Zhang, Zhicheng Tian, Laurence T. Yang, Yang Liu, Mamoun Alazab,
Adversarial malware sample generation method based on the prototype of deep learning detector,
Computers & Security,
Volume 119,
2022,
102762,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.102762.
(https://www.sciencedirect.com/science/article/pii/S0167404822001572)
Abstract: The deep learning methods had been proved to be effective for malware detection in the past. However, the recent studies show that deep learning models are vulnerable to adversarial attacks. Thus, the malware detection models based on deep learning face the threat of adversarial examples. As a popular case of adversarial examples, adversarial images are usually generated by adding unrecognizable perturbations to original pictures. When applying the same method to the windows PE (Portable Executable) malware, the original structure cannot be destroyed and the original functions of PE malware need to be preserved. Most existing windows adversarial malware generation works are derived from adversarial image methods with some adaptive modifications such as inserting perturbations in the slack space of the PE file. The both generation methods have some similarities but also many differences. Thus, directly using the methods of adversarial images to create malware effects the efficiency and fooling rate. In this paper, we overcome these issues by proposing a method for generating windows adversarial malware in PE format based on prototype samples of deep learning models. The prototype samples are the most typical ones of a certain category of the classification models. With the characteristic of the prototype samples, the bytes of the prototype samples are added as perturbations to the malware samples. This way can fast generate adversarial malware that could fool the target model. The proposed method is evaluated on a real world dataset of malware. Promising results show that the method can fool the deep learning based malware detection models with a high rate.
Keywords: Adversarial example; Deep learning; Model interpretability; Malware detection; Prototype

Rasheed Ahmad, Izzat Alsmadi, Wasim Alhamdani, Lo'ai Tawalbeh,
A comprehensive deep learning benchmark for IoT IDS,
Computers & Security,
Volume 114,
2022,
102588,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2021.102588.
(https://www.sciencedirect.com/science/article/pii/S0167404821004119)
Abstract: The significance of an intrusion detection system (IDS) in networks security cannot be overstated in detecting and responding to malicious attacks. Failure to detect large-scale attacks like DDoS not only makes the networks vulnerable, but a failure of critical lifesaving medical and industrial equipment can also put human lives at risk. Lack of availability of comprehensive and quality network datasets and the narrow scope to build an IDS based on a single machine learning classifier adds further limitations. Such issues can risk producing inaccurate or biased results in the solutions proposed by various researchers. Toward this end, this paper analyzed several datasets (old, recent, non-IoT, and IoT specific) using several individual and hybrid deep learning classifiers. Our goal is to establish a benchmark that can compare several classification models on several datasets to limit (1) dataset quality issues and (2) possible bias in produced results. We reported our empirical results by revealing exciting findings on some of the classifiers, which took hours to converge but could not successfully detect attacks. In contrast, others quickly converged and were able to produce the best results in terms of accuracy and other performance metrics. We believe that this paper's findings will help build a comprehensive IDS by recognizing that classification or prediction models should be trained beyond a limited scope of one dataset or application.
Keywords: Intrusion detection system (IDS); Machine learning; Deep learning; Large-scale attacks; Internet of Things (IoT); Benchmark network dataset

Chongbo Wei, Gaogang Xie, Zulong Diao,
A lightweight deep learning framework for botnet detecting at the IoT edge,
Computers & Security,
Volume 129,
2023,
103195,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103195.
(https://www.sciencedirect.com/science/article/pii/S0167404823001050)
Abstract: Nowadays, a large number of Internet-of-Things (IoT) devices are exposed on the Internet. Due to the serious security flaws and users’ misuse, they are vulnerable to various attacks, such as botnet, a major risk for IoT security. Monitoring network traffic at the IoT edge and identifying botnet activities in early-stage becomes increasingly critical. With the powerful capability of learning complex patterns, many studies pay attention to neural networks for solving this problem. However, traditional network intrusion detection systems (NIDS) based on neural networks have a high resource consumption and aren’t suitable for deploying in Internet gateways and routers. In this paper, we propose a novel lightweight and generic NIDS with a two-stage framework to detect botnet activities on the IoT network, only using accessible packet-length features. Our NIDS can be deployed at a resource-limited device and work in an efficient online manner. We first propose 21 statistical features which are discriminative for malicious and normal traffic flows. Based on these features, we design a module based on an autoencoder to filter out a large number of normal traffic flows in the first stage. Then we propose a novel mechanism to transform the packet length sequence into a three-channel RGB image for malicious traffic classification based on a lightweight convolutional neural network (CNN). In order to demonstrate the performance, we build a real IoT environment and deploy our NIDS on a Raspberry PI. The experiment results show that our NIDS has excellent accuracy for detecting botnet activities and higher processing rate for traffic compared with the state-of-the-art ANN-based methods.
Keywords: Network intrusion detection; Internet-of-Things; Botnet detection; Machine learning; Deep Learning

Sultan Asiri, Yang Xiao, Saleh Alzahrani, Tieshan Li,
PhishingRTDS: A real-time detection system for phishing attacks using a Deep Learning model,
Computers & Security,
Volume 141,
2024,
103843,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103843.
(https://www.sciencedirect.com/science/article/pii/S0167404824001445)
Abstract: In recent years, phishing attacks have become more intelligent and more challenging to detect using typical phishing methods. Moreover, attackers have leveraged some web development techniques to increase the website's legitimacy in victims' eyes, such as using JFrame to design a window that looks like a browser inside the webpage. In this paper, we design a system that detects three types of phishing attacks: Tiny Uniform Resource Locators (TinyURLs), Browsers in the Browser (BiTB), and regular phishing attacks. In this system, we aim to protect victims from mistakenly downloading malicious software into their systems. We split our system into three parts: Deep Learning model (DL), browser extension, and docker container. First, we design a DL model using bidirectional long short-term memory (BiLSTM) and an attention mechanism to classify the URL as phishing or benign. Our model shows 99% in its precision, recall, and F1 score. Second, we design a browser extension to extract the original URL from the suspect webpage and then send it to the docker container. Then, the docker container opens the webpage and extracts all URLs from its HyperText Markup Language (HTML) and JavaScript. Then, each URL passes to a DL model for classification, resulting in a list of labels for each webpage. Therefore, we use three decision strategies: Single Phishing Strategy (SPhS), Mean Sum Strategy (MSS), and Weighted Average Strategy (WeAS) to decide whether the webpage is phishing or benign. Our findings indicate that the best results among the three strategies were WeAS.
Keywords: Security; Phishing attacks; Real-time; Detection systems; Deep Learning; Tiny Uniform Resource Locators; Browsers in the Browser (BiTB)

Longtao Guo, Huakun Huang, Lingjun Zhao, Peiliang Wang, Shan Jiang, Chunhua Su,
Reentrancy vulnerability detection based on graph convolutional networks and expert patterns under subspace mapping,
Computers & Security,
Volume 142,
2024,
103894,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103894.
(https://www.sciencedirect.com/science/article/pii/S0167404824001962)
Abstract: Smart contracts with automatic execution capability provide a vast development space for transactions in Blockchain. However, due to the vulnerabilities in smart contracts, Blockchain has suffered huge economic losses, which greatly undermines people’s trust in Blockchain and smart contracts. In this paper, we explore a vulnerability detection method based on graph neural networks and combine both contract source code and opcode. The structure of the method consists of four modules, i.e., preprocessing, subspace mapping, feature extraction, and detection modules. In the feature mapping module, we use a multi-subspace mapping approach to explore the impact of different subspace mappings on the detection method. For reentrancy vulnerability, we conducted extensive experiments. The experiments prove that our method achieves 95% accuracy and 94% F1-Score on average.
Keywords: Blockchain; Smart contract; Vulnerability detection; Graph neural network; Subspace mapping

A. Parameswari, R. Ganeshan, V. Ragavi, M. Shereesha,
Hybrid rat swarm hunter prey optimization trained deep learning for network intrusion detection using CNN features,
Computers & Security,
Volume 139,
2024,
103656,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103656.
(https://www.sciencedirect.com/science/article/pii/S0167404823005655)
Abstract: In recent years, the emerging growth of various network technologies, namely the cloud computing, 5 G networks, Internet of Things (IoT), and so on resulted in the createion of huge quantity of data and creates challenges to the security of networks. The classical firewalls failed to meet various requirements of the current security of the networks due to the increasing number of network attacks. Hence, an optimization-enabled deep learning model Rat Swarm Hunter Prey Optimization-Deep Maxout Network (RSHPO-DMN) technique is designed to effectively handle various network threats. The Z-score data normalization is applied for data pre-processing initially and by considering chord distance, the data is transformed into usable formats. The transformed data are extracted using the Convolutional Neural Network (CNN) feature and the extracted feature is converted into vector format for network intrusion detection process. The DMN is used for intrusion detection in networks and the designed RSHPO model is used to boost the intrusion detection rate exhibited in the classifier. The RSHPO-DMN model achieved superior performance under different evaluation indicators with accuracy of 90.88 %, precision of 93.58 %, recall of 96.54 %, and f1-score of 95.04 % respectively than other prevailing intrusion detection approaches.
Keywords: Deep maxout network; Rat swarm optimization; Hunter prey optimization; Convolution Neural Network; Z-score data normalization

Lalitha Chavali, Abhinav Krishnan, Paresh Saxena, Barsha Mitra, Aneesh Sreevallabh Chivukula,
Off-policy actor-critic deep reinforcement learning methods for alert prioritization in intrusion detection systems,
Computers & Security,
Volume 142,
2024,
103854,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103854.
(https://www.sciencedirect.com/science/article/pii/S016740482400155X)
Abstract: Alert prioritization plays a very important role in network security as it helps security teams manage and respond to the overwhelming volume of alerts generated by intrusion detection systems (IDSs). Although current deep reinforcement learning (DRL) based deep deterministic policy gradient (DDPG) has achieved good performance for alert prioritization, there are still limitations in dealing with DDPG's instability and limited exploration capabilities. In this paper, we propose TD3-AP and SAC-AP, two DRL empowered off-policy actor-critic alert prioritization methods based on twin delayed deep deterministic policy gradient (TD3) and soft actor-critic (SAC), respectively. We model the interaction between an adversary and a defender as a zero-sum game and use a double oracle framework to obtain mixed strategy Nash equilibrium (MSNE). Our objective is to minimize the defender's loss which represents the inability of the defender to investigate alerts generated due to the attacks. To demonstrate the benefits and scalability of the proposed approaches, we conduct extensive experiments on three datasets: MQTT-IoT-IDS2020, DARPA 2000 LLDOS 1.0 and CSE-CIC-IDS2018. The results depict that TD3-AP and SAC-AP exhibit a decrease in the defender's loss by 50% and 14.28%, respectively, in comparison to the alert prioritization method based on DDPG. The improvements are significantly higher when the proposed approaches are compared with traditional alert prioritization methods including Uniform, Snort, Fuzzy and RAP. Additionally, we also provide an analysis of the interpretability of our results through the utilization of SHapley Additive exPlanations (SHAP). We assess the sensitivity of our proposed approaches to different hyperparameters and evaluate the training time and computational resources necessary for their implementation.
Keywords: Alert prioritization; Deep reinforcement learning (DRL); Twin delayed deep deterministic policy gradient (TD3); Soft actor-critic (SAC); Mixed strategy Nash equilibrium (MSNE)

Xiangjuan Li, Yang Li, Zhaowen Feng, Zhaoxuan Wang, Quan Pan,
ATS-O2A: A state-based adversarial attack strategy on deep reinforcement learning,
Computers & Security,
Volume 129,
2023,
103259,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103259.
(https://www.sciencedirect.com/science/article/pii/S0167404823001694)
Abstract: In recent years, deep reinforcement learning has been widely applied in many decision-making tasks requiring high safety and security due to its excellent performance. However, if an adversary attacks when the agent making critical decisions, it is bound to bring disastrous consequences because humans cannot detect it. Therefore, it is necessary to study adversarial attacks against deep reinforcement learning to help researchers design highly robust and secure algorithms and systems. In this paper, we proposed an attack method based on Attack Time Selection (ATS) function and Optimal Attack Action (O2A) strategy, named ATS-O2A. We select the critical attack moment through the ATS function, and then combine the state-based strategy with the O2A strategy to select the optimal attack action which has profound influence as targeted action, finally we launch an attack by making targeted adversarial examples. In order to measure the stealthiness and effectiveness of the attack, we designed a new measurement index. Experiments show that our method can effectively reduce unnecessary attacks and improve the efficiency of attacks.
Keywords: Deep reinforcement learning; Adversarial attack; Targeted attack; Deep learning security; Machine learning

Curtis Rookard, Anahita Khojandi,
RRIoT: Recurrent reinforcement learning for cyber threat detection on IoT devices,
Computers & Security,
Volume 140,
2024,
103786,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103786.
(https://www.sciencedirect.com/science/article/pii/S0167404824000877)
Abstract: To address the recent worldwide proliferation of cybersecurity attacks across computing systems, especially internet-of-things devices, new robust and automated methods are needed to detect and mitigate the attacks in real time, ensuring the confidentiality, integrity, and availability of systems. Machine Learning (ML) techniques have shown promise in detecting some types of attacks. However, they are not universally successful in detecting sequential attacks. In this study, we propose RRIoT, to mitigate this issue. RRIoT applies a Deep Deterministic Policy Gradient reinforcement learning (RL) algorithm in conjunction with an LSTM layer within an adversarial environment to detect and identify attacks. We evaluate our method against novel and state-of-the-art ML/RL algorithms which build upon previous RL algorithms such as deep Q-networks (DQN), dueling deep Q-networks (DDQN), and deep deterministic policy gradient (DDPG). Our results indicate that our proposed RRIoT generally performs better than existing ML algorithms and performs as well as or better than novel RL algorithms with new network architectures. We leverage Shapley Additive Global Importance (SAGE) to provide additional insight into which features contribute most to a model's performance and verify feature importance through the implementation of an ablation study across three IoT telemetry datasets.
Keywords: Reinforcement learning; Internet-of-things; Q-learning; Deep-Q-network; Dueling deep-Q-network; Deep deterministic policy gradient; Intrusion detection system

Yinwei Wu, Meijin Li, Qi Zeng, Tao Yang, Junfeng Wang, Zhiyang Fang, Luyu Cheng,
DroidRL: Feature selection for android malware detection with reinforcement learning,
Computers & Security,
Volume 128,
2023,
103126,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103126.
(https://www.sciencedirect.com/science/article/pii/S0167404823000366)
Abstract: Due to the completely open-source nature of Android, the exploitable vulnerability of malware attacks is increasing. Machine learning, leading to a great evolution in Android malware detection in recent years, is typically applied in the classification phase. Since the correlation between features is ignored in some traditional ranking-based feature selection algorithms, applying wrapper-based feature selection models is a topic worth investigating. Though considering the correlation between features,  wrapper-based approaches are time-consuming for exploring all possible valid feature subsets when processing a large number of Android features. To reduce the computational expense of wrapper-based feature selection, a framework named DroidRL is proposed. The framework deploys DDQN algorithm to obtain a subset of features which can be used for effective malware classification. To select a valid subset of features over a larger range, the exploration-exploitation policy is applied in the model training phase. The recurrent neural network (RNN) is used as the decision network of DDQN to give the framework the ability to sequentially select features. Word embedding is applied for feature representation to enhance the framework’s ability to find the semantic relevance of features. The framework’s feature selection exhibits high performance without any human intervention and can be ported to other feature selection tasks with minor changes. The experiment results show a significant effect when using the Random Forest as DroidRL’s classifier, which reaches 95.6% accuracy with only 24 features selected.
Keywords: Reinforcement learning; Android malware detection; Feature selection; RNN; Sequence processing

Zuohui Chen, Renxuan Wang, Jingyang Xiang, Yue Yu, Xin Xia, Shouling Ji, Qi Xuan, Xiaoniu Yang,
GGT: Graph-guided testing for adversarial sample detection of deep neural network,
Computers & Security,
Volume 140,
2024,
103710,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103710.
(https://www.sciencedirect.com/science/article/pii/S0167404824000117)
Abstract: Deep Neural Networks (DNN) are known to be vulnerable to adversarial samples, the detection of which is crucial for the wide application of these DNN models. While existing methods have utilized differences between clean and adversarial samples to expose these perturbations, most are limited to a single model, rendering them vulnerable to adaptive attacks. To address the problem, we propose Graph-Guided Testing (GGT), a multiple-model-based detection algorithm that generates diverse models guided by graph characteristics. GGT identifies adversarial samples by their instability on the multi-model decision boundaries. GGT is highly efficient, with the generated model requiring only about 5% of the floating-point operations of the original model. Our experiments demonstrate that GGT outperforms state-of-the-art methods against adaptive attacks. We release our code at https://github.com/implicitDeclaration/graph-guided-testing.
Keywords: Adversarial samples detection; Graph structure; Adversarial attack; Model pruning

Yuanhai Fan, Chuanhao Wan, Cai Fu, Lansheng Han, Hao Xu,
VDoTR: Vulnerability detection based on tensor representation of comprehensive code graphs,
Computers & Security,
Volume 130,
2023,
103247,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103247.
(https://www.sciencedirect.com/science/article/pii/S0167404823001578)
Abstract: Code vulnerability detection has long been a critical issue due to its potential threat to computer systems. It is imperative to detect source code vulnerabilities in software and remediate them to avoid cyber attacks. To automate detection and reduce labor costs, many deep learning-based methods have been proposed. However, these approaches have been found to be either ineffective in detecting multiple classes of vulnerabilities or limited by treating original source code as a natural language sequence without exploiting the structural information of code. In this paper, we propose VDoTR, a model that leverages a new tensor representation of comprehensive code graphs, including AST, CFG, DFG, and NCS, to detect multiple types of vulnerabilities. Firstly, a tensor structure is introduced to represent the structured information of code, which deeply captures code features. Secondly, a new Circle Gated Graph Neural Network (CircleGGNN) is designed based on tensor for hidden state embedding of nodes. CircleGGNN can perform heterogeneous graph information fusion more directly and effectively. Lastly, a 1-D convolution-based output layer is applied to hidden embedding features for classification. The experimental results demonstrate that the detection performance of VDoTR is superior to other approaches with higher accuracy, precision, recall, and F1-measure on multiple datasets for vulnerability detection. Moreover, we illustrate which code graph contributes the most to the performance of VDoTR and which code graph is more sensitive to represent vulnerability features for different types of vulnerabilities through ablation experiments.
Keywords: Source code vulnerability detection; Tensor-based feature; GGNN; Code graphs; Heterogeneous information fusion

Hongyu Sun, Guoliang Ou, Ziqiu Zheng, Lei Liao, He Wang, Yuqing Zhang,
Inconsistent measurement and incorrect detection of software names in security vulnerability reports,
Computers & Security,
Volume 135,
2023,
103477,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103477.
(https://www.sciencedirect.com/science/article/pii/S0167404823003875)
Abstract: As the number of vulnerability databases established by various nations continues to grow, they have accumulated hundreds of thousands of security vulnerability reports, which play a crucial role in protecting system security. However, many databases are found to lack essential information, contain inaccuracies, or are inconsistent with others. Despite these challenges, the importance of vulnerability databases continues to grow. Current research on vulnerability databases is limited to software version and vulnerability reproduction, but the software names, an essential component of vulnerability databases, have not been extensively studied. Understanding the consistency of software names in different vulnerability databases is crucial for improving the accuracy of vulnerability databases. The paper introduces VERNIER, an automated method for measuring inconsistencies in 789,954 sets of software names from nine security vulnerability databases (including CVE and NVD) from 1999 to 2019. We utilized a named entity recognition (NER) model with exceptional accuracy (99.5%) and F1 score (95.1%) to extract software names from unstructured Chinese and English vulnerability reports. VERNIER assesses software names' inconsistency at character and semantic levels. The results indicate that inconsistent software names are prevalent in vulnerability databases. The average of the exact matching rate between NVD and other mainstream databases, such as CVE, is only 20.3% at the character-level and 43.3% at the semantic-level. We also discover internal inconsistencies between the structured and unstructured software names inside the same vulnerability database (e.g., NVD). To mitigate the inconsistency, we implement an alert tool using inconsistencies to detect incorrect software names. This tool can effectively warn and correct software names.
Keywords: Inconsistency measurement; NER; Software name; Vulnerability databases; Artificial intelligence

Soroush M. Sohi, Jean-Pierre Seifert, Fatemeh Ganji,
RNNIDS: Enhancing network intrusion detection systems through deep learning,
Computers & Security,
Volume 102,
2021,
102151,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2020.102151.
(https://www.sciencedirect.com/science/article/pii/S0167404820304247)
Abstract: Security of information passing through the Internet is threatened by today’s most advanced malware ranging from orchestrated botnets to simpler polymorphic worms. These threats, as examples of zero-day attacks, are able to change their behavior several times in the early phases of their existence to bypass the network intrusion detection systems (NIDS). In fact, even well-designed, and frequently-updated signature-based NIDS cannot detect the zero-day treats due to the lack of an adequate signature database, adaptive to intelligent attacks on the Internet. More importantly, having an NIDS, it should be tested on malicious traffic dataset that not only represents known attacks, but also can to some extent reflect the characteristics of unknown, zero-day attacks. Generating such traffic is identified in the literature as one of the main obstacles for evaluating the effectiveness of NIDS. To address these issues, we introduce RNNIDS that applies Recurrent Neural Networks (RNNs) to find complex patterns in attacks and generate similar ones. In this regard, for the first time, we demonstrate that RNNs are helpful to generate new, unseen mutants of attacks as well as synthetic signatures from the most advanced malware to improve the intrusion detection rate. Besides, to further enhance the design of an NIDS, RNNs can be employed to generate malicious datasets containing, e.g., unseen mutants of a malware. To evaluate the feasibility of our approaches, we conduct extensive experiments by incorporating publicly available datasets, where we show a considerable improvement in the detection rate of an off-the-shelf NIDS (up to 16.67%).
Keywords: Network security; Network intrusion detection systems; Worm mutants; Dataset generation; Deep learning; Recurrent neural networks

Xinwei Yuan, Shu Han, Wei Huang, Hongliang Ye, Xianglong Kong, Fan Zhang,
A simple framework to enhance the adversarial robustness of deep learning-based intrusion detection system,
Computers & Security,
Volume 137,
2024,
103644,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103644.
(https://www.sciencedirect.com/science/article/pii/S0167404823005539)
Abstract: Deep learning based intrusion detection systems (DL-based IDS) have emerged as one of the best choices for providing security solutions against various network intrusion attacks. However, due to the emergence and development of adversarial deep learning technologies, it becomes challenging for the adoption of DL models into IDS. In this paper, we propose a novel IDS architecture that can enhance the robustness of IDS against adversarial attacks by combining conventional machine learning (ML) models and Deep Learning models. The proposed DLL-IDS consists of three components: DL-based IDS, adversarial example (AE) detector, and ML-based IDS. We first develop a novel AE detector based on the local intrinsic dimensionality (LID). Then, we exploit the low attack transferability between DL models and ML models to find a robust ML model that can assist us in determining the maliciousness of AEs. If the input traffic is detected as an AE, the ML-based IDS will predict the maliciousness of input traffic, otherwise the DL-based IDS will work for the prediction. The fusion mechanism can leverage the high prediction accuracy of DL models and low attack transferability between DL models and ML models to improve the robustness of the whole system. In our experiments, we observe a significant improvement in the prediction performance of the IDS when subjected to adversarial attack, achieving high accuracy with low resource consumption.
Keywords: Intrusion detection system; Adversarial example; Adversarial detection; Adversarial defense; Deep learning; Machine learning; Classification algorithm

Chaofei Li, Ziyuan Zhu, Ruicheng Niu, Yuting Zhao,
Enhancing adversarial robustness for deep metric learning via neural discrete adversarial training,
Computers & Security,
2024,
103899,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103899.
(https://www.sciencedirect.com/science/article/pii/S0167404824002013)
Abstract: Due to the security concerns arising from adversarial vulnerability in deep metric learning models, it is essential to enhance their adversarial robustness for secure neural network software development. Existing defense strategies utilize adversarial triplets to enhance adversarial robustness but sacrifice benign performance. This paper proposes a novel framework for enhancing adversarial robustness and maintaining benign performance by introducing the concept of Neural Discrete Adversarial Training (NDAT) for deep metric learning. NDAT employs VQGAN to transform the adversarial triplets into discrete inputs and then minimizes metric loss function on discrete adversarial triplets. NDAT aligns discrete adversarial examples more closely with clean samples, significantly reducing distribution deviation from their clean counterparts. Moreover, the visual explanations reveal that NDAT maintains consistent attention maps between benign and adversarial triplets and concentrates on structure details and object location perturbations. To demonstrate the effectiveness of our approach, we combine NDAT with popular adversarial methods under various perturbation iterations and intensities. Experiment evaluations on three benchmark databases illustrate that our proposed framework for deep metric learning significantly outperforms state-of-the-art defense approaches in terms of both adversarial robustness and benign performance.
Keywords: Deep metric learning; Neural discrete learning; Adversarial security

Katarzyna Filus, Joanna Domańska,
Software vulnerabilities in TensorFlow-based deep learning applications,
Computers & Security,
Volume 124,
2023,
102948,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.102948.
(https://www.sciencedirect.com/science/article/pii/S0167404822003406)
Abstract: Usage of Deep Learning (DL) methods is ubiquitous. It is common in the DL/Artificial Intelligence domain to use 3rd party software. TensorFlow is one of the most popular Machine Learning (ML) platforms. Every software product is a subject to security failures which often result from software vulnerabilities. In this paper, we focus on threats related to 6 common types of threats in TensorFlow implementation. We identify them using Common Weakness Enumeration. We analyze more than 100 vulnerability instances. We focus on vulnerabilities’ severity, impact on confidentiality, integrity and availability, as well as possible results of exploitation. We also use Orthogonal Defect Classification (ODC). The results show that a majority of vulnerabilities are caused by missing/incorrect checking statements, however some fixes require more advanced algorithmic changes. Static Analysis Tools tested in our study show low effectiveness in detecting known vulnerabilities in TensorFlow, but we provide some recommendations based on the obtained alerts to improve overall code quality. Further analysis of vulnerabilities helped us to understand and characterize different vulnerability types and provide a set of observations. We believe that these observations can be useful for the creators of new static analysis tools as a source of inspiration and to build the test cases. We also aim to draw the programmers’ attention to the prevalence of vulnerabilities in deep learning applications and a low effectiveness of automatic tools to find software vulnerabilities in such products.
Keywords: Software vulnerability; TensorFlow; Deep learning; Security; Static analysis

Rajasekhar Chaganti, Vinayakumar Ravi, Tuan D. Pham,
Deep learning based cross architecture internet of things malware detection and classification,
Computers & Security,
Volume 120,
2022,
102779,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.102779.
(https://www.sciencedirect.com/science/article/pii/S0167404822001742)
Abstract: The number of publicly exposed Internet of Things (IoT) devices has been increasing, as more number of these devices connected to the internet with default settings. The devices accessed with default credentials are getting compromised with brute force attempts or the vulnerable devices are compromised with exploits to install the malware and perform malicious activity like initiating denial of service (DoS) attacks. The malware detection and classification in IoT paradigm is still considered a problem, as the adversary consistently create new variants of IoT malware and actively look for compromising the victim devices. In this paper, we proposed a Deep Learning (DL) based Bidirectional-Gated Recurrent Unit-Convolutional Neural Network (Bi-GRU-CNN) model to detect the IoT malware and classify the IoT malware families using Executable and Linkable Format (ELF, formerly named Extensible Linking Format) binary file byte sequences as an input feature. In addition, Recurrent Neural Network (RNN) based DL model combinations are considered to evaluate the performances of the IoT malware detection and family classification and also those models performance is compared with the proposed method. Our performance evaluation shows that our proposed approach obtained 100% accuracy for IoT malware detection case and 98% for IoT malware family classification. Further evaluation of our proposed model with only byte sequence as an input feature exhibit similar performance as the byte sequence and CPU types as an input features and showed that our model is robust and platform independent to detect and classify the IoT malware.
Keywords: IoT Malware; Deep learning; Recurrent neural network; Gated recurrent unit; Convolution neural network; Byte sequences; Internet of things; Malware classification

Hongyu Pan, Yong Fang, Wenbo Guo, Yijia Xu, Changhui Wang,
Few-shot graph classification on cross-site scripting attacks detection,
Computers & Security,
Volume 140,
2024,
103749,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103749.
(https://www.sciencedirect.com/science/article/pii/S0167404824000506)
Abstract: Cross-site scripting (XSS) payloads are an important part of XSS attacks, which contain malicious code and are injected into Web pages. There have been many research results based on machine learning and deep learning for the detection of XSS attacks. However, the current widely used datasets suffer from a serious data imbalance in the field of XSS attack detection, with a very limited number of samples for most XSS payload categories. Unfortunately, this problem has been overlooked in existing research. Although existing methods generally show high detection performance, they have been experimentally proven to have poor detection and generalization performance for some XSS payload categories. However, since such samples have a sparse number, their classification errors do not significantly affect the overall performance. To solve this problem, a few-shot graph classification method FSXSS applicable to XSS attacks detection is proposed. FSXSS reduces obfuscated malicious code by anti-obfuscation means such as circular decoding and code stitching, and then transforms the sample data into homomorphic graphs using contextual relationships and external word embeddings. These homomorphic graphs are used as input to obtain a vector representation of the graph through graph representation learning, and then the classifier classifies the samples by computing the similarity between them and the prototype. In addition, since there is no publicly available dataset for the few-shot XSS attack detection problem, we processed and labeled the data from the XSSED project to create the dataset FSXSSED. Experiments proved that FSXSS has excellent capabilities for the few-shot XSS attack detection problem.
Keywords: Cross-site scripting attacks; Detection; Few shot learning; Graph neural networks; Prototypical networks

Weina Niu, Jie Zhou, Yibin Zhao, Xiaosong Zhang, Yujie Peng, Cheng Huang,
Uncovering APT malware traffic using deep learning combined with time sequence and association analysis,
Computers & Security,
Volume 120,
2022,
102809,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.102809.
(https://www.sciencedirect.com/science/article/pii/S0167404822002036)
Abstract: Traditional malware detection methods based on static traffic characteristics and machine learning are hard to cope with the increasing number of APT malware variants. In order to alleviate this problem, this paper proposes a deep-learning-based malware classification approach that combines time sequence features and association rules features. This method uses the improved LSTM neural network structure named RESNET_LSTM and PARALLEL_LSTM to extract time sequence features of different protocol traffic. It also utilizes association analysis to generate quantitative rule features. Finally, we connect the time sequence feature vector and the quantization rule vector as input to deep learning models to detect malware traffic. We evaluated our proposed approach on a dataset consisting of malicious traffic generated by 57 types of malware and normal traffic. The experimental results demonstrate that the loss decline rate of PARALLEL_LSTM structure during the training phase is faster than that of the LSTM and RESNET_LSTM structures. When the RESNET_LSTM structure is used, the prediction accuracy is close to 100%, which is slightly higher than the other two structures. The accuracy of the detection methods proposed in this paper are all above 96%, while the accuracy of malware detection methods combined with static traffic characteristics and machine learning is about 85%.
Keywords: APT Malware; Deep learning; Association analysis; PARALLEL_Lstm; RSENET_Lstm

Ali Muzaffar, Hani Ragab Hassen, Michael A. Lones, Hind Zantout,
An in-depth review of machine learning based Android malware detection,
Computers & Security,
Volume 121,
2022,
102833,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.102833.
(https://www.sciencedirect.com/science/article/pii/S0167404822002279)
Abstract: It is estimated that around 70% of mobile phone users have an Android device. Due to this popularity, the Android operating system attracts a lot of malware attacks. The sensitive nature of data present on smartphones means that it is important to protect against these attacks. Classic signature-based detection techniques fall short when they come up against a large number of users and applications. Machine learning, on the other hand, appears to work well, and also helps in identifying zero-day attacks, since it does not require an existing database of malicious signatures. In this paper, we critically review past works that have used machine learning to detect Android malware. The review covers supervised, unsupervised, deep learning and online learning approaches, and organises them according to whether they use static, dynamic or hybrid features.
Keywords: Malware detection; Android security; Static malware analysis; Dynamic malware analysis; Machine learning

Nimish Mishra, SK Hafizul Islam, Sherali Zeadally,
A survey on security and cryptographic perspective of Industrial-Internet-of-Things,
Internet of Things,
Volume 25,
2024,
101037,
ISSN 2542-6605,
https://doi.org/10.1016/j.iot.2023.101037.
(https://www.sciencedirect.com/science/article/pii/S2542660523003608)
Abstract: The Industrial-Internet-of-Things (IIoT) powers several applications in the modern world: smart city, smart grid, smart manufacturing, smart logistics management, etc. The increased connectivity and smartness bring a rich attack surface for adversaries. Past research efforts have extensively explored the security aspects of IIoT. Still, none of them took a cryptographic perspective of IIoT security, which is imperative because almost all modern cyber defenses are based on cryptographic primitives. We address this issue in this work. We present a cryptographic perspective of IIoT for the designers and developers. We review the desirable security properties and existing attacks against the IIoT infrastructure. We then review conventional cryptographic tools used to secure modern IIoT networks. Finally, we discuss shortcomings associated with traditional cryptography and recommend Post-Quantum Cryptography (PQC) techniques that could be integrated with IIoT. Finally, we present future research directions on using cryptography for IIoT environments.
Keywords: Authentication; Access control; Industrial-Internet-Of-Things (IIoT); Post-quantum cryptography (PQC); Security

Prudence Kadebu, Sunil Sikka, Rajesh Kumar Tyagi, Panashe Chiurunge,
A classification approach for software requirements towards maintainable security,
Scientific African,
Volume 19,
2023,
e01496,
ISSN 2468-2276,
https://doi.org/10.1016/j.sciaf.2022.e01496.
(https://www.sciencedirect.com/science/article/pii/S2468227622004008)
Abstract: As trends continue to move toward the introduction of intelligent methods to automate software engineering processes, security requirements classification is rapidly turning into a highly potent field for the software engineering community. There are several models for classifying security requirements proposed in the literature. However, their adoption and use is constrained by the absence of substantial datasets to allow for the replication and generalization of studies, using more advanced machine-learning techniques. Furthermore, most researchers in this area, consider Maintainability as purely a non-functional requirement with no relation to security. This has been identified to be a major source of security concerns. The main objective of this study is to propose a software requirements classification approach that considers maintainability as a security requirement. This seeks to ensure that maintenance efforts don't lead to new software vulnerabilities that were previously not present during deployment. A mixed research methodology is adopted as qualitative data is collected from students’ project documentation, labelled, and transformed into quantitative form during analysis. As a culmination of this process, a validated original publicly accessible, labelled software requirements dataset of student software project requirements (DOSSPRE) is obtained and presented to support the approach. It contains 1317 software requirements, including security requirements, functional requirements, and other non-functional requirements. Two versions of the dataset are presented: one for binary classification of security requirements vs. non-security requirements and the other for multi-class classification tasks with various more granular security requirements vs. non-security requirements. In both instances, well-known machine learning algorithms are used to verify the dataset. Support Vector Machine (SVM) and Logistic Regression were the top performers in multi-class classification with an average Accuracy of 86% in both cases. Multinomial Nave Bayes topped the other machine learning techniques in binary classification with 91% Precision, 69% Recall, 78% F1-Score, and Accuracy of 86%. The dataset is accessible on this link https://data.mendeley.com/datasets/23xtbvk6yp/1
Keywords: Security Requirements classification; Machine Learning; Maintainable Security; Software Requirements Datasets

Jin Wang, Hui Xiao, Shuwen Zhong, Yinhao Xiao,
DeepVulSeeker: A novel vulnerability identification framework via code graph structure and pre-training mechanism,
Future Generation Computer Systems,
Volume 148,
2023,
Pages 15-26,
ISSN 0167-739X,
https://doi.org/10.1016/j.future.2023.05.016.
(https://www.sciencedirect.com/science/article/pii/S0167739X23001978)
Abstract: Software vulnerabilities can pose severe harms to a computing system. They can lead to system crash, privacy leakage, or even physical damage. Correctly identifying vulnerabilities among enormous software codes in a timely manner is so far the essential prerequisite to patch them. Unfortunately, the current vulnerability identification methods, either the classic ones or the deep-learning-based ones, have several critical drawbacks, making them unable to meet the present-day demands put forward by the software industry. To overcome the drawbacks, in this paper, we propose DeepVulSeeker, a novel fully automated vulnerability identification framework, which leverages both code graph structures and the semantic features with the help of the recently advanced Graph Representation Self-Attention and pre-training mechanisms. Our experiments show that DeepVulSeeker not only reaches an accuracy as high as 0.99 on traditional CWE datasets, but also outperforms all other existing methods on two highly-complicated datasets. We also testified DeepVulSeeker based on three case studies, and found that DeepVulSeeker is able to understand the implications of the vulnerabilities. We have fully implemented DeepVulSeeker and open-sourced it for future follow-up research.
Keywords: Vulnerability identification; Software security; Neural network; Pre-training; Vulnerability pattern; Code feature

N.A. Bhaskaran, M. Durairaj,
Highlighting bugs in software development codes using SDPET for enhancing security,
Measurement: Sensors,
Volume 30,
2023,
100930,
ISSN 2665-9174,
https://doi.org/10.1016/j.measen.2023.100930.
(https://www.sciencedirect.com/science/article/pii/S2665917423002660)
Abstract: The requirement for high-quality, inexpensive software that can be maintained is being driven by the rise in demand for automated online software systems. Early defect identification in SDLCs (Software Development Life Cycles) results in early adjustments and eventually on-time delivery of maintainable software, satisfying the client and fostering his trust in the development team. Many MLTs (Machine Learning Techniques) have been put out in the last ten years to increase SDP accuracy. Most of the suggested SDPs frameworks and models employ ANNs (Artificial Neural Networks), which are a popular MLTs. Software defect data are hampered by a number of problems, including duplication, correlation, feature relevance, and missing samples. However, because to the under/over fitting issues, most existing SDPs utilising ANNs have low accuracy. SDPET (Software Defect Predictions Ensemble Technique), an ensemble learning technique to produce accurate SDPs based on the AdaBoost algorithm, is proposed. The proposed schema's efficacy against RFs (Random Forests) and GBs(Gradient Boosts) for needed values through experiments. The experiment results verify that the suggested SDPET has good accuracy in training and better accuracy in test datasets when compared with other methods. The original obtained dataset was cleaned of unnecessary features, converted to csv, and is stored as dataset. csv.
Keywords: SDPs; Software; Defect predictions; Software bugs; Ensemble learning; Ada boost; Classification; Machine learning; Software metrics

Rama Ranjan Panda, Naresh Kumar Nagwani,
Classification and intuitionistic fuzzy set based software bug triaging techniques,
Journal of King Saud University - Computer and Information Sciences,
Volume 34, Issue 8, Part B,
2022,
Pages 6303-6323,
ISSN 1319-1578,
https://doi.org/10.1016/j.jksuci.2022.01.020.
(https://www.sciencedirect.com/science/article/pii/S1319157822000337)
Abstract: Software development is a modular approach involving multiple developers and multi-tasking teams working at different locations. A particular term in a software bug can belong to multiple modules and multiple developers’ profiles. Also, many people who report software bugs are unfamiliar with the exact technical terminology of software development, which causes the software bug to be unlabeled, vague, and noisy. Hence, analyzing, understanding, and assigning the newly reported bugs to the most appropriate developer is a challenging task for the triager. Intuitionistic Fuzzy Sets (IFS) consider the non-membership and hesitant values along with the membership values of the software bug terms mapped to the developers and thus provide a powerful tool for better analysis in cases where the same term can belong to multiple categories. Two IFS similarity measure-based techniques, namely, the Intuitionistic Fuzzy Similarity Model for Developer Term Relation (IFSDTR) and the Intuitionistic Fuzzy Similarity Model for Developer Category Relation (IFSDCR), are proposed in this work. In IFSDTR, a developer-term vocabulary is constructed based on the previous bug-fixing experience of software developers by considering the most frequent terms in the IFS representation of bugs they fixed earlier. In IFSDCR, software bugs are categorized into multiple categories and a developer-category relation is constructed. When a new bug is reported, the IFS similarity measure is calculated with the developer-term and developer-category relationship, and a fuzzy α-cut is applied to find a group of expert developers to fix it. The proposed techniques are evaluated on the available data set and compared with existing approaches to bug triaging. On the Eclipse, Mozilla, and NetBeans data sets, the IFSDTR techniques yield an accuracy of 0.90, 0.89, and 0.87, respectively, whereas the IFSDCR yields a greater accuracy of 0.93, 0.90, and 0.88 for the Eclipse, Mozilla, and NetBeans data sets, respectively. Similarly, in all other performance measures, the proposed approaches outperform the state-of-the-art approaches.
Keywords: Bug Triaging; Fuzzy Modeling; Software Bug Repository; Intuitionistic Fuzzy Similarity; Term Weighting Technique; Expert Identification

Yu Qu, Jianlei Chi, Heng Yin,
Leveraging developer information for efficient effort-aware bug prediction,
Information and Software Technology,
Volume 137,
2021,
106605,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2021.106605.
(https://www.sciencedirect.com/science/article/pii/S0950584921000823)
Abstract: Context:
Software bug prediction techniques can provide informative guidance in software engineering practices. Over the past 15 years, developer information has been intensively used in bug prediction as features or basic data source to construct other useful models.
Objective:
Further leverage developer information from a new and straightforward perspective to improve effort-aware bug prediction.
Methods:
We propose to investigate the direct relations between the number of developers and the probability for a file to be buggy. Based on an empirical study on nine open-source Java systems with 32 versions, we observe a widely-existed and interesting tendency: when there are more developers working on a source file, there will be a stronger possibility for this file to be buggy. Based on the observed tendency, we propose an unsupervised algorithm and a supervised equation both called top-dev to improve effort-aware bug prediction. The key idea is to prioritize the ranking of files, whose number of developers is large, in the suspicious file list generated by effort-aware models.
Results:
Experimental results show that the proposed top-dev algorithm and equation significantly outperform the unsupervised and supervised baseline models (ManualUp, Rad, Rdd, Ree, CBS+, and top-core). Moreover, the unsupervised top-dev algorithm is comparable or superior to existing supervised baseline models.
Conclusion:
The proposed approaches are very useful in effort-aware bug prediction practices. Practitioners can use the top-dev algorithm to generate a high-quality and informative suspicious file list without training complex machine learning classifiers. On the other hand, when building supervised bug prediction model, the best practice is to combine existing models with the top-dev equation.
Keywords: Software bug prediction; Defect prediction; Effort-aware bug prediction; Developer information; Unsupervised model; Empirical study

Navdeep S. Chahal, Preeti Bali, Praveen Kumar Khosla,
A Proactive Approach to assess web application security through the integration of security tools in a Security Orchestration Platform,
Computers & Security,
Volume 122,
2022,
102886,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.102886.
(https://www.sciencedirect.com/science/article/pii/S0167404822002802)
Abstract: The increasing number of attacks leads to a growing research and development interest in cybersecurity systems. As a response to the increasingly distributed nature of attacks, many organizations have demonstrated willingness to exchange information concerning threats, incidents, and mitigation strategies with security detection tools and techniques. Various security detection techniques such as signature recognition, anomaly detection, etc fail to completely detect complicated attacks. The current situation can be dealt with as a significant tool that helps auditors and administrators to manage and identify distributed threats. In this paper, a novel social spider communicating behavior-based swarm intelligent open-source Orchestrated Continuous Vulnerability Assessment (OCVA) scanning tool is proposed. The proposed OCVA tool addresses the requirement of orchestration of continuous vulnerability assessment of all automated cybersecurity detection processes. It scans, monitors, visualizes, analyzes, mitigates, and remediates the vulnerabilities of the network, assets, and web applications. It helps the developers and security auditors overcome challenges by providing the desired visualizations and analytics of the vulnerable assets. Two case studies are conducted on the basis of the algorithmic comparative analysis with BRICK, Fuzzing, ACO, PSO and GA based vulnerability scanners along with the tool based comparative evaluation with W3af, ZAP, Wapiti, and Arachni in terms of vulnerability detection rate, accuracy, false positive rate, true positive rate and consistency. The results indicate that the proposed OCVA tool outperforms in terms of accuracy, vulnerability remediation rate, and consistency in both.
Keywords: Application security; vulnerability scanning tool; Security Information and Event Management; threats; mitigation; vulnerability detection

Sadiq Almuairfi, Mamdouh Alenezi,
Security controls in infrastructure as code,
Computer Fraud & Security,
Volume 2020, Issue 10,
2020,
Pages 13-19,
ISSN 1361-3723,
https://doi.org/10.1016/S1361-3723(20)30109-3.
(https://www.sciencedirect.com/science/article/pii/S1361372320301093)
Abstract: The development, deployment and management of software applications have shifted dramatically in the past 10 years. This fundamental shift is what we now know as development operations (DevOps). Infrastructure as Code (IaC) is one of the main tenets of DevOps. Previously, manual configuration via cloud providers’ UI consoles and physical hardware used to take place. But now, with the concept of IaC, the IT infrastructure can be automated by using blueprints that are easily readable by machines.

Jaechang Nam, Song Wang, Yuan Xi, Lin Tan,
A bug finder refined by a large set of open-source projects,
Information and Software Technology,
Volume 112,
2019,
Pages 164-175,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2019.04.014.
(https://www.sciencedirect.com/science/article/pii/S0950584919300977)
Abstract: Context
Static bug detection techniques are commonly used to automatically detect software bugs. The biggest obstacle to the wider adoption of static bug detection tools is false positives, i.e., reported bugs that developers do not have to act on.
Objective
The objective of this study is to reduce false positives resulting from static bug detection tools and to detect new bugs by exploring the effectiveness of a feedback-based bug detection rule design.
Method
We explored a large number of software projects and applied an iterative feedback-based process to design bug detection rules. The outcome of the process is a set of ten bug detection rules, which we used to build a feedback-based bug finder, FeeFin. Specifically, we manually examined 1622 patches to identify bugs and fix patterns, and implement bug detection rules. Then, we refined the rules by repeatedly using feedback from a large number of software projects.
Results
We applied FeeFin to the latest versions of the 1880 projects on GitHub to detect previously unknown bugs. FeeFin detected 98 new bugs, 63 of which have been reviewed by developers: 57 were confirmed as true bugs, and 9 were confirmed as false positives. In addition, we investigated the benefits of our FeeFin process in terms of new and improved bug patterns. We verified our bug patterns with four existing tools, namely PMD, FindBugs, Facebook Infer, and Google Error Prone, and found that our FeeFin process has the potential to identify new bug patterns and also to improve existing bug patterns.
Conclusion
Based on the results, we suggest that static bug detection tool designers identify new bug patterns by mining real-world patches from a large number of software projects. In addition, the FeeFin process is helpful in mitigating false positives generated from existing tools by refining their bug detection rules.
Keywords: Static bug finder; bug detection rules; bug patterns

Hongsong Chen, Xietian Luo, Lei Shi, Yongrui Cao, Yongpeng Zhang,
Security challenges and defense approaches for blockchain-based services from a full-stack architecture perspective,
Blockchain: Research and Applications,
Volume 4, Issue 3,
2023,
100135,
ISSN 2096-7209,
https://doi.org/10.1016/j.bcra.2023.100135.
(https://www.sciencedirect.com/science/article/pii/S2096720923000106)
Abstract: As an advantageous technique and service, the blockchain has shown great development and application prospects. However, its security has also met great challenges, and many security vulnerabilities and attack issues in blockchain-based services have emerged. Recently, security issues of blockchain have attracted extensive attention. However, there is still a lack of blockchain security research from a full-stack architecture perspective, as well as representative quantitative experimental reproduction and analysis. We aim to provide a security architecture to solve security risks in blockchain services from a full-stack architecture perspective. Meanwhile, we propose a formal definition of the full-stack security architecture for blockchain-based services, and we also propose a formal expression of security issues and defense solutions from a full-stack security perspective. We use ConCert to conduct a smart contract formal verification experiment by property-based testing. The security vulnerabilities of blockchain services in the Common Vulnerabilities and Exposures (CVE) and China Nation Vulnerability Database (CNVD) are selected and enumerated. Additionally, three real contract-layer real attack events are reproduced by an experimental approach. Using Alibaba's blockchain services and Identity Mixer in Hyperledger Fabric as a case study, the security problems and defense techniques are analyzed and researched. At last, the future research directions are proposed.
Keywords: Security and privacy; Blockchain-based services; Full stack; Architecture perspective; Case and experimental study; Formal verification

Nadia Medeiros, Naghmeh Ivaki, Pedro Costa, Marco Vieira,
Trustworthiness models to categorize and prioritize code for security improvement,
Journal of Systems and Software,
Volume 198,
2023,
111621,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111621.
(https://www.sciencedirect.com/science/article/pii/S016412122300016X)
Abstract: The exploitation of software security vulnerabilities can have severe consequences. Thus, it is crucial to devise new processes, techniques, and tools to support teams in the development of secure code from the early stages of the software development process, while potentially reducing costs and shortening the time to market. In this paper, we propose an approach that uses security evidences (e.g., software metrics, bad smells) to feed a set of trustworthiness models, which allow characterizing code from a security perspective. In practice, the goal is to identify the code units that are more prone to be vulnerable (i.e., are less trustworthy from a security perspective), thus helping developers to improve their code. A clustering-based approach is used to categorize the code units based on the combination of the scores provided by several trustworthiness models and taking into account the criticality of the code. To instantiate our proposal, we use a dataset of software metrics (e.g., CountLine, Cyclomatic Complexity, Coupling Between Objects) for files and functions of the Linux Kernel and Mozilla Firefox projects, and a set of machine learning algorithms (i.e., Random Forest, Decision Tree, SVM Linear, SVM Radial, and Xboost) to build the trustworthiness models. Results show that code that is more prone to be vulnerable can be effectively distinguished, thus demonstrating the applicability and usefulness of the proposed approach in diverse scenarios.
Keywords: Software security; Code security review; Code categorization; Trustworthiness model; Software metrics; Machine learning

Matteo Esposito, Davide Falessi,
VALIDATE: A deep dive into vulnerability prediction datasets,
Information and Software Technology,
Volume 170,
2024,
107448,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2024.107448.
(https://www.sciencedirect.com/science/article/pii/S0950584924000533)
Abstract: Context:
Vulnerabilities are an essential issue today, as they cause economic damage to the industry and endanger our daily life by threatening critical national security infrastructures. Vulnerability prediction supports software engineers in preventing the use of vulnerabilities by malicious attackers, thus improving the security and reliability of software. Datasets are vital to vulnerability prediction studies, as machine learning models require a dataset. Dataset creation is time-consuming, error-prone, and difficult to validate.
Objectives:
This study aims to characterise the datasets of prediction studies in terms of availability and features. Moreover, to support researchers in finding and sharing datasets, we provide the first VulnerAbiLty predIction DatAseT rEpository (VALIDATE).
Methods:
We perform a systematic literature review of the datasets of vulnerability prediction studies.
Results:
Our results show that out of 50 primary studies, only 22 studies (i.e., 38%) provide a reachable dataset. Of these 22 studies, only one study provides a dataset in a stable repository.
Conclusions:
Our repository of 31 datasets, 22 reachable plus nine datasets provided by authors via email, supports researchers in finding datasets of interest, hence avoiding reinventing the wheel; this translates into less effort, more reliability, and more reproducibility in dataset creation and use.
Keywords: Security; Replicability; Vulnerability; Machine learning; Repository; Dataset

Zaher Shuraym M. Alharthi, Ravi Rastogi,
An efficient classification of secure and non-secure bug report material using machine learning method for cyber security,
Materials Today: Proceedings,
Volume 37, Part 2,
2021,
Pages 2507-2512,
ISSN 2214-7853,
https://doi.org/10.1016/j.matpr.2020.08.311.
(https://www.sciencedirect.com/science/article/pii/S2214785320361836)
Abstract: In the field of software development, the main problem is to recognize the security-oriented issues within the reported bugs due to its inacceptable rate to provide the satisfied reliability on customer and software dataset. The objective is to propose a novel machine learning approach for multiclass supervised classification named Bug Severity classification to overcome these challenges with the use of supervised Artificial Neural Network and stacking based Navies Bayes classifier. This proposed approach directly examines the latent and highly descriptive features. Primarily, using the natural language programming approaches bug report text is preprocessed. After then, N gram is employed for extracting features by overcoming data sparsity problems. Further, the supervised Artificial Neural Network extracts the salient feature patterns of the corresponding severity classes. Finally, the stacking-based Navies Bayes classifier is employed for classifying multiple bug severity classes.
Keywords: Cyber security; Machine learning; Classification; Bug report; Data sparsity

Naresh Kumar Nagwani, Jasjit S. Suri,
An artificial intelligence framework on software bug triaging, technological evolution, and future challenges: A review,
International Journal of Information Management Data Insights,
Volume 3, Issue 1,
2023,
100153,
ISSN 2667-0968,
https://doi.org/10.1016/j.jjimei.2022.100153.
(https://www.sciencedirect.com/science/article/pii/S2667096822000969)
Abstract: The timely release of defect-free software and the optimization of development costs depend on efficient software bug triaging (SBT) techniques. SBT can also help in managing the vast information available in software bug repositories. Recently, Artificial Intelligence (AI)-based emerging technologies have been utilized excessively, however, it is not clear how it is shaping the design, development, and performance in the field of SBT. It is therefore important to write this well-planned, comprehensive, and timely needed AI-based SBT review, establishing clear findings. For selecting the key studies in SBT, Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) analysis was carried out, and 123 studies were selected for the AI-based review, addressing key research questions. Further, Cochrane protocol was applied for risk-of-bias computations for selecting AI techniques. We studied the six types of software bug triaging techniques (SBTT) that were analyzed. AI has provided the possibility of automating the time-consuming manual SBT process. Our study shows that AI-based architectures, developers for newly reported bugs can be identified more accurately and quickly. Deep learning (DL)-based approaches demonstrate capabilities for developing SBT systems having improved (i) learning rate, (ii) scalability, and (iii) performance as compared to conventional approaches. For evaluating the SBT techniques, apart from the accuracy, precision, and recall, the mean average precision (mAP) is suggested to be an effective metric. In the future, more work is expected in the direction of SBT considering additional information from developer's networks, other repositories, and modern AI technologies.
Keywords: Software bug triaging; Bug assignment; Expert developer; AI; Recommender systems; Tossing graphs; Performance; and accuracy

Zhengliang Li, Zhiwei Jiang, Xiang Chen, Kaibo Cao, Qing Gu,
Laprob: A Label propagation-Based software bug localization method,
Information and Software Technology,
Volume 130,
2021,
106410,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2020.106410.
(https://www.sciencedirect.com/science/article/pii/S0950584920301713)
Abstract: Context
Bug localization, which locates suspicious snippets related to the bugs mentioned in the bug reports, is time-consuming and laborious. Many automatic bug localization methods have been proposed to speed up the process of bug fixing and reduce the burden on developers. However, these methods have not fully utilized the intra-relations and inter-relations among the bug reports and the source files (i.e., call relationships between the source files).
Objective
In this paper, we propose a novel method LaProb (a label propagation-based software bug localization method) that makes full use of the intra-relations and inter-relations among the bug reports and the source files.
Method
LaProb transforms the problem of bug localization into a multi-label distribution learning problem. LaProb first constructs a BHG (Biparty Hybrid Graph) by analyzing the structures and contents of bug reports and source files, and calculates the intra-relations between pairs of bug reports and source files, as well as the inter-relations between bug reports and source files. Based on BHG, LaProb then predicts the label distribution on source files by using the label propagation algorithm for the target bug report. Finally, LaProb finishes the bug localization task by sorting the results of label propagation.
Results
The experimental results on nine open-source software projects (i.e., SWT, AspectJ, Eclipse, ZXing, SEC, HIVE, HBASE, WFLY and ROO) show that compared with several state-of-the-art methods (including BugLocator, BRTracer, BLUiR, AmaLgam, Locus and BLIZZARD), LaProb performs the best in terms of all five metrics on average. For MAP performance measure, LaProb achieves an improvement of 30.9%, 36.6%, 28.0%, 22.2%, 20.1% and 53.5%, respectively.
Conclusion
LaProb is capable of making full use of the intra-relations and inter-relations among the bug reports and the source files and achieves better performance than seven state-of-the-art methods.
Keywords: Bug localization; Label propagation; Biparty hybrid graph; Bug report

Xiaoxue Ma, Jacky Keung, Zhen Yang, Xiao Yu, Yishu Li, Hao Zhang,
CASMS: Combining clustering with attention semantic model for identifying security bug reports,
Information and Software Technology,
Volume 147,
2022,
106906,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2022.106906.
(https://www.sciencedirect.com/science/article/pii/S0950584922000647)
Abstract: Context:
Inappropriate public disclosure of security bug reports (SBRs) is likely to attract malicious attackers to invade software systems; hence being able to detect SBRs has become increasingly important for software maintenance. Due to the class imbalance problem that the number of non-security bug reports (NSBRs) exceeds the number of SBRs, insufficient training information, and weak performance robustness, the existing techniques for identifying SBRs are still less than desirable.
Objective:
This prompted us to overcome the challenges of the most advanced SBR detection methods.
Method:
In this work, we propose the CASMS approach to efficiently alleviate the imbalance problem and predict bug reports. CASMS first converts bug reports into weighted word embeddings based on tf−idf and word2vec techniques. Unlike the previous studies selecting the NSBRs that are the most dissimilar to SBRs, CASMS then automatically finds a certain number of diverse NSBRs via the Elbow method and k-means clustering algorithm. Finally, the selected NSBRs and all SBRs train an effective Attention CNN–BLSTM model to extract contextual and sequential information.
Results:
The experimental results have shown that CASMS is superior to the three baselines (i.e., FARSEC, SMOTUNED, and LTRWES) in assessing the overall performance (g-measure) and correctly identifying SBRs (recall), with improvements of 4.09%–24.26% and 10.33%–36.24%, respectively. The best results are easily obtained under the limited ratio ranges of the two-class training set (1:1 to 3:1), with around 20 experiments for each project. By evaluating the robustness of CASMS via the standard deviation indicator, CASMS is more stable than LTRWES.
Conclusion:
Overall, CASMS can alleviate the data imbalance problem and extract more semantic information to improve performance and robustness. Therefore, CASMS is recommended as a practical approach for identifying SBRs.
Keywords: Security bug report; Clustering; Hybrid neural networks

Ashima Kukkar, Yugal Kumar, Ashutosh Sharma, Jasminder Kaur Sandhu,
Bug severity classification in software using ant colony optimization based feature weighting technique,
Expert Systems with Applications,
Volume 230,
2023,
120573,
ISSN 0957-4174,
https://doi.org/10.1016/j.eswa.2023.120573.
(https://www.sciencedirect.com/science/article/pii/S0957417423010758)
Abstract: At the present, the delivery of the software should be time-bound without affecting the quality of the software. However, bug severity can affect the timely delivery of software. It is a crucial component of the software engineering, including maintenance and testing. Both phases are essential for bug severity classification but require much time. Generally, bug triage is responsible for classifying the bugs based on criticality/severeness. The manual execution of this process is error-prone. Consequently, a model for automatic bug classification is required to help the bug triage. In this work, the ant colony optimization (ACO) based feature extraction technique is proposed to extract more relevant features for bug severity classification. Furthermore, the ACO technique is integrated with NB, SVM, DeepFM and F-SVM techniques for predicting bug severity and classifying bugs into multi-severity classes. Several benchmark projects such as Eclipse, Mozilla, OpenFOAM, JBoss, and Firefox, are considered to evaluate the efficacy of the techniques above. The simulation outcomes are expressed in terms of Accuracy, Precision, Recall, and F1-measure. It is noted that the outcomes of the SVM, NB, DeepFM and F-SVM approaches are improved by the ACO-based feature weighting technique. The accuracy rate of ACO-F-SVM, ACO-NB, ACO-SVM, ACO-DeepFM, NB, SVM, F-SVM, DeepFM techniques are ranging in between 85.73 and 89.38%, 78% to 80%, 73% to 76%, 92.67% to 97.27 %, 71% to 77%,65% to 74%, 78.21% to 81.28% and 90.02% to 95.24% respectively for five benchmark projects. Further, proposed techniques are also produced better simulation results as compared with state-of –the-art techniques. Friedman and post hoc statistical tests are also conducted on proposed techniques.
Keywords: Natural language processing; Feature weighting; Support vector machine; Ant colony optimization; Naive bayes

Mahdi Sahlabadi, Ravie Chandren Muniyandi, Zarina Shukur, Md Rezanur Islam, Morteza SaberiKamarposhti, Kangbin Yim,
LPMSAEF: Lightweight process mining-based software architecture evaluation framework for security and performance analysis,
Heliyon,
Volume 10, Issue 5,
2024,
e26969,
ISSN 2405-8440,
https://doi.org/10.1016/j.heliyon.2024.e26969.
(https://www.sciencedirect.com/science/article/pii/S2405844024030007)
Abstract: The article discusses the need for a lightweight software architecture evaluation framework that can address practitioners' concerns. Specifically, the proposed framework uses process mining and Petri nets to analyze security and performance in software development's early and late stages. Moreover, the framework has been implemented in six case studies, and the results show that it is a feasible and effective solution that can detect security and performance issues in complex and heterogeneous architecture with less time and effort. Furthermore, the article provides a detailed explanation of the framework's features, factors, and evaluation criteria. Additionally, this article discusses the challenges associated with traditional software architecture documentation methods using Unified Modeling Language diagrams and the limitations of code alone for creating comprehensive Software Architecture models. Various methods have been developed to extract implicit Software Architecture from code artifacts, but they tend to produce code-oriented diagrams instead of Software Architecture diagrams. Therefore, to bridge the model-code gap, the article proposes a framework that considers existing Software Architecture in the source code as architectural components and focuses on Software Architecture behaviors for analyzing performance and security. The proposed framework also suggests comparing Software Architecture extracted by different Process Mining algorithms to achieve consensus on architecture descriptions, using visualizations to understand differences and similarities. Finally, the article suggests that analyzing the previous version of a system's Software Architecture can lead to improvements and deviations from planned Software Architecture can be detected using traceability approaches to aid software architects in detecting inconsistencies.
Keywords: Lightweight early and late evaluation; Software architecture; Process mining; Petri nets complex and heterogeneous architecture

Guangfu Wu, HaiPing Wang, Xin Lai, Mengmeng Wang, Daojing He, Sammy Chan,
A comprehensive survey of smart contract security: State of the art and research directions,
Journal of Network and Computer Applications,
Volume 226,
2024,
103882,
ISSN 1084-8045,
https://doi.org/10.1016/j.jnca.2024.103882.
(https://www.sciencedirect.com/science/article/pii/S1084804524000596)
Abstract: Future protocols in the digital society will be built on the foundation of smart contracts, which are code and algorithmic contracts. Smart contracts enable all phases of the contracting process without the need for outside parties by using protocols and user interfaces. But as blockchain technology has quickly advanced, many security flaws in smart contracts have also come to light. This article offers a thorough examination and organized summary of the pertinent material of smart contract security analysis. These sections make up the bulk of our survey’s contributions. First, a brief history of Ethereum is provided, followed by a proposal of the security difficulties now faced by blockchain smart contracts, with a focus on the analysis and classification of various security flaws. Second, based on a thorough examination of these studies, we present a summary of various smart contract security options, including case studies and detailed descriptions of the state-of-the-art in terms of automatic auditing, subject matter experts, scalable smart contracts, smart contract templates, decompilers, semantic frameworks, and anomaly detection. Finally, we go over each sort of solution’s advantages and disadvantages and outline potential future research trajectories.
Keywords: Smart contracts; Smart contract security; Security vulnerabilities; Automated audits; Semantic frameworks; Anomaly detection

Jyoti Prakash Meher, Sourav Biswas, Rajib Mall,
Deep learning-based software bug classification,
Information and Software Technology,
Volume 166,
2024,
107350,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107350.
(https://www.sciencedirect.com/science/article/pii/S0950584923002057)
Abstract: Context:
Accurate classification of bugs can help accelerate the bug triage process, code inspection, and repair activities. In this context, many machine learning techniques have been proposed to classify bugs. The expressive power of deep learning could be used to further improve classification.
Objective:
We propose a novel deep learning-based bug classification approach.
Methods:
We first build a bug taxonomy with eight bug classes, each characterized by a set of keywords. Subsequently, we heuristically annotate a moderately large set (∼1.36M) of software bug resolution reports using an earth-mover distance technique based on the keywords. Finally, we use four attention-based classification techniques to classify these curated bugs.
Results:
Our experiments on a carefully collected dataset indicate that our proposed technique achieved a mean F1-Score of 84.78% and a mean macro-average ROC of 98.25%.
Conclusion:
Our proposed approach was observed to outperform the existing techniques by 16.88% on an average in terms of F1-Score for the considered dataset.
Keywords: Automatic classification; Bug analysis; Self attention; Transfer learning

Youshuai Tan, Sijie Xu, Zhaowei Wang, Tao Zhang, Zhou Xu, Xiapu Luo,
Bug severity prediction using question-and-answer pairs from Stack Overflow,
Journal of Systems and Software,
Volume 165,
2020,
110567,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2020.110567.
(https://www.sciencedirect.com/science/article/pii/S0164121220300480)
Abstract: Nowadays, bugs have been common in most software systems. For large-scale software projects, developers usually conduct software maintenance tasks by utilizing software artifacts (e.g., bug reports). The severity of bug reports describes the impact of the bugs and determines how quickly it needs to be fixed. Bug triagers often pay close attention to some features such as severity to determine the importance of bug reports and assign them to the correct developers. However, a large number of bug reports submitted every day increase the workload of developers who have to spend more time on fixing bugs. In this paper, we collect question-and-answer pairs from Stack Overflow and use logical regression to predict the severity of bug reports. In detail, we extract all the posts related to bug repositories from Stack Overflow and combine them with bug reports to obtain enhanced versions of bug reports. We achieve severity prediction on three popular open source projects (e,g., Mozilla, Ecplise, and GCC) with Naïve Bayesian, k-Nearest Neighbor algorithm (KNN), and Long Short-Term Memory (LSTM). The results of our experiments show that our model is more accurate than the previous studies for predicting the severity. Our approach improves by 23.03%, 21.86%, and 20.59% of the average F-measure for Mozilla, Eclipse, and GCC by comparing with the Naïve Bayesian based approach which performs the best among all baseline approaches.
Keywords: Stack overflow; Severity prediction; Logistic regression; Bug reports

Panchanan Nath, Jaya Rani Mushahary, Ujjal Roy, Maharaj Brahma, Pranav Kumar Singh,
AI and Blockchain-based source code vulnerability detection and prevention system for multiparty software development,
Computers and Electrical Engineering,
Volume 106,
2023,
108607,
ISSN 0045-7906,
https://doi.org/10.1016/j.compeleceng.2023.108607.
(https://www.sciencedirect.com/science/article/pii/S0045790623000320)
Abstract: With the growing demand for application software, there is a race among industries to develop software as quickly as possible. However, maintaining pace and ensuring bug-free software has become increasingly challenging in a work-from-home arrangement as software developers are not under constant supervision. It increases the possibility of buggy products, and traditional testing techniques fail to provide optimal performance. We propose an Artificial Intelligence (AI) and blockchain-based novel decentralized software testing system. The proposed system aims to detect and prevent vulnerable code by synergizing deep learning capabilities and smart-contract-powered blockchain. The vulnerability detection is performed automatically without relying on manually written rules. We propose a non-vulnerability score range map to classify the source code. Furthermore, we integrate an InterPlanetary File System (IPFS) to ensure efficient storage over the blockchain. We conduct a testbed-based experiment to demonstrate the effectiveness of AI and blockchain integration for secure code development and testing.
Keywords: Deep learning; Blockchain; Smart contract; IPFS; Software testing; Software development

Ashima Kukkar, Rajni Mohana, Yugal Kumar,
Does bug report summarization help in enhancing the accuracy of bug severity classification?,
Procedia Computer Science,
Volume 167,
2020,
Pages 1345-1353,
ISSN 1877-0509,
https://doi.org/10.1016/j.procs.2020.03.345.
(https://www.sciencedirect.com/science/article/pii/S1877050920308115)
Abstract: The programmer cannot write a program without any bug. A large numbers of bugs are deposited into the bug tracking system through bug reports. To find the root cause of a bug, a meaningful and huge conversation happens between the developer and reporter. The developer (triager) reads the whole bug report and then classified according to severity. The previous researchers observed that the bug report summaries provide the more resourcefully investigate information in the bug repository to the developer as part of the severity classification task. To further investigate the relationship between bug report summary and bug severity classification. A novel approach is proposed by using swarm intelligence and machine learning approaches. Firstly the n-gram technique is used to extract the semantic features score. These features are fed into the Summary Subset Selection Phase to select the optimal summary subset. The selected subset features are fed into the feature scoring phase to provide a relative score to each feature. These optimized features are used to train the proposed model. At last Naive Bayes approach is used to classify the multiclass severity classification. The results are analyzed by using 10-fold cross-validation on three benchmark datasets showed better performance in terms of Precision, Recall and F-measure. It is observed that the performance depend on the bug report contents. If the bug report has larger data for summarization than the summarization increase the classification accuracy otherwise decrease.
Keywords: Natural Language Processing; Bug Report Summarization; Unsupervised; Supervised; Particle Swarm Optimization; Ant colony Optimization; Bug Severity Classification

Christopher Theisen, Laurie Williams,
Better together: Comparing vulnerability prediction models,
Information and Software Technology,
Volume 119,
2020,
106204,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2019.106204.
(https://www.sciencedirect.com/science/article/pii/S0950584919302125)
Abstract: Context
Vulnerability Prediction Models (VPMs) are an approach for prioritizing security inspection and testing to find and fix vulnerabilities. VPMs have been created based on a variety of metrics and approaches, yet widespread adoption of VPM usage in practice has not occurred. Knowing which VPMs have strong prediction and which VPMs have low data requirements and resources usage would be useful for practitioners to match VPMs to their project’s needs. The low density of vulnerabilities compared to defects is also an obstacle for practical VPMs.
Objective
The goal of the paper is to help security practitioners and researchers choose appropriate features for vulnerability prediction through a comparison of Vulnerability Prediction Models.
Method
We performed replications of VPMs on Mozilla Firefox with 28,750 source code files featuring 271 vulnerabilities using software metrics, text mining, and crash data. We then combined features from each VPM and reran our classifiers.
Results
We improved the F-score of the best VPM (.20 to 0.28) by combining features from three types of VPMs and using Naive Bayes as the classifier. The strongest features in the combined model were the number of times a file was involved in a crash, the number of outgoing calls from a file, and the string “nullptr”.
Conclusion
Our results indicate that further work is needed to develop new features for input into classifiers. In addition, new analytic approaches for VPMs are needed for VPMs to be useful in practical situations, due to the low density of vulnerabilities in software (less than 1% for our dataset).
Keywords: Security; Vulnerabilities; Prediction model; Software engineering

Xiuting Ge, Chunrong Fang, Meiyuan Qian, Yu Ge, Mingshuang Qing,
Locality-based security bug report identification via active learning,
Information and Software Technology,
Volume 147,
2022,
106899,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2022.106899.
(https://www.sciencedirect.com/science/article/pii/S095058492200060X)
Abstract: Context:
Security bug report (SBR) identification is a crucial way to eliminate security-critical vulnerabilities during software development.
Objective:
In recent years, many approaches have utilized supervised machine learning (SML) techniques in the SBR identification. However, such approaches often require a large number of labelled bug reports, which are often hard to obtain in practice. Active learning is a potential approach to reducing the manual labelling cost while maintaining good performance. Nevertheless, the existing active learning-based SBR identification approach still yields poor performance due to ignoring the locality in bug reports.
Method:
To address the above problems, we propose locality-based SBR identification via active learning. Our approach recommends a small part of instances based on locality in bug reports, asks for their labels, and learns the SBR classifier. Specifically, our approach relies on the locality to construct the initial training set, which is designed to address how to start during active learning. Moreover, our approach applies the locality into the query process, which is designed to improve which instance should be queried next during active learning.
Result:
We conduct experiments on large-scale bug reports (nearly 125K) from six real-world projects. In comparison with three state-of-the-art SML-based and active learning-based SBR identification approaches, our approach can obtain the maximum values of F-Measure (0.8176) and AUC (0.8631). Moreover, our approach requires 16.60% to 71.40% of all bug reports when achieving the optimal performance in these six projects, which improves three approaches from 9.82% to 64.19% on average.
Conclusion:
As shown from the experimental results, our approach can be more effective and efficient to identify SBRs than the existing approaches.
Keywords: Security bug report identification; Active learning; Text mining

Manpreet Singh, Jitender Kumar Chhabra,
Improved software fault prediction using new code metrics and machine learning algorithms,
Journal of Computer Languages,
Volume 78,
2024,
101253,
ISSN 2590-1184,
https://doi.org/10.1016/j.cola.2023.101253.
(https://www.sciencedirect.com/science/article/pii/S2590118423000631)
Abstract: Many code metrics exist for bug prediction. However, these metrics are based on the trivial count of code properties and are not sufficient. This research article proposes three new code metrics based on class complexity, coupling, and cohesion to fill the gap. The Promise repository metrics suite's complexity, coupling, and cohesion metrics are replaced by the proposed metrics, and a new metric suite is generated. Experiments show that the proposed metrics suite gives more than 2 % improvement in AUC and precision and approximately 1.5 % in f1-score and recall with fewer code metrics than the existing metrics suite.
Keywords: Cohesion; Complexity; Coupling; Fault prediction; Source code metrics

Dawei Yuan, Xiaohui Wang, Yao Li, Tao Zhang,
Optimizing smart contract vulnerability detection via multi-modality code and entropy embedding,
Journal of Systems and Software,
Volume 202,
2023,
111699,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111699.
(https://www.sciencedirect.com/science/article/pii/S0164121223000948)
Abstract: Smart contracts have been widely used in the blockchain world these years, and simultaneously vulnerability detection has gained more and more attention due to the staggering economic losses caused by the attacker. Existing tools that analyze vulnerabilities for smart contracts heavily rely on rules predefined by experts, which are labour-intense and require domain knowledge. Moreover, predefined rules tend to be misconceptions and increase the risk of crafty potential back-doors in the future. Recently, researchers mainly used static and dynamic execution analysis to detect the vulnerabilities of smart contracts and have achieved acceptable results. However, the dynamic method cannot cover all the program inputs and execution paths, which leads to some vulnerabilities that are hard to detect. The static analysis method commonly includes symbolic execution and theorem proving, which requires using constraints to detect vulnerability. These shortcomings show that traditional methods are challenging to apply and expand on a large scale. This paper aims to detect vulnerabilities via the Bug Injection framework and transfer learning techniques. First, we train a Transformer encoder using multi-modality code, which contains source code, intermediate representation, and assembly code. The input code consists separately of Solidity source code, intermediate representation, and assembly code. Specifically, we translate source code into the intermediate representation and decompile the byte code into assembly code by the EVM compiler. Then, we propose a novel entropy embedding technique, which combines token embedding, segment embedding, and positional embedding of the Transformer encoder in our approach. After that, we utilize the Bug Injection framework to automatically generate specific types of buggy code for fine-tuning and evaluating the performance of vulnerability detection. The experimental results show that our proposed approach improves the performance in detecting reentrancy vulnerabilities and timestamp dependence. Moreover, our approach is more flexible and scalable than static and dynamic analysis approaches in detecting smart contract vulnerabilities. Our approach improves the baseline approaches by an average of 11.89% in term of F1 score.
Keywords: Smart contract; Bug injection; Transfer learning; Vulnerability detection

Ali Majidzadeh, Mehrdad Ashtiani, Morteza Zakeri-Nasrabadi,
Multi-type requirements traceability prediction by code data augmentation and fine-tuning MS-CodeBERT,
Computer Standards & Interfaces,
Volume 90,
2024,
103850,
ISSN 0920-5489,
https://doi.org/10.1016/j.csi.2024.103850.
(https://www.sciencedirect.com/science/article/pii/S0920548924000199)
Abstract: Requirement traceability is a crucial quality factor that highly impacts the software evolution process and maintenance costs. Automated traceability links recovery techniques are required for a reliable and low-cost software development life cycle. Pre-trained language models have shown promising results on many natural language tasks. However, using such pre-trained models for requirement traceability needs large and quality traceability datasets and accurate fine-tuning mechanisms. This paper proposes code augmentation and fine-tuning techniques to prepare the MS-CodeBERT pre-trained language model for various types of requirements traceability prediction including documentation-to-method, issue-to-commit, and issue-to-method links. Three program transformation operations, namely, Rename Variable, Swap Operands, and Swap Statements are designed to generate new quality samples increasing the sample diversity of the traceability datasets. A 2-stage and 3-stage fine-tuning mechanism is proposed to fine-tune the language model for the three types of requirement traceability prediction on provided datasets. Experiments on 14 Java projects demonstrate a 6.2% to 8.5% improvement in the precision, 2.5% to 5.2% improvement in the recall, and 3.8% to 7.3% improvement in the F1 score of the traceability prediction models compared to the best results from the state-of-the-art methods.
Keywords: Requirement traceability; Language model; Data augmentation; Program transformation; Deep learning

Xi Xiao, Renjie Xiao, Qing Li, Jianhui Lv, Shunyan Cui, Qixu Liu,
BugRadar: Bug localization by knowledge graph link prediction,
Information and Software Technology,
Volume 162,
2023,
107274,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107274.
(https://www.sciencedirect.com/science/article/pii/S0950584923001283)
Abstract: Context
: Information Retrieval-based Bug Localization (IRBL) aims to design automatic systems that find buggy files according to bug reports, which can reduce the time consumption to fix bugs for programmers. There has been extensive research on IRBL techniques in recent years. However, these methods cannot make full use of the structure information in bug reports and source files.
Objective
: In this paper, we propose a novel scheme BugRadar. It combines text features and structure features from bug reports and source files for bug localization. Especially, BugRadar leverages a knowledge graph to make use of structure features.
Method
: We originally propose a knowledge graph named TriGraph based on structure features and apply hyperbolic attention embedding to get the link prediction scores. For text features, we propose Partial Text Similarity which improves traditional Text Similarity and Method Level Text Similarity. We also propose Word Collaborative Filtering Score which leverages historical bug reports with more attention on important terms. Finally, we calculate the final suspicious scores based on the structure features, text features, and fixing time information from bug fixing history with a neural network.
Results
: We apply our scheme to four projects (Tomcat, SWT, JDT, and Birt) in a popular dataset and get approving results. BugRadar gets better results than other state-of-the-art methods on three projects out of the four. It achieves a relative improvement of 8.8% in SWT and 9.8% in JDT for Mean Average Precision compared to the previous best scheme KGBugLocator and 11.4% in Birt compared to Adaptive Regression.
Conclusions
: BugRadar can achieve approving performance on large-scale projects with enough historical bug reports. It verifies that knowledge graphs are capable of representing the structure features for bug localization. The novel Partial Text Similarity and Word Collaborative Filtering Score are both effective improvements for using text features.
Keywords: Bug localization; Knowledge graph; Collaborative filtering

Rafał Wojszczyk, Aneta Hapka, Tomasz Królikowski,
Performance analysis of extracting object structure from source code,
Procedia Computer Science,
Volume 225,
2023,
Pages 4065-4073,
ISSN 1877-0509,
https://doi.org/10.1016/j.procs.2023.10.402.
(https://www.sciencedirect.com/science/article/pii/S1877050923015600)
Abstract: Tools for programmers are constantly evolving, and with that evolution comes tools that support their work, such as those that enable testing and analysis of program code. It is expected that tools integrated with programming environments will analyze code on the fly, and the results of the analysis will be available as soon as the program is compiled. This paper attempts to compare solutions for extracting object-oriented structure that begin the process of static source code analysis. Choosing the right solutions already at the beginning of static analysis, will affect the speed of the whole process as well as accuracy. And this will then affect the cost of programmers' work and the quality of the software tests performed.
Keywords: Static software analysis; object-oriented programming paradigm; reverse engineering; managed code; decompilation

Hao Ren, Yanhui Li, Lin Chen, Yuming Zhou, Changhai Nie,
Why and how bug blocking relations are breakable: An empirical study on breakable blocking bugs,
Information and Software Technology,
Volume 166,
2024,
107354,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107354.
(https://www.sciencedirect.com/science/article/pii/S0950584923002094)
Abstract: Context:
Blocking bugs prevents other bugs from being fixed, which is difficult to repair and negatively impacts software quality. During software maintenance, developers usually try to break the blocking relationship between blocking and blocked bugs, e.g., propose a temporary fix.
Object:
However, to our knowledge, no studies have investigated why and how blocking relations between bugs are breakable. In this study, we aim to construct an empirical analysis to explore breakable blocking bugs (BBBs).
Method:
Specifically, we employ quantitative and qualitative analysis to study these BBBs from two aspects. One is to investigate the characteristics of these bugs, and the other is to explore why and how developers break the blocking relationship between bugs during software maintenance. We build a dataset on five large-scale open-source projects and classify bugs into three types (BBBs, normal blocking bugs, and other bugs) to compare the differences between BBBs and other types of bugs.
Results:
We observe that BBBs have higher levels of involvement, take longer to fix, and involve more complex source code than other bugs. Moreover, we summarize four reasons blocking relationships between bugs are broken, i.e., partial association (41.87%), serious influence (26.40%), time pressure (19.73%), and flawed blocking (12.21%), and three measures developers adopt to break these blocking relationships, i.e., quick patch for blocking bugs (41.33%), quick patch for blocked bugs (38.67%), and ignore the blocking relation and fix blocked bugs directly (20.00%).
Conclusion:
Through these analyses, it is meaningful for software maintainers to have a deeper understanding of the characteristics and repair practices of BBBs, which will help solve these BBBs effectively in the future.
Keywords: Breakable blocking bugs; Blocking relations; Empirical study

Jean-Paul A. Yaacoub, Hassan N. Noura, Ola Salman, Ali Chehab,
Ethical hacking for IoT: Security issues, challenges, solutions and recommendations,
Internet of Things and Cyber-Physical Systems,
Volume 3,
2023,
Pages 280-308,
ISSN 2667-3452,
https://doi.org/10.1016/j.iotcps.2023.04.002.
(https://www.sciencedirect.com/science/article/pii/S2667345223000238)
Abstract: In recent years, attacks against various Internet-of-Things systems, networks, servers, devices, and applications witnessed a sharp increase, especially with the presence of 35.82 billion IoT devices since 2021; a number that could reach up to 75.44 billion by 2025. As a result, security-related attacks against the IoT domain are expected to increase further and their impact risks to seriously affect the underlying IoT systems, networks, devices, and applications. The adoption of standard security (counter) measures is not always effective, especially with the presence of resource-constrained IoT devices. Hence, there is a need to conduct penetration testing at the level of IoT systems. However, the main issue is the fact that IoT consists of a large variety of IoT devices, firmware, hardware, software, application/web-servers, networks, and communication protocols. Therefore, to reduce the effect of these attacks on IoT systems, periodic penetration testing and ethical hacking simulations are highly recommended at different levels (end-devices, infrastructure, and users) for IoT, and can be considered as a suitable solution. Therefore, the focus of this paper is to explain, analyze and assess both technical and non-technical aspects of security vulnerabilities within IoT systems via ethical hacking methods and tools. This would offer practical security solutions that can be adopted based on the assessed risks. This process can be considered as a simulated attack(s) with the goal of identifying any exploitable vulnerability or/and a security gap in any IoT entity (end devices, gateway, or servers) or firmware.
Keywords: Internet-of-things (IoT); IoT ethical hacking; IoT penetration testing; Internet of ethical hacking things (IoEHT); IoT cyber-security

Padma Jayaraman, Ranjani Parthasarathi,
Performance counter based online pipeline bugs detection using machine learning techniques,
Microprocessors and Microsystems,
Volume 84,
2021,
104262,
ISSN 0141-9331,
https://doi.org/10.1016/j.micpro.2021.104262.
(https://www.sciencedirect.com/science/article/pii/S0141933121004300)
Abstract: The growing complexity of new features in multicore processors imposes significant pressure towards functional verification. Although a large amount of time and effort are spent on it, functional design bugs escape into the products and cause catastrophic effects. Hence, online design bug detection is needed to detect the functional bugs in the field. In this work, we propose a novel approach by leveraging Performance Monitoring Counters (PMC) and machine learning to detect and locate pipeline bugs in a processor. We establish the correlation between PMC events and pipeline bugs in order to extract the features to build and train machine learning models. We design and implement a synthetic bug injection framework to obtain datasets for our simulation. To evaluate the proposal, Multi2Sim simulator is used to simulate the x86 architecture model. An x86 fault model is developed to synthetically inject bugs in x86 pipeline stages. PMC event values are collected by executing the SPEC CPU2006 and MiBench benchmarks for both bug and no-bug scenarios in the x86 simulator. This training data obtained through simulation is used to build a Bug Detection Model (BDM) that detects a pipeline bug and a Bug Location Model (BLM) that locates the pipeline unit where the bug occurred. Simulation results show that both BDM and BLM provide an accuracy of 97.3% and 91.6% using Decision tree and Random forest, respectively. When compared against other state of art approaches, our solution can locate the pipeline unit where the bug occurred with a high accuracy and without using additional hardware.
Keywords: Performance monitoring counters; Bug detection; Machine learning; Online design bug detection

Giovanni Rosa, Luca Pascarella, Simone Scalabrino, Rosalia Tufano, Gabriele Bavota, Michele Lanza, Rocco Oliveto,
A comprehensive evaluation of SZZ Variants through a developer-informed oracle,
Journal of Systems and Software,
Volume 202,
2023,
111729,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111729.
(https://www.sciencedirect.com/science/article/pii/S0164121223001243)
Abstract: Automatically linking bug-fixing changes to bug-inducing ones (BICs) is one of the key data-extraction steps behind several empirical studies in software engineering. The SZZ algorithm is the de facto standard to achieve this goal, with several improvements proposed over time. Evaluating the performance of SZZ implementations is, however, far from trivial. In previous works, researchers (i) manually assessed whether the BICs identified by the SZZ implementation were correct or not, or (ii) defined oracles in which they manually determined BICs from bug-fixing commits. However, ideally, the original developers should be involved in defining a labeled dataset to evaluate SZZ implementations. We propose a methodology to define a “developer-informed” oracle for evaluating SZZ implementations, without requiring a manual inspection from the original developers. We use Natural Language Processing (NLP) to identify bug-fixing commits in which developers explicitly reference the commit(s) that introduced the fixed bug. We use the built oracle to extensively evaluate existing SZZ variants defined in the literature. We also introduce and evaluate two new variants aimed at addressing two weaknesses we observed in state-of-the-art implementations (i.e., processing added lines and handling of revert commits).
Keywords: SZZ; Defect prediction; Empirical study

Amir Elmishali, Meir Kalech,
Issues-Driven features for software fault prediction,
Information and Software Technology,
Volume 155,
2023,
107102,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2022.107102.
(https://www.sciencedirect.com/science/article/pii/S0950584922002117)
Abstract: Context:
Software systems are an integral part of almost every modern industry. Unfortunately, the more complex the software, the more likely it will fail. A promising strategy is applying fault prediction models to predict which components may be defective. Since features are essential to the prediction model’s success, extracting significant features can improve the model’s accuracy. Previous research studies used software metrics as features in fault prediction models. One disadvantage of these features is that they measure the code developed rather than the requirements. On the other hand, faults are frequently the result of a mismatch between the software’s behavior and its needs.
Objective:
We present a novel paradigm for constructing features that consider the requirements as well by combining novel requirement metrics, called Issues-Driven features, and traditional code metrics.
Method:
We experimentally compare the performance of Issues-Driven features and state-of-the-art traditional features on 86 open-source projects from two organizations.
Results:
The results show that Issues-Driven features are significantly better than state-of-the-art features and achieve an improvement of 6 to 13 percent in terms of AUC.
Conclusions:
The study concludes that integrating the requirements into fault prediction features overcomes the limitations of traditional software metrics that are agnostic to the requirements of the software.
Keywords: Software defect prediction; Mining software repositories; Code debugging; Software prediction; Software quality; Software engineering

Yusuf Kartal, E. Kaan Akdeniz, Kemal Özkan,
Automating modern code review processes with code similarity measurement,
Information and Software Technology,
2024,
107490,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2024.107490.
(https://www.sciencedirect.com/science/article/pii/S0950584924000958)
Abstract: Context:
Modern code review is a critical component in software development processes, as it ensures security, detects errors early and improves code quality. However, manual reviews can be time-consuming and unreliable. Automated code review can address these issues. Although deep-learning methods have been used to recommend code review comments, they are expensive to train and employ. Instead, information retrieval (IR)-based methods for automatic code review are showing promising results in efficiency, effectiveness, and flexibility.
Objective:
Our main objective is to determine the optimal combination of the vectorization method and similarity to measure what gives the best results in an automatic code review, thereby improving the performance of IR-based methods.
Methods:
Specifically, we investigate different vectorization methods (Word2Vec, Doc2Vec, Code2Vec, and Transformer) that differ from previous research (TF-IDF and Bag-of-Words), and similarity measures (Cosine, Euclidean, and Manhattan) to capture the semantic similarities between code texts. We evaluate the performance of these methods using standard metrics, such as Blue, Meteor, and Rouge-L, and include the run-time of the models in our results.
Results:
Our results demonstrate that the Transformer model outperforms the state-of-the-art method in all standard metrics and similarity measurements, achieving a 19.1% improvement in providing exact matches and a 6.2% improvement in recommending reviews closer to human reviews.
Conclusion:
Our findings suggest that the Transformer model is a highly effective and efficient approach for recommending code review comments that closely resemble those written by humans, providing valuable insight for developing more efficient and effective automated code review systems.
Keywords: Modern code review; Vectorization; Code similarity; Information retrieval

Rakesh Kumar Jha,  Puja, Haneet Kour, Manoj Kumar, Shubha Jain,
Layer based security in Narrow Band Internet of Things (NB-IoT),
Computer Networks,
Volume 185,
2021,
107592,
ISSN 1389-1286,
https://doi.org/10.1016/j.comnet.2020.107592.
(https://www.sciencedirect.com/science/article/pii/S1389128620312299)
Abstract: In the recent years, the growth of technology and the resulting transformation is happening at a rapid pace. In this junction, IoT has provided a great platform and bridge between these technologies. A lot of research regarding the application of IoT Systems has been done in the recent years but one area that lacks research is security issues in Narrow Band Internet of Things (NB-IoT).It is noticed that security and Privacy in NB-IoT system is a challenging task for researchers and academia. Application of NB-IoT in Defense security opened a new way for the researchers but at the same time security threat can lead to drastic loss. Nowadays, MEMS-NB-IoT device (Bug)/ BOT are being used for carrying out any malicious security attack. This can be a serious area of concern in the case of defense security. These MEMS device are very dangerous and it can spoof data from any type of network. The size of this device is very small, it can travel to any location for monitoring the enemy movement, and it is very difficult to identify these types of bugs. These BOT device very sensitive at Perception and Network Layered. In this paper, we have provided detail analysis of IoT/NB-IoT Layered architecture. A novel proposal depicting security attack in a Smart home system with IoT and NB-IoT enabled devices is presented. The Secrecy Rate (SR), the Secrecy Outage Probability (SOP) is being calculated, and performance analysis of IoT system in the presence of Bugs for a smart home system is carried out. Simulations have been performed and the performance analysis done is based on Security non-outage probability vs security rate with real time analysis.
Keywords: IoT; Bug; Security; MEMS; Secrecy rate (SR); Secrecy outage probability (SOP)

Xiaoxue Wu, Wei Zheng, Xiang Chen, Fang Wang, Dejun Mu,
CVE-assisted large-scale security bug report dataset construction method,
Journal of Systems and Software,
Volume 160,
2020,
110456,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2019.110456.
(https://www.sciencedirect.com/science/article/pii/S0164121219302304)
Abstract: Identifying SBRs (security bug reports) is crucial for eliminating security issues during software development. Machine learning are promising ways for SBR prediction. However, the effectiveness of the state-of-the-art machine learning models depend on high-quality datasets, while gathering large-scale datasets are expensive and tedious. To solve this issue, we propose an automated data labeling approach based on iterative voting classification. It starts with a small group of ground-truth traing samples, which can be labeled with the help of authoritative vulnerability records hosted in CVE (Common Vulnerabilities and Exposures). The accuracy of the prediction model is improved with an iterative voting strategy. By using this approach, we label over 80k bug reports from OpenStack and 40k bug reports from Chromium. The correctness of these labels are then manually reviewed by three experienced security testing members. Finally, we construct a large-scale SBR dataset with 191 SBRs and 88,472 NSBRs (non-security bug reports) from OpenStack; and improve the quality of existing SBR dataset Chromium by identifying 64 new SBRs from previously labeled NSBRs and filtering out 173 noise bug reports from this dataset. These share datasets as well as the proposed dataset construction method help to promote research progress in SBR prediction research domain.
Keywords: Security bug report prediction; Voting classification; Dataset construction; Common vulnerabilities and exposures

Janaka Senanayake, Harsha Kalutarage, Andrei Petrovski, Luca Piras, Mhd Omar Al-Kadri,
Defendroid: Real-time Android code vulnerability detection via blockchain federated neural network with XAI,
Journal of Information Security and Applications,
Volume 82,
2024,
103741,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2024.103741.
(https://www.sciencedirect.com/science/article/pii/S2214212624000449)
Abstract: Ensuring strict adherence to security during the phases of Android app development is essential, primarily due to the prevalent issue of apps being released without adequate security measures in place. While a few automated tools are employed to reduce potential vulnerabilities during development, their effectiveness in detecting vulnerabilities may fall short. To address this, “Defendroid”, a blockchain-based federated neural network enhanced with Explainable Artificial Intelligence (XAI) is introduced in this work. Trained on the LVDAndro dataset, the vanilla neural network model achieves a 96% accuracy and 0.96 F1-Score in binary classification for vulnerability detection. Additionally, in multi-class classification, the model accurately identifies Common Weakness Enumeration (CWE) categories with a 93% accuracy and 0.91 F1-Score. In a move to foster collaboration and model improvement, the model has been deployed within a blockchain-based federated environment. This environment enables community-driven collaborative training and enhancements in partnership with other clients. The extended model demonstrates improved accuracy of 96% and F1-Score of 0.96 in both binary and multi-class classifications. The use of XAI plays a pivotal role in presenting vulnerability detection results to developers, offering prediction probabilities for each word within the code. This model has been integrated into an Application Programming Interface (API) as the backend and further incorporated into Android Studio as a plugin, facilitating real-time vulnerability detection. Notably, Defendroid exhibits high efficiency, delivering prediction probabilities for a single code line in an average processing time of a mere 300 ms. The weight-sharing transparency in the blockchain-driven federated model enhances trust and traceability, fostering community engagement while preserving source code privacy and contributing to accuracy improvement.
Keywords: Android application protection; Code vulnerability; Neural network; Federated learning; Source code privacy; Explainable AI; Blockchain

Yuan Jiang, Pengcheng Lu, Xiaohong Su, Tiantian Wang,
LTRWES: A new framework for security bug report detection,
Information and Software Technology,
Volume 124,
2020,
106314,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2020.106314.
(https://www.sciencedirect.com/science/article/pii/S0950584920300665)
Abstract: Context: Security bug reports (SBRs) usually contain security-related vulnerabilities in software products, which could be exploited by malicious attackers. Hence, it is important to identify SBRs quickly and accurately among bug reports (BRs) that have been disclosed in bug tracking systems. Although a few methods have been already proposed for the detection of SBRs, challenging issues still remain due to noisy samples, class imbalance and data scarcity. Object: This motivates us to reveal the potential challenges faced by the state-of-the-art SBRs prediction methods from the viewpoint of data filtering and representation. Furthermore, the purpose of this paper is also to provide a general framework and new solutions to solve these problems. Method: In this study, we propose a novel approach LTRWES that incorporates learning to rank and word embedding into the identification of SBRs. Unlike previous keyword-based approaches, LTRWES is a content-based data filtering and representation framework that has several desirable properties not shared in other methods. Firstly, it exploits ranking model to efficiently filter non-security bug reports (NSBRs) that have higher content similarity with respect to SBRs. Secondly, it applies word embedding technology to transform the rest of NSBRs, together with SBRs, into low-dimensional real-value vectors. Result: Experiment results on benchmark and large real-world datasets show that our proposed method outperforms the state-of-the-art method. Conclusion: Overall, the LTRWES is valid with high performance. It will help security engineers to identify SBRs from thousands of NSBRs more accurately than existing algorithms. Therefore, this will positively encourage the research and development of the content-based methods for security bug report detection.
Keywords: Security bug report; Content-based filtering; Word embedding; Machine learning

Thomas Hirsch, Birgit Hofer,
Using textual bug reports to predict the fault category of software bugs,
Array,
Volume 15,
2022,
100189,
ISSN 2590-0056,
https://doi.org/10.1016/j.array.2022.100189.
(https://www.sciencedirect.com/science/article/pii/S259000562200042X)
Abstract: Debugging is a time-consuming and expensive process. Developers have to select appropriate tools, methods and approaches in order to efficiently reproduce, localize and fix bugs. These choices are based on the developers’ assessment of the type of fault for a given bug report. This paper proposes a machine learning (ML) based approach that predicts the fault type for a given textual bug report. We built a dataset from 70+ projects for training and evaluation of our approach. Further, we performed a user study to establish a baseline for non-expert human performance on this task. Our models, incorporating our custom preprocessing approaches, reach up to 0.69% macro average F1 score on this bug classification problem. We demonstrate inter-project transferability of our approach. Further, we identify and discuss issues and limitations of ML classification approaches applied on textual bug reports. Our models can support researchers in data collection efforts, as for example bug benchmark creation. In future, such models could aid inexperienced developers in debugging tool selection, helping save time and resources.
Keywords: Bug report; Bug benchmark; Fault type prediction

Devi Priya V S, Sibi Chakkaravarthy Sethuraman, Muhammad Khurram Khan,
Container security: Precaution levels, mitigation strategies, and research perspectives,
Computers & Security,
Volume 135,
2023,
103490,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103490.
(https://www.sciencedirect.com/science/article/pii/S0167404823004005)
Abstract: The enterprise technique for application deployment has undergone a major transformation during the past two decades. Using conventional techniques, software developers write code in a particular computing environment, frequently leading to mistakes and defects when moving it to a new computing environment. However, during the past few years, enterprises have begun to use containers & microservices to segregate infrastructure in a particular perspective and develop new models of the technology stack. Software developers could construct and deploy apps more quickly and effectively now, thanks to containerization. Despite the fact that containers have their own namespace, it is still feasible for a containerized image to attack the host system by inserting malicious software into it. This necessitates threat modeling of the container life span. During the investigation, we were able to create the elemental systematic modelling that identifies threats pertaining to container application workflow and its preliminary mitigation techniques, where attack trees are defined alongside the model, which helps academics and enthusiasts better comprehend the significance of container security. We utilize the well-known threat modeling framework, DREAD, to further advance threat modeling across the infrastructure of containers that aids in prioritizing the risks. Additionally, tools for assessing container vulnerabilities and discrete real-world exploits were researched, and approaches for security analysis in container technology were compared to the existing literature. Finally, this study brings to a conclusion by outlining the state-of-the-art survey for future research and identifying potential research topics in server-based and serverless containers.
Keywords: Microservices; Software development; Container security- root-based and rootless; Threat modeling-attack trees; DREAD

Wei Zheng, JingYuan Cheng, Xiaoxue Wu, Ruiyang Sun, Xiaolong Wang, Xiaobing Sun,
Domain knowledge-based security bug reports prediction,
Knowledge-Based Systems,
Volume 241,
2022,
108293,
ISSN 0950-7051,
https://doi.org/10.1016/j.knosys.2022.108293.
(https://www.sciencedirect.com/science/article/pii/S095070512200096X)
Abstract: To eliminate security attack risks of software products, the security bug report (SBR) prediction has been increasingly investigated. However, there is still much room for improving the performance of automatic SBR prediction. This work is inspired by the work of two recent studies proposed by Peters et al. and Wu et al., which focused on SBR prediction and have been published on the top tier journal TSE (IEEE Transactions on Software Engineering). The goal of this work is to improve the effectiveness of supervised machine learning-based SBR prediction with the help of software security domain knowledge. First, we split the words in summary and description fields of the SBRs. Then, we use customized relationships to label entities and build a rule-based entity recognition corpus. After that, we establish relationships between entities and construct knowledge graphs. The information of CWE (Common Weakness Enumeration) is used to expand our corpus and the security-related words and phrases are integrated. Finally, we predict SBRs from target project by calculating the cosine similarity between our integrated corpus and the target bug reports. Our experimental evaluation on 5 open-source SBR datasets shows that our domain knowledge-guided approach could improve the effectiveness of SBRs prediction by 52% in terms of F1-score on average.
Keywords: Software security; Security bug report prediction; Domain knowledge; Knowledge graph; Entity recognition

Ola Michalec, Ben Shreeve, Awais Rashid,
Who will keep the lights on? Expertise and inclusion in cyber security visions of future energy systems,
Energy Research & Social Science,
Volume 106,
2023,
103327,
ISSN 2214-6296,
https://doi.org/10.1016/j.erss.2023.103327.
(https://www.sciencedirect.com/science/article/pii/S2214629623003870)
Abstract: Increasing internet connectivity in smart energy systems poses serious cyber security concerns. Using a lens of “sociotechnical imaginaries”, we explored how experts envision the future(s) of cyber security governance in the energy sector. The three imaginaries identified present cyber security issues as a matter of design, as a support function, and as public trust. We argue that while each vision prioritises a different set of actions, none of them adequately considers the interplay between inclusivity and expertise. By exploring what each of these potential futures enables, hinders, or assumes, as well as how they compete or complement each other, we derive a number of recommendations to ensure cyber security expertise becomes more inclusive, democratic and participatory. The paper contributes to energy social science debates by furthering the understanding of how energy experts conceptualise future computing systems for security and sustainability.
Keywords: Digitalisation; Cyber security; Infrastructure; Imaginaries; Energy; Expertise; Inclusion

Felipe Ebert, Fernando Castor, Alexander Serebrenik,
An exploratory study on exception handling bugs in Java programs,
Journal of Systems and Software,
Volume 106,
2015,
Pages 82-101,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2015.04.066.
(https://www.sciencedirect.com/science/article/pii/S0164121215000862)
Abstract: Most mainstream programming languages provide constructs to throw and to handle exceptions. However, several studies argue that exception handling code is usually of poor quality and that it is commonly neglected by developers. Moreover, it is said to be the least understood, documented, and tested part of the implementation of a system. Nevertheless, there are very few studies that analyze the actual exception handling bugs that occur in real software systems or that attempt to understand developers’ perceptions of these bugs. In this work we present an exploratory study on exception handling bugs that employs two complementary approaches: a survey of 154 developers and an analysis of 220 exception handling bugs from the repositories of Eclipse and Tomcat. Only 27% of the respondents claimed that policies and standards for the implementation of error handling are part of the culture of their organizations. Moreover, in 70% of the organizations there are no specific tests for the exception handling code. Also, 61% of the respondents stated that no to little importance is given to the documentation of exception handling in the design phase of the projects with which they are involved. In addition, about 40% of the respondents consider the quality of exception handling code to be either good or very good and only 14% of the respondents consider it to be bad or very bad. Furthermore, the repository analysis has shown (with statistical significance) that exception handling bugs are ignored by developers less often than other bugs. We have also observed that while overly general catch blocks are a well-known bad smell related to exceptions, bugs stemming from these catch blocks are rare, even though many overly general catch blocks occur in the code. Furthermore, while developers often mention empty catch blocks as causes of bugs they have fixed in the past, we found very few bug reports caused by them. On top of that, empty catch blocks are frequently used as part of bug fixes, including fixes for exception handling bugs. Based on our findings, we propose a classification of exception handling bugs and their causes. The proposed classification can be used to assist in the design and implementation of test suites, to guide code inspections, or as a basis for static analysis tools.
Keywords: Exception handling; Bugs; Repository mining

Jean-Paul A. Yaacoub, Hassan N. Noura, Ola Salman,
Security of federated learning with IoT systems: Issues, limitations, challenges, and solutions,
Internet of Things and Cyber-Physical Systems,
Volume 3,
2023,
Pages 155-179,
ISSN 2667-3452,
https://doi.org/10.1016/j.iotcps.2023.04.001.
(https://www.sciencedirect.com/science/article/pii/S2667345223000226)
Abstract: Federated Learning (FL, or Collaborative Learning (CL)) has surely gained a reputation for not only building Machine Learning (ML) models that rely on distributed datasets, but also for starting to play a key role in security and privacy solutions to protect sensitive data and information from a variety of ML-related attacks. This made it an ideal choice for emerging networks such as Internet of Things (IoT) systems, especially with its state-of-the-art algorithms that focus on their practical use over IoT networks, despite the presence of resource-constrained devices. However, the heterogeneous nature of the current devices and models in complex IoT networks has seriously hindered the FL training process's ability to perform well. Thus, rendering it almost unsuitable for direct deployment over IoT networks despite ongoing efforts to tackle this issue and overcome this challenging obstacle. As a result, the main characteristics of FL in the IoT from both security and privacy aspects are presented in this study. We broaden our research to investigate and analyze cutting-edge FL algorithms, models, and protocols, with a focus on their efficacy and practical application across IoT networks and systems alike. This is followed by a comparative analysis of the recently available protection solutions for FL that can be based on cryptographic and non-cryptographic solutions over heterogeneous, dynamic IoT networks. Moreover, the proposed work provides a list of suggestions and recommendations that can be applied to enhance the effectiveness of the adoption of FL and to achieve higher robustness against attacks, especially in heterogeneous dynamic IoT networks and in the presence of resource-constrained devices.

Wei Zheng, Yunfan Li, Xiaoxue Wu, Jingyuan Cheng,
Duplicate Bug Report detection using Named Entity Recognition,
Knowledge-Based Systems,
Volume 284,
2024,
111258,
ISSN 0950-7051,
https://doi.org/10.1016/j.knosys.2023.111258.
(https://www.sciencedirect.com/science/article/pii/S0950705123010079)
Abstract: Software bugs pose significant challenges in management. The Bug Tracking System (BTS) serves as a standard platform to chronicle, oversee, and manage bugs throughout software development and maintenance. While BTS aggregates numerous bug reports for tracking purposes, identical bugs often get reported by various individuals. This redundancy leads to excessive duplicate reports, straining manual inspection efforts, risking repeated bug assignment tasks, and diminishing the efficiency of bug resolution. Notably, many contemporary DBR detection techniques tend to overlook the structured data abundant in descriptive information about bug report behaviors. To mitigate this oversight, this study introduces a groundbreaking method named CorNER. This technique enhances DBR detection precision by converting unstructured textual content into structured data via named entity recognition (NER). Specifically, CorNER employs Random Forest with context (RNER) to annotate entities in the title and description sections of bug reports and subsequently harnesses Text Convolutional Neural Networks (TextCNN) for feature extraction. Empirical evidence indicates a commendable improvement in CorNER’s F1-Score by 6.24% and 4.96% on average, surpassing the benchmarks of two prevalent DBR detection methods across five datasets.
Keywords: Duplicate Bug Report detection; Named Entity Recognition; Context-aware random forest; Convolutional neural networks

Yifan Yao, Jinhao Duan, Kaidi Xu, Yuanfang Cai, Zhibo Sun, Yue Zhang,
A Survey on Large Language Model (LLM) Security and Privacy: The Good, The Bad, and The Ugly,
High-Confidence Computing,
Volume 4, Issue 2,
2024,
100211,
ISSN 2667-2952,
https://doi.org/10.1016/j.hcc.2024.100211.
(https://www.sciencedirect.com/science/article/pii/S266729522400014X)
Abstract: Large Language Models (LLMs), such as ChatGPT and Bard, have revolutionized natural language understanding and generation. They possess deep language comprehension, human-like text generation capabilities, contextual awareness, and robust problem-solving skills, making them invaluable in various domains (e.g., search engines, customer support, translation). In the meantime, LLMs have also gained traction in the security community, revealing security vulnerabilities and showcasing their potential in security-related tasks. This paper explores the intersection of LLMs with security and privacy. Specifically, we investigate how LLMs positively impact security and privacy, potential risks and threats associated with their use, and inherent vulnerabilities within LLMs. Through a comprehensive literature review, the paper categorizes the papers into “The Good” (beneficial LLM applications), “The Bad” (offensive applications), and “The Ugly” (vulnerabilities of LLMs and their defenses). We have some interesting findings. For example, LLMs have proven to enhance code security (code vulnerability detection) and data privacy (data confidentiality protection), outperforming traditional methods. However, they can also be harnessed for various attacks (particularly user-level attacks) due to their human-like reasoning abilities. We have identified areas that require further research efforts. For example, Research on model and parameter extraction attacks is limited and often theoretical, hindered by LLM parameter scale and confidentiality. Safe instruction tuning, a recent development, requires more exploration. We hope that our work can shed light on the LLMs’ potential to both bolster and jeopardize cybersecurity.
Keywords: Large Language Model (LLM); LLM security; LLM privacy; ChatGPT; LLM attacks; LLM vulnerabilities

Hariharan M., Sathish Kumar C., Anshul Tanwar, Krishna Sundaresan, Prasanna Ganesan, Sriram Ravi, R. Karthik,
Proximal Instance Aggregator networks for explainable security vulnerability detection,
Future Generation Computer Systems,
Volume 134,
2022,
Pages 303-318,
ISSN 0167-739X,
https://doi.org/10.1016/j.future.2022.04.008.
(https://www.sciencedirect.com/science/article/pii/S0167739X22001315)
Abstract: Security vulnerabilities in software are the root cause of cyberattacks. Considering that these defects have huge associated costs, they should be proactively detected and resolved before shipping the software. Data-driven approaches like Artificial Intelligence (AI) are vastly explored for automatic vulnerability detection, given their potential to leverage large-scale vulnerability data feeds and learn from these scenarios. This work introduces a novel Proximal Instance Aggregator (PIA) neural network for accurately capturing insecure C code patterns from Abstract Syntax Tree (AST). It is built upon the concept of Multiple Instance Learning (MIL), which treats the AST representation of the code as a ‘bag’ of tree path ‘instances’. The security vulnerability can manifest in one or multiple such AST path instances. The PIA model dynamically learns a set of abstract concepts to describe the patterns associated with the AST paths. Specifically, the vulnerable nature of an AST path is characterized by its proximity to these concepts. The model also employs the attention mechanism to generate deep representations. By drawing cross-correlation of features between the path instances, the self-attention robustly weighs the relevance of each AST path towards vulnerability classification. The MIL utilizes these deep feature sets to construct the concept space. Thus, even without explicit supervision for localizing the line of defect, the AI automatically learns AST instance classification in a weakly supervised manner. Since AST-level prediction is formed as an aggregation of instance classifications, the AI is inherently explainable. The model outperforms state-of-the-art methods by a fair margin. It achieves 95.63% detection accuracy and 95.65% F1-score on the benchmarked NIST SARD, NVD datasets for a range of vulnerabilities.
Keywords: Multiple-Instance learning; Interpretability; Deep learning; Vulnerability detection; Abstract Syntax Tree; Weakly supervised learning

Ali Rezaei Nasab, Mojtaba Shahin, Peng Liang, Mohammad Ehsan Basiri, Seyed Ali Hoseyni Raviz, Hourieh Khalajzadeh, Muhammad Waseem, Amineh Naseri,
Automated identification of security discussions in microservices systems: Industrial surveys and experiments,
Journal of Systems and Software,
Volume 181,
2021,
111046,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2021.111046.
(https://www.sciencedirect.com/science/article/pii/S0164121221001436)
Abstract: Lack of awareness and knowledge of microservices-specific security challenges and solutions often leads to ill-informed security decisions in microservices system development. We claim that identifying and leveraging security discussions scattered in existing microservices systems can partially close this gap. We define security discussion as “a paragraph from developer discussions that includes design decisions, challenges, or solutions relating to security”. We first surveyed 67 practitioners and found that securing microservices systems is a unique challenge and that having access to security discussions is useful for making security decisions. The survey also confirms the usefulness of potential tools that can automatically identify such security discussions. We developed fifteen machine/deep learning models to automatically identify security discussions. We applied these models on a manually constructed dataset consisting of 4,813 security discussions and 12,464 non-security discussions. We found that all the models can effectively identify security discussions: an average precision of 84.86%, recall of 72.80%, F1-score of 77.89%, AUC of 83.75% and G-mean 82.77%. DeepM1, a deep learning model, performs the best, achieving above 84% in all metrics and significantly outperforms three baselines. Finally, the practitioners’ feedback collected from a validation survey reveals that security discussions identified by DeepM1 have promising applications in practice.
Keywords: Microservices architecture; Security; Machine learning; Deep learning; Automation

Suman, Raees Ahmad Khan,
An optimized neural network for prediction of security threats on software testing,
Computers & Security,
Volume 137,
2024,
103626,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103626.
(https://www.sciencedirect.com/science/article/pii/S0167404823005369)
Abstract: Software testing involves evaluating and confirming a software program or product to ensure it operates according to its intended functionality. Testing offers advantages like bug prevention, reduced development expenses, and improved performance. The problems are dialogue gap, ecological danger, creation of software quickly, cost of operation and upkeep, inadequate assessment, and incorrect testing estimates. The structure was initially educated using internet presentation data that included intrusion information. A novel Dove Swarm-based Deep Neural Method (DSbDNM) with the required traits and stages of processing has been developed. Moving forward, feature extraction and malicious behaviour forecast have both been completed. Also, the different types of assaults and negative behaviours were categorized. The developed prediction model is also examined by initiating and detecting an unidentified assault. Finally, the performance measures' accuracy, error rate, Precision, Recall and f-measure were computed. Moreover, the proposed system implementation is done in Python. Therefore, the proposed work performance can be enhanced and attain high accuracy in low computational time. For the DSbDNM dataset, the designed prototypical achieved 94.65 accuracy, 94.95 precision, 90.16 Recall and 92.02 F-measure for the NF-UQ-NIDS-v2 Dataset. Moreover, the Intrusion Detection Dataset attained an accuracy of 98, Precision of 98.8, Recall of 94.2, and F-score of 96 in the developed model. Subsequently, the Network Intrusion Detection Dataset attained an accuracy of 99, a precision of 99.2, a Recall of 95.8 and an F-measure of 97.1
Keywords: Intrusion data; Optimized; Attacks; Security; Preprocessing; Prediction; High quality

Tao Zhang, Jiachi Chen, Geunseok Yang, Byungjeong Lee, Xiapu Luo,
Towards more accurate severity prediction and fixer recommendation of software bugs,
Journal of Systems and Software,
Volume 117,
2016,
Pages 166-184,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2016.02.034.
(https://www.sciencedirect.com/science/article/pii/S0164121216000765)
Abstract: Due to the unavoidable bugs appearing in the most of the software systems, bug resolution has become one of the most important activities in software maintenance. For large-scale software programs, developers usually depend on bug reports to fix the given bugs. When a new bug is reported, a triager has to complete two important tasks that include severity identification and fixer assignment. The purpose of severity identification is to decide how quickly the bug report should be addressed while fixer assignment means that the new bug needs to be assigned to an appropriate developer for fixing. However, a large number of bug reports submitted every day increase triagers’ workload, thus leading to the reduction in the accuracy of severity identification and fixer assignment. Therefore it is necessary to develop an automatic approach to perform severity prediction and fixer recommendation instead of manual work. This article proposes a more accurate approach to accomplish the goal. We firstly utilize modified REP algorithm (i.e., REPtopic) and K-Nearest Neighbor (KNN) classification to search the historical bug reports that are similar to a new bug. Next, we extract their features (e.g., assignees and similarity) to develop the severity prediction and fixer recommendation algorithms. Finally, by adopting the proposed algorithms, we achieve severity prediction and semi-automatic fixer recommendation on five popular open source projects, including GNU Compiler Collection (GCC), OpenOffice, Eclipse, NetBeans, and Mozilla. The results demonstrated that our method can improve the performance of severity prediction and fixer recommendation through comparison with the cutting-edge studies.
Keywords: Severity prediction; Fixer recommendation; Topic model

Umar Iftikhar, Nauman Bin Ali, Jürgen Börstler, Muhammad Usman,
A tertiary study on links between source code metrics and external quality attributes,
Information and Software Technology,
Volume 165,
2024,
107348,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107348.
(https://www.sciencedirect.com/science/article/pii/S0950584923002033)
Abstract: Context:
Several secondary studies have investigated the relationship between internal quality attributes, source code metrics and external quality attributes. Sometimes they have contradictory results.
Objective:
We synthesize evidence of the link between internal quality attributes, source code metrics and external quality attributes along with the efficacy of the prediction models used.
Method:
We conducted a tertiary review to identify, evaluate and synthesize secondary studies. We used several characteristics of secondary studies as indicators for the strength of evidence and considered them when synthesizing the results.
Results:
From 711 secondary studies, we identified 15 secondary studies that have investigated the link between source code and external quality. Our results show : (1) primarily, the focus has been on object-oriented systems, (2) maintainability and reliability are most often linked to internal quality attributes and source code metrics, with only one secondary study reporting evidence for security, (3) only a small set of complexity, coupling, and size-related source code metrics report a consistent positive link with maintainability and reliability, and (4) group method of data handling (GMDH) based prediction models have performed better than other prediction models for maintainability prediction.
Conclusions:
Based on our results, lines of code, coupling, complexity and the cohesion metrics from Chidamber & Kemerer (CK) metrics are good indicators of maintainability with consistent evidence from high and moderate-quality secondary studies. Similarly, four CK metrics related to coupling, complexity and cohesion are good indicators of reliability, while inheritance and certain cohesion metrics show no consistent evidence of links to maintainability and reliability. Further empirical studies are needed to explore the link between internal quality attributes, source code metrics and other external quality attributes, including functionality, portability, and usability. The results will help researchers and practitioners understand the body of knowledge on the subject and identify future research directions.
Keywords: Product quality; Quality models; Code quality; Evidence; Tertiary study; Tertiary review

Gemma Catolino, Fabio Palomba, Andy Zaidman, Filomena Ferrucci,
Not all bugs are the same: Understanding, characterizing, and classifying bug types,
Journal of Systems and Software,
Volume 152,
2019,
Pages 165-181,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2019.03.002.
(https://www.sciencedirect.com/science/article/pii/S0164121219300536)
Abstract: Modern version control systems, e.g., GitHub, include bug tracking mechanisms that developers can use to highlight the presence of bugs. This is done by means of bug reports, i.e., textual descriptions reporting the problem and the steps that led to a failure. In past and recent years, the research community deeply investigated methods for easing bug triage, that is, the process of assigning the fixing of a reported bug to the most qualified developer. Nevertheless, only a few studies have reported on how to support developers in the process of understanding the type of a reported bug, which is the first and most time-consuming step to perform before assigning a bug-fix operation. In this paper, we target this problem in two ways: first, we analyze 1280 bug reports of 119 popular projects belonging to three ecosystems such as Mozilla, Apache, and Eclipse, with the aim of building a taxonomy of the types of reported bugs; then, we devise and evaluate an automated classification model able to classify reported bugs according to the defined taxonomy. As a result, we found nine main common bug types over the considered systems. Moreover, our model achieves high F-Measure and AUC-ROC (64% and 74% on overall, respectively).
Keywords: Bug classification; Taxonomy; Empirical study

Emrah Yasasin, Julian Prester, Gerit Wagner, Guido Schryen,
Forecasting IT security vulnerabilities – An empirical analysis,
Computers & Security,
Volume 88,
2020,
101610,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2019.101610.
(https://www.sciencedirect.com/science/article/pii/S016740481830854X)
Abstract: Today, organizations must deal with a plethora of IT security threats and to ensure smooth and uninterrupted business operations, firms are challenged to predict the volume of IT security vulnerabilities and allocate resources for fixing them. This challenge requires decision makers to assess which system or software packages are prone to vulnerabilities, how many post-release vulnerabilities can be expected to occur during a certain period of time, and what impact exploits might have. Substantial research has been dedicated to techniques that analyze source code and detect security vulnerabilities. However, only limited research has focused on forecasting security vulnerabilities that are detected and reported after the release of software. To address this shortcoming, we apply established methodologies which are capable of forecasting events exhibiting specific time series characteristics of security vulnerabilities, i.e., rareness of occurrence, volatility, non-stationarity, and seasonality. Based on a dataset taken from the National Vulnerability Database (NVD), we use the Mean Absolute Error (MAE) and Root Mean Square Error (RMSE) to measure the forecasting accuracy of single, double, and triple exponential smoothing methodologies, Croston’s methodology, ARIMA, and a neural network-based approach. We analyze the impact of the applied forecasting methodology on the prediction accuracy with regard to its robustness along the dimensions of the examined system and software package “operating systems”, “browsers” and “office solutions” and the applied metrics. To the best of our knowledge, this study is the first to analyze the effect of forecasting methodologies and to apply metrics that are suitable in this context. Our results show that the optimal forecasting methodology depends on the software or system package, as some methodologies perform poorly in the context of IT security vulnerabilities, that absolute metrics can cover the actual prediction error precisely, and that the prediction accuracy is robust within the two applied forecasting-error metrics.
Keywords: Security vulnerability; Prediction; Forecasting; Competition setup; Time series

Philipp Kühn, David N. Relke, Christian Reuter,
Common vulnerability scoring system prediction based on open source intelligence information sources,
Computers & Security,
Volume 131,
2023,
103286,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103286.
(https://www.sciencedirect.com/science/article/pii/S0167404823001967)
Abstract: The number of newly published vulnerabilities is constantly increasing. Until now, the information available when a new vulnerability is published is manually assessed by experts using a Common Vulnerability Scoring System (CVSS) vector and score. This assessment is time consuming and requires expertise. Various works already try to predict CVSS vectors or scores using machine learning based on the textual descriptions of the vulnerability to enable faster assessment. However, for this purpose, previous works only use the texts available in databases such as National Vulnerability Database. With this work, the publicly available web pages referenced in the National Vulnerability Database are analyzed and made available as sources of texts through web scraping. A Deep Learning based method for predicting the CVSS vector is implemented and evaluated. The present work provides a classification of the National Vulnerability Database’s reference texts based on the suitability and crawlability of their texts. While we identified the overall influence of the additional texts is negligible, we outperformed the state-of-the-art with our Deep Learning prediction models.
Keywords: IT Security; Common vulnerability scoring system; Classification; National vulnerability database; Security management; Deep learning

Gerardo Canfora, Andrea Di Sorbo, Sara Forootani, Antonio Pirozzi, Corrado Aaron Visaggio,
Investigating the vulnerability fixing process in OSS projects: Peculiarities and challenges,
Computers & Security,
Volume 99,
2020,
102067,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2020.102067.
(https://www.sciencedirect.com/science/article/pii/S0167404820303400)
Abstract: Although vulnerabilities can be considered and treated as bugs, they present numerous peculiarities compared to other types of bugs (canonical bugs in the remainder of the paper). A vulnerability adds functionality to a system, as it allows an adversary to misuse or abuse the system, while a canonical bug is an incomplete or incorrect implementation of a requirement, and thus degrades the functionality of the system. This difference can affect the fixing process of vulnerabilities. By mining the repositories of 6 open source projects, we characterize the differences in the fixing process between vulnerabilities and canonical bugs, highlighting critical issues which could represent challenges for future research. Results of our study demonstrate that: (i) more re-assignments (than the ones observed in canonical bugs) are required for finding the developers able to handle vulnerability-related bugs, (ii) developers’ security-related skills should be profiled, to improve the efficiency of the security bug assignment tasks, and, consequently, reduce the re-assignments, and (iii) vulnerabilities require more effort, contributors and time to define the fixing strategy but smaller time to fix than canonical bugs.
Keywords: Security bugs; Process improvement; Software maintenance and evolution; Bug management; Empirical study

Antonio Muñoz, Ruben Ríos, Rodrigo Román, Javier López,
A survey on the (in)security of trusted execution environments,
Computers & Security,
Volume 129,
2023,
103180,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103180.
(https://www.sciencedirect.com/science/article/pii/S0167404823000901)
Abstract: As the number of security and privacy attacks continue to grow around the world, there is an ever increasing need to protect our personal devices. As a matter of fact, more and more manufactures are relying on Trusted Execution Environments (TEEs) to shield their devices. In particular, ARM TrustZone (TZ) is being widely used in numerous embedded devices, especially smartphones, and this technology is the basis for secure solutions both in industry and academia. However, as shown in this paper, TEE is not bullet-proof and it has been successfully attacked numerous times and in very different ways. To raise awareness among potential stakeholders interested in this technology, this paper provides an extensive analysis and categorization of existing vulnerabilities in TEEs and highlights the design flaws that led to them. The presented vulnerabilities, which are not only extracted from existing literature but also from publicly available exploits and databases, are accompanied by some effective countermeasures to reduce the likelihood of new attacks. The paper ends with some appealing challenges and open issues.
Keywords: Computer security; Secure hardware; Trusted execution environments; Hardware attacks; Software attacks; Side-channel attacks

Natalie Grattan, Daniel Alencar da Costa, Nigel Stanger,
The need for more informative defect prediction: A systematic literature review,
Information and Software Technology,
Volume 171,
2024,
107456,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2024.107456.
(https://www.sciencedirect.com/science/article/pii/S0950584924000612)
Abstract: Context:
Software defect prediction is crucial for prioritising quality assurance tasks, however, there are still limitations to the use of defect models. For example, the outputs often do not provide the defect type, severity, or the cause of the defect. Current models are also often complex in implementation (they use low transparency classifiers such as random forest or support vector machines) and primarily output binary predictions. They lack directly actionable outputs, that is, outputs that provide additional information (e.g., defect severity or defect type) to aid in fixing the defect. One approach is to utilise tools of explainable AI.
Objective:
In order to improve current models and plan the direction for explainability in software defect prediction, we need to understand how explainable current models are.
Methods:
Starting from 861 papers from multiple databases, we investigated a sample of 132 papers in a systematic literature review. We extracted the following information to answer our research questions: (i) information about the outputs (e.g., how informative they were) and explainability methods used, (ii) how explainability and performance is measured and (iii) explainability in future research. Our results were summarised by manually labelling the data so that trends could be analysed across selected papers, along with a thematic analysis.
Results:
We found that 71% of current models used binary outputs, while 68% of models were not yet utilising any explainability techniques. Only 7% of studies considered explainability in their future research suggestions.
Conclusion:
There is still a lack of awareness among researchers for the need for explainability and motivation to invest further research into more explainable and more informative software defect prediction models.
Keywords: Systematic literature review; Software quality; Software defect prediction; Explainable AI; Machine learning

Mazen Mohamad, Jan-Philipp Steghöfer, Eric Knauss, Riccardo Scandariato,
Managing security evidence in safety-critical organizations,
Journal of Systems and Software,
Volume 214,
2024,
112082,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2024.112082.
(https://www.sciencedirect.com/science/article/pii/S0164121224001274)
Abstract: With the increasing prevalence of open and connected products, cybersecurity has become a serious issue in safety-critical domains such as the automotive industry. As a result, regulatory bodies have become more stringent in their requirements for cybersecurity, necessitating security assurance for products developed in these domains. In response, companies have implemented new or modified processes to incorporate security into their product development lifecycle, resulting in a large amount of evidence being created to support claims about the achievement of a certain level of security. However, managing evidence is not a trivial task, particularly for complex products and systems. This paper presents a qualitative interview study conducted in six companies on the maturity of managing security evidence in safety-critical organizations. We find that the current maturity of managing security evidence is insufficient for the increasing requirements set by certification authorities and standardization bodies. Organizations currently fail to identify relevant artifacts as security evidence and manage this evidence on an organizational level. One part of the reason are educational gaps, the other a lack of processes. The impact of AI on the management of security evidence is still an open question.
Keywords: Security; Assurance; Evidence; Safety-critical

B. Arulmozhi, Dr. J I Sheeba, S. Pradeep Devaneyan,
Revolutionizing COVID-19 Management: Block chain-Enabled Prediction and Secure Storage using Deep Learning Techniques,
Procedia Computer Science,
Volume 230,
2023,
Pages 853-863,
ISSN 1877-0509,
https://doi.org/10.1016/j.procs.2023.12.047.
(https://www.sciencedirect.com/science/article/pii/S1877050923020379)
Abstract: The proposed research presents a blockchain-based healthcare system that seeks to address the limitations of current data-sharing methods by providing secure and efficient data transfer, enhancing data privacy and security, enabling effective data sharing interoperability, and promoting data-driven healthcare decision-making. A blockchain platform, IPFS, and rule-based access control are among the technologies suggested for use in the proposed system. Implementing this system could result in more personalized and effective medication for patients, as well as lower healthcare costs and improved care quality. The suggested approach, known as the Homomorphic Zero-Knowledge Blockchain Algorithm (HZBA), employs a block chain technique linked with Proxy Re Encryption with Homomorphic with Zero proof knowledge. Finally, the Covid19-dataset has collected from Kaggle repository and HCDNN method has used to complete the classification. The proposed blockchain-based healthcare system has the potential to revolutionize healthcare by resolving data privacy and security concerns, increasing data accuracy, fostering more interoperability in data sharing, and enhancing data-driven healthcare decision-making. The proposed blockchain-based healthcare system provides potential answers to data sharing difficulties in the healthcare business. One potential disadvantage is the system's complexity and cost of installation. The experimental results and classification performance parameters have been thoroughly demonstrated
Keywords: Blockchain; healthcare; data sharing; deep learning; COVID-19; security; prediction; privacy; data transfer; interoperability

Karthik Chandra Swarna, Noble Saji Mathews, Dheeraj Vagavolu, Sridhar Chimalakonda,
On the impact of multiple source code representations on software engineering tasks — An empirical study,
Journal of Systems and Software,
Volume 210,
2024,
111941,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111941.
(https://www.sciencedirect.com/science/article/pii/S0164121223003369)
Abstract: Efficiently representing source code is crucial for various software engineering tasks such as code classification and clone detection. Existing approaches primarily use Abstract Syntax Tree (AST), and only a few focus on semantic graphs such as Control Flow Graph (CFG) and Program Dependency Graph (PDG), which contain information about source code that AST does not. Even though some works tried to utilize multiple representations, they do not provide any insights about the costs and benefits of using multiple representations. The primary goal of this paper is to discuss the implications of utilizing multiple source code representations, specifically AST, CFG, and PDG. We modify an AST path-based approach to accept multiple representations as input to an attention-based model. We do this to measure the impact of additional representations (such as CFG and PDG) over AST. We evaluate our approach on three tasks: Method Naming, Program Classification, and Clone Detection. Our approach increases the performance on these tasks by 11% (F1), 15.7% (Accuracy), and 9.3% (F1), respectively, over the baseline. In addition to the effect on performance, we discuss timing overheads incurred with multiple representations. We envision that this work can provide a base for researchers to explore and experiment with a variety of source code representations for software engineering tasks.
Keywords: Source code representation; Abstract Syntax Tree; Control Flow Graph; Program Dependence Graph; Code embedding; Method naming

Behzad Soleimani Neysiani, Seyed Morteza Babamir, Masayoshi Aritsugi,
Efficient feature extraction model for validation performance improvement of duplicate bug report detection in software bug triage systems,
Information and Software Technology,
Volume 126,
2020,
106344,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2020.106344.
(https://www.sciencedirect.com/science/article/pii/S0950584920301117)
Abstract: Context
There are many duplicate bug reports in the semi-structured software repository of various software bug triage systems. The duplicate bug report detection (DBRD) process is a significant problem in software triage systems.
Objective
The DBRD problem has many issues, such as efficient feature extraction to calculate similarities between bug reports accurately, building a high-performance duplicate detector model, and handling continuous real-time queries. Feature extraction is a technique that converts unstructured data to structured data. The main objective of this study is to improve the validation performance of DBRD using a feature extraction model.
Method
This research focuses on feature extraction to build a new general model containing all types of features. Moreover, it introduces a new feature extractor method to describe a new viewpoint of similarity between texts. The proposed method introduces new textual features based on the aggregation of term frequency and inverse document frequency of text fields of bug reports in uni-gram and bi-gram forms. Further, a new hybrid measurement metric is proposed for detecting efficient features, whereby it is used to evaluate the efficiency of all features, including the proposed ones.
Results
The validation performance of DBRD was compared for the proposed features and state-of-the-art features. To show the effectiveness of our model, we applied it and other related studies to DBRD of the Android, Eclipse, Mozilla, and Open Office datasets and compared the results. The comparisons showed that our proposed model achieved (i) approximately 2% improvement for accuracy and precision and more than 4.5% and 5.9% improvement for recall and F1-measure, respectively, by applying the linear regression (LR) and decision tree (DT) classifiers and (ii) a performance of 91%−99% (average ~97%) for the four metrics, by applying the DT classifier as the best classifier.
Conclusion
Our proposed features improved the validation performance of DBRD concerning runtime performance. The pre-processing methods (primarily stemming) could improve the validation performance of DBRD slightly (up to 0.3%), but rule-based machine learning algorithms are more useful for the DBRD problem. The results showed that our proposed model is more effective both for the datasets for which state-of-the-art approaches were effective (i.e., Mozilla Firefox) and those for which state-of-the-art approaches were less effective (i.e., Android). The results also showed that the combination of all types of features could improve the validation performance of DBRD even for the LR classifier with less validation performance, which can be implemented easily for software bug triage systems. Without using the longest common subsequence (LCS) feature, which is effective but time-consuming, our proposed features could cover the effectiveness of LCS with lower time-complexity and runtime overhead. In addition, a statistical analysis shows that the results are reliable and can be generalized to other datasets or similar classifiers.
Keywords: Duplicate detection; Bug reports; Information retrieval; Feature selection; Dimension reduction; Natural language processing; Textual similarity metric; Feature extraction

Petar Afric, Lucija Sikic, Adrian Satja Kurdija, Marin Silic,
REPD: Source code defect prediction as anomaly detection,
Journal of Systems and Software,
Volume 168,
2020,
110641,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2020.110641.
(https://www.sciencedirect.com/science/article/pii/S0164121220301138)
Abstract: In this paper, we present a novel approach for within-project source code defect prediction. Since defect prediction datasets are typically imbalanced, and there are few defective examples, we treat defect prediction as anomaly detection. We present our Reconstruction Error Probability Distribution (REPD) model which can handle point and collective anomalies. We compare it on five different traditional code feature datasets against five models: Gaussian Naive Bayes, logistic regression, k-nearest-neighbors, decision tree, and Hybrid SMOTE-Ensemble. In addition, REPD is compared on 24 semantic features datasets against previously mentioned models. In order to compare the performance of competing models, we utilize F1-score measure. By using statistical means, we show that our model produces significantly better results, improving F1-score up to 7.12%. Additionally, REPD’s robustness to dataset imbalance is analyzed by creating defect undersampled and non-defect oversampled datasets.
Keywords: Defect prediction; Anomaly detection; REPD; Program analysis

Yao Tong, Xiaofang Zhang,
Crowdsourced test report prioritization considering bug severity,
Information and Software Technology,
Volume 139,
2021,
106668,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2021.106668.
(https://www.sciencedirect.com/science/article/pii/S0950584921001300)
Abstract: In crowdsourced testing, a large number of test reports will be generated in a short time. How to efficiently inspect these reports becomes one of the critical steps in the testing process. In recent years, many automated techniques like clustering, classification, and prioritization have emerged to provide an automated inspection order over test reports. Even though these methods have achieved good performance, they did not consider the priority to image and text information. Simultaneously, existing prioritization approaches only focus on the rate of detecting faults but ignore the severity of the faults. In fact, bug severity is a vital indicator that the users provide to flag the criticality of a bug, so developers can then use it to set their priority for the resolution process. For these reasons, this paper presents a novel prioritization approach for crowdsourcing test reports. It extracts features from text and screenshot information of the test reports, uses the hash technique to index test reports, and finally designs a prioritization algorithm. To validate our approach, we conducted experiments on six industrial projects. The results and the hypotheses analysis show that our approach can detect all faults faster in a limited time and can prioritize reports that have higher severity faults compared with the existing methods.
Keywords: Crowdsourced testing; Test report processing; Prioritization; Bug severity; Textual description

José Carlos Sancho, Andrés Caro, Mar Ávila, Alberto Bravo,
New approach for threat classification and security risk estimations based on security event management,
Future Generation Computer Systems,
Volume 113,
2020,
Pages 488-505,
ISSN 0167-739X,
https://doi.org/10.1016/j.future.2020.07.015.
(https://www.sciencedirect.com/science/article/pii/S0167739X20301849)
Abstract: Security Information and Event Management (SIEM) systems are essential for identifying cyber attacks, being an extended practice in organizations to detect threats, vulnerabilities and to estimate security risks. The management of events and information related to security is done through systems that provide all the information, processing different data sources. The developing of alternative models that provide complementary information to commercial solutions, based on the same data sources, is presented as a novel and interesting challenge, not only for organizations, but also for the scientific community. This paper presents a new system to classify security threats, computing their criticality according to the Bug Bar technique, with the aim of addressing threats in order of priority. High correlations were achieved between severity risk values achieved from commercial systems and results computed by the new approach. Accordingly, the new proposal could complement the information of SIEM systems, and help in the prediction of criticalities of future threats.
Keywords: SIEM; Cybersecurity; STRIDE; Knowledge extraction; Data processing; Bug bar

Bingjie Liu, Hany Kim, Lori Pennington-Gray,
Responding to the bed bug crisis in social media,
International Journal of Hospitality Management,
Volume 47,
2015,
Pages 76-84,
ISSN 0278-4319,
https://doi.org/10.1016/j.ijhm.2015.03.005.
(https://www.sciencedirect.com/science/article/pii/S0278431915000365)
Abstract: The increasing trend in social media changes the landscape of crisis communication and thus, calls for innovation in hotel crisis management practices. This research examined how New York City hotels responded to recent issues surrounding the bed bug crisis on the social media site TripAdviosr. This study adopted a mixed methods research design. The quantitative findings revealed that hotels’ response behaviors were associated with organizational factors (e.g. hotel's popularity, average rating, and star rating) and the rating of online reviews. The qualitative findings indicated that hotels employed various types of strategies in the response, which were dominated by strategies of bolstering and enhancing. In conclusion, this study addressed the need for a proactive approach in hotel crisis management and provided practical implications.
Keywords: Hotel crisis management; New York City; Bed bug crisis; Social media; Crisis communication; Health-related crisis

Houda Harkat, Luis M. Camarinha-Matos, João Goes, Hasmath F.T. Ahmed,
Cyber-physical systems security: A systematic review,
Computers & Industrial Engineering,
Volume 188,
2024,
109891,
ISSN 0360-8352,
https://doi.org/10.1016/j.cie.2024.109891.
(https://www.sciencedirect.com/science/article/pii/S0360835224000123)
Abstract: In recent years, cyber-physical systems (CPS) have been to many vital areas, including medical devices, smart cars, industrial systems, energy grid, etc. As these systems increasingly rely on Internet, ensuring their security requirements, which are different from those of ordinary information technology systems, has become an important research topic. However, the area is not yet well structured and, therefore, it is essential to review and analyze recent work in this field to better understand the adopted approaches and also to identify corresponding gaps and future interesting research directions. This article is based on a systematic literature review that addresses core issues in CPS security. Part of the focus is placed on the defense mechanisms introduced to help the system fully recover from attacks. However, the framework devoted to risk/threat assessments has also been highlighted, as there is a substantial need to strengthen the systems architecture to be more proactive. In addition, the ethical and societal impact of CPS is emphasized since it is essential to get a vision of the unintended outcomes of the possible evolution of these systems.
Keywords: Cyber-physical systems; Security; Vulnerabilities; Attacks/threats; Defense mechanisms

Xiaoxue Wu, Wei Zheng, Xiang Chen, Yu Zhao, Tingting Yu, Dejun Mu,
Improving high-impact bug report prediction with combination of interactive machine learning and active learning,
Information and Software Technology,
Volume 133,
2021,
106530,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2021.106530.
(https://www.sciencedirect.com/science/article/pii/S0950584921000185)
Abstract: Context:
Bug reports record issues found during software development and maintenance. A high-impact bug report (HBR) describes an issue that can cause severe damage once occurred after deployment. Identifying HBRs from the bug repository as early as possible is crucial for guaranteeing software quality.
Objective:
In recent years, many machine learning-based approaches have been proposed for HBR prediction, and most of them are based on supervised machine learning. However, the assumption of supervised machine learning is that it needs a large number of labeled data, which is often difficult to gather in practice.
Method:
In this paper, we propose hbrPredictor, which combines interactive machine learning and active learning to HBR prediction. On the one hand, it can dramatically reduce the number of bug reports required for prediction model training; on the other hand, it improves the diversity and generalization ability of training samples via uncertainty sampling.
Result:
We take security bug report (SBR) prediction as an example of HBR prediction and perform a large-scale experimental evaluation on datasets from different open-source projects. The results show: (1) hbrPredictor substantially outperforms the two baselines and obtains the maximum values of F1-score (0.7939) and AUC (0.8789); (2) with the dynamic stop criteria, hbrPredictor could reach its best performance with only 45% and 13% of the total bug reports for small-sized datasets and large-sized datasets, respectively.
Conclusion:
By reducing the number of required training samples, hbrPredictor could substantially save the data labeling effort without decreasing the effectiveness of the model.
Keywords: High-impact bug report; Interactive machine learning; Active learning; Uncertainty-sampling; Security bug report prediction

Yi-Ting Yang, Se Jin Lee, Yu-Shin Nai, Sihyeon Kim, Jae Su Kim,
Up-regulation of carbon metabolism-related glyoxylate cycle and toxin production in Beauveria bassiana JEF-007 during infection of bean bug, Riptortus pedestris (Hemiptera: Alydidae),
Fungal Biology,
Volume 120, Issue 10,
2016,
Pages 1236-1248,
ISSN 1878-6146,
https://doi.org/10.1016/j.funbio.2016.07.008.
(https://www.sciencedirect.com/science/article/pii/S1878614616300848)
Abstract: Beauveria bassiana (Bb) is used as an environment-friendly biopesticide. However, the molecular mechanisms of Bb-host interactions are not well understood. Herein, RNA isolated from B. bassiana (Bb JEF-007) and Riptortus pedestris (Hemiptera: Alydidae) infected with this strain were firstly subjected to high-throughput next generation sequencing (NGS) to analyze and compare transcriptomes. Due to lack of fungal and host genome information, fungal transcriptome was processed to partially exclude non-infection specific genes and host-flora. Differentially Expressed Gene (DEG) analysis showed that 2381 genes were up-regulated and 2303 genes were down-regulated upon infection. Most DEGs were classified into the categories of single-organism, cellular and metabolism processes by Gene Ontology analysis. Most DEGs were involved in metabolic pathways based on Kyoto Encyclopedia of Genes and Genomes pathway mapping. Carbon metabolism-related enzymes in the glyoxylate cycle were significantly up-regulated, suggesting a possible role for them in Bb growth in the host. Additionally, transcript levels of several fungal genes were dramatically increased after infection, such as cytotoxic lectin-like protein, bacterial-like toxin, proteins related to cell wall formation, hyphal growth, nutrient uptake, and halogenated compound synthesis. This work provides insight into how entomopathogenic B. bassiana grows in agriculturally harmful bean bug at 6 d post infection.
Keywords: Differentially expressed gene; Entomopathogenic fungi; Next generation sequencing; Transcriptome

Wentao Wang, Kavya Reddy Mahakala, Arushi Gupta, Nesrin Hussein, Yinglin Wang,
A linear classifier based approach for identifying security requirements in open source software development,
Journal of Industrial Information Integration,
Volume 14,
2019,
Pages 34-40,
ISSN 2452-414X,
https://doi.org/10.1016/j.jii.2018.11.001.
(https://www.sciencedirect.com/science/article/pii/S2452414X17301000)
Abstract: There are several security requirements identification methods proposed by researchers in up-front requirements engineering (RE). However, in open source software (OSS) projects, developers use lightweight representation and refine requirements frequently by writing comments. They also tend to discuss security aspect in comments by providing code snippets, attachments, and external resource links. Since most security requirements identification methods in up-front RE are based on textual information retrieval techniques, these methods are not suitable for OSS projects or just-in-time RE. In this study, we proposed a linear based approach to identify security requirements. It first uses logistic regression models (RMs) to calculate feature values for requirements in OSS project. Then it uses the linear combination of all feature values to classify security and non-security requirements Our results show that compares to single RMs, our approach can achieve higher recall and precision.

Phuong T. Nguyen, Juri Di Rocco, Claudio Di Sipio, Riccardo Rubei, Davide Di Ruscio, Massimiliano Di Penta,
GPTSniffer: A CodeBERT-based classifier to detect source code written by ChatGPT,
Journal of Systems and Software,
Volume 214,
2024,
112059,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2024.112059.
(https://www.sciencedirect.com/science/article/pii/S0164121224001043)
Abstract: Since its launch in November 2022, ChatGPT has gained popularity among users, especially programmers who use it to solve development issues. However, while offering a practical solution to programming problems, ChatGPT should be used primarily as a supporting tool (e.g., in software education) rather than as a replacement for humans. Thus, detecting automatically generated source code by ChatGPT is necessary, and tools for identifying AI-generated content need to be adapted to work effectively with code. This paper presents GPTSniffer– a novel approach to the detection of source code written by AI – built on top of CodeBERT. We conducted an empirical study to investigate the feasibility of automated identification of AI-generated code, and the factors that influence this ability. The results show that GPTSniffer can accurately classify whether code is human-written or AI-generated, outperforming two baselines, GPTZero and OpenAI Text Classifier. Also, the study shows how similar training data or a classification context with paired snippets helps boost the prediction. We conclude that GPTSniffer can be leveraged in different contexts, e.g., in software engineering education, where teachers use the tool to detect cheating and plagiarism, or in development, where AI-generated code may require peculiar quality assurance activities.
Keywords: ChatGPT; Code classification; CodeBERT; Pre-trained Models

Thomas Hirsch, Birgit Hofer,
A systematic literature review on benchmarks for evaluating debugging approaches,
Journal of Systems and Software,
Volume 192,
2022,
111423,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2022.111423.
(https://www.sciencedirect.com/science/article/pii/S0164121222001303)
Abstract: Bug benchmarks are used in development and evaluation of debugging approaches, e.g. fault localization and automated repair. Quantitative performance comparison of different debugging approaches is only possible when they have been evaluated on the same dataset or benchmark. However, benchmarks are often specialized towards usage for certain debugging approaches in their contained data, metrics, and artifacts. Such benchmarks cannot be easily used on debugging approaches outside their scope as such approach may rely on specific data such as bug reports or code metrics that are not included in the dataset. Furthermore, benchmarks vary in their size w.r.t. the number of subject programs and the size of the individual subject programs. For these reasons, we have performed a systematic literature review where we have identified 73 benchmarks that can be used to evaluate debugging approaches. We compare the different benchmarks w.r.t. their size and the provided information such as bug reports, contained test cases, and other code metrics. This comparison is intended to help researchers to quickly identify all suitable benchmarks for evaluating their specific debugging approaches. Furthermore, we discuss reoccurring issues and challenges in selection, acquisition, and usage of such bug benchmarks, i.e., data availability, data quality, duplicated content, data formats, reproducibility, and extensibility. Editor’s note: Open Science material was validated by the Journal of Systems and Software Open Science Board.
Keywords: Debugging; Benchmark; Fault localization; Automatic repair

Reza Gharibi, Mohammad Hadi Sadreddini, Seyed Mostafa Fakhrahmad,
T5APR: Empowering automated program repair across languages through checkpoint ensemble,
Journal of Systems and Software,
Volume 214,
2024,
112083,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2024.112083.
(https://www.sciencedirect.com/science/article/pii/S0164121224001286)
Abstract: Automated program repair (APR) using deep learning techniques has become an important area of research in recent years, aiming to automatically generate bug-fixing patches that can improve software reliability and maintainability. However, most existing methods either target a single language or require high computational resources to train multilingual models. In this paper, we propose T5APR, a novel neural program repair approach that provides a unified solution for bug fixing across multiple programming languages. T5APR leverages CodeT5, a powerful pre-trained text-to-text transformer model, and adopts a checkpoint ensemble strategy to improve patch recommendation. We conduct comprehensive evaluations on six well-known benchmarks in four programming languages (Java, Python, C, JavaScript), demonstrating T5APR’s competitiveness against state-of-the-art techniques. T5APR correctly fixes 1,985 bugs, including 1,442 bugs that none of the compared techniques has fixed. We further support the effectiveness of our approach by conducting detailed analyses, such as comparing the correct patch ranking among different techniques. The findings of this study demonstrate the potential of T5APR for use in real-world applications and highlight the importance of multilingual approaches in the field of APR.
Keywords: Automated program repair; Neural program repair; Deep learning; Transformer

Xiangping Chen, Furen Xu, Yuan Huang, Xiaocong Zhou, Zibin Zheng,
An empirical study of code reuse between GitHub and stack overflow during software development,
Journal of Systems and Software,
Volume 210,
2024,
111964,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2024.111964.
(https://www.sciencedirect.com/science/article/pii/S0164121224000074)
Abstract: With the rise of programming Q&A websites (e.g., Stack Overflow) and the open-source movement, code reuse has become a common phenomenon. Our study aims to provide a comprehensive study of the code reuse behavior of programmers during software development, i.e., we mainly focus on the code reuse between the code snippets in the commits of open-source projects and the code snippets on Stack Overflow (SO). The open-source java project code dataset we construct contains 793 projects which include 342,148 modified code snippets, and the SO code dataset includes 1,355,617 posts. Then, we employ a code clone detection tool to identify the instances of code reuse between the modified code snippets of commits and the code snippets of the SO posts. We find that the average code reuse ratio of the projects is 6.32%, which will have a significant upward trend in the future. Additionally, we find that experienced developers seem to be more likely to reuse the code on SO, and prefer to reuse posts with more favorites and higher scores. We combine deep learning and topic analysis algorithms to fully exploit the semantic information of SO posts. The result shows a certain difference in the distribution of post types reused by bug-related commits and non-bug-related commits. We also discover that the code reuse ratio (14.44%) in java class files that have undergone multiple modifications is more than double the overall code reuse ratio (6.32%). Finally, we discuss the reuse habits of programmers and find that they may refer to multiple posts in one reuse, and these posts are related to a certain extent. From these results, our study provides multiple practical insights for different stakeholders: researchers, developers, and the SO platform.
Keywords: Stack overflow; Code reuse; Code clone; Semantic analysis

Sekione Reward Jeremiah, Abir El Azzaoui, Neal N. Xiong, Jong Hyuk Park,
A comprehensive survey of digital twins: Applications, technologies and security challenges,
Journal of Systems Architecture,
Volume 151,
2024,
103120,
ISSN 1383-7621,
https://doi.org/10.1016/j.sysarc.2024.103120.
(https://www.sciencedirect.com/science/article/pii/S1383762124000572)
Abstract: Alongside advancements in Artificial Intelligence (AI), significant progress has been made in big data processing, edge/cloud computing, and ubiquitous computing in the past two decades. These advancements catalyzed the development and adoption of Digital Twins (DT) across various domains, serving as virtual replicas of Physical Objects (POs). DTs provide advanced visualization and simulation capabilities, enabling effective estimation, optimization, and forecasting of PO's behaviors. However, the widespread adoption of DTs has introduced various security threats, vulnerabilities, and attacks. Despite ongoing research in DT applications and security, there is a lack of systematic review of the DT security literature across domains and architectural layers. This study fills this gap by systematically reviewing DT research, focusing on three interrelated aspects: DT applications, architectural layers, and security. We explore DT's architectural layers, functional requirements, application, and creation software to identify potential threats, attacks, and vulnerabilities specific to DT layers and application domains. We then systematize our findings under a unified security framework and pinpoint countermeasures against identified security challenges. Furthermore, our study explores DT's role in mitigating existing cyber threats, and we conclude our work by identifying open challenges and potential research directions.
Keywords: Digital twin; Virtual twin; Digital twin security; Digital twin network; Digital twin modeling; DT enabling technologies

Shaymaa E. Sorour, Hanan E. Abdelkader, Karam M. Sallam, Ripon K. Chakrabortty, Michael J. Ryan, Amr Abohany,
An analytical code quality methodology using Latent Dirichlet Allocation and Convolutional Neural Networks,
Journal of King Saud University - Computer and Information Sciences,
Volume 34, Issue 8, Part B,
2022,
Pages 5979-5997,
ISSN 1319-1578,
https://doi.org/10.1016/j.jksuci.2022.01.013.
(https://www.sciencedirect.com/science/article/pii/S131915782200026X)
Abstract: Recently, Code Quality (CQ) has become critical in a wide range of organizations and in many areas from academia to industry. CQ, in terms of readability, security, and testability, is a major goal throughout the software development process because it affects overall Software Quality (SQ) in terms of subsequent releases, maintenance, and updates. It is particularly important for the development of safety critical systems. Existing studies on CQ have several shortcomings in that they are based on incomplete information about the source code, and tend to focus on only one feature, which is likely to determine the performance of the model. Moreover, these considerations often limit obtaining high accuracy because there is no strong relationship between the input data and the output data. Thus, it is necessary to design an effective and efficient SQ measurement system for measuring multiple quality factors. To that end, we propose a deep learning framework that employed a Latent Dirichlet Allocation (LDA) with Convolutional Neural Networks (CNN), called CNN-LDA, to classify input data into topics that are related to CQ features and to identify hidden patterns and correlations in programming data. Three SQ metrics (i.e., readability, security, and testability) and machine learning techniques (e.g., random forest (RF) and support vector machine (SVM)) are taken into account to validate the proposed model. The proposed CNN-LDA outperformed its peers across the vast majority of datasets examined. The average overall F-measure for readability, security, and testability are 94%,94% and 93%. The average overall accuracy for readability, security, and testability are 93%,93% and 92%. The superiority of LDA-CNN over the other classifiers was very clear based on a Wilcoxon’s non-parametric statistical test (α=0.05).
Keywords: Code Quality (CQ); Latent Dirichlet Allocation (LDA); Convolutional Neural Networks (CNN); Deep Learning (DL); Classification

Alan Mills, Jonathan White, Phil Legg,
Longitudinal risk-based security assessment of docker software container images,
Computers & Security,
Volume 135,
2023,
103478,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103478.
(https://www.sciencedirect.com/science/article/pii/S0167404823003887)
Abstract: As the use of software containerisation has increased, so too has the need for security research on their usage, with various surveys and studies conducted to assess the overall security posture of software container images. To date, there has been very little work that has taken a longitudinal view of container security to observe whether vulnerabilities are being resolved over time, as well as understanding the real-world implications of reported vulnerabilities, to assess the evolving security posture. In this work, we study the evolution of 380 software container images across 3 analysis periods between July 2022 and January 2023 to analyse maintenance and vulnerabilities factors over time. We sample across the 3 DockerHub categories: Official, Verified and OSS (Sponsored) Open Source Software. We found that the number of vulnerabilities present increased over time despite many containers receiving regular updates by providers. We also found that the choice of container OS can dramatically impact the number of reported vulnerabilities present over time, with Debian-based images typically having many more vulnerabilities that other Linux distributions, and with some containers still reporting vulnerabilities that date back as far as 1999. However, when taking into account additional reported attributes such as the attack vector required and the existence of a public exploit rated higher than negligible, we found that for each analysis period, less than 1% of all vulnerabilities present what we would consider as high risk real-world impact. Through our investigation, we aim to improve the understanding of the threat landscape posed by software containerisation that is further complicated by the discrepancies between different vulnerability reporting tools.
Keywords: Container security; Vulnerability analysis; CVE

Weijing Wang, Junjie Chen, Lin Yang, Hongyu Zhang, Zan Wang,
Understanding and predicting incident mitigation time,
Information and Software Technology,
Volume 155,
2023,
107119,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2022.107119.
(https://www.sciencedirect.com/science/article/pii/S0950584922002282)
Abstract: Context:
Incident management plays a significant role in online service systems. Incidents should be mitigated as soon as possible in order to achieve high service stability. However, available resources tend to be limited, and thus engineers have to schedule their tasks carefully. Time to Mitigate (TTM) refers to the time an incident requires to restore the service availability. Predicting TTM can help better estimate maintenance efforts and provide developers more information when arranging their tasks.
Objective:
Our work aims to predict TTM precisely, which consists of two main steps. First, we perform an empirical study to understand incidents deeply. Then, we design an effective approach for TTM prediction based on the findings from the empirical study.
Methods:
In the empirical study, we used 20 Microsoft online service systems to investigate the duration of each stage in incident management and the relationship between TTM and incident indicators. Then, we propose TTMPred, a deep-learning-based approach for TTM prediction in the continuous triage scenario based on the features identified from our empirical study. In particular, we improve the generality of TTMPred by extending it to predicting the fixing time of traditional software bugs.
Results:
We investigate the effectiveness of TTMPred on four large-scale online service systems in Microsoft, as well as four widely-used Bugzilla-based projects. The results show that TTMPred performs better than the compared approaches for both incident TTM prediction and bug-fixing time prediction. For example, on average, TTMPred improves the state-of-the-art regression-based approach by 25.66% in terms of MAE (Mean Absolute Error) on the incident data and 42.14% on MAE on the bug data.
Conclusion:
TTMPred can be extended to the bug scenario, and continuously predict accurate bug-fixing time during the triage process.
Keywords: Incident management; Online service systems; Bug-fixing time; Effort estimation; Software maintenance

Ricardo J. Rodríguez, Stefano Marrone, Ibai Marcos, Giuseppe Porzio,
MOSTO: A toolkit to facilitate security auditing of ICS devices using Modbus/TCP,
Computers & Security,
Volume 132,
2023,
103373,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103373.
(https://www.sciencedirect.com/science/article/pii/S0167404823002833)
Abstract: The integration of the Internet into industrial plants has connected Industrial Control Systems (ICS) worldwide, resulting in an increase in the number of attack surfaces and the exposure of software and devices not originally intended for networking. In addition, the heterogeneity and technical obsolescence of ICS architectures, legacy hardware, and outdated software pose significant challenges. Since these systems control essential infrastructure such as power grids, water treatment plants, and transportation networks, security is of the utmost importance. Unfortunately, current methods for evaluating the security of ICS are often ad-hoc and difficult to formalize into a systematic evaluation methodology with predictable results. In this paper, we propose a practical method supported by a concrete toolkit for performing penetration testing in an industrial setting. The primary focus is on the Modbus/TCP protocol as the field control protocol. Our approach relies on a toolkit, named MOSTO, which is licensed under GNU GPL and enables auditors to assess the security of existing industrial control settings without interfering with ICS workflows. Furthermore, we present a model-driven framework that combines formal methods, testing techniques, and simulation to (formally) test security properties in ICS networks.
Keywords: Industrial control systems; Penetration testing; Security auditing; Modbus

Luiz Alberto Ferreira Gomes, Ricardo da Silva Torres, Mario Lúcio Côrtes,
On the prediction of long-lived bugs: An analysis and comparative study using FLOSS projects,
Information and Software Technology,
Volume 132,
2021,
106508,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2020.106508.
(https://www.sciencedirect.com/science/article/pii/S0950584920302482)
Abstract: Context:
Software evolution and maintenance activities in today’s Free/Libre Open Source Software (FLOSS) rely primarily on information extracted from bug reports registered in bug tracking systems. Many studies point out that most bugs that adversely affect the user’s experience across versions of FLOSS projects are long-lived bugs. However, proposed approaches that support bug fixing procedures do not consider the real-world lifecycle of a bug, in which bugs are often fixed very fast. This may lead to useless efforts to automate the bug management process.
Objective:
This study aims to confirm whether the number of long-lived bugs is significantly high in popular open-source projects and to characterize the population of long-lived bugs by considering the attributes of bug reports. We also aim to conduct a comparative study evaluating the prediction accuracy of five well-known machine learning algorithms and text mining techniques in the task of predicting long-lived bugs.
Methods:
We collected bug reports from six popular open-source projects repositories (Eclipse, Freedesktop, Gnome, GCC, Mozilla, and WineHQ) and used the following machine learning algorithms to predict long-lived bugs: K-Nearest Neighbor, Naïve Bayes, Neural Networks, Random Forest, and Support Vector Machines.
Results:
Our results show that long-lived bugs are relatively frequent (varying from 7.2% to 40.7%) and have unique characteristics, confirming the need to study solutions to support bug fixing management. We found that the Neural Network classifier yielded the best results in comparison to the other algorithms evaluated.
Conclusion:
Research efforts regarding long-lived bugs are needed and our results demonstrate that it is possible to predict long-lived bugs with a high accuracy (around 70.7%) despite the use of simple prediction algorithms and text mining methods.
Keywords: Software maintenance; Bug Tracking System; Long-lived bugs; Machine learning; Text mining

Wenkai Li, Jiuyang Bu, Xiaoqi Li, Hongli Peng, Yuanzheng Niu, Yuqing Zhang,
A survey of DeFi security: Challenges and opportunities,
Journal of King Saud University - Computer and Information Sciences,
Volume 34, Issue 10, Part B,
2022,
Pages 10378-10404,
ISSN 1319-1578,
https://doi.org/10.1016/j.jksuci.2022.10.028.
(https://www.sciencedirect.com/science/article/pii/S1319157822003792)
Abstract: DeFi, or Decentralized Finance, is based on a distributed ledger called blockchain technology. Using blockchain, DeFi may customize the execution of predetermined operations between parties. The DeFi system use blockchain technology to execute user transactions, such as lending and exchanging. The total value locked in DeFi decreased from $200 billion in April 2022 to $80 billion in July 2022, indicating that security in this area remained problematic. In this paper, we address the deficiency in DeFi security studies. To our best knowledge, our paper is the first to make a systematic analysis of DeFi security. First, we summarize the DeFi-related vulnerabilities in each blockchain layer. Additionally, application-level vulnerabilities are also analyzed. Then we classify and analyze real-world DeFi attacks based on the principles that correlate to the vulnerabilities. In addition, we collect optimization strategies from the data, network, consensus, smart contract, and application layers. And then, we describe the weaknesses and technical approaches they address. On the basis of this comprehensive analysis, we summarize several challenges and possible future directions in DeFi to offer ideas for further research.
Keywords: Blockchain; Cryptocurrency; Decentralized finance; Smart contract

Yangyang Zhao, Mingyue Jiang, Yibiao Yang, Yuming Zhou, Hanjie Ma, Zuohua Ding,
Towards an understanding of intra-defect associations: Implications for defect prediction,
Journal of Systems and Software,
Volume 207,
2024,
111858,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111858.
(https://www.sciencedirect.com/science/article/pii/S0164121223002534)
Abstract: In previous studies, when collecting defect data, if the fix of a defect spans multiple modules, each involved module is labeled as defective. In this context, the defect prediction models are built based on the features of each individual module, ignoring the potential associations between the modules involved in the same defect(referred to as “intra-defect associations”). Considering the possibility of numerous cross-module defects in practice, we hypothesize that these intra-defect associations could play a crucial role in enhancing defect prediction performance. Unfortunately, there is no empirical evidence to know that. To this end, we are motivated to conduct a comprehensive study to explore the implications of intra-defect associations for defect prediction. We first examine the proportion of cross-module defects and the relationships between the involved modules. The results reveal that, at function level, the majority of defects occur across functions, with most of the cross-module defects exhibiting implicit dependencies. Inspired by these findings, we propose a novel data processing approach for building defect prediction models. This approach leverages the intra-defect associations by merging the involved modules into new instances with mean or median variables to augment the training data. The experimental results indicate that considering intra-defect associations can significantly improve the defect prediction performance in both the ranking and classification scenarios. This study provides valuable insights into the implications of intra-defect associations for defect prediction.
Keywords: Defect prediction; Intra-defect association; Data processing; Software quality

Kisub Kim, Sankalp Ghatpande, Kui Liu, Anil Koyuncu, Dongsun Kim, Tegawendé F. Bissyandé, Jacques Klein, Yves Le Traon,
DigBug—Pre/post-processing operator selection for accurate bug localization,
Journal of Systems and Software,
Volume 189,
2022,
111300,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2022.111300.
(https://www.sciencedirect.com/science/article/pii/S0164121222000528)
Abstract: Bug localization is a recurrent maintenance task in software development. It aims at identifying relevant code locations (e.g., code files) that must be inspected to fix bugs. When such bugs are reported by users, the localization process become often overwhelming as it is mostly a manual task due to incomplete and informal information (written in natural languages) available in bug reports. The research community has then invested in automated approaches, notably using Information Retrieval techniques. Unfortunately, reported performance in the literature is still limited for practical usage. Our key observation, after empirically investigating a large dataset of bug reports as well as workflow and results of state-of-the-art approaches, is that most approaches attempt localization for every bug report without considering the different characteristics of the bug reports. We propose DigBug as a straightforward approach to specialized bug localization. This approach selects pre/post-processing operators based on the attributes of bug reports; and the bug localization model is parameterized in accordance as well. Our experiments confirm that departing from “one-size-fits-all” approaches, DigBug outperforms the state-of-the-art techniques by 6 and 14 percentage points, respectively in terms of MAP and MRR on average.
Keywords: Bug report; Bug localization; Fault localization; Bug characteristics; Information retrieval; Operator combination

Fanlong Zhang, Yi Che, Tiancai Liang, Wenchao Jiang,
Clone consistent-defect prediction based on deep learning method,
Information Sciences,
Volume 633,
2023,
Pages 357-369,
ISSN 0020-0255,
https://doi.org/10.1016/j.ins.2023.03.007.
(https://www.sciencedirect.com/science/article/pii/S0020025523003031)
Abstract: Many consistent changes take place across code clones in software, and this has emerged as a severe issue for software security. If the developers forget to modify the relevant clones consistently, such modifications will introduce consistent-defect. Researchers leverage machine learning techniques to predict clone consistent-defect by representing these changes with the designed attributes. Meanwhile, deep learning technology has demonstrated tremendous potential in characterizing source code. As such, we explore whether deep learning technology can enhance the effectiveness of clone consistent-defect prediction. In this study, we investigate various neural networks for modeling clone consistent change. Specifically, our approach models code clones and their evolution to capture the semantic properties automatically from the perspectives of clone fragment, clone group, and clone evolution, as opposed to manually generated attributes. To evaluate the effectiveness of our approach, we conduct an experiment on the dataset collected from 8 open-source projects. The results demonstrate that our neural network models are efficient both in cross-project and within-project scenarios, with F-measures of around 80% and recalls of around 90%. We conclude that deep learning technology may successfully assist developers in predicting clone consistent-defect, so helping to improve the security of code clones by alerting developers to confirm their consistency.
Keywords: Clone consistent change; Consistent-defect; Software maintenance; Software safety; Deep learning

W. Eric Wong, Xuelin Li, Philip A. Laplante,
Be more familiar with our enemies and pave the way forward: A review of the roles bugs played in software failures,
Journal of Systems and Software,
Volume 133,
2017,
Pages 68-94,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2017.06.069.
(https://www.sciencedirect.com/science/article/pii/S0164121217301334)
Abstract: There has been an increasing frequency of failures due to defective software that cost millions of dollars. Recent high profile incidents have drawn increased attention to the risks of failed software systems to the public. Yet aside from the Therac-25 case, very few incidents of software failure causing humans harm have been proven and widely reported. With increased government oversight and the expanded use of social networking for real time reporting of problems, we are only beginning to understand the potential for major injury or death related to software failures. However, debugging defective software can be costly and time consuming. Moreover, undetected bugs could induce great harm to the public when software systems are applied in safety-critical areas, such as consumer products, public infrastructure, transportation systems, etc. Therefore, it is vital that we remove these bugs as early as possible. To gain more understanding of the nature of these bugs, we review the reported software failures that have impacted the health, safety, and welfare of the public. A focus on lessons learned and implications for future software systems is also provided which acts as guidelines for engineers to improve the quality of their products and avoid similar failures from happening.
Keywords: Accidents; Bugged software systems; Software failures; Mishaps; Lessons learned

Yuan Huang, Xinyu Hu, Nan Jia, Xiangping Chen, Zibin Zheng, Xiapu Luo,
CommtPst: Deep learning source code for commenting positions prediction,
Journal of Systems and Software,
Volume 170,
2020,
110754,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2020.110754.
(https://www.sciencedirect.com/science/article/pii/S0164121220301758)
Abstract: Existing techniques for automatic code commenting assume that the code snippet to be commented has been identified, thus requiring users to provide the code snippet in advance. A smarter commenting approach is desired to first self-determine where to comment in a given source code and then generate comments for the code snippets that need comments. To achieve the first step of this goal, we propose a novel method, CommtPst, to automatically find the appropriate commenting positions in the source code. Since commenting is closely related to the code syntax and semantics, we adopt neural language model (word embeddings) to capture the code semantic information, and analyze the abstract syntax trees to capture code syntactic information. Then, we employ LSTM (long short term memory) to model the long-term logical dependency of code statements over the fused semantic and syntactic information and learn the commenting patterns on the code sequence. We evaluated CommtPst using large data sets from dozens of open-source software systems in GitHub. The experimental results show that the precision, recall and F-Measure values achieved by CommtPst are 0.792, 0.602 and 0.684, respectively, which outperforms the traditional machine learning method with 11.4% improvement on F-measure.
Keywords: Comment position; LSTM; Code syntax; Code semantics; Comment generation

Zeinab Abou Khalil, Eleni Constantinou, Tom Mens, Laurence Duchien,
On the impact of release policies on bug handling activity: A case study of Eclipse,
Journal of Systems and Software,
Volume 173,
2021,
110882,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2020.110882.
(https://www.sciencedirect.com/science/article/pii/S0164121220302727)
Abstract: Large software projects follow a continuous development process with regular releases during which bugs are handled. In recent years, many software projects shifted to rapid releases that reduce time-to-market and claim a faster delivery of fixed issues, but also have a shorter period to address bugs. To better understand the impact of rapid releases on bug handling activity, we empirically analyze successive releases of the Eclipse Core projects, focusing on the bug handling rates and durations as well as the feature freeze period. We study the impact of Eclipse’s transition from a yearly to quarterly release cycle. We confirm our findings through feedback received from five Eclipse Core maintainers. Among others, our results reveal that Eclipse’s bug handling process is becoming more stable over time, with a decreasing number of reported bugs before releases, an increasing bug fixing rate and an increasingly balanced bug handling workload before and after releases. The transition to a quarterly release cycle continued to improve bug handling. In addition, more effort is spent on bug fixing during the feature freeze period, while the bug handling rates do not differ between both periods.
Keywords: Bug handling process; Rapid release cycle; Feature freeze; Continuous software development; Software maintenance; Empirical software engineering

Tushar Sharma, Maria Kechagia, Stefanos Georgiou, Rohit Tiwari, Indira Vats, Hadi Moazen, Federica Sarro,
A survey on machine learning techniques applied to source code,
Journal of Systems and Software,
Volume 209,
2024,
111934,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111934.
(https://www.sciencedirect.com/science/article/pii/S0164121223003291)
Abstract: The advancements in machine learning techniques have encouraged researchers to apply these techniques to a myriad of software engineering tasks that use source code analysis, such as testing and vulnerability detection. Such a large number of studies hinders the community from understanding the current research landscape. This paper aims to summarize the current knowledge in applied machine learning for source code analysis. We review studies belonging to twelve categories of software engineering tasks and corresponding machine learning techniques, tools, and datasets that have been applied to solve them. To do so, we conducted an extensive literature search and identified 494 studies. We summarize our observations and findings with the help of the identified studies. Our findings suggest that the use of machine learning techniques for source code analysis tasks is consistently increasing. We synthesize commonly used steps and the overall workflow for each task and summarize machine learning techniques employed. We identify a comprehensive list of available datasets and tools useable in this context. Finally, the paper discusses perceived challenges in this area, including the availability of standard datasets, reproducibility and replicability, and hardware resources. Editor’s note: Open Science material was validated by the Journal of Systems and Software Open Science Board.
Keywords: Machine learning for software engineering; Source code analysis; Deep learning; Datasets; Tools

Mounika Deverashetti, Ranjitha K., Pradeepthi K.V.,
Security analysis of menstruation cycle tracking applications using static, dynamic and machine learning techniques,
Journal of Information Security and Applications,
Volume 67,
2022,
103171,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2022.103171.
(https://www.sciencedirect.com/science/article/pii/S2214212622000564)
Abstract: There have been many incidents in the past, where user’s private information, health and vitals, shared to a mobile app have been disclosed. In this paper, we consider Menstruation Cycle Tracking Android apps, and analyse their security features to understand if the app developers have taken adequate care to avoid such incidents of breach or disclosure. These apps store extremely personal information of women and need to take security very seriously. We have initially applied Static Analysis techniques on these apps, and understood the various loopholes from the developer’s prospective. Moreover, we used Dynamic Analysis techniques to further scrutinise the apps and exploit the discovered vulnerabilities. We found many apps are not observant in implementing minimal security features. Further, we propose a machine learning based-Ranking and Extraction of Android Permissions (REAP) framework, where we extract the permissions of these apps and apply Classification and Clustering algorithms to aid in identifying apps that are seeking more permissions and are potentially more risky. Classification accuracy of 94.52% was achieved using Naive Bayes classifier. Menstruation cycle tracking apps carry extremely private information, however, the app developers, sometimes, fail to provide a secure environment to the end-users.
Keywords: Period/menstruation cycle tracking apps; Android apps; Static analysis; Dynamic analysis; Permission based; Machine learning

Rongze Xu, Zhanyong Tang, Guixin Ye, Huanting Wang, Xin Ke, Dingyi Fang, Zheng Wang,
Detecting code vulnerabilities by learning from large-scale open source repositories,
Journal of Information Security and Applications,
Volume 69,
2022,
103293,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2022.103293.
(https://www.sciencedirect.com/science/article/pii/S221421262200148X)
Abstract: Machine learning methods are widely used to identify common, repeatedly occurring bugs and code vulnerabilities. The performance of a machine-learned model is bounded by the quality and quantity of training data and the model’s capability in extracting and capturing the essential information of the problem domain. Unfortunately, there is a storage of high-quality samples for training code vulnerability detection models, and existing machine learning methods are inadequate in capturing code vulnerability patterns. We present Developer,11Developer = Detecting codE VulnerabilitiEs at the Large scale by learning from OPen sourcE Repositories. a novel learning framework for building code vulnerability detection models. To address the data scarcity challenge, Developer automatically gathers training samples from open-source projects and applies constraints rules to the collected data to filter out noisy data to improve the quality of the collected samples. The collected data provides many real-world vulnerable code training samples to complement the samples available in standard vulnerable databases. To build an effective code vulnerability detection model, Developer employs a convolutional neural network architecture with attention mechanisms to extract code representation from the program abstract syntax tree. The extracted program representation is then fed to a downstream network – a bidirectional long–short term memory architecture – to predict if the target code contains a vulnerability or not. We apply Developer to identify vulnerabilities at the program source-code level. Our evaluation shows that Developer outperforms state-of-the-art methods by uncovering more vulnerabilities with a lower false-positive rate.
Keywords: Code vulnerability detection; Deep learning; Attention mechanism; Software vulnerability

Ilias Kalouptsoglou, Miltiadis Siavvas, Apostolos Ampatzoglou, Dionysios Kehagias, Alexander Chatzigeorgiou,
Software vulnerability prediction: A systematic mapping study,
Information and Software Technology,
Volume 164,
2023,
107303,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107303.
(https://www.sciencedirect.com/science/article/pii/S095058492300157X)
Abstract: Context:
Software security is considered a major aspect of software quality as the number of discovered vulnerabilities in software products is growing. Vulnerability prediction is a mechanism that helps engineers to prioritize their inspection efforts focusing on vulnerable parts. Despite the recent advancements, current literature lacks a systematic mapping study on vulnerability prediction.
Objective:
This paper aims to analyze the state-of-the-art of vulnerability prediction focusing on: (a) the goals of vulnerability prediction-related studies; (b) the data collection processes and the types of datasets that exist in the literature; (c) the mostly examined techniques for the construction of the prediction models and their input features; and (d) the utilized evaluation techniques.
Method:
We collected 180 primary studies following a broad search methodology across four popular digital libraries. We mapped these studies to the variables of interest and we identified trends and relationships between the studies.
Results:
The main findings suggest that: (i) there are two major study types, prediction of vulnerable software components and forecasting of the evolution of vulnerabilities in software; (ii) most studies construct their own vulnerability-related dataset retrieving information from vulnerability databases for real-world software; (iii) there is a growing interest for deep learning models along with a trend on textual source code representation; and (iv) F1-score was found to be the most widely used evaluation metric.
Conclusions:
The results of our study indicate that there are several open challenges in the domain of vulnerability prediction. One of the major conclusions, is the fact that most studies focus on within-project prediction, neglecting the real-world scenario of cross-project prediction.
Keywords: Systematic mapping study; Software security; Vulnerability prediction; Machine learning

Son Nguyen, Thu-Trang Nguyen, Thanh Trong Vu, Thanh-Dat Do, Kien-Tuan Ngo, Hieu Dinh Vo,
Code-centric learning-based just-in-time vulnerability detection,
Journal of Systems and Software,
Volume 214,
2024,
112014,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2024.112014.
(https://www.sciencedirect.com/science/article/pii/S0164121224000578)
Abstract: Attacks against computer systems exploiting software vulnerabilities can cause substantial damage to the cyber infrastructure of our modern society and economy. To minimize the consequences, it is vital to detect and fix vulnerabilities as soon as possible. Just-in-time vulnerability detection (JIT-VD) discovers vulnerability-prone (“dangerous”) commits to prevent them from being merged into source code and causing vulnerabilities. By JIT-VD, the commits’ authors, who understand the commits properly, can review these dangerous commits and fix them if necessary while the relevant modifications are still fresh in their minds. In this paper, we propose CodeJIT, a novel graph-based code-centric learning-based approach for just-in-time vulnerability detection. The key idea of CodeJIT is that the meaning of the code changes of a commit is the direct and deciding factor for determining if the commit is dangerous for the code. Based on that idea, we design a novel graph-based representation, Code Transformation Graph (CTG) to represent the semantics of code changes in terms of both code syntactic structure and program dependencies. A graph neural network (GNN) model is developed to capture the meaning of the code changes represented by our graph-based representation and learn to discriminate between dangerous and safe commits. We conducted experiments to evaluate the JIT-VD performance of CodeJIT on a dataset of 20K+ dangerous and safe commits in 506 real-world projects from 1998 to 2022. Our results show that CodeJIT significantly improves the state-of-the-art JIT-VD methods by up to 66% in Recall, 136% in Precision, and 68% in F1. Moreover, CodeJIT correctly classifies nearly 9/10 of dangerous/safe (benign) commits and even detects 69 commits that fix a vulnerability yet produce other issues in source code.
Keywords: Just-in-time vulnerability detection; Code-centric; Code change representation; Graph-based model; Commit-level bugs

Misbah Anjum, Shakshi Singhal, P.K. Kapur, Sunil Kumar Khatri, Saurabh Panwar,
Analysis of vulnerability fixing process in the presence of incorrect patches,
Journal of Systems and Software,
Volume 195,
2023,
111525,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2022.111525.
(https://www.sciencedirect.com/science/article/pii/S0164121222002011)
Abstract: Software vulnerabilities or security breaches can have consequences like leakage of sensitive information and malware execution, which are critical to network security. Consequently, eliminating security loopholes and vulnerabilities is imperative for the system administrator to counteract security attacks. Software should be thoroughly reviewed before it is released to uncover these security invasions. However, it is not feasible to identify and overcome all software failures during software testing due to external instances of software development, implementation costs, execution time, and unanticipated modifications to the specification. Security patching is a viable solution for such software systems to prevent attackers from exploiting existing vulnerabilities. Even after patch distribution and installation, it is crucial to determine whether the patch has effectively eliminated the vulnerability. Incorrect patches may lead to new security bugs, which may be malicious and disastrous for developing businesses and users. The present research aims to model the trend of patched vulnerabilities methodically by incorporating the generation of new vulnerabilities due to unsuccessful updations and encompassed bug fixes. The proposed analytical model is validated on the vulnerability databases obtained from the Common Vulnerabilities and Exposures repository. The empirical analysis yields that the present research has better forecasting efficacy than the benchmark studies.
Keywords: Software vulnerabilities; Security bugs; Patch correctness; Intrusion detection; Patch management

Sabah Suhail, Mubashar Iqbal, Rasheed Hussain, Raja Jurdak,
ENIGMA: An explainable digital twin security solution for cyber–physical systems,
Computers in Industry,
Volume 151,
2023,
103961,
ISSN 0166-3615,
https://doi.org/10.1016/j.compind.2023.103961.
(https://www.sciencedirect.com/science/article/pii/S0166361523001112)
Abstract: Digital Twins (DTs), being the virtual replicas of their physical counterparts, share valuable knowledge of the underlying physical processes and act as data acquisition and dissemination sources to Cyber–Physical System (CPS). Moreover, without obstructing the ongoing operations, DTs also provide an assessment platform for evaluating the operational behavior and security of the CPS. Therefore, they become a potential source of data breaches and a broad attack surface for attackers to launch covert attacks. To detect and mitigate security loopholes in DTs, one of the potential solutions is to leverage a gamification approach that can assess the security level of DTs while providing security analysts with a controlled and supportive virtual training environment. Artificial Intelligence/Machine Learning (AI/ML)-based approaches can complement the idea of security orchestration and automation in the gamification approach. However, AI/ML-based DTs security solutions are generally constrained by the lack of transparency of AI operations, which results in less confidence in the decisions made by the AI models. To address the explainable security challenges of DTs, this article proposes a gamification approach called sEcuriNg dIgital twins through GaMification Approach (ENIGMA). While leveraging DTs as an offensive security platform, ENIGMA provides gaming scenarios to assess DTs’ security and train security analysts. The game players within ENIGMA are humans (the attacker team) and AI agents (the defender team). Furthermore, ENIGMA is supported by an eXplainable AI (XAI)-based DT security assessment model that explains the decisions made based on the SHAP values by the AI model on attack vectors for the defender team, i.e., the AI agent. The SHAP values illustrate the contribution of different features towards predicting the outcome of attack vectors. This explanation can help security analysts to take security measures based on reasoned and trustworthy decisions. Finally, experimental validation has been carried out to demonstrate the viability of ENIGMA.
Keywords: Cyber-physical system (CPS); Cybersecurity awareness; Digital twins (DTs); eXplainable AI (XAI); Gamification; Industry 5.0

Nibir Mandal, Gias Uddin,
An empirical study of IoT security aspects at sentence-level in developer textual discussions,
Information and Software Technology,
Volume 150,
2022,
106970,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2022.106970.
(https://www.sciencedirect.com/science/article/pii/S0950584922001082)
Abstract: Context:
IoT is a rapidly emerging paradigm that now encompasses almost every aspect of our modern life. As such, ensuring the security of IoT devices is crucial. IoT devices can differ from traditional computing (e.g., low power, storage, computing), thereby the design and implementation of proper security measures can be challenging in IoT devices. We observed that IoT developers discuss their security-related challenges in developer forums like Stack Overflow (SO). However, we find that IoT security discussions can also be buried inside non-security discussions in SO.
Objective:
In this paper, we aim to understand the challenges IoT developers face while applying security practices and techniques to IoT devices. We have two goals: (1) Develop a model that can automatically find security-related IoT discussions in SO, and (2) Study the model output (i.e., the security discussions) to learn about IoT developer security-related challenges.
Methods:
First, we download all 53K posts from StackOverflow (SO) that contain discussions about various IoT devices, tools, and techniques. Second, we manually labeled 5,919 sentences from 53K posts as 1 or 0 (i.e., whether they contain a security aspect or not). Third, we then use this benchmark to investigate a suite of deep learning transformer models. The best performing model is called SecBot. Fourth, we apply SecBot on the entire 53K posts and find around 30K sentences labeled as security. Fifth, we apply topic modeling to the 30K security-related sentences labeled by SecBot. Then we label and categorize the topics. Sixth, we analyze the evolution of the topics in SO.
Results:
We found that (1) SecBot is based on the retraining of the deep learning model RoBERTa. SecBot offers the best F1-Score of .935, (2) there are six error categories in misclassified samples by SecBot. SecBot was mostly wrong when the keywords/contexts were ambiguous (e.g., ‘gateway’ can be a security gateway or a simple gateway), (3) there are 9 security topics grouped into three categories: Software, Hardware, and Network, and (4) the highest number of topics belongs to software security, followed by network security and hardware security.
Conclusion:
IoT researchers and vendors can use SecBot to collect and analyze security-related discussions from developer discussions in SO. The analysis of nine security-related topics can guide major IoT stakeholders like IoT Security Enthusiasts, Developers, Vendors, Educators, and Researchers in the rapidly emerging IoT ecosystems.
Keywords: IoT; Security; Stack overflow; Deep learning; Empirical study

Görkem Giray, Kwabena Ebo Bennin, Ömer Köksal, Önder Babur, Bedir Tekinerdogan,
On the use of deep learning in software defect prediction,
Journal of Systems and Software,
Volume 195,
2023,
111537,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2022.111537.
(https://www.sciencedirect.com/science/article/pii/S0164121222002138)
Abstract: Context:
Automated software defect prediction (SDP) methods are increasingly applied, often with the use of machine learning (ML) techniques. Yet, the existing ML-based approaches require manually extracted features, which are cumbersome, time consuming and hardly capture the semantic information reported in bug reporting tools. Deep learning (DL) techniques provide practitioners with the opportunities to automatically extract and learn from more complex and high-dimensional data.
Objective:
The purpose of this study is to systematically identify, analyze, summarize, and synthesize the current state of the utilization of DL algorithms for SDP in the literature.
Method:
We systematically selected a pool of 102 peer-reviewed studies and then conducted a quantitative and qualitative analysis using the data extracted from these studies.
Results:
Main highlights include: (1) most studies applied supervised DL; (2) two third of the studies used metrics as an input to DL algorithms; (3) Convolutional Neural Network is the most frequently used DL algorithm.
Conclusion:
Based on our findings, we propose to (1) develop more comprehensive DL approaches that automatically capture the needed features; (2) use diverse software artifacts other than source code; (3) adopt data augmentation techniques to tackle the class imbalance problem; (4) publish replication packages.
Keywords: Software defect prediction; Deep learning; Quality assurance; Systematic literature review

Xueqi Yang, Zhe Yu, Junjie Wang, Tim Menzies,
Understanding static code warnings: An incremental AI approach,
Expert Systems with Applications,
Volume 167,
2021,
114134,
ISSN 0957-4174,
https://doi.org/10.1016/j.eswa.2020.114134.
(https://www.sciencedirect.com/science/article/pii/S0957417420308824)
Abstract: Knowledge-based systems reason over some knowledge base. Hence, an important issue for such systems is how to acquire the knowledge needed for their inference. This paper assesses active learning methods for acquiring knowledge for “static code warnings”. Static code analysis is a widely-used method for detecting bugs and security vulnerabilities in software systems. As software becomes more complex, analysis tools also report lists of increasingly complex warnings that developers need to address on a daily basis. Such static code analysis tools are usually over-cautious; i.e. they often offer many warnings about spurious issues. Previous research work shows that about 35% to 91 % warnings reported as bugs by SA tools are actually unactionable (i.e., warnings that would not be acted on by developers because they are falsely suggested as bugs). Experienced developers know which errors are important and which can be safely ignored. How can we capture that experience? This paper reports on an incremental AI tool that watches humans reading false alarm reports. Using an incremental support vector machine mechanism, this AI tool can quickly learn to distinguish spurious false alarms from more serious matters that deserve further attention. In this work, nine open-source projects are employed to evaluate our proposed model on the features extracted by previous researchers and identify the actionable warnings in a priority order given by our algorithm. We observe that our model can identify over 90% of actionable warnings when our methods tell humans to ignore 70 to 80% of the warnings.
Keywords: Actionable warning identification; Active learning; Static analysis; Selection process

Ziye Zhu, Hanghang Tong, Yu Wang, Yun Li,
Enhancing bug localization with bug report decomposition and code hierarchical network,
Knowledge-Based Systems,
Volume 248,
2022,
108741,
ISSN 0950-7051,
https://doi.org/10.1016/j.knosys.2022.108741.
(https://www.sciencedirect.com/science/article/pii/S0950705122003483)
Abstract: Bug localization, which aims to locate buggy source code files for given bug reports, is a crucial yet challenging software-mining task. Despite remarkable success, the state of the art falls short in handling (1) bug reports with diverse characteristics and (2) programs with wildly different behaviors. In response, this paper proposes a graph-based neural model BLoco for automated bug localization. To be specific, our proposed model decomposes bug reports into several bug clues to capture bug-related information from various perspectives for highly diverse bug reports. To understand the program in depth, we first design a code hierarchical network structure, Code-NoN, based on basic blocks to represent source code files. Correspondingly, a multilayer graph neural network is tailored to capture program behaviors from the Code-NoN structure of each source code file. Finally, BLoco further incorporates a bi-affine classifier to comprehensively predict the relationship between the bug reports and source files. Extensive experiments on five large-scale real-world projects demonstrate that the proposed model significantly outperforms existing techniques.
Keywords: Software mining; Bug localization; Bug report; Program behavior; Hierarchical network; Network of networks

Antonios Gkortzis, Daniel Feitosa, Diomidis Spinellis,
Software reuse cuts both ways: An empirical analysis of its relationship with security vulnerabilities,
Journal of Systems and Software,
Volume 172,
2021,
110653,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2020.110653.
(https://www.sciencedirect.com/science/article/pii/S0164121220301199)
Abstract: Software reuse is a widely adopted practice among both researchers and practitioners. The relation between security and reuse can go both ways: a system can become more secure by relying on mature dependencies, or more insecure by exposing a larger attack surface via exploitable dependencies. To follow up on a previous study and shed more light on this subject, we further examine the association between software reuse and security threats. In particular, we empirically investigate 1244 open-source projects in a multiple-case study to explore and discuss the distribution of security vulnerabilities between the code created by a development team and the code reused through dependencies. For that, we consider both potential vulnerabilities, as assessed through static analysis, and disclosed vulnerabilities, reported in public databases. The results suggest that larger projects in size are associated with an increase on the amount of potential vulnerabilities in both native and reused code. Moreover, we found a strong correlation between a higher number of dependencies and vulnerabilities. Based on our empirical investigation, it appears that source code reuse is neither a silver bullet to combat vulnerabilities nor a frightening werewolf that entail an excessive number of them.
Keywords: Software reuse; Security vulnerabilities; Case study; Open-source software

Jin Wang, Hui Xiao, Shuwen Zhong, Yinhao Xiao,
DeepVulSeeker: A novel vulnerability identification framework via code graph structure and pre-training mechanism,
Future Generation Computer Systems,
Volume 148,
2023,
Pages 15-26,
ISSN 0167-739X,
https://doi.org/10.1016/j.future.2023.05.016.
(https://www.sciencedirect.com/science/article/pii/S0167739X23001978)
Abstract: Software vulnerabilities can pose severe harms to a computing system. They can lead to system crash, privacy leakage, or even physical damage. Correctly identifying vulnerabilities among enormous software codes in a timely manner is so far the essential prerequisite to patch them. Unfortunately, the current vulnerability identification methods, either the classic ones or the deep-learning-based ones, have several critical drawbacks, making them unable to meet the present-day demands put forward by the software industry. To overcome the drawbacks, in this paper, we propose DeepVulSeeker, a novel fully automated vulnerability identification framework, which leverages both code graph structures and the semantic features with the help of the recently advanced Graph Representation Self-Attention and pre-training mechanisms. Our experiments show that DeepVulSeeker not only reaches an accuracy as high as 0.99 on traditional CWE datasets, but also outperforms all other existing methods on two highly-complicated datasets. We also testified DeepVulSeeker based on three case studies, and found that DeepVulSeeker is able to understand the implications of the vulnerabilities. We have fully implemented DeepVulSeeker and open-sourced it for future follow-up research.
Keywords: Vulnerability identification; Software security; Neural network; Pre-training; Vulnerability pattern; Code feature

Gaigai Tang, Lin Yang, Long Zhang, Hongyu Kuang, Huiqiang Wang,
MRC-VulLoc: Software source code vulnerability localization based on multi-choice reading comprehension,
Computers & Security,
Volume 141,
2024,
103816,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103816.
(https://www.sciencedirect.com/science/article/pii/S0167404824001172)
Abstract: Recently, automatic vulnerability detection approaches based on machine learning (ML) have outperformed traditional rule-based approaches in terms of detection performance. Existing ML-based approaches typically concentrate on function or line granularity, which fail to realize accurate vulnerability localization and are insufficient to support effective root cause analysis of vulnerability. To address this issue, we propose a new approach that maps the multi-choice reading comprehension (MRC) task to the vulnerability localization task at the granularity of vulnerability triggering path named MRC-VulLoc. Initially, we design six large datasets (including C/C++ and Java languages) in the form of MRC. Subsequently, we introduce a novel pre-trained vulnerability localization model, combining the effective code semantic comprehension ability of pre-trained model with the advantages of Bidirectional Short-Term Memory Network (Bi-LSTM) and Convolutional Neural Network (CNN) models. Lastly, we conduct experiments to evaluate the vulnerability localization with several state-of-the-art MRC approaches and vulnerability detectors. Experimental results demonstrate the effectiveness of the proposed datasets in evaluating MRC approaches for vulnerability localization. Furthermore, MRC-VulLoc achieves higher precision on vulnerability localization compared to comparative vulnerability detectors.
Keywords: Source code; Vulnerability localization; Machine learning; MRC

Felix Schuckert, Basel Katt, Hanno Langweg,
Insecurity Refactoring: Automated Injection of Vulnerabilities in Source Code,
Computers & Security,
Volume 128,
2023,
103121,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103121.
(https://www.sciencedirect.com/science/article/pii/S0167404823000317)
Abstract: Insecurity Refactoring is a change to the internal structure of software to inject a vulnerability without changing the observable behavior in a normal use case scenario. An implementation of Insecurity Refactoring is formally explained to inject vulnerabilities in source code projects by using static code analysis. It creates learning examples with source code patterns from known vulnerabilities. Insecurity Refactoring is achieved by creating an Adversary Controlled Input Dataflow tree based on a Code Property Graph. The tree is used to find possible injection paths. Transformation of the possible injection paths allows to inject vulnerabilities. Insertion of data flow patterns introduces different code patterns from related Common Vulnerabilities and Exposures (CVE) reports. The approach is evaluated on 307 open source projects. Additionally, insecurity-refactored projects are deployed in virtual machines to be used as learning examples. Different static code analysis tools, dynamic tools and manual inspections are used with modified projects to confirm the presence of vulnerabilities. The results show that in 8.1% of the open source projects it is possible to inject vulnerabilities. Different inspected code patterns from CVE reports can be inserted using corresponding data flow patterns. Furthermore the results reveal that the injected vulnerabilities are useful for a small sample size of attendees (n=16). Insecurity Refactoring is useful to automatically generate learning examples to improve software security training. It uses real projects as base whereas the injected vulnerabilities stem from real CVE reports. This makes the injected vulnerabilities unique and realistic.
Keywords: Web security; Static code analysis; Refactoring; Vulnerability Pattern; PHP; SQLi; XSS

Zhilong Cai, Yongwei Cai, Xiang Chen, Guilong Lu, Wenlong Pei, Junjie Zhao,
CSVD-TF: Cross-project software vulnerability detection with TrAdaBoost by fusing expert metrics and semantic metrics,
Journal of Systems and Software,
Volume 213,
2024,
112038,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2024.112038.
(https://www.sciencedirect.com/science/article/pii/S0164121224000815)
Abstract: Recently, deep learning-based software vulnerability detection (SVD) approaches have achieved promising performance. However, the scarcity of high-quality labeled SVD data influences the practicality of these approaches. Therefore, cross-project software vulnerability detection (CSVD) has gradually attracted the attention of researchers since CSVD can utilize the labeled SVD data from the source project to construct an effective CSVD model for the target project via transfer learning. However, if a certain number of program modules in the target project can be labeled by security experts, it can help to improve CSVD model performance by effectively utilizing similar SVD data in the source project. For this more practical CSVD scenario, we propose a novel approach CSVD-TF via the transfer learning method TrAdaBoost. Moreover, we find expert metrics and semantic metrics extracted from the functions show a certain complementary in our investigated scenario. Therefore, we utilize a model-level metric fusion method to further improve the performance. We perform a comprehensive study to evaluate the effectiveness of CSVD-TF on four real-world projects. Our empirical results show that CSVD-TF can achieve performance improvements of 7.5% to 24.6% in terms of AUC when compared to five state-of-the-art baselines.
Keywords: Cross-project software vulnerability detection; Transfer learning; Expert metrics; Semantic metrics; Metric fusion

Kuo Zhou, Jing Huang, Honggui Han, Bei Gong, Ao Xiong, Wei Wang, Qihui Wu,
Smart contracts vulnerability detection model based on adversarial multi-task learning,
Journal of Information Security and Applications,
Volume 77,
2023,
103555,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2023.103555.
(https://www.sciencedirect.com/science/article/pii/S2214212623001394)
Abstract: Vulnerability detection is important for smart contracts because of their immutable and irreversible features. In this work, a new detection method based on adversarial multi-task learning is proposed to improve the accuracy of existing vulnerability detection methods, which is based on the multi-task learning framework, including a shared part and a task-specific part. We optimize the multi-task learning frameworks and propose the mixed parameter sharing method to make each task not only maintain its uniqueness, but also share features with other tasks, which helps solve the problem that the hard parameter sharing method cannot constrain the underlying shared layer and improve the quality of extracted features. In addition, we introduce adversarial transfer learning to reduce noise pollution caused by the private feature and interference between the general feature and the private feature. We experimented on datasets obtained from our previous work, and the experimental results prove that our proposed model can judge whether there are vulnerabilities in smart contracts and then identify their types. Additionally, the results also show that our model effectively improves detection accuracy and has an advantage in performance over representative methods.
Keywords: Vulnerability detection; Smart contracts; Multi-task learning; Adversarial transfer learning; Blockchain security supervision

Han Yan, Senlin Luo, Limin Pan, Yifei Zhang,
HAN-BSVD: A hierarchical attention network for binary software vulnerability detection,
Computers & Security,
Volume 108,
2021,
102286,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2021.102286.
(https://www.sciencedirect.com/science/article/pii/S0167404821001103)
Abstract: Deep learning has shown effectiveness in binary software vulnerability detection due to its outstanding feature extraction capability independent of human expert experience. However, detection approaches such as Instruction2vec still have the following defects: (1) the context between an instruction’s elements (opcode, registers, etc.) is not fully incorporated when embedding a single instruction into its vector representation; (2) the crucial regions that related to vulnerability are not highlighted when extracting features of the vulnerable code. In this paper, we propose a hierarchical attention network for binary software vulnerability detection (HAN-BSVD). Through HAN-BSVD, the contextual information is first enriched by the preprocessor with unifying jump address and normalizing instruction, and then preserved by the instruction embedding network that composed of Bi-GRU and word-attention module; the local features are captured and the crucial regions are highlighted by the feature extraction network that composed of Text-CNN and spatial-attention module. The proposed approach is evaluated on the Juliet Test Suite dataset and the ICLR19 dataset, detection result performs better than the other compared approaches. Extensive ablation studies are also conducted to further prove the effectiveness of each design choice.
Keywords: Vulnerability detection; Static binary analysis; Hierarchical attention; Instruction embedding; Deep learning

Jie Cai, Bin Li, Jiale Zhang, Xiaobing Sun, Bing Chen,
Combine sliced joint graph with graph neural networks for smart contract vulnerability detection,
Journal of Systems and Software,
Volume 195,
2023,
111550,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2022.111550.
(https://www.sciencedirect.com/science/article/pii/S0164121222002266)
Abstract: Smart contract security has drawn extensive attention in recent years because of the enormous economic losses caused by vulnerabilities. Even worse, fixing bugs in a deployed smart contract is difficult, so developers must detect security vulnerabilities in a smart contract before deployment. Existing smart contract vulnerability detection efforts heavily rely on fixed rules defined by experts, which are inefficient and inflexible. To overcome the limitations of existing vulnerability detection approaches, we propose a GNN based approach for smart contract vulnerability detection. First, we construct a graph representation for a smart contract function with syntactic and semantic features by combining abstract syntax tree (AST), control flow graph (CFG), and program dependency graph (PDG). To further strengthen the presentation ability of our approach, we perform program slicing to normalize the graph and eliminate the redundant information unrelated to vulnerabilities. Then, we use a Bidirectional Gated Graph Neural-Network model with hybrid attention pooling to identify potential vulnerabilities in smart contract functions. Empirical results show that our approach can achieve 89.2% precision and 92.9% recall in smart contract vulnerability detection on our dataset and reveal the effectiveness and efficiency of our approach.
Keywords: Smart contract; Vulnerability detection; Code representation; Graph neural network

Jingwei Hao, Senlin Luo, Limin Pan,
A novel vulnerability severity assessment method for source code based on a graph neural network,
Information and Software Technology,
Volume 161,
2023,
107247,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107247.
(https://www.sciencedirect.com/science/article/pii/S0950584923001015)
Abstract: Context
Vulnerability severity assessment is an important part of vulnerability management that can help security personnel determine the priority of vulnerability repair work.
Objective
Aiming at the problems of low evaluation efficiency and poor timeliness in the existing method, a vulnerability severity evaluation method combining a function call graph and vulnerability attribute graph is proposed.
Method
This method constructs a function call graph centered on vulnerable functions and uses the call relationship between vulnerable functions and sensitive API functions to reflect the severity of the damage of the vulnerable functions. The graph attention neural network algorithm is used to mine the key vulnerability characteristics in the function call graph and the vulnerability attribute graph to realize the assessment of vulnerability severity.
Results
The ablation experiment results showed that the combined vulnerability attribute graph and function call graph had higher evaluation accuracy than the vulnerability attribute graph or function call graph alone, which increased by 6.85% and 32.90%, respectively. Compared with other existing methods, our method has achieved a better evaluation effect, and the evaluation accuracy has increased by 10%.
Conclusion
The vulnerability severity assessment method incorporating function call graphs and vulnerability property graphs demonstrates an enhancement in the ability to represent the severity of vulnerabilities and increases the efficiency of vulnerability severity evaluation through elimination of the requirement for manual analysis.
Keywords: Vulnerability severity assessment; Source code; Vulnerability property graph; Function call graph

Christoforos Ntantogian, Panagiotis Bountakas, Dimitris Antonaropoulos, Constantinos Patsakis, Christos Xenakis,
NodeXP: NOde.js server-side JavaScript injection vulnerability DEtection and eXPloitation,
Journal of Information Security and Applications,
Volume 58,
2021,
102752,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2021.102752.
(https://www.sciencedirect.com/science/article/pii/S221421262100003X)
Abstract: Web applications are widely used, and new ways for easier and cost-effective methods to develop them are constantly introduced. A common omission among the new development and implementation techniques when designing them is security; Node.js is no exception, as Server-Side JavaScript Injection (SSJI) attacks are possible due to the use of vulnerable functions and neglecting to sanitize data input provided by untrusted sources. This specific kind of injection attack stands out because it has the potential to compromise servers, where the JavaScript code is executed. In this work, we fill a significant gap in the literature by introducing NodeXP, which, to the best of our knowledge, is the first methodology (presented as a software tool) that detects and automatically exploits SSJI vulnerabilities. Beyond the capabilities of the current state-of-the-art tools, NodeXP uses obfuscation methods, making it more stealth and adaptive to the current needs of red teaming. To this end, we provide a thorough analysis of SSJI attacks and the foundation upon which they rely on, along with concrete examples to facilitate the reader to comprehend the underlying concepts. Finally, we evaluate NodeXP, compare it to its peers, and discuss its efficacy.
Keywords: Code injection; Server-Side Javascript Injection; Detection; Exploitation; Deep learning; Node.js

Qian Wang, Zhengdao Li, Hetong Liang, Xiaowei Pan, Hui Li, Tingting Li, Xiaochen Li, Chenchen Li, Shikai Guo,
Graph Confident Learning for Software Vulnerability Detection,
Engineering Applications of Artificial Intelligence,
Volume 133, Part C,
2024,
108296,
ISSN 0952-1976,
https://doi.org/10.1016/j.engappai.2024.108296.
(https://www.sciencedirect.com/science/article/pii/S0952197624004548)
Abstract: Code vulnerability exposes millions of software to the possibility of being attacked, as evidence every year on increasing reports of security issues, such as information leaks, system compromise, and denial of service. Despite with many vulnerability detection models proposed so far, their effectiveness is still limited due to the ignorance of syntactic structural information analysis in source code and the improper handling of labeling errors. To address these issues, we propose the Graph Confident Learning for Software Vulnerability Detection (GCL4SVD) model, a machine learning model to detect software vulnerability in the development phase. It comprises two components: code graph embedding and graph confident learning denoising. To address the syntactic structural information analysis limitation, the code graph embedding component extracts the structure and semantic information of source code with a sliding window mechanism, and then encodes source code into a graph structure to capture the patterns and characteristics of code vulnerabilities. Additionally, the graph confident learning denoising component identifies labeling errors to improve the quality of training set. Experimental results show that GCL4SVD outperforms the state-of-the-art vulnerability detection models on four open source datasets by 3.7%, 3.3%, 2.5%, 0.8% in terms of Accuracy, respectively, and by 10.2%, 21.8%, 8.2%, 11.2% in terms of F1-score.
Keywords: Software code vulnerability detection; Learning with noisy labels; Gated graph neural networks

Zhenzhou Tian, Binhui Tian, Jiajun Lv, Yanping Chen, Lingwei Chen,
Enhancing vulnerability detection via AST decomposition and neural sub-tree encoding,
Expert Systems with Applications,
Volume 238, Part B,
2024,
121865,
ISSN 0957-4174,
https://doi.org/10.1016/j.eswa.2023.121865.
(https://www.sciencedirect.com/science/article/pii/S0957417423023679)
Abstract: The explosive growth of software vulnerabilities poses a serious threat to the system security and has become one of the urgent problems of the day. However, existing vulnerability detection methods are still faced with limitations in reaching the balance between detection accuracy, efficiency and applicability. Following a divide-and-conquer strategy, this paper proposes TrVD (abstract syntax Tree decomposition based Vulnerability Detector) to disclose the indicative semantics implied in the source code fragments for accurate and efficient vulnerability detection. To facilitate the capture of subtle semantic features, TrVD converts the AST of a code fragment into an ordered set of sub-trees of restricted sizes and depths with a novel decomposition algorithm. The semantics of each sub-tree can thus be effectively collected with a carefully designed tree-structured neural network. Finally, a Transformer-style encoder is utilized to aggregate the long-range contextual semantics of all sub-trees into a vulnerability-specific vector to represent the target code fragment. The extensive experiments conducted on five large datasets consisting of diverse real-world and synthetic vulnerable samples demonstrate the performance superiority of TrVD against SOTA approaches in detecting the presence of vulnerabilities and pinpointing the vulnerability types. The ablation studies also confirm the effectiveness of TrVD’s core designs.
Keywords: Vulnerability detection; Tree decomposition; Tree-structured neural network; Deep semantic extraction

Sepideh HajiHosseinKhani, Arash Habibi Lashkari, Ali Mizani Oskui,
Unveiling vulnerable smart contracts: Toward profiling vulnerable smart contracts using genetic algorithm and generating benchmark dataset,
Blockchain: Research and Applications,
Volume 5, Issue 1,
2024,
100171,
ISSN 2096-7209,
https://doi.org/10.1016/j.bcra.2023.100171.
(https://www.sciencedirect.com/science/article/pii/S2096720923000465)
Abstract: Smart contracts (SCs) are crucial in maintaining trust within blockchain networks. However, existing methods for analyzing SC vulnerabilities often lack accuracy and effectiveness, while approaches based on Deep Neural Networks (DNNs) struggle with detecting complex vulnerabilities due to limited data availability. This paper proposes a novel approach for analyzing SC vulnerabilities. Our method leverages an advanced form of the Genetic Algorithm (GA) and includes the development of a comprehensive benchmark dataset consisting of 36,670 Solidity source code samples. The primary objective of our study is to profile vulnerable SCs effectively. To achieve this goal, we have devised an analyzer called SCsVulLyzer based on GAs, designed explicitly for profiling SCs. Additionally, we have carefully curated a new dataset encompassing a wide range of examples, ensuring the practical validation of our approach. Furthermore, we have established three distinct taxonomies that cover SCs, profiling techniques, and feature extraction. These taxonomies provide a systematic classification and analysis of information, improving the efficiency of our approach. Our methodology underwent rigorous testing through experimentation, and the results demonstrated the superior capabilities of our model in detecting vulnerabilities. Compared to traditional and DNN-based approaches, our approach achieved higher precision, recall, and F1-score, which are widely used metrics for evaluating model performance. Across all these metrics, our model showed exceptional results. The customization and adaptations we implemented within the GA significantly enhanced its effectiveness. Our approach detects SC vulnerabilities more efficiently and facilitates robust exploration. These promising results highlight the potential of GA-based profiling to improve the detection of SC vulnerabilities, contributing to enhanced security in blockchain networks.
Keywords: Smart contracts (SCs); Vulnerability; Vulnerable smart contracts; Vulnerability profiling; Genetic algorithm

Yan Wang, Peng Jia, Xi Peng, Cheng Huang, Jiayong Liu,
BinVulDet: Detecting vulnerability in binary program via decompiled pseudo code and BiLSTM-attention,
Computers & Security,
Volume 125,
2023,
103023,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.103023.
(https://www.sciencedirect.com/science/article/pii/S0167404822004151)
Abstract: Static detection of security vulnerabilities in binary programs is an important research field in software supply chain security. However, existing vulnerability detection methods based on code similarity can only detect known vulnerabilities. Vulnerability features generated by vulnerability pattern-based detection methods are low robust due to the influence of manually defined patterns, compiler diversity, and irrelevant function instructions. In this paper, we propose BinVulDet, which is a binary level vulnerability detection tool for accurate known and unknown vulnerability detection. BinVulDet uses decompilation techniques to obtain pseudo code containing high-level semantic information against the impact of compilation diversity. Then the program slicing technique is used to extract the statements with data dependencies and control dependencies related to the vulnerability. A BiLSTM-attention neural network is used to extract rich contextual semantic information from slice codes to generate more robust vulnerability patterns to detect vulnerabilities. The experimental results show that BinVulDet outperforms the state-of-the-art binary vulnerability detection methods. The FPR and FNR of BinVulDet are 1.04% and 0.89% on average, respectively, which are 3.93% and 22.86% lower than the baseline model on average. BinVulDet can effectively against the influence of compilation diversity and successfully be used for real-world vulnerability detection by being evaluated in three CVE vulnerability projects.
Keywords: Binary program; Decompile; Vulnerability detection; Program slicing; BiLSTM-attention

Xiaozhi Du, Shiming Zhang, Yanrong Zhou, Hongyuan Du,
A vulnerability severity prediction method based on bimodal data and multi-task learning,
Journal of Systems and Software,
Volume 213,
2024,
112039,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2024.112039.
(https://www.sciencedirect.com/science/article/pii/S0164121224000827)
Abstract: Facing the increasing number of software vulnerabilities, the automatic analysis of vulnerabilities has become an important task in the field of software security. However, the existing severity prediction methods are mainly based on vulnerability descriptions and ignore the relevant features of vulnerability code, which only includes unimodal information and result in low prediction accuracy. This paper proposes a vulnerability severity prediction method based on bimodal data and multi-task learning. First the bimodal data, which consists of the description and source code of each vulnerability, is preprocessed. Next the GraphCodeBert is used for the word embedding module to extract different vulnerability features from the bimodal data. Then the Bi-GRU with attention mechanism is adopted for further feature extraction of vulnerability severity. Considering the strong correlation between the two tasks of vulnerability severity prediction and exploitability prediction, this paper proposes a multi-task learning approach, which allows the model to learn the connection and shared information between different tasks through a hard parameter sharing strategy, so as to achieve more accurate and reliable prediction of vulnerability severity. Experimental results show that the severity prediction method proposed in this paper outperforms state-of-the-art methods, and can achieve an average F1 score of 93.83 % on the public vulnerability dataset.
Keywords: Vulnerability severity prediction; Bimodal data; Multi-task learning; GraphCodeBert

Jie Cai, Bin Li, Tao Zhang, Jiale Zhang, Xiaobing Sun,
Fine-grained smart contract vulnerability detection by heterogeneous code feature learning and automated dataset construction,
Journal of Systems and Software,
Volume 209,
2024,
111919,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111919.
(https://www.sciencedirect.com/science/article/pii/S016412122300314X)
Abstract: Context:
Recently, several deep learning based smart contract vulnerability detection approaches have been proposed. However, challenges still exist in applying deep learning for fine-grained vulnerability detection in smart contracts, including the lack of the dataset with sufficient statement-level labeled smart contract samples and neglect of heterogeneity between syntax and semantic features during code feature learning.
Objective:
To utilize deep learning for fine-grained smart contract vulnerability detection, we propose a security best practices (SBP) based dataset construction approach to address the scarcity of datasets. Moreover, we propose a syntax-sensitive graph neural network to address the challenge of heterogeneous code feature learning.
Method:
The dataset construction approach is motivated by the insight that smart contract code fragments guarded by security best practices may contain vulnerabilities in their original unguarded code form. Thus, we locate and strip security best practices from the smart contract code to recover its original vulnerable code form and perform sample labeling. Meanwhile, as the heterogeneity between tree-structured syntax features embodied inside the abstract syntax tree (AST) and graph-structured semantic features reflected by relations between statements, we propose a code graph whose nodes are each statement’s AST subtree with a syntax-sensitive graph neural network that enhances the graph neural network by a child-sum tree-LSTM cell to learn these heterogeneous features for fine-grained smart contract vulnerability detection.
Results:
We compare our approach with three state-of-the-art deep learning-based approaches that only support contract-level vulnerability detection and two popular static analysis-based approaches that support fine detection granularity. The experiment results show that our approach outperforms the baselines at both coarse and fine granularities.
Conclusion:
In this paper, we propose utilizing security best practices inside the smart contract code to construct the dataset with statement-level labels. To learn both tree-structured syntax and graph-structured semantic code features, we propose a syntax-sensitive graph neural network. The experimental results show that our approach outperforms the baselines.
Keywords: Smart contract; Static analysis; Vulnerability detection; Graph neural network

Lejun Zhang, Jinlong Wang, Weizheng Wang, Zilong Jin, Yansen Su, Huiling Chen,
Smart contract vulnerability detection combined with multi-objective detection,
Computer Networks,
Volume 217,
2022,
109289,
ISSN 1389-1286,
https://doi.org/10.1016/j.comnet.2022.109289.
(https://www.sciencedirect.com/science/article/pii/S1389128622003437)
Abstract: Blockchains have been booming in recent years. As a decentralized system architecture, smart contracts give blockchains a user-defined logic. A smart contract is an executable program that can automatically carry out transactions on the Ethereum blockchain. However, some security issues in smart contracts are difficult to fix, and smart contracts also lack quality assessment standards. Therefore, this study proposes a Multiple-Objective Detection Neural Network (MODNN), a more scalable smart contract vulnerability detection tool. MODNN can validate 12 types of vulnerabilities, including 10 recognized threats, and identify more unknown types without the need for specialist or predefined knowledge through implicit features and Multi-Objective detection (MOD) algorithms. It supports the parallel detection of multiple vulnerabilities and has high scalability, eliminating the need to train separate models for each type of vulnerability and reducing significant time and labor costs. This paper also developed a data processing tool called Smart Contract-Crawler (SCC) to address the lack of smart contract vulnerability datasets. MODNN was evaluated using more than 18,000 smart contracts from Ethereum. Experiments showed that MODNN could achieve an average F1 Score of 94.8%, the current highest compared to several standard machine learning (ML) classification models.
Keywords: Blockchain; Smart contract; Vulnerability detection; Machine learning; Multi-objective

Mingke Wang, Chuanqi Tao, Hongjing Guo,
LCVD: Loop-oriented code vulnerability detection via graph neural network,
Journal of Systems and Software,
Volume 202,
2023,
111706,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111706.
(https://www.sciencedirect.com/science/article/pii/S0164121223001012)
Abstract: Due to the unique mechanism and complex structure, loops in programs can easily lead to various vulnerabilities such as dead loops, memory leaks, resource depletion, etc. Traditional approaches to loop-oriented program analysis (e.g. loop summarization) are costly with a high rate of false positives in complex software systems. To address the issues above, recent works have applied deep learning (DL) techniques to vulnerability detection. However, existing DL-based approaches mainly focused on the general characteristics of most vulnerabilities without considering the semantic information of specific vulnerabilities. As a typical structure in programs, loops are highly iterative with multi-paths. Currently, there is a lack of available approaches to represent loops, as well as useful methods to extract the implicit vulnerability patterns. Therefore, this paper introduces LCVD, an automated loop-oriented code vulnerability detection approach. LCVD represents the source code as the Loop-flow Abstract Syntax Tree (LFAST), which focuses on interleaving multi-paths around loop structures. Then a novel Loop-flow Graph Neural Network (LFGNN) is proposed to learn both the local and overall structure of loop-oriented vulnerabilities. The experimental results demonstrate that LCVD outperforms the three static analysis-based and four state-of-the-art DL-based vulnerability detection approaches across evaluation settings.
Keywords: Loop-oriented vulnerability; Vulnerability detection; Deep learning; Code representation; Graph neural network

Lingdi Kong, Senlin Luo, Limin Pan, Zhouting Wu, Xinshuai Li,
A multi-type vulnerability detection framework with parallel perspective fusion and hierarchical feature enhancement,
Computers & Security,
Volume 140,
2024,
103787,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103787.
(https://www.sciencedirect.com/science/article/pii/S0167404824000889)
Abstract: A core problem of vulnerability detection is to detect multi-type vulnerabilities simultaneously by characterizing vulnerabilities of high diversity and complexity in real program source code. Current methods mainly adjust and compromise multiple code representations such as code sequence and code graph based on composite graph. However, sequential features extracted by graph are hardly sufficient to model the contextual semantic associations of the token sequence. Meanwhile, structural features of the code graph extracted by models based on Euclidean Graph Neural Network are difficult to fit the tree-like calling relationships between code lines. These limitations make it difficult to detect diverse vulnerabilities. In addition, most of the existing models ignore the type of code statement, which is closely associated with some specific vulnerability types. In this paper, we propose a Parallelism Framework with Hierarchical feature Enhancement for Multi-type Vulnerability Detection (PFHE-MVD). PFHE-MVD models program code from three parallel perspectives, containing sequence, code graph, and Abstract Syntax Tree statistic. Hyperbolic Graph Convolutional Neural Network is integrated to model the top-down hierarchical calling structure in program code graph through hyperbolic space mapping. Besides, the statement type of code is embedded along with the code text to strengthen the identification ability for different types of vulnerabilities. Experimental results show that PFHE-MVD achieves new state-of-the-art results in multi-type vulnerability detection. PFHE-MVD captures tree-like hierarchical code structure feature and enhances the distinguishing ability for vulnerabilities by code statement type embedding.
Keywords: Vulnerability detection; Multiple types; Hyperbolic graph; Feature fusion

Panchanan Nath, Jaya Rani Mushahary, Ujjal Roy, Maharaj Brahma, Pranav Kumar Singh,
AI and Blockchain-based source code vulnerability detection and prevention system for multiparty software development,
Computers and Electrical Engineering,
Volume 106,
2023,
108607,
ISSN 0045-7906,
https://doi.org/10.1016/j.compeleceng.2023.108607.
(https://www.sciencedirect.com/science/article/pii/S0045790623000320)
Abstract: With the growing demand for application software, there is a race among industries to develop software as quickly as possible. However, maintaining pace and ensuring bug-free software has become increasingly challenging in a work-from-home arrangement as software developers are not under constant supervision. It increases the possibility of buggy products, and traditional testing techniques fail to provide optimal performance. We propose an Artificial Intelligence (AI) and blockchain-based novel decentralized software testing system. The proposed system aims to detect and prevent vulnerable code by synergizing deep learning capabilities and smart-contract-powered blockchain. The vulnerability detection is performed automatically without relying on manually written rules. We propose a non-vulnerability score range map to classify the source code. Furthermore, we integrate an InterPlanetary File System (IPFS) to ensure efficient storage over the blockchain. We conduct a testbed-based experiment to demonstrate the effectiveness of AI and blockchain integration for secure code development and testing.
Keywords: Deep learning; Blockchain; Smart contract; IPFS; Software testing; Software development

Yeming Gu, Hui Shu, Fei Kang,
BinAIV: Semantic-enhanced vulnerability detection for Linux x86 binaries,
Computers & Security,
Volume 135,
2023,
103508,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103508.
(https://www.sciencedirect.com/science/article/pii/S0167404823004182)
Abstract: Binary code vulnerability detection is an important research direction in the field of network security. The extensive reuse of open-source code has led to the spread of vulnerabilities that originally only affected a small number of targets to other software. Existing vulnerability detection methods are mainly based on binary code similarity analysis, that is, by comparing the similarity of code embedding to detect vulnerabilities. However, existing methods lack semantic understanding of binary code and cannot distinguish between different functions with similar code structures, which reduces the accuracy of vulnerability detection. This paper proposes a binary vulnerability detection method BinAIV based on function semantics. BinAIV is based on a neural network model, which defines and constructs binary function semantics to achieve more accurate similarity analysis. Experimental results show that in terms of binary code similarity analysis performance, BinAIV has a significant improvement compared to traditional methods that only use function embedding. In cross-compiler function search, cross-optimization function search, and cross-obfuscation function search experiments, the average Recall@1 value of BinAIV compared to the best-performing baseline methods increased by 40.1 %, 99.8 %, and 184.0 %. In the real-world vulnerability detection experiment, BinAIV had the highest detection accuracy for all vulnerabilities, with an improvement of 155.1 % and 97.7 % compared to Asm2Vec and SAFE, respectively.
Keywords: Function semantic; Vulnerability detection; Code similarity; Binary code; Deep learning

Morteza Zakeri-Nasrabadi, Saeed Parsa, Mohammad Ramezani, Chanchal Roy, Masoud Ekhtiarzadeh,
A systematic literature review on source code similarity measurement and clone detection: Techniques, applications, and challenges,
Journal of Systems and Software,
Volume 204,
2023,
111796,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111796.
(https://www.sciencedirect.com/science/article/pii/S0164121223001917)
Abstract: Measuring and evaluating source code similarity is a fundamental software engineering activity that embraces a broad range of applications, including but not limited to code recommendation, duplicate code, plagiarism, malware, and smell detection. This paper proposes a systematic literature review and meta-analysis on code similarity measurement and evaluation techniques to shed light on the existing approaches and their characteristics in different applications. We initially found over 10,000 articles by querying four digital libraries and ended up with 136 primary studies in the field. The studies were classified according to their methodology, programming languages, datasets, tools, and applications. A deep investigation reveals 80 software tools, working with eight different techniques on five application domains. Nearly 49% of the tools work on Java programs and 37% support C and C++, while there is no support for many programming languages. A noteworthy point was the existence of 12 datasets related to source code similarity measurement and duplicate codes, of which only eight datasets were publicly accessible. The lack of reliable datasets, empirical evaluations, hybrid methods, and focuses on multi-paradigm languages are the main challenges in the field. Emerging applications of code similarity measurement concentrate on the development phase in addition to the maintenance.
Keywords: Source code similarity; Code clone; Plagiarism detection; Code recommendation; Systematic literature review

Dawei Yuan, Xiaohui Wang, Yao Li, Tao Zhang,
Optimizing smart contract vulnerability detection via multi-modality code and entropy embedding,
Journal of Systems and Software,
Volume 202,
2023,
111699,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111699.
(https://www.sciencedirect.com/science/article/pii/S0164121223000948)
Abstract: Smart contracts have been widely used in the blockchain world these years, and simultaneously vulnerability detection has gained more and more attention due to the staggering economic losses caused by the attacker. Existing tools that analyze vulnerabilities for smart contracts heavily rely on rules predefined by experts, which are labour-intense and require domain knowledge. Moreover, predefined rules tend to be misconceptions and increase the risk of crafty potential back-doors in the future. Recently, researchers mainly used static and dynamic execution analysis to detect the vulnerabilities of smart contracts and have achieved acceptable results. However, the dynamic method cannot cover all the program inputs and execution paths, which leads to some vulnerabilities that are hard to detect. The static analysis method commonly includes symbolic execution and theorem proving, which requires using constraints to detect vulnerability. These shortcomings show that traditional methods are challenging to apply and expand on a large scale. This paper aims to detect vulnerabilities via the Bug Injection framework and transfer learning techniques. First, we train a Transformer encoder using multi-modality code, which contains source code, intermediate representation, and assembly code. The input code consists separately of Solidity source code, intermediate representation, and assembly code. Specifically, we translate source code into the intermediate representation and decompile the byte code into assembly code by the EVM compiler. Then, we propose a novel entropy embedding technique, which combines token embedding, segment embedding, and positional embedding of the Transformer encoder in our approach. After that, we utilize the Bug Injection framework to automatically generate specific types of buggy code for fine-tuning and evaluating the performance of vulnerability detection. The experimental results show that our proposed approach improves the performance in detecting reentrancy vulnerabilities and timestamp dependence. Moreover, our approach is more flexible and scalable than static and dynamic analysis approaches in detecting smart contract vulnerabilities. Our approach improves the baseline approaches by an average of 11.89% in term of F1 score.
Keywords: Smart contract; Bug injection; Transfer learning; Vulnerability detection

Wenxin Tao, Xiaohong Su, Jiayuan Wan, Hongwei Wei, Weining Zheng,
Vulnerability detection through cross-modal feature enhancement and fusion,
Computers & Security,
Volume 132,
2023,
103341,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103341.
(https://www.sciencedirect.com/science/article/pii/S0167404823002511)
Abstract: Software vulnerability detection is critical to computer security. Most existing vulnerability detection methods use single modal-based vulnerability detection models, which cannot effectively extract cross-modal features. To solve this problem, we propose a new multimodal deep learning based vulnerability detection method through a cross-modal feature enhancement and fusion. Firstly, we utilize a special compilation and debugging method to obtain the alignment relationship between source code statements and assembly instructions, as well as between source code variables and assembly code registers. Based on this alignment relationship and program slicing technology, we propose a cross-slicing method to generate bimodal program slices. Then, we propose a cross-modal feature enhanced code representation learning model to capture the fine-grained semantic correlation between source code and assembly code by using the co-attention mechanisms. Finally, vulnerability detection is achieved by feature level fusion of semantic features captured in fine-grained aligned source code and assembly code. Extensive experiments show that our method improves the performance of vulnerability detection compared with state-of-the-art methods. Specifically, our method achieves an accuracy of 97.4% and an F1-measure of 93.4% on the SARD dataset. An average accuracy of 95.4% and an F1-measure of 89.1% on two real-world software projects (i.e., FFmpeg and OpenSSL) is also achieved by our method, improving over SOTA method 4.5% and 2.9%.
Keywords: Software security; Multimodal deep learning; Fine-grained cross modal alignment; Co-attention; Vulnerability detection

Hussien Al-haj Ahmad, Yasser Sedaghat,
An automated framework for selectively tolerating SDC errors based on rigorous instruction-level vulnerability assessment,
Future Generation Computer Systems,
Volume 157,
2024,
Pages 392-407,
ISSN 0167-739X,
https://doi.org/10.1016/j.future.2024.04.006.
(https://www.sciencedirect.com/science/article/pii/S0167739X24001365)
Abstract: The recent trend in most processor manufacturing technologies has significantly increased the vulnerability of embedded systems operating in harsh environments against soft errors. These errors can cause Silent Data Corruptions (SDCs) that produce erroneous execution results silently, disturbing the system’s execution and potentially leading to severe financial, human or environmental disasters. The use of fault tolerance techniques that take into account the performance and constraints of safety-critical systems is therefore essential to improve system reliability efficiently. Given the significant overhead imposed by conventional techniques, e.g., performance loss, increased memory usage, and additional hardware costs, researchers have developed cost-effective software-based techniques for fault tolerance. However, as detection rates grow, these techniques can increase code size and execution time significantly, which creates a challenge. This paper proposes an automated framework for selective fault tolerance of SDCs in software running on different architectures. The framework comprises a sequence of several consecutive techniques executed automatically. It offers a software-based technique that operates at the microarchitecture level and evaluates the vulnerability of program instructions against SDC errors. The framework conducts vulnerability assessment at the binary code level using a non-intrusive, runtime fault injection mechanism. It can inject faults at different granularity levels to maximize fault activation, including fine-grained injection at specific instruction fields or encoding bits, and coarse-grained injection into the entire software system. The framework makes minor modifications to the software being tested, enabling it to run at near-native speed. When SDC vulnerable instructions are identified, the framework selectively protects them automatically using a compiler extension, achieving a more appropriate trade-off between SDC detection and overhead by avoiding overprotection. Our framework was evaluated by conducting a large number of fault injection-based experiments on real-world benchmark programs using the cycle-accurate Gem5 simulator. Leveraging the accurate vulnerability assessment results provided by our framework, the proposed selective technique reduces SDC errors by up to 99% by selectively protecting only 45% of the program’s static instructions, with a performance overhead ranging from 8% to 35%.
Keywords: Fault tolerance; Transient hardware fault; Silent data corruptions; Vulnerability assessment; Fault injection

Huiwen Yang, Xiguo Gu, Xiang Chen, Liwei Zheng, Zhanqi Cui,
CrossFuzz: Cross-contract fuzzing for smart contract vulnerability detection,
Science of Computer Programming,
Volume 234,
2024,
103076,
ISSN 0167-6423,
https://doi.org/10.1016/j.scico.2023.103076.
(https://www.sciencedirect.com/science/article/pii/S0167642323001582)
Abstract: Context:
Smart contracts are computer programs that run on a blockchain. As the functions implemented by smart contracts become increasingly complex, the number of cross-contract interactions within them also rises. Consequently, the combinatorial explosion of transaction sequences poses a significant challenge for smart contract security vulnerability detection. Existing static analysis-based methods for detecting cross-contract vulnerabilities suffer from high false-positive rates and cannot generate test cases, while fuzz testing-based methods exhibit low code coverage and may not accurately detect security vulnerabilities.
Objective:
The goal of this paper is to address the above limitations and efficiently detect cross-contract vulnerabilities. To achieve this goal, we present CrossFuzz, a fuzz testing-based method for detecting cross-contract vulnerabilities.
Method:
First, CrossFuzz generates parameters of constructors by tracing data propagation paths. Then, it collects inter-contract data flow information. Finally, CrossFuzz optimizes mutation strategies for transaction sequences based on inter-contract data flow information to improve the performance of fuzz testing.
Results:
We implemented CrossFuzz, which is an extension of ConFuzzius, and conducted experiments on a real-world dataset containing 396 smart contracts. The results show that CrossFuzz outperforms xFuzz, a fuzz testing-based tool optimized for cross-contract vulnerability detection, with a 10.58% increase in bytecode coverage. Furthermore, CrossFuzz detects 1.82 times more security vulnerabilities than ConFuzzius.
Conclusion:
Our method utilizes data flow information to optimize mutation strategies. It significantly improves the efficiency of fuzz testing for detecting cross-contract vulnerabilities.
Keywords: Smart contract; Fuzz testing; Cross-contract vulnerability; Security vulnerability detection

Mingwei Tang, Wei Tang, Qingchi Gui, Jie Hu, Mingfeng Zhao,
A vulnerability detection algorithm based on residual graph attention networks for source code imbalance (RGAN),
Expert Systems with Applications,
Volume 238, Part D,
2024,
122216,
ISSN 0957-4174,
https://doi.org/10.1016/j.eswa.2023.122216.
(https://www.sciencedirect.com/science/article/pii/S0957417423027185)
Abstract: It is essential to detect potential vulnerabilities in software to ensure its safety. As software systems become more complex, traditional static vulnerability detection methods perform poorly. Currently, deep learning-based vulnerability detection models only extract source code vulnerability features using sequences or graphs. Sequential neural networks ignore structural information in the code, such as control flow diagrams and data flow diagrams. Additionally, graph neural networks cannot accurately extract features due to the lack of effective methods for extracting nodes’ features and aggregating global information. To address the above issue, we propose a vulnerability detection algorithm based on residual graph attention networks for source code imbalance (RGAN). Firstly, a local feature extraction module (PE-BL-A module) is designed. Using the sequence neural network, the module extracts various useful features, including node features in a control flow diagram based on local semantic features. Secondly, we present the Residual Graph Attention Network module (RGAT). To learn and update node features along the control flow direction, the module uses a graph attention network with residual connections. In this module, a mean biaffine attention pooling mechanism is proposed that can extract total graph vulnerability features more effectively. Thirdly, a dynamic cross-entropy loss function is designed. Using this function, it can handle sample imbalances during training. Finally, experiments conducted on several benchmark datasets demonstrate that the proposed model achieves state-of-the-art results.
Keywords: Source code vulnerability detection; Sequence neural network; Graph neural network; Attention mechanism; Imbalance processing

Wenjing Cai, Junlin Chen, Jiaping Yu, Lipeng Gao,
A software vulnerability detection method based on deep learning with complex network analysis and subgraph partition,
Information and Software Technology,
Volume 164,
2023,
107328,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107328.
(https://www.sciencedirect.com/science/article/pii/S0950584923001830)
Abstract: The increasing size and complexity of software programs have made them an integral part of modern society’s infrastructure, making software vulnerabilities a major threat to computer security. To address this issue, the use of deep learning-based software vulnerability detection methods has become increasingly popular. Although the effectiveness of the deep learning-based methods has been demonstrated, these methods have faced challenges in scalability and detection performance. To tackle this challenge, we propose a new vulnerability detection method based on deep learning with complex network analysis and subgraph partition that enhances detection accuracy while maintaining scalability. The method uses complex network analysis theory to convert the CPG into an image-like matrix, and then utilizes TextCNN for vulnerability detection. As a result, our method shows a 6% improvement in accuracy and a 10% reduction in false positive rates compared to state-of-the-art methods. In addition, our approach is able to detect some of the vulnerabilities recently released by CVE.
Keywords: Vulnerability detection; Code representation; Complex network analysis; TextCNN

Pingyan Wang, Shaoying Liu, Ai Liu, Wen Jiang,
Detecting security vulnerabilities with vulnerability nets,
Journal of Systems and Software,
Volume 208,
2024,
111902,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111902.
(https://www.sciencedirect.com/science/article/pii/S0164121223002972)
Abstract: Detecting security vulnerabilities is a crucial part in secure software development. Many static analysis tools have proved to be effective in finding vulnerabilities, but generally there are some complex and subtle vulnerabilities that can escape from detection. Manual audits are a complementary approach to using tools. Unfortunately, most manual analyses are tedious and error prone. To benefit from both the tools and manual audits, some approaches incorporate the auditor's expertise into a static analysis tool during vulnerability discovery. Following this strategy, this paper presents a representation of source code called a vulnerability net, which is a special Petri net that integrates with data dependence graphs and control flow graphs. The combined representation can facilitate the detection of taint-style vulnerabilities such as buffer overflows and injection vulnerabilities. We test the proposed approach on Securibench Micro and demonstrate that it has the capability to identify a variety of vulnerabilities while keeping the rates of false negatives and positives low.
Keywords: Vulnerability; Security; Static analysis; Manual audits; Petri nets

Da Chen, Lin Feng, Yuqi Fan, Siyuan Shang, Zhenchun Wei,
Smart contract vulnerability detection based on semantic graph and residual graph convolutional networks with edge attention,
Journal of Systems and Software,
Volume 202,
2023,
111705,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111705.
(https://www.sciencedirect.com/science/article/pii/S0164121223001000)
Abstract: Smart contracts are becoming the forefront of blockchain technology, allowing the performance of credible transactions without third parties. However, smart contracts on blockchain are not immune to vulnerability exploitation and cannot be modified after being deployed on the blockchain. Therefore, it is imperative to assure the security of smart contracts via intelligent vulnerability detection tools with the exponential increase in the number of smart contracts. The remarkably developing deep learning technology provides a promising way to detect potential smart contract vulnerabilities. Nevertheless, existing deep learning-based approaches fail to effectively capture the rich syntax and semantic information embedded in smart contracts for vulnerability detection. In this paper, we tackle the problem of smart contract vulnerability detection at the function level by constructing a novel semantic graph (SG) for each function and learning the SGs using graph convolutional networks (GCNs) with residual blocks and edge attention. Our proposed method consists of three stages. In the first stage, we create the SG which contains rich syntax and semantic information including the data–data, instruction–instruction and instruction–data relationships, variables, operations, etc., by building an abstract syntax tree (AST) from the code of each function, removing the unimportant nodes in the AST, and adding edges between the nodes to represent the data flows and the execution sequence of the statements. In the second stage, we propose a new graph convolutional network model EA-RGCN to learn the content and semantic features of the code. EA-RGCN contains three parts: node and edge representation via word2vec, content feature extraction with a residual GCN (RGCN) module, and semantic feature extraction using an edge attention (EA) module. In the third stage, we concatenate the code content features and the semantic features to obtain the global code feature and use a classifier to identify whether the function is vulnerable. We conduct experiments on the datasets constructed from real-world smart contracts. Experimental results demonstrate that the proposed semantic graph and the EA-RGCN model can effectively improve the performance in terms of accuracy, precision, recall, and F1-score on smart contract vulnerability detection.
Keywords: Smart contract vulnerability detection; Code graph; Graph convolutional networks; Edge attention; Residual block

Abdalla Wasef Marashdih, Zarul Fitri Zaaba, Khaled Suwais,
An Enhanced Static Taint Analysis Approach to Detect Input Validation Vulnerability,
Journal of King Saud University - Computer and Information Sciences,
Volume 35, Issue 2,
2023,
Pages 682-701,
ISSN 1319-1578,
https://doi.org/10.1016/j.jksuci.2023.01.009.
(https://www.sciencedirect.com/science/article/pii/S1319157823000095)
Abstract: The detection of feasible paths helps to minimize the false positive rate. However, the previous works did not consider the feasibility of the program paths during the analysis detection of input validation vulnerabilities, which led to false positive results. They also needed to validate the usage of the proper sanitization functions for each context of the user input. Therefore, we proposed an enhanced static taint analysis approach to analyse the source code and track the tainted inputs in the program. It started by examining the source code to find the feasibility of each path in the program. The tainted variables were tracked through the analysis until the sink statement, which executes the tainted variables. An algorithm was built to enhance the static analyzer to handle the variables handling functions in PHP. The proposed approach was evaluated with SARD datasets and large-scale PHP programs. The results indicated that the precision in detecting XSS vulnerability was approximately 44% better than WAP and 26% better than RIPS, and its precision in detecting SQL injection was about 10% better than WAP and 19% better than RIPS. Furthermore, the proposed approach outperformed previous symbolic execution studies regarding the number of detected vulnerabilities.
Keywords: Input validation vulnerability; XSS; SQLi; Static analysis; Taint analysis

Miles Q. Li, Benjamin C.M. Fung, Ashita Diwan,
A Novel Deep Multi-head Attentive Vulnerable Line Detector,
Procedia Computer Science,
Volume 222,
2023,
Pages 35-44,
ISSN 1877-0509,
https://doi.org/10.1016/j.procs.2023.08.142.
(https://www.sciencedirect.com/science/article/pii/S1877050923009079)
Abstract: Detecting and fixing vulnerabilities in software programs before production is crucial in software engineering. Manual vulnerability detection is labor-intensive, especially for large programs, leading to the proposal of machine learning-based methods for automation. However, existing approaches primarily detect vulnerabilities at the function level, providing non-specific results that require additional developer effort to locate vulnerabilities. Detection at the line-of-code level is an underexplored area. In this paper, we propose a novel deep learning method for line-of-code vulnerability detection. Our hybrid neural network combines a memory network and multi-head attention mechanism. Through comprehensive experiments, we analyze the impact of each modification, demonstrating significant improvements in performance. Our approach outperforms existing methods for comparison, showcasing its effectiveness in vulnerability detection.
Keywords: Deep learning; vulnerability detection; memory networks; multi-head attention

Hao Sun, Lei Cui, Lun Li, Zhenquan Ding, Zhiyu Hao, Jiancong Cui, Peng Liu,
VDSimilar: Vulnerability detection based on code similarity of vulnerabilities and patches,
Computers & Security,
Volume 110,
2021,
102417,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2021.102417.
(https://www.sciencedirect.com/science/article/pii/S0167404821002418)
Abstract: Vulnerability detection using machine learning is a hot topic in improving software security. However, existing works formulate detection as a classification problem, which requires a large set of labelled data while capturing semantical and syntactic similarity. In this work, we argue that similarity in the view of vulnerability is the key in detecting vulnerabilities. We prepare a relatively smaller data set composed of both vulnerabilities and associated patches, and attempt to realize security similarity from (i) the similarity between pair of vulnerabilities and (ii) the difference between a pair of vulnerability and patch. To achieve this, we setup the detection model using the Siamese network cooperated with BiLSTM and Attention to deal with source code, Attention network to improve the detection accuracy. On a data set of 876 vulnerabilities and patches of OpenSSL and Linux, the proposed model (VDSimilar) achieves about 97.17% in AUC value of OpenSSL (where the Attention network contributes 1.21% than BiLSTM in Siamese), which is more outstanding than the most advanced methods based on deep learning.
Keywords: Siamese network; BiLSTM; Attention; Vulnerability detection; Code similarity

Janaka Senanayake, Harsha Kalutarage, Andrei Petrovski, Luca Piras, Mhd Omar Al-Kadri,
Defendroid: Real-time Android code vulnerability detection via blockchain federated neural network with XAI,
Journal of Information Security and Applications,
Volume 82,
2024,
103741,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2024.103741.
(https://www.sciencedirect.com/science/article/pii/S2214212624000449)
Abstract: Ensuring strict adherence to security during the phases of Android app development is essential, primarily due to the prevalent issue of apps being released without adequate security measures in place. While a few automated tools are employed to reduce potential vulnerabilities during development, their effectiveness in detecting vulnerabilities may fall short. To address this, “Defendroid”, a blockchain-based federated neural network enhanced with Explainable Artificial Intelligence (XAI) is introduced in this work. Trained on the LVDAndro dataset, the vanilla neural network model achieves a 96% accuracy and 0.96 F1-Score in binary classification for vulnerability detection. Additionally, in multi-class classification, the model accurately identifies Common Weakness Enumeration (CWE) categories with a 93% accuracy and 0.91 F1-Score. In a move to foster collaboration and model improvement, the model has been deployed within a blockchain-based federated environment. This environment enables community-driven collaborative training and enhancements in partnership with other clients. The extended model demonstrates improved accuracy of 96% and F1-Score of 0.96 in both binary and multi-class classifications. The use of XAI plays a pivotal role in presenting vulnerability detection results to developers, offering prediction probabilities for each word within the code. This model has been integrated into an Application Programming Interface (API) as the backend and further incorporated into Android Studio as a plugin, facilitating real-time vulnerability detection. Notably, Defendroid exhibits high efficiency, delivering prediction probabilities for a single code line in an average processing time of a mere 300 ms. The weight-sharing transparency in the blockchain-driven federated model enhances trust and traceability, fostering community engagement while preserving source code privacy and contributing to accuracy improvement.
Keywords: Android application protection; Code vulnerability; Neural network; Federated learning; Source code privacy; Explainable AI; Blockchain

Uelinton Brezolin, Andressa Vergütz, Michele Nogueira,
A method for vulnerability detection by IoT network traffic analytics,
Ad Hoc Networks,
Volume 149,
2023,
103247,
ISSN 1570-8705,
https://doi.org/10.1016/j.adhoc.2023.103247.
(https://www.sciencedirect.com/science/article/pii/S1570870523001671)
Abstract: The Internet of Things comprises wireless devices with limited computing resources. It targets attacks that exploit vulnerabilities such as unencrypted data transfer. Conventional vulnerability detection occurs from databases that list the most common vulnerabilities and exploits (CVEs). However, these bases are limited to known vulnerabilities, which is not the case for the IoT context most of the time. This work proposes MANDRAKE: a Method for vulnerAbilities detectioN baseD on the IoT netwoRk pAcKEt traffic using machine learning techniques. A performance evaluation has been conducted in a smart home scenario taking as basis two datasets, one generated experimentally for this work and the other from the literature. The results have achieved 99% precision in detecting vulnerabilities in network traffic.
Keywords: Internet of Things; Vulnerability detection; Entropy; Traffic analysis

Yukun Dong, Yeer Tang, Xiaotong Cheng, Yufei Yang, Shuqi Wang,
SedSVD: Statement-level software vulnerability detection based on Relational Graph Convolutional Network with subgraph embedding,
Information and Software Technology,
Volume 158,
2023,
107168,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107168.
(https://www.sciencedirect.com/science/article/pii/S0950584923000228)
Abstract: Context:
Current deep-learning based vulnerability detection methods have been proven more automatic and correct to a certain extent, nonetheless, they are limited to detect at function-level or file-level, which can hinder software developers from acquiring more detailed information and conducting more targeted repairs. Graph-based detection methods have shown dominant performance over others. Unfortunately, the information they reveal has not been fully utilized.
Objective:
We design SedSVD (Subgraph embedding driven Statement-level Vulnerability Detection) with two objectives: (i) to better utilize the information the code-related graphs can reflect; (ii) to detect vulnerabilities at a finer-grained level.
Method:
In our work, we propose a novel graph-based detection framework that embeds graphs at subgraph-level to realize statement-level detection. It first leverages Code Property Graph (CPG) to learn both semantic and syntactic information from source code, and then selects several center nodes (code elements) in CPG to build their subgraphs. After embedding each subgraph with its nodes and edges, we apply Relational Graph Convolutional Network (RGCN) to process different edges differently. A Multi-Layer Perceptron (MLP) layer is further added to ensure its prediction performance.
Results:
We conduct our experiments on C/C++ projects from NVD and SARD. Experimental results show that SedSVD achieves 95.15% in F1-measure which proves our work to be more effective.
Conclusion:
Our work detects at a finer-grained level and achieves higher F1-measure than existing state-of-art vulnerability detection techniques. Besides, we provide a more detailed detection report pointing the specific error code elements within statements.
Keywords: Software vulnerability detection; Code property graph; Relational graph convolutional network; Subgraph embedding; Statement-level detection

Xin Li, Yang Xin, Hongliang Zhu, Yixian Yang, Yuling Chen,
Cross-domain vulnerability detection using graph embedding and domain adaptation,
Computers & Security,
Volume 125,
2023,
103017,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.103017.
(https://www.sciencedirect.com/science/article/pii/S0167404822004096)
Abstract: Vulnerability detection is an effective means to maintain cyberspace security. Machine learning methods have risen much attention in software security due to their advantage of accuracy and automation. However, current researches mainly focus on in-domain vulnerability detection where the training data and test data belong to the same domain. Due to application scenarios, coding habits, and other factors, vulnerabilities in different software projects may obey different probability distributions. This discrepancy compromises the performance of machine learning methods when they are applied to a brand-new project. To address this cold start problem, we propose a cross-domain vulnerability detection framework using graph embedding and deep domain adaption (VulGDA). It works in a variety of cross-domain fashions, including the Zero-Shot fashion that no labeled data in the target domain is available for training. VulGDA is decomposed to graph embedding and domain adaptation. At the graph embedding stage, we transform the samples in source code into graph representations where elements are directly concatenated according to their syntactic and semantic relationships. Then, we aggregate information from neighbors and edges defined in the graph into real-valued vectors. By graph embedding, VulGDA extracts comprehensive vulnerability features and compromises the challenge of long-term dependency. Aiming at the discrepancy between training data and test data, domain adaption is used to train a feature generator. This feature generator maps the graph embedding to a “deep” feature that is discriminative for vulnerability detection, and invariant to the shift between domains. We perform a systematic experiment to validate the effectiveness of VulGDA. The results show that combining graph embedding and deep domain adaptation promotes VulGDA's performance in cross-domain vulnerability detection. Compared with the state-of-the-art methods, our method has better performance under the cold start condition.
Keywords: Cross-domain; Vulnerability detection; Graph embedding; Domain adaption; Software security

Bolun Wu, Futai Zou, Ping Yi, Yue Wu, Liang Zhang,
SlicedLocator: Code vulnerability locator based on sliced dependence graph,
Computers & Security,
Volume 134,
2023,
103469,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103469.
(https://www.sciencedirect.com/science/article/pii/S0167404823003796)
Abstract: Machine learning-based fine-grained vulnerability detection is an important technique for locating vulnerable statements, which assists engineers in efficiently analyzing and fixing the vulnerabilities. However, due to insufficient code representations, code embeddings, and neural network design, current methods suffer low vulnerability localization performance. In this paper, we propose to address these shortcomings by presenting SlicedLocator, a novel fine-grained code vulnerability detection model that is trained in a dual-grained manner and can predict both program-level and statement-level vulnerabilities. We design the sliced dependence graph, a new code representation that not only preserves rich interprocedural relations but also eliminates vulnerability-irrelevant statements. We create attention-based code embedding networks that are trained with the entire model to extract vulnerability-aware code features. In addition, we present a new LSTM-GNN model as a fusion of semantic modeling and structural modeling. Experiment results on a large-scale C/C++ vulnerability dataset reveal that SlicedLocator outperforms state-of-the-art machine learning-based vulnerability detectors, especially in terms of localization metrics.
Keywords: Vulnerability detection; Localization; Program analysis; Program representation; Deep learning

Huan Mei, Guanjun Lin, Da Fang, Jun Zhang,
Detecting vulnerabilities in IoT software: New hybrid model and comprehensive data analysis,
Journal of Information Security and Applications,
Volume 74,
2023,
103467,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2023.103467.
(https://www.sciencedirect.com/science/article/pii/S2214212623000510)
Abstract: Software vulnerabilities have always been an essential issue in cyberspace, for which many vulnerability detection techniques have been investigated. Among them, deep learning-based detection techniques have demonstrated promising detection results. However, due to the various programming patterns of developers, vulnerabilities are usually associated with the code context, such as Internet of Things (IoT) programs. Therefore, we propose a contextual embedding model to integrate three hybrid models, CLSTM, CBiLSTM (sequential structure), and CNN-BiLSTM (parallel structure), based on the code characteristics of IoT applications. To further improve the precision and robustness, we apply information augment by adding synthetic data to the real-world vulnerability data to address the severe data imbalance and facilitate neural models learning vulnerability patterns. The new method inherits the architecture of CodeBERT with multiheaded attention mechanisms and learns a richer set of vulnerable code patterns with long-range context dependencies when processing code sequence data. To assess the effectiveness of hybrid contextual embedding, we contrast the neural network models developed using the representations obtained from the three embedding methods, including CodeBERT, Word2Vec, and FastText. The experiments involve IoT applications and well-known open-source APIs. The results show that the hybrid model built based on the neural features outperforms the non-hybrid model in vulnerability detection.
Keywords: Vulnerability detection; IoT; CodeBERT; Contextual embedding; Deep learning; Hybrid model

Arvinder Kaur, Ruchikaa Nayyar,
A Comparative Study of Static Code Analysis tools for Vulnerability Detection in C/C++ and JAVA Source Code,
Procedia Computer Science,
Volume 171,
2020,
Pages 2023-2029,
ISSN 1877-0509,
https://doi.org/10.1016/j.procs.2020.04.217.
(https://www.sciencedirect.com/science/article/pii/S1877050920312023)
Abstract: Software security has become an essential component of software development process. It is necessary for an organisation to maintain software security in order to ensure integrity, authenticity and availability of the software product. To ensure software security, one of the major task is to identify vulnerabilities present in the source code before the software is being deployed. Detecting vulnerabilities in early phases of software development cycle, makes the process of fixing those vulnerabilities much easier for software developers. The vulnerability detection can be done either at the production phase, this means when the software is still being developed by statically auditing the source code, or dynamically at run time. In this study, vulnerability detection was done through Static code analysis process. Static code analysis can be done either manually or through automated tools. This paper focuses on using automated source code scanning tools for vulnerabilities detection in a software. Automated static Code Analysis tools audits the entire source code for its quality and identify any potential security vulnerability, if present. Unlike dynamic source code analysis that evaluates the source code behaviour during code execution, which is done quite late in the software development life cycle, Static Code Analysis leads to detection of security vulnerabilities in a source code in early stages of software development process, when the software is still in production phase because it does not require code to be in execution state. This paper firstly explains the importance of incorporating static code analysis in software development life cycle process so as to facilitate early detection of vulnerabilities in software product, and then present a comparative study of various static code analysis tools available for vulnerability detection in C/C++ and JAVA source code. The comparative study of three C/C++ static code analysis tools (flawfinder, RATS and CPPCheck) and two JAVA static code analysis tools (spotbugs and PMD) is done using Juliet (version1.3) test suite and APACHE tomcat dataset respectively, on the basis of category of vulnerability detected by each of the selected tool and the likelihood of false positive reported by each tool. Results showed that Flawfinder detected maximum categories of vulnerabilities and RATS and CPPCheck were almost similar in types of vulnerabilities detected. Also, it was observed that CPPCheck reported maximum number of false positives as compared to other two tools. Java static code analysis tools Spot bugs was able to detect more number of vulnerabilities than PMD.
Keywords: software security; vulnerabilities; static code analysis

Chunyong Zhang, Yang Xin,
VulGAI: vulnerability detection based on graphs and images,
Computers & Security,
Volume 135,
2023,
103501,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103501.
(https://www.sciencedirect.com/science/article/pii/S016740482300411X)
Abstract: Deep learning models have been widely used in the field of vulnerability detection. Deep learning-based vulnerability detection methods can automatically learn code patterns. Some methods consider processing codes as text sequences to achieve scalable vulnerability detection. They leverage natural language processing models to extract code features. These methods do not consider the code's semantic structure and treat code slices as text. Vulnerability detection methods based on graph structures and graph neural networks are more accurate than text-based methods. However, these methods lack scalability in practice. Both graph generation and graph neural network training are all time-consuming. We propose a vulnerability detection method based on graphs and images (VulGAI). VulGAI choose the more reasonable node centrality to generate the image. It can preserve program details and distinguish node importance from different perspectives. In addition, we design a more efficient CNN model, which reduces computational overhead and improves detection performance (Time and Accuracy). We implement VulGAI and evaluate six methods (VulDePecker, SySeVR, Devign, VulCNN, mVulPreter, and VulGAI) on 40,657 functions. Experimental results show that VulGAI achieves higher Accuracy, TPR, and F1-Score than the others. In addition, we compare VulGAI and VulCNN on 30270 real-world functions. VulGAI outperforms VulCNN by 1.48 times in the number of TP. VulGAI is about 3.9 times faster than VulCNN in detection time.
Keywords: Vulnerability detection; Program dependency graph; Node centrality; RGB image; CNN

Hazim Hanif, Mohd Hairul Nizam Md Nasir, Mohd Faizal Ab Razak, Ahmad Firdaus, Nor Badrul Anuar,
The rise of software vulnerability: Taxonomy of software vulnerabilities detection and machine learning approaches,
Journal of Network and Computer Applications,
Volume 179,
2021,
103009,
ISSN 1084-8045,
https://doi.org/10.1016/j.jnca.2021.103009.
(https://www.sciencedirect.com/science/article/pii/S1084804521000369)
Abstract: The detection of software vulnerability requires critical attention during the development phase to make it secure and less vulnerable. Vulnerable software always invites hackers to perform malicious activities and disrupt the operation of the software, which leads to millions in financial losses to software companies. In order to reduce the losses, there are many reliable and effective vulnerability detection systems introduced by security communities aiming to detect the software vulnerabilities as early as in the development or testing phases. To summarise the software vulnerability detection system, existing surveys discussed the conventional and data mining approaches. These approaches are widely used and mostly consist of traditional detection techniques. However, they lack discussion on the newly trending machine learning approaches, such as supervised learning and deep learning techniques. Furthermore, existing studies fail to discuss the growing research interest in the software vulnerability detection community throughout the years. With more discussion on this, we can predict and focus on what are the research problems in software vulnerability detection that need to be urgently addressed. Aiming to reduce these gaps, this paper presents the research interests’ taxonomy in software vulnerability detection, such as methods, detection, features, code and dataset. The research interest categories exhibit current trends in software vulnerability detection. The analysis shows that there is considerable interest in addressing methods and detection problems, while only a few are interested in code and dataset problems. This indicates that there is still much work to be done in terms of code and dataset problems in the future. Furthermore, this paper extends the machine learning approaches taxonomy, which is used to detect the software vulnerabilities, like supervised learning, semi-supervised learning, ensemble learning and deep learning. Based on the analysis, supervised learning and deep learning approaches are trending in the software vulnerability detection community as these techniques are able to detect vulnerabilities such as buffer overflow, SQL injection and cross-site scripting effectively with a significant detection performance, up to 95% of F1 score. Finally, this paper concludes with several discussions on potential future work in software vulnerability detection in terms of datasets, multi-vulnerabilities detection, transfer learning and real-world applications.
Keywords: Software vulnerability detection; Software security; Computer security; Machine learning; Deep learning

Nami Ashizawa, Naoto Yanai, Jason Paul Cruz, Shingo Okamura,
Eth2Vec: Learning contract-wide code representations for vulnerability detection on Ethereum smart contracts,
Blockchain: Research and Applications,
Volume 3, Issue 4,
2022,
100101,
ISSN 2096-7209,
https://doi.org/10.1016/j.bcra.2022.100101.
(https://www.sciencedirect.com/science/article/pii/S2096720922000422)
Abstract: Ethereum smart contracts are computer programs that are deployed and executed on the Ethereum blockchain to enforce agreements among untrusting parties. Being the most prominent platform that supports smart contracts, Ethereum has been targeted by many attacks and plagued by security incidents. Consequently, many smart contract vulnerabilities have been discovered in the past decade. To detect and prevent such vulnerabilities, different security analysis tools, including static and dynamic analysis tools, have been created, but their performance decreases drastically when codes to be analyzed are constantly being rewritten. In this paper, we propose Eth2Vec, a machine-learning-based static analysis tool that detects smart contract vulnerabilities. Eth2Vec maintains its robustness against code rewrites; i.e., it can detect vulnerabilities even in rewritten codes. Other machine-learning-based static analysis tools require features, which analysts create manually, as inputs. In contrast, Eth2Vec uses a neural network for language processing to automatically learn the features of vulnerable contracts. In doing so, Eth2Vec can detect vulnerabilities in smart contracts by comparing the similarities between the codes of a target contract and those of the learned contracts. We performed experiments with existing open databases, such as Etherscan, and Eth2Vec was able to outperform a recent model based on support vector machine in terms of well-known metrics, i.e., precision, recall, and F1-score.
Keywords: Ethereum; Smart contracts; Blockchain; Neural networks; Static analysis; Code similarity; Vulnerability detection

Zihua Song, Junfeng Wang, Kaiyuan Yang, Jigang Wang,
HGIVul: Detecting inter-procedural vulnerabilities based on hypergraph convolution,
Information and Software Technology,
Volume 160,
2023,
107219,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107219.
(https://www.sciencedirect.com/science/article/pii/S0950584923000733)
Abstract: Context:
Detecting source code vulnerabilities is one way to block cyber attacks from an early stage. Vulnerability-triggered code typically involves one or more function procedures, while current research pays more attention to the code on a single procedure. Due to lacking a comprehensive analysis of multiple vulnerability-related procedures, current methods suffer disorder false-positive and false-negative rates, especially in detecting inter-procedural vulnerability.
Objective:
This paper proposes HGIVul, an inter-procedural vulnerability detection method for source code based on hypergraph convolution. The key of HGIVul is to derive the syntax-semantic characteristic from multiple procedures in a suitable code information space, which brings more balanced detection.
Methods:
Firstly, the potential vulnerability-related code trace across multiple procedures is located via static analyzer Infer. Then, HGIVul reconstructs the soft inter-procedural control flow graph (ICFG) from the trace to restore the complex relationship between multiple-procedural codes. Next, HGIVul performs multi-level graph convolution on the soft ICFG to grasp holistic code characteristics within multiple procedures. Finally, a classifier is applied to the extracted code features for vulnerability detection.
Results:
The experimental results show that HGIVul outperforms in detecting vulnerabilities and identifying vulnerability types, with the F1-measure of 66.33% and 79.58% for detection and identification, respectively. Moreover, the experiment on cross-projects indicates HGIVul has a better detection ability.
Conclusion:
The proposed HGIVul achieves a balanced detection performance than the related state-of-the-art methods, which proves that fusing syntactic–semantic information from multiple procedures benefits inter-procedural vulnerability detection. In addition, the results applied to five actual projects indicate that HGIVul has the feasibility of detection in practical.
Keywords: Vulnerability detection; Inter-procedural vulnerability; Hypergraph neural network; Software security engineering; Static analysis

Laura Wartschinski, Yannic Noller, Thomas Vogel, Timo Kehrer, Lars Grunske,
VUDENC: Vulnerability Detection with Deep Learning on a Natural Codebase for Python,
Information and Software Technology,
Volume 144,
2022,
106809,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2021.106809.
(https://www.sciencedirect.com/science/article/pii/S0950584921002421)
Abstract: Context:
Identifying potential vulnerable code is important to improve the security of our software systems. However, the manual detection of software vulnerabilities requires expert knowledge and is time-consuming, and must be supported by automated techniques.
Objective:
Such automated vulnerability detection techniques should achieve a high accuracy, point developers directly to the vulnerable code fragments, scale to real-world software, generalize across the boundaries of a specific software project, and require no or only moderate setup or configuration effort.
Method:
In this article, we present Vudenc (Vulnerability Detection with Deep Learning on a Natural Codebase), a deep learning-based vulnerability detection tool that automatically learns features of vulnerable code from a large and real-world Python codebase. Vudenc applies a word2vec model to identify semantically similar code tokens and to provide a vector representation. A network of long-short-term memory cells (LSTM) is then used to classify vulnerable code token sequences at a fine-grained level, highlight the specific areas in the source code that are likely to contain vulnerabilities, and provide confidence levels for its predictions.
Results:
To evaluate Vudenc, we used 1,009 vulnerability-fixing commits from different GitHub repositories that contain seven different types of vulnerabilities (SQL injection, XSS, Command injection, XSRF, Remote code execution, Path disclosure, Open redirect) for training. In the experimental evaluation, Vudenc achieves a recall of 78%–87%, a precision of 82%–96%, and an F1 score of 80%–90%. Vudenc’s code, the datasets for the vulnerabilities, and the Python corpus for the word2vec model are available for reproduction.
Conclusions:
Our experimental results suggest that Vudenc is capable of outperforming most of its competitors in terms of vulnerably detection capabilities on real-world software. Comparable accuracy was only achieved on synthetic benchmarks, within single projects, or on a much coarser level of granularity such as entire source code files.
Keywords: Static analysis; Vulnerability detection; Deep learning; Long-short-term memory network; Natural codebase; Software repository mining

Teresa K. George, K. Poulose Jacob, Rekha K. James,
Token based Detection and Neural Network based Reconstruction framework against code injection vulnerabilities,
Journal of Information Security and Applications,
Volume 41,
2018,
Pages 75-91,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2018.05.005.
(https://www.sciencedirect.com/science/article/pii/S2214212617300480)
Abstract: Security vulnerabilities are frequently detected and exploited in modern web applications. Intruders obtain unrestricted access to the information stored at the back-end database server of a web application by exploiting security vulnerabilities. Code injection attacks top the list due to lack of effective strategies for detecting and blocking injection attacks. The proposed Token based Detection and Neural Network based Reconstruction (TbD-NNbR) framework is a unique approach to detect and block code injections with negligible processing overheads. This framework makes use of an efficient token mapping and validation technique to match the statically generated legal query tokens against the parsed dynamic query tokens at run time. The proposed approach also has the provision to reconstruct queries from authenticated users. The prototype implementation of TbD-NNbR shows that it does not demand any source code modifications and incurs only a negligible computational overhead without any incidents of false positives or false negatives.
Keywords: Code injection attack; Neural network; Query validation; Reconstruction of queries; Security vulnerability; Web application

Guodong Ye, Xin Liu, Siqi Fan, Yuan Tan, Qingguo Zhou, Rui Zhou, Xiaokang Zhou,
Novel supply chain vulnerability detection based on heterogeneous-graph-driven hash similarity in IoT,
Future Generation Computer Systems,
Volume 148,
2023,
Pages 201-210,
ISSN 0167-739X,
https://doi.org/10.1016/j.future.2023.06.006.
(https://www.sciencedirect.com/science/article/pii/S0167739X23002194)
Abstract: Supply chain vulnerability (SCV) exists in third-party components (operating systems, basic libraries, etc.). These vulnerabilities do not exist in code written by ordinary developers, who unknowingly introduce them due to the use of third-party components, resulting in the software they developed being affected by these vulnerabilities. Compared with traditional devices, IoT devices have various architectures, and the security issues introduced by code reuse are prominent. This paper proposes PhG-vNet, an effective and efficient SCV detection approach for IoT devices based on heterogeneous-graph-driven hash similarity. PhG-vNet uses customized graph embedding to feature the pseudo-code and uses the heterogeneous graph neural network to extract the graph structure to binary hash embeddings. Then, PhG-vNet detects SCVs based on self-designed bit similarity with Bayesian weighted. Experiments show that PhG-vNet does not need expensive hardware requirements and has impressive low overhead and acceptable detection performance.
Keywords: Binary code similarity; Supply chain vulnerability; Heterogeneous graph; Vulnerability detection

Xue Yuan, Guanjun Lin, Huan Mei, Yonghang Tai, Jun Zhang,
Software vulnerable functions discovery based on code composite feature,
Journal of Information Security and Applications,
Volume 81,
2024,
103718,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2024.103718.
(https://www.sciencedirect.com/science/article/pii/S2214212624000218)
Abstract: Vulnerability identification is crucial to protecting software systems from attacks. Although numerous learning-based solutions have been suggested to assist in vulnerability identification, these approaches often face challenges due to the scarcity of real-world vulnerability data. To extract as much vulnerability information as possible from limited data, we consider obtaining the characteristics of vulnerabilities from different forms of code by leveraging two distinct deep neural models. First, source code functions are considered to be textual sequences, and Gated Recurrent Unit (GRU) is applied to extract serialized features. Then, Abstract Syntax Trees (ASTs) of these functions, which reflects the code structure, are fed to a Gated Graph Recurrent Network (GGRN) to obtain structural features indicative of software vulnerability. To better handle data imbalance issues in real-world scenarios, we employ Random Forest (RF) to construct a predictive model to learn the concatenation of serialized and structural features extracted by GRU and GGRN. To evaluate the proposed approach, we collected 12 open-source projects containing function-level samples and compared the proposed method with a series of baselines, including popular learning-based methods and static analysis tools. The empirical results demonstrate that our proposed approach outperforms the baselines and can identify more vulnerabilities.
Keywords: Vulnerability detection; Source code; Deep learning; Deep representation learning

Hariharan M., Sathish Kumar C., Anshul Tanwar, Krishna Sundaresan, Prasanna Ganesan, Sriram Ravi, R. Karthik,
Proximal Instance Aggregator networks for explainable security vulnerability detection,
Future Generation Computer Systems,
Volume 134,
2022,
Pages 303-318,
ISSN 0167-739X,
https://doi.org/10.1016/j.future.2022.04.008.
(https://www.sciencedirect.com/science/article/pii/S0167739X22001315)
Abstract: Security vulnerabilities in software are the root cause of cyberattacks. Considering that these defects have huge associated costs, they should be proactively detected and resolved before shipping the software. Data-driven approaches like Artificial Intelligence (AI) are vastly explored for automatic vulnerability detection, given their potential to leverage large-scale vulnerability data feeds and learn from these scenarios. This work introduces a novel Proximal Instance Aggregator (PIA) neural network for accurately capturing insecure C code patterns from Abstract Syntax Tree (AST). It is built upon the concept of Multiple Instance Learning (MIL), which treats the AST representation of the code as a ‘bag’ of tree path ‘instances’. The security vulnerability can manifest in one or multiple such AST path instances. The PIA model dynamically learns a set of abstract concepts to describe the patterns associated with the AST paths. Specifically, the vulnerable nature of an AST path is characterized by its proximity to these concepts. The model also employs the attention mechanism to generate deep representations. By drawing cross-correlation of features between the path instances, the self-attention robustly weighs the relevance of each AST path towards vulnerability classification. The MIL utilizes these deep feature sets to construct the concept space. Thus, even without explicit supervision for localizing the line of defect, the AI automatically learns AST instance classification in a weakly supervised manner. Since AST-level prediction is formed as an aggregation of instance classifications, the AI is inherently explainable. The model outperforms state-of-the-art methods by a fair margin. It achieves 95.63% detection accuracy and 95.65% F1-score on the benchmarked NIST SARD, NVD datasets for a range of vulnerabilities.
Keywords: Multiple-Instance learning; Interpretability; Deep learning; Vulnerability detection; Abstract Syntax Tree; Weakly supervised learning

Wanqing Jie, Qi Chen, Jiaqi Wang, Arthur Sandor Voundi Koe, Jin Li, Pengfei Huang, Yaqi Wu, Yin Wang,
A novel extended multimodal AI framework towards vulnerability detection in smart contracts,
Information Sciences,
Volume 636,
2023,
118907,
ISSN 0020-0255,
https://doi.org/10.1016/j.ins.2023.03.132.
(https://www.sciencedirect.com/science/article/pii/S0020025523004565)
Abstract: Current automatic data-driven vulnerability detection in smart contracts selects and processes features of interest under black box settings without empirical justification. In this paper, we propose a smart contract testing methodology that bestows developers with flexible, practical and customizable strategies to detect vulnerabilities. Our work enforces strong whitebox knowledge to a series of supervised multimodal tasks under static analysis. Each task encapsulates a vulnerability detection branch test and pipelines feature selection, dimension unification, feature fusion, model training and decision-making. We exploit multiple features made up of code and graph embeddings at the single modality level (intramodal settings) and across individual modalities (intermodal settings). We assign each task to either intramodal or intermodal settings, and show how to train state-of-the-art self-attentive bi-LSTM, textCNN, and random forest (RF) models to extract a joint multimodal feature representation per task. We evaluate our framework over 101,082 functions extracted from the SmartEmbed dataset, and rank each multimodal vulnerability mining strategy in terms of detection performance. Extensive experiments show that our work outperforms existing schemes, and the highest performance reaches 99.71%.
Keywords: Smart contract; Vulnerability detection; Multimodal; AI approach; White box

Jinfu Chen, Chi Zhang, Saihua Cai, Lin Zhang, Liang Ma,
A memory-related vulnerability detection approach based on vulnerability model with Petri Net,
Journal of Logical and Algebraic Methods in Programming,
Volume 132,
2023,
100859,
ISSN 2352-2208,
https://doi.org/10.1016/j.jlamp.2023.100859.
(https://www.sciencedirect.com/science/article/pii/S2352220823000135)
Abstract: With the continuous development of information technology, software vulnerabilities have become a critical threat to information security. Post-release detection of memory leaks, double free and use after free is one of the most challenging research problems in software vulnerability analysis. To tackle this challenge, we introduce a vulnerability model based on Petri Net. We consider the characteristics and causes of vulnerabilities, modeling is conducted from the subject and environment of vulnerabilities. Based on this vulnerability model, we propose a memory-related vulnerability detection framework based on vulnerability model (MRVD-VM) and its vulnerability detection algorithm based on vulnerability mode (VDA-VM). The results of experiments on Juliet Test Suite 1.2 for C_CPP show that MRVD-VM significantly outperforms three state-of-the-art baseline tools, including Cppcheck, Flawfinder, and Splint, in detecting memory leaks, double free and use after free.
Keywords: Vulnerability model; Vulnerability detection; Memory leak; Double free; Use after free

Francesco Lomio, Emanuele Iannone, Andrea De Lucia, Fabio Palomba, Valentina Lenarduzzi,
Just-in-time software vulnerability detection: Are we there yet?,
Journal of Systems and Software,
Volume 188,
2022,
111283,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2022.111283.
(https://www.sciencedirect.com/science/article/pii/S0164121222000437)
Abstract: Background:
Software vulnerabilities are weaknesses in source code that might be exploited to cause harm or loss. Previous work has proposed a number of automated machine learning approaches to detect them. Most of these techniques work at release-level, meaning that they aim at predicting the files that will potentially be vulnerable in a future release. Yet, researchers have shown that a commit-level identification of source code issues might better fit the developer’s needs, speeding up their resolution.
Objective:
To investigate how currently available machine learning-based vulnerability detection mechanisms can support developers in the detection of vulnerabilities at commit-level.
Method:
We perform an empirical study where we consider nine projects accounting for 8991 commits and experiment with eight machine learners built using process, product, and textual metrics.
Results:
We point out three main findings: (1) basic machine learners rarely perform well; (2) the use of ensemble machine learning algorithms based on boosting can substantially improve the performance; and (3) the combination of more metrics does not necessarily improve the classification capabilities.
Conclusion:
Further research should focus on just-in-time vulnerability detection, especially with respect to the introduction of smart approaches for feature selection and training strategies.
Keywords: Software vulnerabilities; Machine learning; Empirical SE

Maryam Mouzarani, Babak Sadeghiyan,
Towards designing an extendable vulnerability detection method for executable codes,
Information and Software Technology,
Volume 80,
2016,
Pages 231-244,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2016.09.004.
(https://www.sciencedirect.com/science/article/pii/S095058491630146X)
Abstract: Context: Software vulnerabilities allow the attackers to harm the computer systems. Timely detection and removal of vulnerabilities help to improve the security of computer systems and avoid the losses from exploiting the vulnerabilities. Objective: Various methods have been proposed to detect the vulnerabilities in the past decades. However, most of these methods are suggested for detecting one or a limited number of vulnerability classes and require fundamental changes to be able to detect other vulnerabilities. In this paper, we present a first step towards designing an extendable vulnerability detection method that is independent from the characteristics of specific vulnerabilities. Method: To do so, we first propose a general model for specifying software vulnerabilities. Based on this model, a general specification method and an extendable algorithm is then presented for detecting the specified vulnerabilities in executable codes. As the first step, single-instruction vulnerabilities–the vulnerabilities that appear in one instruction–are specified and detected. We present a formal definition for single-instruction vulnerabilities. In our method, detection of the specified vulnerabilities is considered as solving a satisfaction problem. The suggested method is implemented as a plug-in for Valgrind binary instrumentation framework and the vulnerabilities are specified by the use of Valgrind intermediate language, called Vex. Results: Three classes of single-instruction vulnerabilities are specified in this paper, i. e. division by zero, integer bugs and NULL pointer dereference. The experiments demonstrate that the presented specification for these vulnerabilities are accurate and the implemented method can detect all the specified vulnerabilities. Conclusion: As we employ a general model for specifying the vulnerabilities and the structure of our vulnerability detection method does not depend on a specific vulnerability, our method can be extended to detect other specified vulnerabilities.
Keywords: Software vulnerability; Executable codes; General specification; Extendable method

Hieu Dinh Vo, Son Nguyen,
Can an old fashioned feature extraction and a light-weight model improve vulnerability type identification performance?,
Information and Software Technology,
Volume 164,
2023,
107304,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107304.
(https://www.sciencedirect.com/science/article/pii/S0950584923001581)
Abstract: Recent advances in automated vulnerability detection have achieved potential results in helping developers determine vulnerable components. However, after detecting vulnerabilities, investigating to fix vulnerable code is a non-trivial task. In fact, the types of vulnerability, such as buffer overflow or memory corruption, could help developers quickly understand the nature of the weaknesses and localize vulnerabilities for security analysis. In this work, we investigate the problem of vulnerability type identification (VTI). The problem is modeled as the multi-label classification task, which could be effectively addressed by “pre-training, then fine-tuning” framework with deep pre-trained embedding models. We evaluate the performance of the well-known and advanced pre-trained models for VTI on a large set of vulnerabilities. Surprisingly, their performance is not much better than that of the classical baseline approach with an old-fashioned bag-of-word, TF-IDF. Meanwhile, these deep neural network approaches cost much more resources and require GPU. We also introduce a lightweight independent component to refine the predictions of the baseline approach. Our idea is that the types of vulnerabilities could strongly correlate to certain code tokens (distinguishing tokens) in several crucial parts of programs. The distinguishing tokens for each vulnerability type are statistically identified based on their prevalence in the type versus the others. Our results show that the baseline approach enhanced by our component can outperform the state-of-the-art deep pre-trained approaches while retaining very high efficiency. Furthermore, the proposed component could also improve the neural network approaches by up to 92.8% in macro-average F1.
Keywords: Vulnerability type identification; Vulnerability resolution; Software vulnerability

Sicong Cao, Xiaobing Sun, Lili Bo, Ying Wei, Bin Li,
BGNN4VD: Constructing Bidirectional Graph Neural-Network for Vulnerability Detection,
Information and Software Technology,
Volume 136,
2021,
106576,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2021.106576.
(https://www.sciencedirect.com/science/article/pii/S0950584921000586)
Abstract: Context:
Previous studies have shown that existing deep learning-based approaches can significantly improve the performance of vulnerability detection. They represent code in various forms and mine vulnerability features with deep learning models. However, the differences of code representation forms and deep learning models make various approaches still have some limitations. In practice, their false-positive rate (FPR) and false-negative rate (FNR) are still high.
Objective:
To address the limitations of existing deep learning-based vulnerability detection approaches, we propose BGNN4VD (Bidirectional Graph Neural Network for Vulnerability Detection), a vulnerability detection approach by constructing a Bidirectional Graph Neural-Network (BGNN).
Method:
In Phase 1, we extract the syntax and semantic information of source code through abstract syntax tree (AST), control flow graph (CFG), and data flow graph (DFG). Then in Phase 2, we use vectorized source code as input to Bidirectional Graph Neural-Network (BGNN). In Phase 3, we learn the different features between vulnerable code and non-vulnerable code by introducing backward edges on the basis of traditional Graph Neural-Network (GNN). Finally in Phase 4, a Convolutional Neural-Network (CNN) is used to further extract features and detect vulnerabilities through a classifier.
Results:
We evaluate BGNN4VD on four popular C/C++ projects from NVD and GitHub, and compare it with four state-of-the-art (Flawfinder, RATS, SySeVR, and VUDDY) vulnerab ility detection approaches. Experiment results show that, when compared these baselines, BGNN4VD achieves 4.9%, 11.0%, and 8.4% improvement in F1-measure, accuracy and precision, respectively.
Conclusion:
The proposed BGNN4VD achieves a higher precision and accuracy than the state-of-the-art methods. In addition, when applied on the latest vulnerabilities reported by CVE, BGNN4VD can still achieve a precision at 45.1%, which demonstrates the feasibility of BGNN4VD in practical application.
Keywords: Vulnerability detection; Bidirectional Graph Neural-Network; Code representation

Clemens-Alexander Brust, Tim Sonnekalb, Bernd Gruner,
ROMEO: A binary vulnerability detection dataset for exploring Juliet through the lens of assembly language,
Computers & Security,
Volume 128,
2023,
103165,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103165.
(https://www.sciencedirect.com/science/article/pii/S0167404823000755)
Abstract: Context
Automatic vulnerability detection on C/C++ source code has benefitted from the introduction of machine learning to the field, with many recent publications targeting this combination. In contrast, assembly language or machine code artifacts receive less attention, although there are compelling reasons to study them. They are more representative of what is executed, more easily incorporated in dynamic analysis, and in the case of closed-source code, there is no alternative.
Objective
We evaluate the representative capability of assembly language compared to C/C++ source code for vulnerability detection. Furthermore, we investigate the role of call graph context in detecting function-spanning vulnerabilities. Finally, we verify whether compiling a benchmark dataset compromises an experiment’s soundness by inadvertently leaking label information.
Method
We propose ROMEO, a publicly available, reproducible and reusable binary vulnerability detection benchmark dataset derived from the synthetic Juliet test suite. Alongside, we introduce a simple text-based assembly language representation that includes context for function-spanning vulnerability detection and semantics to detect high-level vulnerabilities. It is constructed by disassembling the .text segment of the respective binaries.
Results
We evaluate an x86 assembly language representation of the compiled dataset, combined with an off-the-shelf classifier. It compares favorably to state-of-the-art methods, including those operating on the full C/C++ code. Including context information using the call graph improves detection of function-spanning vulnerabilities. There is no label information leaked during the compilation process.
Conclusion
Performing vulnerability detection on a compiled program instead of the source code is a worthwhile tradeoff. While certain information is lost, e.g., comments and certain identifiers, other valuable information is gained, e.g., about compiler optimizations.

Qianchong Zhao, Cheng Huang, Liuhu Dai,
VULDEFF: Vulnerability detection method based on function fingerprints and code differences,
Knowledge-Based Systems,
Volume 260,
2023,
110139,
ISSN 0950-7051,
https://doi.org/10.1016/j.knosys.2022.110139.
(https://www.sciencedirect.com/science/article/pii/S0950705122012357)
Abstract: The significant increase in Open Source Software has led to a sharp increase in code cloning vulnerabilities. Code similarity detection methods are usually used to detect these vulnerabilities. However, cloned code often modifies the original code to varying degrees, and the difference between vulnerable code and patch code can be very small. Traditional code similarity detection methods cannot effectively detect common mutation patterns in code cloning and distinguish vulnerable code from patch code. The paper proposes a vulnerability detection method named VULDEFF based on function fingerprints and code differences. This paper designs a lightweight function fingerprint method based on the Context Triggered Piecewise Hashing algorithm, which can characterize the basic syntax features of function source code. In particular, the fingerprint of the vulnerable function contains the syntax features, vulnerability features, and patch features of the vulnerable function. VULDEFF detects whether target function has vulnerabilities by searching target function fingerprint in the vulnerable function fingerprint library. Compared with five advanced software vulnerability detection tools, VULDEFF significantly reduces the false positive and false negative rates while ensuring the scalability of vulnerability detection. VULDEFF discovered 111 new vulnerabilities in 10 open source projects.
Keywords: Open source software; Vulnerability detection; Code similarity detection; Function fingerprint

Wei Zheng, Peiran Deng, Kui Gui, Xiaoxue Wu,
An Abstract Syntax Tree based static fuzzing mutation for vulnerability evolution analysis,
Information and Software Technology,
Volume 158,
2023,
107194,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107194.
(https://www.sciencedirect.com/science/article/pii/S0950584923000484)
Abstract: Context:
Zero-day vulnerabilities are highly destructive and sudden. However, traditional static and dynamic testing methods cannot efficiently detect them.
Objective:
In this paper, a static fuzzy mutation method for program code is studied. This method can improve the efficiency of mutation sample generation according to the vulnerability evolution law, thus promoting the development of zero-day vulnerability detection methods based on deep learning techniques.
Method:
A static fuzzy mutation method based on the Abstract Syntax Tree (AST) is proposed. Under the guidance of software vulnerability evolution law, potential evolution paths that threaten program security are detected, and mutation samples containing vulnerabilities are generated at the syntax tree level based on the paths. To verify the effectiveness of static fuzzy mutation based on ASTs, this paper starts with Concurrent Use After Free (CUAF) homologous vulnerability. It uses multi-threaded programs to perform vulnerability feature statement insertion processing to infer the optimal mutation operator execution sequence corresponding to CUAF vulnerabilities triggered by data competition. The Linux kernel code is used to verify whether it can effectively reduce the number of invalid mutation samples.
Results:
In this paper, we filter the code fragments in the Linux kernel public code containing CUAF vulnerability fix commits and perform static fuzzy mutation on the fix versions of the vulnerabilities to reproduce the vulnerabilities of this type triggered by these code fragments on the timeline. We compare the process with the execution of the random mutation operator in traditional detection methods horizontally and improve the efficiency by 42.4% on average.
Conclusion:
The static fuzzy mutation based on the AST is effective in stages. When this method is explored in more vulnerability-type evolution laws, it is expected to promote the development of the zero-day vulnerability active detection technology framework.
Keywords: Static fuzzy mutation; Abstract Syntax Tree; Potential evolution paths; Concurrent Use After Free; Multi-threaded programs

Zixian Zhen, Xiangfu Zhao, Jinkai Zhang, Yichen Wang, Haiyue Chen,
DA-GNN: A smart contract vulnerability detection method based on Dual Attention Graph Neural Network,
Computer Networks,
Volume 242,
2024,
110238,
ISSN 1389-1286,
https://doi.org/10.1016/j.comnet.2024.110238.
(https://www.sciencedirect.com/science/article/pii/S1389128624000707)
Abstract: A smart contract is an automated computer program based on blockchain technology. In recent years, the security incidents of smart contracts have caused serious economic losses. However, existing smart contract vulnerability detection methods rely on fixed expert rules, resulting in reduced detection accuracy and scalability. Therefore, addressing the issues of low accuracy in traditional smart contract vulnerability detection methods and the insufficient feature extraction in neural network-based approaches for smart contracts, this paper introduces an intelligent contract vulnerability identification method, Dual Attention Graph Neural Network (DA-GNN). Firstly, DA-GNN transforms the operation code sequence of nodes in the smart contract Control Flow Graph (CFG) into a feature matrix of semantic features and relationships between nodes based on the five types of instructions we propose. Secondly, our proposed dual attention mechanism introduces node semantic features and relationship features between nodes into the GAT to achieve node embedding updates. The updated graph node information is fused through self-attention mechanism to obtain the graph features. Then, the classification and prediction of vulnerabilities are achieved through the classification module. Finally, we evaluated our method on 17,670 real smart contracts. The experimental results show that the precision in detecting integer overflow vulnerabilities, self-destruct vulnerabilities, and transaction sequence dependency vulnerabilities reaches 72.17%, 67.03%, and 73.66%, respectively.
Keywords: Smart contract; Vulnerability detection; Graph neural networks; Attention mechanisms; Opcodes

Chunyong Zhang, Yang Xin,
Static vulnerability detection based on class separation,
Journal of Systems and Software,
Volume 206,
2023,
111832,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111832.
(https://www.sciencedirect.com/science/article/pii/S0164121223002273)
Abstract: Software vulnerability detection is a key step to prevent the system from being attacked. However, tens of thousands of codes have brought great challenges to engineers, so we urgently need an automatic and intelligent vulnerability detection method. The existing vulnerability detection model based on deep learning has the problem that it is difficult to separate the features of vulnerable and neutral code. Based on the code data drive, this paper proposes a static vulnerability detection method SDV(Statically Detecting Vulnerability) for C∖C++ programs. SDV is a function-level vulnerability code detection method. This paper uses a code property graph to represent the code and decouples the feature extractor and the classifier. In the graph feature extraction stage, we use Jump Graph Attention Network layers and convolutional pooling layers. Their combination can not only prevent the over-smoothing problem but also separate the sample classes deeply. Finally, on the chrdeb dataset, SDV outperforms state-of-the-art function-level vulnerability detection methods by 52.3%, 15.9%, and 39.6% in Precision, Recall, and F1-Score, respectively. On the real project sard, the number of vulnerabilities detected by SDV is 10.7 times more than Reveal.
Keywords: Vulnerability detection; Code property graph; Jump structure; Graph attention network; Class separation

Zhonglin Liu, Yong Fang, Cheng Huang, Yijia Xu,
MFXSS: An effective XSS vulnerability detection method in JavaScript based on multi-feature model,
Computers & Security,
Volume 124,
2023,
103015,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.103015.
(https://www.sciencedirect.com/science/article/pii/S0167404822004072)
Abstract: The widespread use of web applications has also made them more vulnerable to hackers, resulting in the leakage of large amounts of application and personal privacy data. Cross-site scripting (XSS) attacks are one of the most significant threats to web applications. Attackers can inject scripts to control the victim’s browser to send data or execute commands, leading to the theft of privacy or the hijacking of login tokens. Therefore, we proposed a multi-feature fusion-based neural network vulnerability detection model for detecting XSS vulnerabilities in the JavaScript source code of websites (We termed our implementation of this approach MFXSS). We combine abstract syntax tree (AST) and code control flow graph (CFG) to convert the generalized sample data into graph structure and code string structure. Then, through the graph convolutional neural network, weighted aggregation, and the bidirectional recurrent neural network, the logical call features and the context execution relationship features of the source code are extracted and fused respectively. Finally, the fused feature vectors are used to detect and predict XSS vulnerabilities in JavaScript. In the experiment, we designed multiple control experiments to verify that the model construction is optimal, and the accuracy rates in the standard and variant datasets are 0.997 and 0.986. Moreover, in comparing similar detection schemes, MFXSS also performs better. Applying the model to an actual web environment, we successfully detected the presence of XSS vulnerabilities in websites.
Keywords: Cross-site scripting; Multi-feature fusion; Graph convolutional network; Weighted aggregation; Vulnerability detection

Huijiang Liu, Shuirou Jiang, Xuexin Qi, Yang Qu, Hui Li, Tingting Li, Cheng Guo, Shikai Guo,
Detect software vulnerabilities with weight biases via graph neural networks,
Expert Systems with Applications,
Volume 238, Part B,
2024,
121764,
ISSN 0957-4174,
https://doi.org/10.1016/j.eswa.2023.121764.
(https://www.sciencedirect.com/science/article/pii/S0957417423022662)
Abstract: Code vulnerabilities are common in software systems and may cause many problems, including Stack Overflow, memory leaks, and so on. Public reports show that code vulnerabilities are increasing year by year, which brings greater threats to the security of software systems. Thus a variety of neural network models have been developed to detect code vulnerabilities. However, the previous neural network models cannot fully express the semantics and structure of the code with as little overhead as possible, and they also cannot enhance learning of difficult samples. Addressing to this issue, we designed a model built upon GGNN for Detecting Software Vulnerabilities (GDSV), which contains three components. Specifically, Graph Embedding component extracts the semantic and structural features, and generates a graph representation of the code; GGNN component learns these features and detects vulnerabilities in the code; weighted component improves the learning ability of Vulnerable samples through the Focal Loss function. A serial of experiments on the datasets of FFmpeg and QEMU were conducted, and the results show that GDSV performs better than the state-of-the-art efforts based on various widely used evaluations.
Keywords: Software vulnerabilities; Weight biases; Gated Graph Neural Network

Xiaobing Sun, Liangqiong Tu, Jiale Zhang, Jie Cai, Bin Li, Yu Wang,
ASSBert: Active and semi-supervised bert for smart contract vulnerability detection,
Journal of Information Security and Applications,
Volume 73,
2023,
103423,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2023.103423.
(https://www.sciencedirect.com/science/article/pii/S221421262300008X)
Abstract: With the popularity of blockchain, the amount of smart contracts has increased very fast, and the safety of smart contracts has come to more extensive notice. Recently, machine learning technology has been widely applied in vulnerability detection for smart contracts. However, it implements effective smart contract vulnerability detection still faces a major challenge, that is, there is a problem of insufficient labeled data in the current field. Active learning can label data more efficiently. Nevertheless, classical active learning only uses limited labeled data for model training, contrary to the deep learning of a large amount of data required for model training. Because of the above, we provide a new framework, called ASSBert, that leverages active and semi-supervised bidirectional encoder representation from transformers network, which is dedicated to completing the task of smart contract vulnerability classification with a little amount of labeled code data and a large number of unlabeled code data. In our framework, active learning is responsible for selecting highly uncertain code data from unlabeled sol files and putting them into the training set after manual labeling. Besides, semi-supervised learning is charged to continuously pick a certain number of high-confidence unlabeled code data from unlabeled sol files, and put them into the training dataset behind pseudo-labeling. Intuitively, by combining active learning and semi-supervised learning, we are able to get more valuable data to increase the performance of our detection model. In our experiments, we collect our benchmark dataset included 6 vulnerabilities in about 20829 smart contracts. The result of the experiment demonstrates that our framework is superior to the baseline methods with a little amount of labeled code data and a large number of unlabeled code data.
Keywords: Smart contract; Vulnerability detection; Active learning; Semi-supervised learning

Peng Zhou, Yuhan Gao,
Detecting prototype pollution for node.js: Vulnerability review and new fuzzing inputs,
Computers & Security,
Volume 137,
2024,
103625,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103625.
(https://www.sciencedirect.com/science/article/pii/S0167404823005357)
Abstract: Prototype pollution is a unique vulnerability originating from the JavaScript languages and has been found widely prevalent across the modern Node.js ecosystem. To detect this kind of vulnerability, state-of-the-art research either runs dynamic fuzzing on the function level to trigger the pollution in the run time or performs static analysis to look up the polluted objects in symbolic conditions. Despite succeeding to some extent, we find the current dynamic fuzzing highly relies on a very limited set of pre-defined function inputs for detection, and the static analysis cannot adapt well to large and complex Node.js modules, hence likely missing lots of potential detection possibilities. In this paper, to the best of our knowledge, we take the first review by re-detecting historical vulnerabilities of prototype pollution that have been disclosed and recorded in public databases. Surprisingly, we find out the current research can only cover some of these records. Our further analysis reveals that many cases cannot be detected because of the very limited code coverage of dynamic fuzzing and their incapability to parse large-scale code bases by static analysis. We thus can confirm the current research still has much room to improve and accordingly, we take dynamic fuzzing as a case study to show this possibility. Specifically, we have extended dynamic fuzzing by reusing new function inputs summarized from historical vulnerabilities and evaluated it over 60,000 Node.js packages. With this extension, we have discovered 65 new prototype pollution vulnerabilities in zero days, which cannot be covered by original dynamic fuzzing. Compared with static analysis, we also find 28 of the 65 new vulnerabilities that cannot be detected. Furthermore, for the vulnerabilities covered by both the approaches, our extended fuzzing runs more reliably and faster (with more than tens of times of speed) than its static counterpart. To the date we write this paper, we have received 6 CVE numbers and continuously negotiated with respective package maintainers (via Snyk and GitHub) for reporting and patching the remaining vulnerabilities.
Keywords: Prototype pollution; Node.js security; Dynamic fuzzing; Static taint analysis; Vulnerability review

Chunyong Zhang, Tianxiang Yu, Bin Liu, Yang Xin,
Vulnerability detection based on federated learning,
Information and Software Technology,
Volume 167,
2024,
107371,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107371.
(https://www.sciencedirect.com/science/article/pii/S0950584923002264)
Abstract: Context:
Detecting potential vulnerabilities is a key step in defending against network attacks. However, manual detection is time-consuming and requires expertise. Therefore, vulnerability detection must require automated techniques.
Objective:
Vulnerability detection methods based on deep learning need to rely on sufficient vulnerable code samples. However, the problem of code islands has not been extensively researched. For example, in the case of multi-party vulnerability data, how to securely combine multi-party data to improve vulnerability detection performance. From the perspectives of data augmentation and data security, we propose a vulnerability detection framework based on federated learning (VDBFL). VDBFL is a new model for vulnerability code detection that combines multi-party data.
Method:
Firstly, VDBFL utilizes the code property graph as a code representation. The code property graph contains various semantic dependencies of the code. Secondly, VDBFL utilizes graph neural networks and convolutional neural networks as the code feature extractor. VDBFL utilizes the jump-structured graph attention network to aggregate node information of important neighbors. Finally, VDBFL utilizes horizontal federated learning to train a local vulnerability detection model for the client.
Result:
In the real world, VDBFL improves F1-Score by 37.4% compared to the vulnerability detection method Reveal. Among the 5401 vulnerability samples, VDBFL detected 11.8 times more vulnerabilities than Reveal.
Conclusion:
Under different datasets, VDBFL has shown better performance than advanced vulnerability detection methods in multiple metrics. In addition, the federated learning stage of VDBFL can be expanded on top of the feature extraction stage of any vulnerable detection method.
Keywords: Vulnerability detection; Code property graph; Graph neural network; Horizontal federated learning; Data security

Hao Sun, Lei Cui, Lun Li, Zhenquan Ding, Siyuan Li, Zhiyu Hao, Hongsong Zhu,
VDTriplet: Vulnerability detection with graph semantics using triplet model,
Computers & Security,
Volume 139,
2024,
103732,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103732.
(https://www.sciencedirect.com/science/article/pii/S0167404824000336)
Abstract: This study presents VDTriplet, a novel learning framework for building vulnerability detection models. VDTriplet is the first attempt using deep learning to avoid the potential known vulnerability function misjudgment due to the small difference between vulnerability and its fixed vulnerability function. Unlike prior work that treats the program as sequential tokens or randomly initialized graphs for supervised binary classification detection tasks, our model not only fuses rich syntactic and semantic information to obtain the most accurate program representation, but also utilizes the TripletNN model to reduce misjudgment of potential known vulnerabilities. VDTriplet first extracts the subgraphs that causes the vulnerability through the typical programming errors to reduce redundant code. Then, it uses the pre-trained model and unsupervised model for the graph encoding of subgraphs, thereby minimizing the influence of randomly initialized graph nodes and avoiding the need for supervised labeling. Finally, TripletNN model minimizes the distance between potential vulnerabilities and vulnerabilities with the same vulnerability type, and maximizes the distance between potential vulnerabilities and fixed vulnerabilities to reduce false positives. The results show that the performance of VDTriplet is significantly better than the studied baselines. Compared with the best performing model in the literature, our model achieves a total of 4.89%, 4.23%, 4.56% and 5.34% improvement in Accuracy, Precision, Recall and F1-Score in the test results respectively. Moreover, it exhibits well generalization in detecting new eight applications, demonstrating that it is potentially valuable in practical usage. Overall, this is indeed an outstanding improvement.
Keywords: Vulnerability detection; Deep learning; Extracting subgraphs; Encoding subgraphs; TripletNN model

Guilong Lu, Xiaolin Ju, Xiang Chen, Wenlong Pei, Zhilong Cai,
GRACE: Empowering LLM-based software vulnerability detection with graph structure and in-context learning,
Journal of Systems and Software,
Volume 212,
2024,
112031,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2024.112031.
(https://www.sciencedirect.com/science/article/pii/S0164121224000748)
Abstract: Software vulnerabilities inflict considerable economic and societal harm. Therefore, timely and accurate detection of these flaws has become vital. Large language models (LLMs) have emerged as a promising tool for vulnerability detection in recent studies. However, their effectiveness suffers when limited to plain text source code, which may ignore the syntactic and semantic information of the code. To address this limitation, we propose a novel vulnerability detection approach GRACE that empowers LLM-based software vulnerability detection by incorporating graph structural information in the code and in-context learning. We also design an effective demonstration retrieval approach that identifies highly relevant code examples by considering semantic, lexical, and syntactic similarities for the target code to provide better demonstrations for in-context learning. To evaluate the effectiveness of GRACE, we conducted an empirical study on three vulnerability detection datasets (i.e., Devign, Reveal, and Big-Vul). The results demonstrate that GRACE outperforms six state-of-the-art vulnerability detection baselines by at least 28.65% in terms of the F1 score across these three datasets. Therefore, our study highlights the effectiveness of integrating graph structural information and in-context learning in LLMs for vulnerability detection. These findings motivate further investigation into tailoring such approaches for specific vulnerability types or adapting them to other security tasks.
Keywords: Vulnerability detection; Large language model; In-context learning; Source code representation; Graph structure

Cristina Cifuentes, François Gauthier, Behnaz Hassanshahi, Padmanabhan Krishnan, Davin McCall,
The role of program analysis in security vulnerability detection: Then and now,
Computers & Security,
Volume 135,
2023,
103463,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103463.
(https://www.sciencedirect.com/science/article/pii/S0167404823003735)
Abstract: Program analysis techniques play an important role in detecting security vulnerabilities. In this paper we describe our experiences in developing a variety of tools that detect security vulnerabilities in an industrial setting. The main driving forces for adoption of program analysis tools by a development organisation are low false positive rate, ease of integration in the developer's workflow, scalability to handle industrial size systems and results that are easy to understand. Even if one the above dimensions is not supported, the tool will not be used in practice. We show how the analyses of program analysis tools have changed over more than a decade due to differences in languages, e.g., code written in systems-level languages like C tend to focus on memory-related vulnerabilities, in contrast to languages like Java, JavaScript and Python where the focus is more on injection vulnerabilities in web or cloud applications. Based on language, static or dynamic analysis approaches are needed, including hybrid approaches. We conclude with our vision on Intelligent Application Security – how program analysis tools will keep changing to enable the DevSecOps model given the fertile ground that the DevOps model provides today. We foresee different program analysis tools working together by sharing information, including the results they produce, while addressing newer security issues such as those related to supply chain issues. In this way, program analysis tools would be extended with relevant machine learning techniques and be integrated in all different phases of the code development, building, testing, deployment and monitoring cycle.
Keywords: Static analysis; Dynamic analysis; Industrial scale application; DevOps

Yukun Dong, Yeer Tang, Xiaotong Cheng, Yufei Yang,
DeKeDVer: A deep learning-based multi-type software vulnerability classification framework using vulnerability description and source code,
Information and Software Technology,
Volume 163,
2023,
107290,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107290.
(https://www.sciencedirect.com/science/article/pii/S0950584923001441)
Abstract: Context:
Software vulnerabilities have confused software developers for a long time. Vulnerability classification is thus crucial, through which we can know the specific type of vulnerability and then conduct targeted repair. Stack of papers have looked into deep learning-based multi-type vulnerability classification, among which most are based on vulnerability descriptions and some are based on source code. While vulnerability descriptions can sometimes mislead vulnerability classification and source code-based approaches have been rarely explored in multi-type vulnerability classification.
Objective:
We design DeKeDVer (Vulnerability Descriptions and Key Domain based Vulnerability Classifier) with two objectives: (i) to extract more useful information from vulnerability descriptions; (ii) to better utilize the information source code can reflect.
Method:
In this work, we propose a multi-type vulnerability classifier which combine vulnerability descriptions and source code together. We process vulnerability descriptions and source code of each project separately. For the vulnerability description of a sample, we preprocess it using a specified way we design based on our observations on numerous descriptions and then select text features. After that, Text Recurrent Convolutional Neural Network (TextRCNN) is applied to learn text information. For source code, we leverage its Code Property Graph (CPG) and extract key domain from it which are then embedded. Acquired feature vectors are then fed into Relational Graph Attention Network (RGAT). Result vectors gained from TextRCNN and RGAT are combined together as the feature vector of the current sample. A Multi-Layer Perceptron (MLP) layer is further added to undertake classification.
Results:
We conduct our experiments on C/C++ projects from NVD. Experimental results show that our work achieves 84.49% in weighted F1-measure which proves our work to be more effective.
Conclusion:
Our work utilizes information reflected both from vulnerability descriptions and source code to facilitate vulnerability classification and achieves higher weighted F1-measure than existing vulnerability classification tools.
Keywords: Multi-type vulnerability classification; Vulnerability description; Source code; Text Recurrent Convolutional Neural Network; Relational graph attention network

Junfeng Tian, Wenjing Xing, Zhen Li,
BVDetector: A program slice-based binary code vulnerability intelligent detection system,
Information and Software Technology,
Volume 123,
2020,
106289,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2020.106289.
(https://www.sciencedirect.com/science/article/pii/S0950584920300392)
Abstract: Context
Software vulnerability detection is essential to ensure cybersecurity. Currently, most software is published in binary form, thus researchers can only detect vulnerabilities in these software by analysing binary programs. Although existing research approaches have made a substantial contribution to binary vulnerability detection, there are still many deficiencies, such as high false positive rate, detection with coarse granularity, and dependence on expert experience.
Objective
The goal of this study is to perform fine-grained intelligent detection on the vulnerabilities in binary programs. This leads us to propose a fine-grained representation of binary programs and introduce deep learning techniques to intelligently detect the vulnerabilities.
Method
We use program slices of library/API function calls to represent binary programs. Additionally, we design and construct a Binary Gated Recurrent Unit (BGRU) network model to intelligently learn vulnerability patterns and automatically detect vulnerabilities in binary programs.
Results
This approach yields the design and implementation of a program slice-based binary code vulnerability intelligent detection system called BVDetector. We show that BVDetector can effectively detect vulnerabilities related to library/API function calls in binary programs, which reduces the false positive rate and false negative rate of vulnerability detection.
Conclusion
This paper proposes a program slice-based binary code vulnerability intelligent detection system called BVDetector. The experimental results show that BVDetector can effectively reduce the false negative rate and false positive rate of binary vulnerability detection.
Keywords: Binary program; Vulnerability detection; Deep learning; Program slice; Library/API function call

Huakun Huang, Longtao Guo, Lingjun Zhao, Haoda Wang, Chenkai Xu, Shan Jiang,
Effective combining source code and opcode for accurate vulnerability detection of smart contracts in edge AI systems,
Applied Soft Computing,
Volume 158,
2024,
111556,
ISSN 1568-4946,
https://doi.org/10.1016/j.asoc.2024.111556.
(https://www.sciencedirect.com/science/article/pii/S1568494624003302)
Abstract: Automating transactions using smart contracts extends the functionality of blockchains and secures the decentralization of blockchains in edge AI systems. Whereas, since plenty of smart contracts are deployed to support various decentralized edge applications, the security vulnerabilities of smart contracts will lead to huge irreversible losses. To deal with this problem, many deep learning-based methods have been developed for vulnerability detection. However, most existing methods use only contract source codes for feature extraction, resulting in low accuracy. In contrast, we propose a method based on deep learning model to integrate both the features of contract source codes and opcodes for vulnerability detection. Particularly, the contextual features are extracted based on opcodes while the expert pattern features are extracted from the source codes. Using the real-world dataset of Ethereum smart contracts targeting reentrancy vulnerability, experiment results demonstrate that our method outperforms the state-of-the-art methods and achieves 96.89% accuracy and 95.41% F1-Score.
Keywords: Smart contract; Edge AI; Vulnerability detection; Deep learning

Chen Tsfaty, Michael Fire,
Malicious source code detection using a translation model,
Patterns,
Volume 4, Issue 7,
2023,
100773,
ISSN 2666-3899,
https://doi.org/10.1016/j.patter.2023.100773.
(https://www.sciencedirect.com/science/article/pii/S2666389923001241)
Abstract: Summary
Modern software development often relies on open-source code sharing. Open-source code reuse, however, allows hackers to access wide developer communities, thereby potentially affecting many products. An increasing number of such “supply chain attacks” have occurred in recent years, taking advantage of open-source software development practices. Here, we introduce the Malicious Source code Detection using a Translation model (MSDT) algorithm. MSDT is a novel deep-learning-based analysis method that detects real-world code injections into source code packages. We have tested MSDT by embedding examples from a dataset of over 600,000 different functions and then applying a clustering algorithm to the resulting embedding vectors to identify malicious functions by detecting outliers. We evaluated MSDT’s performance with extensive experiments and demonstrated that MSDT could detect malicious code injections with precision@k values of up to 0.909.
Keywords: malware analysis; deep learning; static analysis; software supply chain attack; open source; PyPi

Jinfu Chen, Weijia Wang, Bo Liu, Saihua Cai, Dave Towey, Shengran Wang,
Hybrid semantics-based vulnerability detection incorporating a Temporal Convolutional Network and Self-attention Mechanism,
Information and Software Technology,
Volume 171,
2024,
107453,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2024.107453.
(https://www.sciencedirect.com/science/article/pii/S0950584924000582)
Abstract: Context:
Desirable characteristics in vulnerability-detection (VD) systems (VDSs) include both good detection capability (high accuracy, low false positive rate, low false negative rate, etc.) and low time overheads. The widely used VDSs based on models such as Recurrent Neural Networks (RNNs) have some problems, such as low time efficiency, failing to learn the vulnerability features better, and insufficient amounts of vulnerability features. Therefore, it is very important to construct an automatic detection model with high detection accuracy.
Objective:
This paper reports on training based on the source code to analyze and learn from the code’s patterns and structures by deep-learning techniques to generate an efficient VD model that does not require manual feature design.
Method:
We propose a software VD model based on multi-feature fusion and deep neural networks called AIdetectorX-SP. It first uses a Temporal Convolutional Network (TCN) and adds a Self-attention Mechanism (SaM) to the TCN to build a model for extracting vulnerability logic features, then transforms the source code into an image input to a Convolutional Neural Network (CNN) to extract structural and semantic information. Finally, we use feature-fusion technology to design and implement an improved deep-learning-based VDS, called AIdetectorX Sequence with Picturization (AIdetectorX-SP).
Results:
We report on experiments conducted using publicly-available and widely-used datasets to evaluate the effectiveness of AIdetectorX-SP, with results indicating that AIdetectorX-SP is an effective VDS; that the combination of TCN and SaM can effectively extract vulnerability logic features; and that the pictorial code can extract code structure features, which can further improve the VD capability.
Conclusion:
In this paper, we propose a novel detection model for software vulnerability based on TCNs, SaM, and software picturization. The proposed model solves some shortcomings and limitations of existing VDSs, and obtains a high software-VD accuracy with a high degree of stability.
Keywords: Deep learning; Software vulnerability detection; Temporal Convolutional Network; Self-attention Mechanism; Source-code picturization; Feature fusion

Hanting Chu, Pengcheng Zhang, Hai Dong, Yan Xiao, Shunhui Ji, Wenrui Li,
A survey on smart contract vulnerabilities: Data sources, detection and repair,
Information and Software Technology,
Volume 159,
2023,
107221,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107221.
(https://www.sciencedirect.com/science/article/pii/S0950584923000757)
Abstract: Smart contracts contain many built-in security features, such as non-immutability once being deployed and non-involvement of third parties for contract execution. These features reduce security risks and enhance users’ trust towards smart contracts. However, smart contract security issues still persist, resulting in huge financial losses. Contract publishers cannot fully cover contract vulnerabilities through contract version updating. These security issues affect further development of blockchain technologies. So far, there are many related studies focusing on smart contract security issues and tend to discuss from a particular perspective (e.g., development cycle, vulnerability attack methods, security detection tools, etc.). However, smart contract security is a complicated issue that needs to be explored from a multi-dimensional perspective. In this paper, we explore smart contract security from the perspectives of vulnerability data sources, vulnerability detection, and vulnerability defense. We first analyze the existing security issues and challenges of smart contracts, investigate the existing vulnerability classification frameworks and common security vulnerabilities, followed by reviewing the existing contract vulnerability injection, detection, and repair methods. We then analyze the performance of existing security methods. Next, we summarize the current status of smart contract security-related research. Finally, we summarize the state of the art and future trends of smart contract security-related research. This paper aims to provide systematic knowledge and references to this research field.
Keywords: Blockchains; Smart contracts; Vulnerability detection; Vulnerability repair; Information security

Wenbo Guo, Yong Fang, Cheng Huang, Haoran Ou, Chun Lin, Yongyan Guo,
HyVulDect: A hybrid semantic vulnerability mining system based on graph neural network,
Computers & Security,
Volume 121,
2022,
102823,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.102823.
(https://www.sciencedirect.com/science/article/pii/S0167404822002176)
Abstract: In recent years, software programs tend to be large and complex, software has become the infrastructure of modern society, but software security issues can not be ignored. software vulnerabilities have become one of the main threats to computer security. There are countless cases of exploiting source code vulnerabilities to launch attacks. At the same time, the development of open source software has made source code vulnerability detection more and more critical. Traditional vulnerability mining methods have been unable to meet the security analysis needs of complex software because of the high false-positive rate and false-negative rate. To resolve the existing problems, we propose a graph neural network vulnerability mining system named HyVulDect based on hybrid semantics, which constructs a composite semantic code property graph for code representation based on the causes of vulnerabilities. A gated graph neural network is used to extract deep semantic information. Since most of the vulnerabilities are data flow associated, we use taint analysis to extract the taint propagation chain, use the BiLSTM model to extract the token-level features of the context, and finally use the classifier to classify the fusion features. We introduce a dual-attention mechanism that allows the model to focus on vulnerability-related code, making it more suitable for vulnerability mining tasks. The experimental results show that HyVulDect outperforms existing state-of-the-art methods and can achieve an accuracy rate of 92% on the benchmark dataset. Compared with the rule-based static mining tools Flawfinder, RATS, and Cppcheck, it has better performance and can effectively detect the actual CVE source code vulnerabilities.
Keywords: Program analysis; Vulnerability mining; Graph neural network; Taint analysis; Code representation,

Wei Zheng, Jialiang Gao, Xiaoxue Wu, Fengyu Liu, Yuxing Xun, Guoliang Liu, Xiang Chen,
The impact factors on the performance of machine learning-based vulnerability detection: A comparative study,
Journal of Systems and Software,
Volume 168,
2020,
110659,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2020.110659.
(https://www.sciencedirect.com/science/article/pii/S0164121220301229)
Abstract: Machine learning-based Vulnerability detection is an active research topic in software security. Different traditional machine learning-based and deep learning-based vulnerability detection methods have been proposed. To our best knowledge, we are the first to identify four impact factors and conduct a comparative study to investigate the performance influence of these factors. In particular, the quality of datasets, classification models and vectorization methods can directly affect the detection performance, in contrast function/variable name replacement can affect the features of vulnerability detection and indirectly affect the performance. We collect three different vulnerability code datasets from two various sources (i.e., NVD and SARD). These datasets can correspond to different types of vulnerabilities. Moreover, we extract and analyze the features of vulnerability code datasets to explain some experimental results. Our findings based on the experimental results can be summarized as follows: (1) Deep learning models can achieve better performance than traditional machine learning models. Of all the models, BLSTM can achieve the best performance. (2) CountVectorizer can significantly improve the performance of traditional machine learning models. (3) Features generated by the random forest algorithm include system-related functions, syntax keywords, and user-defined names. Different vulnerability types and code sources will generate different features. (4) Datasets with user-defined variable and function name replacement will decrease the performance of vulnerability detection. (5) As the proportion of code from SARD increases, the performance of vulnerability detection will increase.
Keywords: Vulnerability detection; Machine learning; Comparative study; Deep learning; Feature extraction

Haiyang Liu, Yuqi Fan, Lin Feng, Zhenchun Wei,
Vulnerable smart contract function locating based on Multi-Relational Nested Graph Convolutional Network,
Journal of Systems and Software,
Volume 204,
2023,
111775,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111775.
(https://www.sciencedirect.com/science/article/pii/S016412122300170X)
Abstract: The immutable and trustable characteristics of blockchain enable smart contracts to be applied in various fields. Unfortunately, smart contracts are subject to various vulnerabilities, which are frequently exploited by attackers, causing financial damage to users. Therefore, it is extremely important to perform effective vulnerability detection and locating to ensure the security of smart contracts. Deep learning has shown great advantages in smart contract vulnerability detection due to its powerful end-to-end feature learning. The previous deep learning based approaches to smart contract vulnerability detection focus on identifying whether there are vulnerabilities in a smart contract. However, this kind of detection cannot achieve fine-grained vulnerability detection, i.e., locating which function in the smart contract is vulnerable. In this paper, we study the problem of vulnerable smart contract function locating. We construct a novel Multi-Relational Nested contract Graph (MRNG) to better characterize the rich syntactic and semantic information in the smart contract code, including the relationships between data and instructions. An MRNG represents a smart contract, where each node represents a function in the smart contract and each edge describes the calling relationship between the functions. In addition, we create a Multi-Relational Function Graph (MRFG) for each function, which characterizes the corresponding function code. That is, each function is characterized as an MRFG, which corresponds to a node in the MRNG. Each MRFG uses different types of edges to represent the different control and data relationships between nodes within a function. We also propose a Multi-Relational Nested Graph Convolutional Network (MRN-GCN) to process the MRNG. MRN-GCN first extracts and aggregates features from each MRFG, using the edge-enhanced graph convolution network and self-attention mechanism. The extracted feature vector is then assigned to the corresponding node in the MRNG to obtain a new Featured Contract Graph (FCG) for the smart contract. Graph convolution is used to further extract features from the FCG. Finally, a feed forward network with a Sigmoid function is used to locate the vulnerable functions. Experimental results on the real-world smart contract datasets show that model MRN-GCN can effectively improve the accuracy, precision, recall and F1-score performance of vulnerable smart contract function locating.
Keywords: Smart contract; Vulnerable function locating; Graph neural network; Self-attention mechanism

Maoyuan Qin, Jiacheng Zhu, Baolei Mao, Wei Hu,
Hardware/software security co-verification and vulnerability detection: An information flow perspective,
Integration,
Volume 94,
2024,
102089,
ISSN 0167-9260,
https://doi.org/10.1016/j.vlsi.2023.102089.
(https://www.sciencedirect.com/science/article/pii/S0167926023001311)
Abstract: Security vulnerabilities provide attackers unauthorized access to critical resources and effective attack surfaces to compromise a system. Security verification is an emerging technique for detecting and locating such threats. However, existing security verification methods are typically restricted within the hardware or software boundary and incapable of meeting cross-layer verification requirements due to the differences in design semantics and the lack of a security model that fits both hardware and software. We attempt to address such a limitation from the perspective of information flow analysis and propose a hardware/software security co-verification method, which can check information flow security properties on fine-grained hardware information flow models. The proposed method can pinpoint security vulnerabilities by capturing information flow security property violations under clues of malicious information flows. Our information flow security model and properties are described using standard hardware design and verification languages, which allows our method to be seamlessly integrated with electronics design automation flows. Experimental results using RISC-V hardware/software designs show that the proposed method detects software, hardware and system-level security vulnerabilities, effectively.
Keywords: Hardware and software security co-verification; Information flow security; Security model; Security property; Vulnerability detection

Gerardo Canfora, Andrea Di Sorbo, Sara Forootani, Matias Martinez, Corrado A. Visaggio,
Patchworking: Exploring the code changes induced by vulnerability fixing activities,
Information and Software Technology,
Volume 142,
2022,
106745,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2021.106745.
(https://www.sciencedirect.com/science/article/pii/S0950584921001932)
Abstract: Context:
Identifying and repairing vulnerable code is a critical software maintenance task. Change impact analysis plays an important role during software maintenance, as it helps software maintainers to figure out the potential effects of a change before it is applied. However, while the software engineering community has extensively studied techniques and tools for performing impact analysis of change requests, there are no approaches for estimating the impact when the change involves the resolution of a vulnerability bug.
Objective:
We hypothesize that similar vulnerabilities may present similar strategies for patching. More specifically, our work aims at understanding whether the class of the vulnerability to fix may determine the type of impact on the system to repair.
Method:
To verify our conjecture, in this paper, we examine 524 security patches applied to vulnerabilities belonging to ten different weakness categories and extracted from 98 different open-source projects written in Java.
Results:
We obtain empirical evidence that vulnerabilities of the same types are often resolved by applying similar code transformations, and, thus, produce almost the same impact on the codebase.
Conclusion:
On the one hand, our findings open the way to better management of software maintenance activities when dealing with software vulnerabilities. Indeed, vulnerability class information could be exploited to better predict how much code will be affected by the fixing, how the structural properties of the code (i.e., complexity, coupling, cohesion, size) will change, and the effort required for the fix. On the other hand, our results can be leveraged for improving automated strategies supporting developers when they have to deal with security flaws.
Keywords: Software vulnerabilities; Software maintenance; Empirical study

Melanie Ehrenberg, Shahram Sarkani, Thomas A. Mazzuchi,
Python source code vulnerability detection with named entity recognition,
Computers & Security,
Volume 140,
2024,
103802,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103802.
(https://www.sciencedirect.com/science/article/pii/S0167404824001032)
Abstract: Vulnerabilities within source code have grown over the last 20 years to become a common threat to systems and networks. As the implementation of open-source software continues to develop, more unknown vulnerabilities will exist throughout system networks. This research proposes an enhanced vulnerability detection method specific to Python source code that utilizes pre-trained, BERT-based transformer models to apply tokenization, embedding, and named entity recognition (a natural language processing technique). The use of named entity recognition not only allows for the detection of potential vulnerabilities, but also for the classification of different vulnerability types. This research uses the publicly available CodeBERT, RoBERTa, and DistilBERT models to fine-tune for the downstream task of token classification for six different common weakness enumeration specifications. The results achieved in this research outperform previous Python-based vulnerability detection methods and demonstrate the effectiveness of applying named entity recognition to enhance the overall research into Python source code vulnerabilities.
Keywords: Vulnerability detection; Natural language processing; Machine learning; Named entity recognition; Transformer; Python; BERT; Programming language; Common weakness enumeration; CWE

Anjana Wijekoon, Nirmalie Wiratunga,
A user-centred evaluation of DisCERN: Discovering counterfactuals for code vulnerability detection and correction,
Knowledge-Based Systems,
Volume 278,
2023,
110830,
ISSN 0950-7051,
https://doi.org/10.1016/j.knosys.2023.110830.
(https://www.sciencedirect.com/science/article/pii/S0950705123005804)
Abstract: Counterfactual explanations highlight actionable knowledge which helps to understand how a machine learning model outcome could be altered to a more favourable outcome. Understanding actionable corrections in source code analysis can be critical to proactively mitigate security attacks that are caused by known vulnerabilities. In this paper, we present the DisCERN explainer for discovering counterfactuals for code vulnerability correction. Given a vulnerable code segment, DisCERN finds counterfactual (i.e. non-vulnerable) code segments and recommends actionable corrections. DisCERN uses feature attribution knowledge to identify potentially vulnerable code statements. Subsequently, it applies a substitution-focused correction, suggesting suitable fixes by analysing the nearest-unlike neighbour. Overall, DisCERN aims to identify vulnerabilities and correct them while preserving both the code syntax and the original functionality of the code. A user study evaluated the utility of counterfactuals for vulnerability detection and correction compared to more commonly used feature attribution explainers. The study revealed that counterfactuals foster positive shifts in mental models, effectively guiding users towards making vulnerability corrections. Furthermore, counterfactuals significantly reduced the cognitive load when detecting and correcting vulnerabilities in complex code segments. Despite these benefits, the user study showed that feature attribution explanations are still more widely accepted than counterfactuals, possibly due to the greater familiarity with the former and the novelty of the latter. These findings encourage further research and development into counterfactual explanations, as they demonstrate the potential for acceptability over time among developers as a reliable resource for both coding and training.
Keywords: Counterfactual explanations; Vulnerability detection; Explainable AI

Yiran Cheng, Shouguo Yang, Zhe Lang, Zhiqiang Shi, Limin Sun,
VERI: A Large-scale Open-Source Components Vulnerability Detection in IoT Firmware,
Computers & Security,
Volume 126,
2023,
103068,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.103068.
(https://www.sciencedirect.com/science/article/pii/S0167404822004606)
Abstract: IoT device manufacturers integrate open-source components (OSCs) to serve necessary and common functions for facilitating firmware development. However, outdated versions of OSC conceal N-day vulnerabilities and continue to function on IoT devices. The security risks can be predicted once we can identify the OSC versions employed in the firmware. Existing works make attempts at OSC version identification but fail to perform vulnerability detection on a large-scale IoT firmware due to i) unsuitable version identification method for IoT firmware scenario. ii) the lack of a large-scale version-vulnerability relation database. To this end, we propose a system VERI for large-scale vulnerability detection based on lightweight version identification. First, for OSC version identification, VERI leverages symbolic execution with static analysis to identify exact OSC versions even though there are many version-like strings in OSC. Second, VERI employs a deep learning-based method to extract OSC names and vulnerable version ranges from vulnerability descriptions, constructs and maintains an OSC version-vulnerability relation database to serve the vulnerability detection. Finally, VERI polls the relation database to confirm the N-day security risk of the OSC with identified version. The evaluation results show that VERI achieves 96.43% accuracy with high efficiency in OSC version identification. Meanwhile, the deep learning model accurately extracts the OSC names and versions from vulnerability descriptions dataset with 97.19% precision and 96.56% recall. Based on the model, we build a large-scale version-vulnerability relation database. Furthermore, we utilize VERI to conduct a large-scale analysis on 28,890 firmware and find 38,654 vulnerable OSCs with 266,109 N-day vulnerabilities, most of which are with high risks. From the detection results, we find that after the official patch for the vulnerability is released, manufacturers delay an average of 473 days to patch the firmware.
Keywords: IoT Firmware; Open-source component; Vulnerability detection; Version identification

Chongyang Liu, Xiang Chen, Xiangwei Li, Yinxing Xue,
Making vulnerability prediction more practical: Prediction, categorization, and localization,
Information and Software Technology,
Volume 171,
2024,
107458,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2024.107458.
(https://www.sciencedirect.com/science/article/pii/S0950584924000636)
Abstract: Context:
Due to the prevalence of software vulnerabilities, vulnerability detection becomes a fundamental problem in system security.
Objective:
To solve this problem, academics and industries have made great efforts to propose deep-learning-based (DL-based) approaches but these attempts have three main limitations: (1) perform poorly on real-world projects (e.g., Accuracy below 74.33% and F1 below 73.55%); (2) perform poorly in catching vulnerable patterns due to incomplete code representations; (3) mostly perform coarse-grained function-level prediction and lack interpretability analysis.
Methods:
In this paper, we propose VulPCL, a BLSTM and CodeBERT based approach, which makes the first attempt to perform vulnerability prediction, categorization, and localization automatically within a framework. To alleviate the above-mentioned limitations, our VulPCL considers multi-dimension (i.e., text-based, sequence-based, and graph-based) representations to catch latent vulnerable patterns and multi-model training to learn high-level semantics.
Results:
Through experiments on four real-world datasets containing 114+ CWE (Common Weakness Enumeration) types spanning from 2005 to 2022, we find that our VulPCL outperforms the baselines by (1) 13.51%∼60.64% and 14.34%∼180.23% on Accuracy, and F1 respectively on vulnerability prediction; (2) 10.32%∼46.79%, and 10.71%∼127.80% on Accuracy, and macro-F1 respectively on vulnerability categorization; (3) 9.23%∼36.54% on Top-10 Accuracy on vulnerability localization.
Conclusion:
These results indicate that our VulPCL is considerably more accurate, effective, fine-grained, and practical than previous studies. Besides, our further analyses show that VulPCL is indeed capable of capturing all vulnerability lines, and the result of line-level vulnerability localization is consistent with the function-level vulnerability prediction as the increase of predicted lines. Thus making VulPCL more interpretable than previous studies. Our additional investigation also shows that VulPCL effectively detects the Most Dangerous 25 CWEs in 2022, which is instructive for security researchers.
Keywords: Deep learning; Pre-trained language model; Semantic analysis; Vulnerability detection

Thu-Trang Nguyen, Hieu Dinh Vo,
Context-based statement-level vulnerability localization,
Information and Software Technology,
Volume 169,
2024,
107406,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2024.107406.
(https://www.sciencedirect.com/science/article/pii/S0950584924000119)
Abstract: Context:
The number of attacks exploring software vulnerabilities has dramatically increased, which has caused various severe damages. Thus, early and accurately detecting vulnerabilities becomes essential to guarantee software quality and prevent the systems from malicious attacks. Multiple automated vulnerability detection approaches have been proposed and obtained promising results. However, most studies detect vulnerabilities at a coarse-grained, i.e., file or method level. Thus, developers still have to spend significant investigation efforts on localizing vulnerable statements.
Objective:
In this paper, we introduce COSTA, a novel context-based approach to localize vulnerable statements.
Method:
In particular, given a vulnerable function, COSTA identifies vulnerable statements based on their suspiciousness scores. Specifically, the suspiciousness of each statement is measured according to its semantics captured by four contexts, including operation context, dependence context, surrounding context, and vulnerability type.
Results:
Our experimental results on a large vulnerability dataset show that COSTA outperforms the state-of-the-art approaches up to 96% in F1-score and 167% in Accuracy. COSTA also surpasses these approaches up to two times in Top-1 Accuracy. Especially, COSTA obtains about 80% at Top-3 Recall. In other words, developers can find about 80% of the vulnerable statements by investigating only three first-ranked statements in each function.
Conclusion:
COSTA effectively addresses the challenge of statement-level vulnerability localization by leveraging multiple contextual features. Our experimental results show that COSTA outperforms existing state-of-the-art approaches. With the ability to accurately and efficiently identify vulnerable statements, developers can better allocate their investigation efforts, reduce the risk of potential security threats, and ensure software quality and security in real-world applications.
Keywords: Vulnerable statement; Vulnerability detection; Vulnerability localization; Context representation; COSTA

Ahmed Alzahrani, Muhammad Zubair Asghar,
Cyber vulnerabilities detection system in logistics-based IoT data exchange,
Egyptian Informatics Journal,
Volume 25,
2024,
100448,
ISSN 1110-8665,
https://doi.org/10.1016/j.eij.2024.100448.
(https://www.sciencedirect.com/science/article/pii/S1110866524000112)
Abstract: Modern-day digitalization has a profound impact on business and society, revolutionizing logistics. Supply chain digitalization improves transparency, speed, and cost-effectiveness, increasingtech adoption—transportationbenefits from IoT-driven shipment tracking and web data storage. However, cyber threats target IoT data by exploiting cyber vulnerabilities. Although ML/DL approaches have showed potential in finding IoT vulnerabilities, the difficulty of selecting appropriate features remains. Existing research has produced surprising outcomes, and deep neural networks have been utilised to extract characteristics without taking sequence information into account. To address this, the paper presents a unique approach for accurate IoT vulnerability identification that combines deep learning and better feature selection. On the BoT-IoT dataset, the LSTM + CNN model achieved 95.73 % accuracy. This approach has the ability to successfully anticipate IoT based vulnerabilities by leveraging benchmark data, selecting relevant features, and enhancing overall system performance.
Keywords: Hybrid deep learning; Feature selection; IoT-based vulnerabilities; Logistics

Xueshuo Xie, Haolong Wang, Zhaolong Jian, Yaozheng Fang, Zichun Wang, Tao Li,
Block-gram: Mining knowledgeable features for efficiently smart contract vulnerability detection,
Digital Communications and Networks,
2023,
,
ISSN 2352-8648,
https://doi.org/10.1016/j.dcan.2023.07.009.
(https://www.sciencedirect.com/science/article/pii/S2352864823001347)
Abstract: Smart contracts are widely used on the blockchain to implement complex transactions, such as decentralized applications on Ethereum. Effective vulnerability detection of large-scale smart contracts is critical, as attacks on smart contracts often cause huge economic losses. Since it is difficult to repair and update smart contracts, it is necessary to find the vulnerabilities before they are deployed. However, code analysis, which requires traversal paths, and learning methods, which require many features to be trained, are too time-consuming to detect large-scale on-chain contracts. Learning-based methods will obtain detection models from a feature space compared to code analysis methods such as symbol execution. But the existing features lack the interpretability of the detection results and training model, even worse, the large-scale feature space also affects the efficiency of detection. This paper focuses on improving the detection efficiency by reducing the dimension of the features, combined with expert knowledge. In this paper, a feature extraction model Block-gram is proposed to form low-dimensional knowledge-based features from bytecode. First, the metadata is separated and the runtime code is converted into a sequence of opcodes, which are divided into segments based on some instructions (jumps, etc.). Then, scalable Block-gram features, including 4-dimensional block features and 8-dimensional attribute features, are mined for the learning-based model training. Finally, feature contributions are calculated from SHAP values to measure the relationship between our features and the results of the detection model. In addition, six types of vulnerability labels are made on a dataset containing 33,885 contracts, and these knowledge-based features are evaluated using seven state-of-the-art learning algorithms, which show that the average detection latency speeds up 25× to 650×, compared with the features extracted by N-gram, and also can enhance the interpretability of the detection model.
Keywords: Smart contract; Bytecode & opcode; Knowledgeable features; Vulnerability detection; Feature contribution

Wei Xiao, Zhengzhang Hou, Tao Wang, Chengxian Zhou, Chao Pan,
MSGVUL: Multi-semantic integration vulnerability detection based on relational graph convolutional neural networks,
Information and Software Technology,
Volume 170,
2024,
107442,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2024.107442.
(https://www.sciencedirect.com/science/article/pii/S0950584924000478)
Abstract: Software security has drawn extensive attention as software projects have grown increasingly large and complex. Since the traditional manual or equipment vulnerability detection technology cannot meet today's software development needs, there is a recognized need to create more effective techniques to address security issues. Although various vulnerability detection systems have been proposed, most are based only on serialization or graph representation, to inadequate effect. We propose a system, MSGVUL, that provides superior vulnerability detection using a new multi-semantic approach. MSGVUL uses versatile and efficient code slicing employing a search algorithm based on sensitive data and functions and innovatively constructs an SSVEC model to fully integrate the semantic and structural information into the code. We also developed a novel BAG model, made up of BAP and PAG frameworks, that enables the hierarchical extraction of code vulnerability representations from the graph and sequence levels. The MSGVUL model is evaluated on slice-level and function-level vulnerability datasets, and the results demonstrate that the MSGVUL method outperforms other state-of-the-art methods.
Keywords: Vulnerability detection; Code representation; Program slicing; Graph convolutional neural networks

Jinfu Chen, Wei Lin, Saihua Cai, Yemin Yin, Haibo Chen, Dave Towey,
BiTCN_DRSN: An effective software vulnerability detection model based on an improved temporal convolutional network,
Journal of Systems and Software,
Volume 204,
2023,
111772,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111772.
(https://www.sciencedirect.com/science/article/pii/S016412122300167X)
Abstract: The detection of software vulnerabilities is a challenging task in the field of security. With the increasing scale of software and the rapid development of artificial intelligence technology, deep learning has been extensively applied to automatic vulnerability detection. Temporal Convolutional Networks (TCNs) have been shown to perform well in tasks that can be processed in parallel; they can adaptively learn complex structures (including in-time series data); and they have exhibited stable gradients — they are relatively easier to train, and can quickly converge to an optimal solution. However, TCNs cannot simultaneously capture the bidirectional semantics of the source code, since they do not have a bidirectional network structure. Furthermore, because of the weak noise resistance of residual TCN connections, TCNs are also susceptible to learning features that are not related to vulnerabilities when learning the source code features. To overcome the limitations of the traditional TCN, we propose a bidirectional TCN model based on the Deep Residual Shrinkage Network (DRSN), namely BiTCN_DRSN. BiTCN_DRSN combines TCN and DRSN to enhance the noise immunity and make the network model more attentive to the features associated with vulnerabilities. In addition, addressing the limitation that the TCN is a unidirectional network structure, the forward and backward sequences are utilized for bidirectional source-code feature learning. The experimental results show that the proposed BiTCN_DRSN model can effectively improve the accuracy of source-code vulnerability detection, compared with some existing neural-network models. Compared with the traditional TCN, our model increases the accuracy by 4.22%, 2.42% and 2.66% on the BE-ALL, RM-ALL and HY-ALL datasets, respectively. The proposed BiTCN_DRSN model also exhibits improved detection stability.
Keywords: Software security; Vulnerability detection; Deep learning; Deep residual shrinkage network

Longtao Guo, Huakun Huang, Lingjun Zhao, Peiliang Wang, Shan Jiang, Chunhua Su,
Reentrancy vulnerability detection based on graph convolutional networks and expert patterns under subspace mapping,
Computers & Security,
Volume 142,
2024,
103894,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103894.
(https://www.sciencedirect.com/science/article/pii/S0167404824001962)
Abstract: Smart contracts with automatic execution capability provide a vast development space for transactions in Blockchain. However, due to the vulnerabilities in smart contracts, Blockchain has suffered huge economic losses, which greatly undermines people’s trust in Blockchain and smart contracts. In this paper, we explore a vulnerability detection method based on graph neural networks and combine both contract source code and opcode. The structure of the method consists of four modules, i.e., preprocessing, subspace mapping, feature extraction, and detection modules. In the feature mapping module, we use a multi-subspace mapping approach to explore the impact of different subspace mappings on the detection method. For reentrancy vulnerability, we conducted extensive experiments. The experiments prove that our method achieves 95% accuracy and 94% F1-Score on average.
Keywords: Blockchain; Smart contract; Vulnerability detection; Graph neural network; Subspace mapping

Xiaojun Ren, Yongtang Wu, Jiaqing Li, Dongmin Hao, Muhammad Alam,
Smart contract vulnerability detection based on a semantic code structure and a self-designed neural network,
Computers and Electrical Engineering,
Volume 109, Part B,
2023,
108766,
ISSN 0045-7906,
https://doi.org/10.1016/j.compeleceng.2023.108766.
(https://www.sciencedirect.com/science/article/pii/S0045790623001908)
Abstract: Smart contracts are riddled with vulnerabilities due to flaws in programming languages and the inexperience of developers, causing damage. Nonetheless, the current research on smart contract vulnerability detection is insufficient. In this study, we propose a novel approach, namely, Blass, based on a semantic code structure and a self-designed neural network. Blass constructs program slices with complete semantic structure information (CPSs) and uses an abstract syntax tree and a depth-first traversal algorithm to convert CPSs into code chains during the process of CPS vectorization, which increases its ability to express vulnerability features. Blass also uses a self-designed neural network, Bi-LSTM-Att, as the classification model, which introduces an attention mechanism to capture the key features of vulnerabilities and effectively achieve improved smart contract vulnerability detection performance. The CPSs and the Bi-LSTM-Att can improve the vulnerability detection effectiveness of Blass, and Blass can be applied to malicious contract detection with satisfactory precision, recall, and F1 values.
Keywords: Smart contract; Vulnerability; Semantic code structure; Code chain; Bi-LSTM-Att classification model

Tolga Yilmaz, Özgür Ulusoy,
Understanding security vulnerabilities in student code: A case study in a non-security course,
Journal of Systems and Software,
Volume 185,
2022,
111150,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2021.111150.
(https://www.sciencedirect.com/science/article/pii/S0164121221002430)
Abstract: Secure coding education is quite important for students to acquire the skills to quickly adapt to the evolving threats towards the software they are expected to create once they graduate. Educators are also more aware of this situation and incorporate teaching security in their respective fields. An effective application of this is only possible by cultivating the teaching and learning perspectives. Understanding the security awareness and practice of students is useful as an initial step to create a baseline for teaching methods and content. In this paper, we first survey to investigate how students approach security and what could motivate them to learn and apply security practices. Then, we analyze the source code for 6 semesters of coding assignments for 2 tasks using a source code vulnerability analysis tool. In our analysis, we report the types of vulnerabilities and various aspects between them while incorporating the effect of student grades. We then explore the lexical and structural features of security in student code using data analysis and machine learning. For the lexical analysis, we build a classifier to extract informative features and for the structural analysis, we utilize Syntax Trees to represent code and perform clustering in terms of structural features where clusters themselves yield different vulnerability levels.
Keywords: Secure coding education; Source code analysis; Data mining; Vulnerability analysis

Yuanhai Fan, Chuanhao Wan, Cai Fu, Lansheng Han, Hao Xu,
VDoTR: Vulnerability detection based on tensor representation of comprehensive code graphs,
Computers & Security,
Volume 130,
2023,
103247,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103247.
(https://www.sciencedirect.com/science/article/pii/S0167404823001578)
Abstract: Code vulnerability detection has long been a critical issue due to its potential threat to computer systems. It is imperative to detect source code vulnerabilities in software and remediate them to avoid cyber attacks. To automate detection and reduce labor costs, many deep learning-based methods have been proposed. However, these approaches have been found to be either ineffective in detecting multiple classes of vulnerabilities or limited by treating original source code as a natural language sequence without exploiting the structural information of code. In this paper, we propose VDoTR, a model that leverages a new tensor representation of comprehensive code graphs, including AST, CFG, DFG, and NCS, to detect multiple types of vulnerabilities. Firstly, a tensor structure is introduced to represent the structured information of code, which deeply captures code features. Secondly, a new Circle Gated Graph Neural Network (CircleGGNN) is designed based on tensor for hidden state embedding of nodes. CircleGGNN can perform heterogeneous graph information fusion more directly and effectively. Lastly, a 1-D convolution-based output layer is applied to hidden embedding features for classification. The experimental results demonstrate that the detection performance of VDoTR is superior to other approaches with higher accuracy, precision, recall, and F1-measure on multiple datasets for vulnerability detection. Moreover, we illustrate which code graph contributes the most to the performance of VDoTR and which code graph is more sensitive to represent vulnerability features for different types of vulnerabilities through ablation experiments.
Keywords: Source code vulnerability detection; Tensor-based feature; GGNN; Code graphs; Heterogeneous information fusion

Tushar Sharma, Maria Kechagia, Stefanos Georgiou, Rohit Tiwari, Indira Vats, Hadi Moazen, Federica Sarro,
A survey on machine learning techniques applied to source code,
Journal of Systems and Software,
Volume 209,
2024,
111934,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111934.
(https://www.sciencedirect.com/science/article/pii/S0164121223003291)
Abstract: The advancements in machine learning techniques have encouraged researchers to apply these techniques to a myriad of software engineering tasks that use source code analysis, such as testing and vulnerability detection. Such a large number of studies hinders the community from understanding the current research landscape. This paper aims to summarize the current knowledge in applied machine learning for source code analysis. We review studies belonging to twelve categories of software engineering tasks and corresponding machine learning techniques, tools, and datasets that have been applied to solve them. To do so, we conducted an extensive literature search and identified 494 studies. We summarize our observations and findings with the help of the identified studies. Our findings suggest that the use of machine learning techniques for source code analysis tasks is consistently increasing. We synthesize commonly used steps and the overall workflow for each task and summarize machine learning techniques employed. We identify a comprehensive list of available datasets and tools useable in this context. Finally, the paper discusses perceived challenges in this area, including the availability of standard datasets, reproducibility and replicability, and hardware resources. Editor’s note: Open Science material was validated by the Journal of Systems and Software Open Science Board.
Keywords: Machine learning for software engineering; Source code analysis; Deep learning; Datasets; Tools

Rongze Xu, Zhanyong Tang, Guixin Ye, Huanting Wang, Xin Ke, Dingyi Fang, Zheng Wang,
Detecting code vulnerabilities by learning from large-scale open source repositories,
Journal of Information Security and Applications,
Volume 69,
2022,
103293,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2022.103293.
(https://www.sciencedirect.com/science/article/pii/S221421262200148X)
Abstract: Machine learning methods are widely used to identify common, repeatedly occurring bugs and code vulnerabilities. The performance of a machine-learned model is bounded by the quality and quantity of training data and the model’s capability in extracting and capturing the essential information of the problem domain. Unfortunately, there is a storage of high-quality samples for training code vulnerability detection models, and existing machine learning methods are inadequate in capturing code vulnerability patterns. We present Developer,11Developer = Detecting codE VulnerabilitiEs at the Large scale by learning from OPen sourcE Repositories. a novel learning framework for building code vulnerability detection models. To address the data scarcity challenge, Developer automatically gathers training samples from open-source projects and applies constraints rules to the collected data to filter out noisy data to improve the quality of the collected samples. The collected data provides many real-world vulnerable code training samples to complement the samples available in standard vulnerable databases. To build an effective code vulnerability detection model, Developer employs a convolutional neural network architecture with attention mechanisms to extract code representation from the program abstract syntax tree. The extracted program representation is then fed to a downstream network – a bidirectional long–short term memory architecture – to predict if the target code contains a vulnerability or not. We apply Developer to identify vulnerabilities at the program source-code level. Our evaluation shows that Developer outperforms state-of-the-art methods by uncovering more vulnerabilities with a lower false-positive rate.
Keywords: Code vulnerability detection; Deep learning; Attention mechanism; Software vulnerability

Son Nguyen, Thu-Trang Nguyen, Thanh Trong Vu, Thanh-Dat Do, Kien-Tuan Ngo, Hieu Dinh Vo,
Code-centric learning-based just-in-time vulnerability detection,
Journal of Systems and Software,
Volume 214,
2024,
112014,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2024.112014.
(https://www.sciencedirect.com/science/article/pii/S0164121224000578)
Abstract: Attacks against computer systems exploiting software vulnerabilities can cause substantial damage to the cyber infrastructure of our modern society and economy. To minimize the consequences, it is vital to detect and fix vulnerabilities as soon as possible. Just-in-time vulnerability detection (JIT-VD) discovers vulnerability-prone (“dangerous”) commits to prevent them from being merged into source code and causing vulnerabilities. By JIT-VD, the commits’ authors, who understand the commits properly, can review these dangerous commits and fix them if necessary while the relevant modifications are still fresh in their minds. In this paper, we propose CodeJIT, a novel graph-based code-centric learning-based approach for just-in-time vulnerability detection. The key idea of CodeJIT is that the meaning of the code changes of a commit is the direct and deciding factor for determining if the commit is dangerous for the code. Based on that idea, we design a novel graph-based representation, Code Transformation Graph (CTG) to represent the semantics of code changes in terms of both code syntactic structure and program dependencies. A graph neural network (GNN) model is developed to capture the meaning of the code changes represented by our graph-based representation and learn to discriminate between dangerous and safe commits. We conducted experiments to evaluate the JIT-VD performance of CodeJIT on a dataset of 20K+ dangerous and safe commits in 506 real-world projects from 1998 to 2022. Our results show that CodeJIT significantly improves the state-of-the-art JIT-VD methods by up to 66% in Recall, 136% in Precision, and 68% in F1. Moreover, CodeJIT correctly classifies nearly 9/10 of dangerous/safe (benign) commits and even detects 69 commits that fix a vulnerability yet produce other issues in source code.
Keywords: Just-in-time vulnerability detection; Code-centric; Code change representation; Graph-based model; Commit-level bugs

Ilias Kalouptsoglou, Miltiadis Siavvas, Apostolos Ampatzoglou, Dionysios Kehagias, Alexander Chatzigeorgiou,
Software vulnerability prediction: A systematic mapping study,
Information and Software Technology,
Volume 164,
2023,
107303,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107303.
(https://www.sciencedirect.com/science/article/pii/S095058492300157X)
Abstract: Context:
Software security is considered a major aspect of software quality as the number of discovered vulnerabilities in software products is growing. Vulnerability prediction is a mechanism that helps engineers to prioritize their inspection efforts focusing on vulnerable parts. Despite the recent advancements, current literature lacks a systematic mapping study on vulnerability prediction.
Objective:
This paper aims to analyze the state-of-the-art of vulnerability prediction focusing on: (a) the goals of vulnerability prediction-related studies; (b) the data collection processes and the types of datasets that exist in the literature; (c) the mostly examined techniques for the construction of the prediction models and their input features; and (d) the utilized evaluation techniques.
Method:
We collected 180 primary studies following a broad search methodology across four popular digital libraries. We mapped these studies to the variables of interest and we identified trends and relationships between the studies.
Results:
The main findings suggest that: (i) there are two major study types, prediction of vulnerable software components and forecasting of the evolution of vulnerabilities in software; (ii) most studies construct their own vulnerability-related dataset retrieving information from vulnerability databases for real-world software; (iii) there is a growing interest for deep learning models along with a trend on textual source code representation; and (iv) F1-score was found to be the most widely used evaluation metric.
Conclusions:
The results of our study indicate that there are several open challenges in the domain of vulnerability prediction. One of the major conclusions, is the fact that most studies focus on within-project prediction, neglecting the real-world scenario of cross-project prediction.
Keywords: Systematic mapping study; Software security; Vulnerability prediction; Machine learning

Akashdeep Bhardwaj, Salil Bharany, Anas W. Abulfaraj, Ashraf Osman Ibrahim, Wamda Nagmeldin,
Fortifying home IoT security: A framework for comprehensive examination of vulnerabilities and intrusion detection strategies for smart cities,
Egyptian Informatics Journal,
Volume 25,
2024,
100443,
ISSN 1110-8665,
https://doi.org/10.1016/j.eij.2024.100443.
(https://www.sciencedirect.com/science/article/pii/S1110866524000069)
Abstract: Smart home devices have brought in a disruptive, revolutionary Internet-based ecosystem that enhanced our daily lives but has pushed private data from inside our homes to external public sources. Threats and attacks mounted against IoT deployments have only increased in recent times. There have been several proposals to secure home automation environments, but there is no full protection against Cybersecurity threats for our home IoT platforms. This research investigates attack attempts on smart home environments, focusing on firmware, brute force, and DoS attacks on the Internet of Things (IoT) network which were successful in bringing down the device in less than a minute. Weak passwords were cracked using Brute Force techniques related to HTTP, SSH, Telnet, and FTP protocols, and an unknown service port to reveal backdoor access. Cross-site scripting vulnerability was detected on IoT devices that could allow running malicious scripts on the devices. The authors also exploited the unknown services to reveal backdoors and access sensitive device details and potentially exploited them to add new ports or rules to turn the IoT devices into a router to attack other devices. To detect and mitigate such attacks, the authors present an IoT-based intrusion detection and prevention system to secure smart home network devices. The authors compared the proposed framework with other similar research based on Precision, Accuracy, F-measure, and Recall. The proposed model outperforms all the other known models reporting a high of 95% for identifying malicious attack packets, while others reported 58% and 71% detection percentage.
Keywords: IoT; Firmware attack; XSS; Brute Force; Cross-site scripting; UPnP; IDS

Wei Tang, Mingwei Tang, Minchao Ban, Ziguo Zhao, Mingjun Feng,
CSGVD: A deep learning approach combining sequence and graph embedding for source code vulnerability detection,
Journal of Systems and Software,
Volume 199,
2023,
111623,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111623.
(https://www.sciencedirect.com/science/article/pii/S0164121223000183)
Abstract: In order to secure software, it is critical to detect potential vulnerabilities. The performance of traditional static vulnerability detection methods is limited by predefined rules, which rely heavily on the expertise of developers. Existing deep learning-based vulnerability detection models usually use only a single sequence or graph embedding approach to extract vulnerability features. Sequence embedding-based models ignore the structured information inherent in the code, and graph embedding-based models lack effective node and graph embedding methods. As a result, we propose a novel deep learning-based approach, CSGVD (Combining Sequence and Graph embedding for Vulnerability Detection), which considers function-level vulnerability detection as a graph binary classification task. Firstly, we propose a PE-BL module, which inherits and enhances the knowledge from the pre-trained language model. It extracts the code’s local semantic features as node embedding in the control flow graph by using sequence embedding. Secondly, CSGVD uses graph neural networks to extract the structured information of the graph. Finally, we propose a mean biaffine attention pooling, M-BFA, to better aggregate node information as a graph’s feature representation. The experimental results show that CSGVD outperforms the existing state-of-the-art models and obtains 64.46% accuracy on the real-world benchmark dataset from CodeXGLUE for vulnerability detection.
Keywords: Graph neural networks; Vulnerability detection; Sequence embedding; Graph embedding; Pre-trained language model; Attention pooling

Prabith GS, Rohit Narayanan M, Arya A, Aneesh Nadh R, Binu PK,
BiT5: A Bidirectional NLP Approach for Advanced Vulnerability Detection in Codebase,
Procedia Computer Science,
Volume 233,
2024,
Pages 812-821,
ISSN 1877-0509,
https://doi.org/10.1016/j.procs.2024.03.270.
(https://www.sciencedirect.com/science/article/pii/S1877050924006306)
Abstract: In this research paper, a detailed investigation presents the utilization of the BiT5 Bidirectional NLP model for detecting vulnerabilities within codebases. The study addresses the pressing need for techniques enhancing software security by effectively identifying vulnerabilities. Methodologically, the paper introduces BiT5, specifically designed for code analysis and vulnerability detection, encompassing dataset collection, preprocessing steps, and model fine-tuning. The key findings underscore BiT5’s efficacy in pinpointing vulnerabilities within code snippets, notably reducing both false positives and false negatives. This research contributes by offering a methodology for leveraging BiT5 in vulnerability detection, thus significantly bolstering software security and mitigating risks associated with code vulnerabilities.
Keywords: Bidirectional Transformer; BiT5 Model; Code Analysis; Code Vulnerabilities; Machine Learning; Natural Language Processing (NLP); Software Security; Vulnerability Detection

Solmaz Salimi, Mehdi Kharrazi,
VulSlicer: Vulnerability detection through code slicing,
Journal of Systems and Software,
Volume 193,
2022,
111450,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2022.111450.
(https://www.sciencedirect.com/science/article/pii/S0164121222001443)
Abstract: There has been a multitude of techniques proposed for identifying vulnerabilities in software. Forcing a program into a vulnerable state has become increasingly unscalable, given the size of the programs and the number of possible execution states. At the same time, techniques that are looking for vulnerability signatures are marred with weak and incomplete signatures. This is not to say that such techniques have failed to identify previously unknown vulnerabilities in the code. However, they have inherent weaknesses, which result in identifying vulnerabilities that are limited in type and complexity. We propose a novel technique to extract succinct vulnerability-relevant statements representing the self-contained nature of vulnerabilities and reproduce the vulnerable behavior independently of the rest of the program. We also introduce an innovative technique to slice target programs and search for similar vulnerability-relevant statements in them. We developed VulSlicer, a prototype system capable of extracting vulnerability-relevant statements from vulnerable programs and searching for them on target programs at scale. Furthermore, we have examined four candidate open-source projects and have been able to identify 118 potential vulnerabilities, out of which 94 were found to be silently patched, and from the remaining reported cases, three were confirmed by obtaining a CVE designation.
Keywords: Code slicing; Static analysis; Vulnerability detection

Xiaozhou Li, Sergio Moreschini, Zheying Zhang, Fabio Palomba, Davide Taibi,
The anatomy of a vulnerability database: A systematic mapping study,
Journal of Systems and Software,
Volume 201,
2023,
111679,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111679.
(https://www.sciencedirect.com/science/article/pii/S0164121223000742)
Abstract: Software vulnerabilities play a major role, as there are multiple risks associated, including loss and manipulation of private data. The software engineering research community has been contributing to the body of knowledge by proposing several empirical studies on vulnerabilities and automated techniques to detect and remove them from source code. The reliability and generalizability of the findings heavily depend on the quality of the information mineable from publicly available datasets of vulnerabilities as well as on the availability and suitability of those databases. In this paper, we seek to understand the anatomy of the currently available vulnerability databases through a systematic mapping study where we analyze (1) what are the popular vulnerability databases adopted; (2) what are the goals for adoption; (3) what are the other sources of information adopted; (4) what are the methods and techniques; (5) which tools are proposed. An improved understanding of these aspects might not only allow researchers to take informed decisions on the databases to consider when doing research but also practitioners to establish reliable sources of information to inform their security policies and standards.
Keywords: Software security; Vulnerability databases; Systematic mapping studies; Software evolution

M.M. Rahimifar, H. Jahanirad, M. Fathi,
Deep transfer learning approach for digital circuits vulnerability analysis,
Expert Systems with Applications,
Volume 237, Part C,
2024,
121757,
ISSN 0957-4174,
https://doi.org/10.1016/j.eswa.2023.121757.
(https://www.sciencedirect.com/science/article/pii/S0957417423022595)
Abstract: Hardware Trojans (HT) are the most malicious components attacking modern integrated circuits (ICs). Information leakage, incorrect functionality, and overheating are the major effects of HT insertion. Due to the outsourcing of multi-stage digital circuit design and fabrication, HTs can be inserted by rogues at every stage. The types of HTs and insertion methods evolve continuously and their detection becomes more complex. Consequently, designing integrated circuits robust to HT insertion seems efficient. A prerequisite for such a strategy is the evaluation of integrated circuit vulnerability to HT insertion. There are several factors involved in the vulnerability of fabricated integrated circuits such as the distribution of white spaces in the IC layout, the ratio of unutilized routing resources, the amount of activity of the circuit’s nodes, the geometrical properties of the circuit’s gates, the delay of various paths, and etc. The interrelation of these diverse factors makes IC vulnerability modeling a challenging problem. In this paper, a deep neural network (DNN) based approach is developed to combine all the effective factors in IC vulnerability analysis. Firstly, we generate a comprehensive dataset containing various types and sizes of hardware Trojans inserted into benchmark circuits. The benchmark circuits used in this study are ISCAS 85, ISCAS 89, and ITC 99. Then using the transfer learning concept seven state-of-the-art deep convolutional neural networks are trained and verified using the constructed dataset to classify every integrated circuit into three vulnerability levels (low, moderate, and highly vulnerable classes). Simulation results show that our proposed method achieves almost 95 % accuracy in the most successful case (VGG16). The lowest accuracy belongs to Inception V3 (∼87.65 %) which is much better than the most successful previous studies (72 %). This is mainly because the DNN-based method handles shortcomings (such as incomplete modeling of vulnerability-related factors) in the previous state-of-the-art methods efficiently.
Keywords: Transfer Learning; Deep Neural Networks; Digital circuits; Vulnerability analysis; Hardware Trojans

Jin Wang, Hui Xiao, Shuwen Zhong, Yinhao Xiao,
DeepVulSeeker: A novel vulnerability identification framework via code graph structure and pre-training mechanism,
Future Generation Computer Systems,
Volume 148,
2023,
Pages 15-26,
ISSN 0167-739X,
https://doi.org/10.1016/j.future.2023.05.016.
(https://www.sciencedirect.com/science/article/pii/S0167739X23001978)
Abstract: Software vulnerabilities can pose severe harms to a computing system. They can lead to system crash, privacy leakage, or even physical damage. Correctly identifying vulnerabilities among enormous software codes in a timely manner is so far the essential prerequisite to patch them. Unfortunately, the current vulnerability identification methods, either the classic ones or the deep-learning-based ones, have several critical drawbacks, making them unable to meet the present-day demands put forward by the software industry. To overcome the drawbacks, in this paper, we propose DeepVulSeeker, a novel fully automated vulnerability identification framework, which leverages both code graph structures and the semantic features with the help of the recently advanced Graph Representation Self-Attention and pre-training mechanisms. Our experiments show that DeepVulSeeker not only reaches an accuracy as high as 0.99 on traditional CWE datasets, but also outperforms all other existing methods on two highly-complicated datasets. We also testified DeepVulSeeker based on three case studies, and found that DeepVulSeeker is able to understand the implications of the vulnerabilities. We have fully implemented DeepVulSeeker and open-sourced it for future follow-up research.
Keywords: Vulnerability identification; Software security; Neural network; Pre-training; Vulnerability pattern; Code feature

Gaigai Tang, Lin Yang, Long Zhang, Hongyu Kuang, Huiqiang Wang,
MRC-VulLoc: Software source code vulnerability localization based on multi-choice reading comprehension,
Computers & Security,
Volume 141,
2024,
103816,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103816.
(https://www.sciencedirect.com/science/article/pii/S0167404824001172)
Abstract: Recently, automatic vulnerability detection approaches based on machine learning (ML) have outperformed traditional rule-based approaches in terms of detection performance. Existing ML-based approaches typically concentrate on function or line granularity, which fail to realize accurate vulnerability localization and are insufficient to support effective root cause analysis of vulnerability. To address this issue, we propose a new approach that maps the multi-choice reading comprehension (MRC) task to the vulnerability localization task at the granularity of vulnerability triggering path named MRC-VulLoc. Initially, we design six large datasets (including C/C++ and Java languages) in the form of MRC. Subsequently, we introduce a novel pre-trained vulnerability localization model, combining the effective code semantic comprehension ability of pre-trained model with the advantages of Bidirectional Short-Term Memory Network (Bi-LSTM) and Convolutional Neural Network (CNN) models. Lastly, we conduct experiments to evaluate the vulnerability localization with several state-of-the-art MRC approaches and vulnerability detectors. Experimental results demonstrate the effectiveness of the proposed datasets in evaluating MRC approaches for vulnerability localization. Furthermore, MRC-VulLoc achieves higher precision on vulnerability localization compared to comparative vulnerability detectors.
Keywords: Source code; Vulnerability localization; Machine learning; MRC

K. Lakshmi Narayana, K. Sathiyamurthy,
Automation and smart materials in detecting smart contracts vulnerabilities in Blockchain using deep learning,
Materials Today: Proceedings,
Volume 81, Part 2,
2023,
Pages 653-659,
ISSN 2214-7853,
https://doi.org/10.1016/j.matpr.2021.04.125.
(https://www.sciencedirect.com/science/article/pii/S2214785321030273)
Abstract: Smart contracts are a vital component of applications being built by blockchain or distributed ledger technology. Smart contracts consists of computer code that composed set of rules agreed upon by the involved parties. When these predefined conditions or rules are satisfied by the transactions initiated by parties, the smart contract executes itself to complete the transaction. Normally, while performing transactions with agreements involving multiple parties, a third party have to be involve to verify all the information, which makes it complex and time consuming process. Smart contracts simplify this process by eliminating the third party and automating the process, enabling the stakeholders to perform transactions directly with each other. Smart contract itself is replicated among multiple nodes of a blockchain there by giving benefits of immutability, security and permanence. Most smart contracts are written in Solidity programming language due to its simplicity and conciseness. Attackers are attracted by the popularity of Solidity language and its vulnerability possibilities. For example, in the 2016 year, 60 million US dollars was theft by Decentralized Autonomous Organization (DAO) attack due to vulnerabilities present in smart contracts. There are few existing tools and papers on this area to find vulnerabilities on smart contracts but taking more time to predict. Thus, this paper presents different Deep learning techniques with satisfactory results to identify smart contract vulnerabilities which are Re-entrancy, Denial of Service (DOS) and Transaction Origin using binary, multi class and multi label classification techniques.
Keywords: Blockchain; Ethereum; Smart contracts; Solidity; Vulnerabilities; Deep learning models

Weiping Ding, Ibrahim Alrashdi, Hossam Hawash, Mohamed Abdel-Basset,
DeepSecDrive: An explainable deep learning framework for real-time detection of cyberattack in in-vehicle networks,
Information Sciences,
Volume 658,
2024,
120057,
ISSN 0020-0255,
https://doi.org/10.1016/j.ins.2023.120057.
(https://www.sciencedirect.com/science/article/pii/S0020025523016432)
Abstract: Autonomous driving (AD) technologies are becoming increasingly popular, promising significant enhancements in road safety and efficiency. However, the susceptibility of autonomous vehicles to cyberattacks highlights the critical need for protecting the security and dependability of in-vehicular networks (IVNs). This study proposes a lightweight, efficient, and explainable deep learning framework, DeepSecDrive, for early detection of security threats against IVN. DeepSecDrive presents robust feature extractor units designed with deformable convolutions and a lightweight non-local network (LNLN). The former promotes dynamic change of receptive field to enhance extraction of complex features from the traffics of in-vehicle networks, while the latter enables learning contextual representations and non-local relationships in vehicular data. DeepSecDrive integrates Shapley Additive exPlanations to construct multi-level interpretability units, providing local and global explanations for model decisions in terms of feature contributions to the overall performance. Proof-of-concept experiments are conducted to evaluate the efficacy and durability of DeepSecDrive on real-world IVN attacks from Car-Hacking dataset, and the experimental results demonstrate the ability of our model to outperform state-of-the-art detection methods.
Keywords: Explainable AI (XAI); In-Vehicular Network; Security; Deep Learning; Autonomous Driving

Zhilong Cai, Yongwei Cai, Xiang Chen, Guilong Lu, Wenlong Pei, Junjie Zhao,
CSVD-TF: Cross-project software vulnerability detection with TrAdaBoost by fusing expert metrics and semantic metrics,
Journal of Systems and Software,
Volume 213,
2024,
112038,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2024.112038.
(https://www.sciencedirect.com/science/article/pii/S0164121224000815)
Abstract: Recently, deep learning-based software vulnerability detection (SVD) approaches have achieved promising performance. However, the scarcity of high-quality labeled SVD data influences the practicality of these approaches. Therefore, cross-project software vulnerability detection (CSVD) has gradually attracted the attention of researchers since CSVD can utilize the labeled SVD data from the source project to construct an effective CSVD model for the target project via transfer learning. However, if a certain number of program modules in the target project can be labeled by security experts, it can help to improve CSVD model performance by effectively utilizing similar SVD data in the source project. For this more practical CSVD scenario, we propose a novel approach CSVD-TF via the transfer learning method TrAdaBoost. Moreover, we find expert metrics and semantic metrics extracted from the functions show a certain complementary in our investigated scenario. Therefore, we utilize a model-level metric fusion method to further improve the performance. We perform a comprehensive study to evaluate the effectiveness of CSVD-TF on four real-world projects. Our empirical results show that CSVD-TF can achieve performance improvements of 7.5% to 24.6% in terms of AUC when compared to five state-of-the-art baselines.
Keywords: Cross-project software vulnerability detection; Transfer learning; Expert metrics; Semantic metrics; Metric fusion

Kuo Zhou, Jing Huang, Honggui Han, Bei Gong, Ao Xiong, Wei Wang, Qihui Wu,
Smart contracts vulnerability detection model based on adversarial multi-task learning,
Journal of Information Security and Applications,
Volume 77,
2023,
103555,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2023.103555.
(https://www.sciencedirect.com/science/article/pii/S2214212623001394)
Abstract: Vulnerability detection is important for smart contracts because of their immutable and irreversible features. In this work, a new detection method based on adversarial multi-task learning is proposed to improve the accuracy of existing vulnerability detection methods, which is based on the multi-task learning framework, including a shared part and a task-specific part. We optimize the multi-task learning frameworks and propose the mixed parameter sharing method to make each task not only maintain its uniqueness, but also share features with other tasks, which helps solve the problem that the hard parameter sharing method cannot constrain the underlying shared layer and improve the quality of extracted features. In addition, we introduce adversarial transfer learning to reduce noise pollution caused by the private feature and interference between the general feature and the private feature. We experimented on datasets obtained from our previous work, and the experimental results prove that our proposed model can judge whether there are vulnerabilities in smart contracts and then identify their types. Additionally, the results also show that our model effectively improves detection accuracy and has an advantage in performance over representative methods.
Keywords: Vulnerability detection; Smart contracts; Multi-task learning; Adversarial transfer learning; Blockchain security supervision

Jingwei Hao, Senlin Luo, Limin Pan,
A novel vulnerability severity assessment method for source code based on a graph neural network,
Information and Software Technology,
Volume 161,
2023,
107247,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107247.
(https://www.sciencedirect.com/science/article/pii/S0950584923001015)
Abstract: Context
Vulnerability severity assessment is an important part of vulnerability management that can help security personnel determine the priority of vulnerability repair work.
Objective
Aiming at the problems of low evaluation efficiency and poor timeliness in the existing method, a vulnerability severity evaluation method combining a function call graph and vulnerability attribute graph is proposed.
Method
This method constructs a function call graph centered on vulnerable functions and uses the call relationship between vulnerable functions and sensitive API functions to reflect the severity of the damage of the vulnerable functions. The graph attention neural network algorithm is used to mine the key vulnerability characteristics in the function call graph and the vulnerability attribute graph to realize the assessment of vulnerability severity.
Results
The ablation experiment results showed that the combined vulnerability attribute graph and function call graph had higher evaluation accuracy than the vulnerability attribute graph or function call graph alone, which increased by 6.85% and 32.90%, respectively. Compared with other existing methods, our method has achieved a better evaluation effect, and the evaluation accuracy has increased by 10%.
Conclusion
The vulnerability severity assessment method incorporating function call graphs and vulnerability property graphs demonstrates an enhancement in the ability to represent the severity of vulnerabilities and increases the efficiency of vulnerability severity evaluation through elimination of the requirement for manual analysis.
Keywords: Vulnerability severity assessment; Source code; Vulnerability property graph; Function call graph

Qian Wang, Zhengdao Li, Hetong Liang, Xiaowei Pan, Hui Li, Tingting Li, Xiaochen Li, Chenchen Li, Shikai Guo,
Graph Confident Learning for Software Vulnerability Detection,
Engineering Applications of Artificial Intelligence,
Volume 133, Part C,
2024,
108296,
ISSN 0952-1976,
https://doi.org/10.1016/j.engappai.2024.108296.
(https://www.sciencedirect.com/science/article/pii/S0952197624004548)
Abstract: Code vulnerability exposes millions of software to the possibility of being attacked, as evidence every year on increasing reports of security issues, such as information leaks, system compromise, and denial of service. Despite with many vulnerability detection models proposed so far, their effectiveness is still limited due to the ignorance of syntactic structural information analysis in source code and the improper handling of labeling errors. To address these issues, we propose the Graph Confident Learning for Software Vulnerability Detection (GCL4SVD) model, a machine learning model to detect software vulnerability in the development phase. It comprises two components: code graph embedding and graph confident learning denoising. To address the syntactic structural information analysis limitation, the code graph embedding component extracts the structure and semantic information of source code with a sliding window mechanism, and then encodes source code into a graph structure to capture the patterns and characteristics of code vulnerabilities. Additionally, the graph confident learning denoising component identifies labeling errors to improve the quality of training set. Experimental results show that GCL4SVD outperforms the state-of-the-art vulnerability detection models on four open source datasets by 3.7%, 3.3%, 2.5%, 0.8% in terms of Accuracy, respectively, and by 10.2%, 21.8%, 8.2%, 11.2% in terms of F1-score.
Keywords: Software code vulnerability detection; Learning with noisy labels; Gated graph neural networks

Deepak Kumar, R.K. Pateriya, Rajeev Kumar Gupta, Vasudev Dehalwar, Ashutosh Sharma,
DDoS Detection using Deep Learning,
Procedia Computer Science,
Volume 218,
2023,
Pages 2420-2429,
ISSN 1877-0509,
https://doi.org/10.1016/j.procs.2023.01.217.
(https://www.sciencedirect.com/science/article/pii/S187705092300217X)
Abstract: The network's infrastructure becomes more vulnerable to cyber-attacks as the number of services offered through the internet expands. The complexity of "Distributed Denial-of-Service (DDoS)" threats on the internet has recently increased, posing a challenge to typical protection systems. As a result, early identification and separation of network data is the most crucial part of protecting against DDoS threats. A "Long Short-Term Memory (LSTM)" based model is created in this study to identify DDoS threats on a sample of network traffic packets. LSTM is a deep learning technique that includes a feature selection and extraction algorithm. When trained, it updates itself; Even with a smaller number of data points, LSTM functions swiftly and correctly. Using the "CICDDoS2019 dataset" for training and testing, the suggested LSTM model can achieve an accuracy of up to 98 percent in the current work, and Deep learning exceeds machine learning on the CICDDoS2019 dataset.
Keywords: DDoS; Long Short-Term Memory (LSTM); CICDDoS2019; Classification; Deep Learning

Zhenzhou Tian, Binhui Tian, Jiajun Lv, Yanping Chen, Lingwei Chen,
Enhancing vulnerability detection via AST decomposition and neural sub-tree encoding,
Expert Systems with Applications,
Volume 238, Part B,
2024,
121865,
ISSN 0957-4174,
https://doi.org/10.1016/j.eswa.2023.121865.
(https://www.sciencedirect.com/science/article/pii/S0957417423023679)
Abstract: The explosive growth of software vulnerabilities poses a serious threat to the system security and has become one of the urgent problems of the day. However, existing vulnerability detection methods are still faced with limitations in reaching the balance between detection accuracy, efficiency and applicability. Following a divide-and-conquer strategy, this paper proposes TrVD (abstract syntax Tree decomposition based Vulnerability Detector) to disclose the indicative semantics implied in the source code fragments for accurate and efficient vulnerability detection. To facilitate the capture of subtle semantic features, TrVD converts the AST of a code fragment into an ordered set of sub-trees of restricted sizes and depths with a novel decomposition algorithm. The semantics of each sub-tree can thus be effectively collected with a carefully designed tree-structured neural network. Finally, a Transformer-style encoder is utilized to aggregate the long-range contextual semantics of all sub-trees into a vulnerability-specific vector to represent the target code fragment. The extensive experiments conducted on five large datasets consisting of diverse real-world and synthetic vulnerable samples demonstrate the performance superiority of TrVD against SOTA approaches in detecting the presence of vulnerabilities and pinpointing the vulnerability types. The ablation studies also confirm the effectiveness of TrVD’s core designs.
Keywords: Vulnerability detection; Tree decomposition; Tree-structured neural network; Deep semantic extraction

Matteo Esposito, Davide Falessi,
VALIDATE: A deep dive into vulnerability prediction datasets,
Information and Software Technology,
Volume 170,
2024,
107448,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2024.107448.
(https://www.sciencedirect.com/science/article/pii/S0950584924000533)
Abstract: Context:
Vulnerabilities are an essential issue today, as they cause economic damage to the industry and endanger our daily life by threatening critical national security infrastructures. Vulnerability prediction supports software engineers in preventing the use of vulnerabilities by malicious attackers, thus improving the security and reliability of software. Datasets are vital to vulnerability prediction studies, as machine learning models require a dataset. Dataset creation is time-consuming, error-prone, and difficult to validate.
Objectives:
This study aims to characterise the datasets of prediction studies in terms of availability and features. Moreover, to support researchers in finding and sharing datasets, we provide the first VulnerAbiLty predIction DatAseT rEpository (VALIDATE).
Methods:
We perform a systematic literature review of the datasets of vulnerability prediction studies.
Results:
Our results show that out of 50 primary studies, only 22 studies (i.e., 38%) provide a reachable dataset. Of these 22 studies, only one study provides a dataset in a stable repository.
Conclusions:
Our repository of 31 datasets, 22 reachable plus nine datasets provided by authors via email, supports researchers in finding datasets of interest, hence avoiding reinventing the wheel; this translates into less effort, more reliability, and more reproducibility in dataset creation and use.
Keywords: Security; Replicability; Vulnerability; Machine learning; Repository; Dataset

Xiaozhi Du, Shiming Zhang, Yanrong Zhou, Hongyuan Du,
A vulnerability severity prediction method based on bimodal data and multi-task learning,
Journal of Systems and Software,
Volume 213,
2024,
112039,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2024.112039.
(https://www.sciencedirect.com/science/article/pii/S0164121224000827)
Abstract: Facing the increasing number of software vulnerabilities, the automatic analysis of vulnerabilities has become an important task in the field of software security. However, the existing severity prediction methods are mainly based on vulnerability descriptions and ignore the relevant features of vulnerability code, which only includes unimodal information and result in low prediction accuracy. This paper proposes a vulnerability severity prediction method based on bimodal data and multi-task learning. First the bimodal data, which consists of the description and source code of each vulnerability, is preprocessed. Next the GraphCodeBert is used for the word embedding module to extract different vulnerability features from the bimodal data. Then the Bi-GRU with attention mechanism is adopted for further feature extraction of vulnerability severity. Considering the strong correlation between the two tasks of vulnerability severity prediction and exploitability prediction, this paper proposes a multi-task learning approach, which allows the model to learn the connection and shared information between different tasks through a hard parameter sharing strategy, so as to achieve more accurate and reliable prediction of vulnerability severity. Experimental results show that the severity prediction method proposed in this paper outperforms state-of-the-art methods, and can achieve an average F1 score of 93.83 % on the public vulnerability dataset.
Keywords: Vulnerability severity prediction; Bimodal data; Multi-task learning; GraphCodeBert

Hongliang Liang, Zhuosi Xie, Yixiu Chen, Hua Ning, Jianli Wang,
FIT: Inspect vulnerabilities in cross-architecture firmware by deep learning and bipartite matching,
Computers & Security,
Volume 99,
2020,
102032,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2020.102032.
(https://www.sciencedirect.com/science/article/pii/S0167404820303059)
Abstract: Widely deployed IoT devices expose serious security threats because the firmware in them contains vulnerabilities, which are difficult to detect due to two main factors: 1) The firmware’s code is usually not available; 2) A same vulnerability often exists in multiple firmware with different architectures and/or release versions. In this paper, we propose a novel neural network-based staged approach to inspect vulnerabilities in firmware, which first learns semantics in binary code and utilizes neural network model to screen out the potential vulnerable functions, then performs bipartite graph matching upon three-level features between two binary functions. We implement the approach in a tool called FIT and evaluation results show that FIT outperforms state-of-the-art approaches, i.e., Gemini, CVSSA and discovRE, on both effectiveness and efficiency. FIT also detects vulnerabilities in real-world firmware of IoT devices, such as D-Link routers. Moreover, we make our tool and dataset publicly available in the hope of facilitating further researches in the firmware security field.
Keywords: firmware security; binary code; similarity detection; neural network; bipartite matching

Jie Cai, Bin Li, Tao Zhang, Jiale Zhang, Xiaobing Sun,
Fine-grained smart contract vulnerability detection by heterogeneous code feature learning and automated dataset construction,
Journal of Systems and Software,
Volume 209,
2024,
111919,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111919.
(https://www.sciencedirect.com/science/article/pii/S016412122300314X)
Abstract: Context:
Recently, several deep learning based smart contract vulnerability detection approaches have been proposed. However, challenges still exist in applying deep learning for fine-grained vulnerability detection in smart contracts, including the lack of the dataset with sufficient statement-level labeled smart contract samples and neglect of heterogeneity between syntax and semantic features during code feature learning.
Objective:
To utilize deep learning for fine-grained smart contract vulnerability detection, we propose a security best practices (SBP) based dataset construction approach to address the scarcity of datasets. Moreover, we propose a syntax-sensitive graph neural network to address the challenge of heterogeneous code feature learning.
Method:
The dataset construction approach is motivated by the insight that smart contract code fragments guarded by security best practices may contain vulnerabilities in their original unguarded code form. Thus, we locate and strip security best practices from the smart contract code to recover its original vulnerable code form and perform sample labeling. Meanwhile, as the heterogeneity between tree-structured syntax features embodied inside the abstract syntax tree (AST) and graph-structured semantic features reflected by relations between statements, we propose a code graph whose nodes are each statement’s AST subtree with a syntax-sensitive graph neural network that enhances the graph neural network by a child-sum tree-LSTM cell to learn these heterogeneous features for fine-grained smart contract vulnerability detection.
Results:
We compare our approach with three state-of-the-art deep learning-based approaches that only support contract-level vulnerability detection and two popular static analysis-based approaches that support fine detection granularity. The experiment results show that our approach outperforms the baselines at both coarse and fine granularities.
Conclusion:
In this paper, we propose utilizing security best practices inside the smart contract code to construct the dataset with statement-level labels. To learn both tree-structured syntax and graph-structured semantic code features, we propose a syntax-sensitive graph neural network. The experimental results show that our approach outperforms the baselines.
Keywords: Smart contract; Static analysis; Vulnerability detection; Graph neural network

Mingke Wang, Chuanqi Tao, Hongjing Guo,
LCVD: Loop-oriented code vulnerability detection via graph neural network,
Journal of Systems and Software,
Volume 202,
2023,
111706,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111706.
(https://www.sciencedirect.com/science/article/pii/S0164121223001012)
Abstract: Due to the unique mechanism and complex structure, loops in programs can easily lead to various vulnerabilities such as dead loops, memory leaks, resource depletion, etc. Traditional approaches to loop-oriented program analysis (e.g. loop summarization) are costly with a high rate of false positives in complex software systems. To address the issues above, recent works have applied deep learning (DL) techniques to vulnerability detection. However, existing DL-based approaches mainly focused on the general characteristics of most vulnerabilities without considering the semantic information of specific vulnerabilities. As a typical structure in programs, loops are highly iterative with multi-paths. Currently, there is a lack of available approaches to represent loops, as well as useful methods to extract the implicit vulnerability patterns. Therefore, this paper introduces LCVD, an automated loop-oriented code vulnerability detection approach. LCVD represents the source code as the Loop-flow Abstract Syntax Tree (LFAST), which focuses on interleaving multi-paths around loop structures. Then a novel Loop-flow Graph Neural Network (LFGNN) is proposed to learn both the local and overall structure of loop-oriented vulnerabilities. The experimental results demonstrate that LCVD outperforms the three static analysis-based and four state-of-the-art DL-based vulnerability detection approaches across evaluation settings.
Keywords: Loop-oriented vulnerability; Vulnerability detection; Deep learning; Code representation; Graph neural network

Lingdi Kong, Senlin Luo, Limin Pan, Zhouting Wu, Xinshuai Li,
A multi-type vulnerability detection framework with parallel perspective fusion and hierarchical feature enhancement,
Computers & Security,
Volume 140,
2024,
103787,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103787.
(https://www.sciencedirect.com/science/article/pii/S0167404824000889)
Abstract: A core problem of vulnerability detection is to detect multi-type vulnerabilities simultaneously by characterizing vulnerabilities of high diversity and complexity in real program source code. Current methods mainly adjust and compromise multiple code representations such as code sequence and code graph based on composite graph. However, sequential features extracted by graph are hardly sufficient to model the contextual semantic associations of the token sequence. Meanwhile, structural features of the code graph extracted by models based on Euclidean Graph Neural Network are difficult to fit the tree-like calling relationships between code lines. These limitations make it difficult to detect diverse vulnerabilities. In addition, most of the existing models ignore the type of code statement, which is closely associated with some specific vulnerability types. In this paper, we propose a Parallelism Framework with Hierarchical feature Enhancement for Multi-type Vulnerability Detection (PFHE-MVD). PFHE-MVD models program code from three parallel perspectives, containing sequence, code graph, and Abstract Syntax Tree statistic. Hyperbolic Graph Convolutional Neural Network is integrated to model the top-down hierarchical calling structure in program code graph through hyperbolic space mapping. Besides, the statement type of code is embedded along with the code text to strengthen the identification ability for different types of vulnerabilities. Experimental results show that PFHE-MVD achieves new state-of-the-art results in multi-type vulnerability detection. PFHE-MVD captures tree-like hierarchical code structure feature and enhances the distinguishing ability for vulnerabilities by code statement type embedding.
Keywords: Vulnerability detection; Multiple types; Hyperbolic graph; Feature fusion

Seema Pillai, Dr. Anurag Sharma,
Hybrid unsupervised web-attack detection and classification – A deep learning approach,
Computer Standards & Interfaces,
Volume 86,
2023,
103738,
ISSN 0920-5489,
https://doi.org/10.1016/j.csi.2023.103738.
(https://www.sciencedirect.com/science/article/pii/S0920548923000193)
Abstract: Web requests made by users of web applications are manipulated by hackers to gain control of web servers. Moreover, detecting web attacks has been increasingly important in the distribution of information over the last few decades. Also, several existing techniques had been performed on detecting vulnerable web attacks using machine learning and deep learning techniques. However, there is a lack in achieving attack detection ratio owing to the utilization of supervised and semi-supervised learning approaches. Thus to overcome the aforementioned issues, this research proposes a hybrid unsupervised detection model a deep learning-based anomaly-based web attack detection. Whereas, the encoded outputs of De-Noising Autoencoder (DAE), as well as Stacked Autoencoder (SAE), are integrated and given to the Generative adversarial network (GAN) as input to improve the feature representation ability to detect the web attacks. Consequently, for classifying the type of attacks, a novel DBM-Bi LSTM-based classification model has been introduced. Which incorporates DBM for binary classification and Bi-LSTM for multi-class classification to classify the various attacks. Finally, the performance of the classifier in terms of recall, precision, F1-Score, and accuracy are evaluated and compared. The proposed method achieved high accuracy of 98%.
Keywords: SQL injection attack; Cross-site scripting attacks; Denoising autoencoder; Deep Boltzmann machine; Binary long term short term memory

Panchanan Nath, Jaya Rani Mushahary, Ujjal Roy, Maharaj Brahma, Pranav Kumar Singh,
AI and Blockchain-based source code vulnerability detection and prevention system for multiparty software development,
Computers and Electrical Engineering,
Volume 106,
2023,
108607,
ISSN 0045-7906,
https://doi.org/10.1016/j.compeleceng.2023.108607.
(https://www.sciencedirect.com/science/article/pii/S0045790623000320)
Abstract: With the growing demand for application software, there is a race among industries to develop software as quickly as possible. However, maintaining pace and ensuring bug-free software has become increasingly challenging in a work-from-home arrangement as software developers are not under constant supervision. It increases the possibility of buggy products, and traditional testing techniques fail to provide optimal performance. We propose an Artificial Intelligence (AI) and blockchain-based novel decentralized software testing system. The proposed system aims to detect and prevent vulnerable code by synergizing deep learning capabilities and smart-contract-powered blockchain. The vulnerability detection is performed automatically without relying on manually written rules. We propose a non-vulnerability score range map to classify the source code. Furthermore, we integrate an InterPlanetary File System (IPFS) to ensure efficient storage over the blockchain. We conduct a testbed-based experiment to demonstrate the effectiveness of AI and blockchain integration for secure code development and testing.
Keywords: Deep learning; Blockchain; Smart contract; IPFS; Software testing; Software development

Yeming Gu, Hui Shu, Fei Kang,
BinAIV: Semantic-enhanced vulnerability detection for Linux x86 binaries,
Computers & Security,
Volume 135,
2023,
103508,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103508.
(https://www.sciencedirect.com/science/article/pii/S0167404823004182)
Abstract: Binary code vulnerability detection is an important research direction in the field of network security. The extensive reuse of open-source code has led to the spread of vulnerabilities that originally only affected a small number of targets to other software. Existing vulnerability detection methods are mainly based on binary code similarity analysis, that is, by comparing the similarity of code embedding to detect vulnerabilities. However, existing methods lack semantic understanding of binary code and cannot distinguish between different functions with similar code structures, which reduces the accuracy of vulnerability detection. This paper proposes a binary vulnerability detection method BinAIV based on function semantics. BinAIV is based on a neural network model, which defines and constructs binary function semantics to achieve more accurate similarity analysis. Experimental results show that in terms of binary code similarity analysis performance, BinAIV has a significant improvement compared to traditional methods that only use function embedding. In cross-compiler function search, cross-optimization function search, and cross-obfuscation function search experiments, the average Recall@1 value of BinAIV compared to the best-performing baseline methods increased by 40.1 %, 99.8 %, and 184.0 %. In the real-world vulnerability detection experiment, BinAIV had the highest detection accuracy for all vulnerabilities, with an improvement of 155.1 % and 97.7 % compared to Asm2Vec and SAFE, respectively.
Keywords: Function semantic; Vulnerability detection; Code similarity; Binary code; Deep learning

O.O. Büyük, A. Nizam,
Deep learning with class-level abstract syntax tree and code histories for detecting code modification requirements,
Journal of Systems and Software,
Volume 206,
2023,
111851,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111851.
(https://www.sciencedirect.com/science/article/pii/S0164121223002467)
Abstract: Improving code quality is one of the most significant issues in the software industry. Deep learning is an emerging area of research for detecting code smells and addressing refactoring requirements. The aim of this study is to develop a deep learning-based system for code modification analysis to predict the locations and types of code modifications, while significantly reducing the need for manual labeling. We created an experimental dataset by collecting historical code data from open-source project repositories on the Internet. We introduce a novel class-level abstract syntax tree-based code embedding method for code analysis. A recurrent neural network was employed to effectively identify code modification requirements. Our system achieves an average accuracy of approximately 83% across different repositories and 86% for the entire dataset. These findings indicate that our system provides higher performance than the method-based and text-based code embedding approaches. In addition, we performed a comparative analysis with a static code analysis tool to justify the readiness of the proposed model for deployment. The correlation coefficient between the outputs demonstrates a significant correlation of 67%. Consequently, this research highlights that the deep learning-based analysis of code histories empowers software teams in identifying potential code modification requirements.
Keywords: Refactoring; Code smell; Recurrent neural network; Abstract syntax tree; Code embedding

Dawei Yuan, Xiaohui Wang, Yao Li, Tao Zhang,
Optimizing smart contract vulnerability detection via multi-modality code and entropy embedding,
Journal of Systems and Software,
Volume 202,
2023,
111699,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111699.
(https://www.sciencedirect.com/science/article/pii/S0164121223000948)
Abstract: Smart contracts have been widely used in the blockchain world these years, and simultaneously vulnerability detection has gained more and more attention due to the staggering economic losses caused by the attacker. Existing tools that analyze vulnerabilities for smart contracts heavily rely on rules predefined by experts, which are labour-intense and require domain knowledge. Moreover, predefined rules tend to be misconceptions and increase the risk of crafty potential back-doors in the future. Recently, researchers mainly used static and dynamic execution analysis to detect the vulnerabilities of smart contracts and have achieved acceptable results. However, the dynamic method cannot cover all the program inputs and execution paths, which leads to some vulnerabilities that are hard to detect. The static analysis method commonly includes symbolic execution and theorem proving, which requires using constraints to detect vulnerability. These shortcomings show that traditional methods are challenging to apply and expand on a large scale. This paper aims to detect vulnerabilities via the Bug Injection framework and transfer learning techniques. First, we train a Transformer encoder using multi-modality code, which contains source code, intermediate representation, and assembly code. The input code consists separately of Solidity source code, intermediate representation, and assembly code. Specifically, we translate source code into the intermediate representation and decompile the byte code into assembly code by the EVM compiler. Then, we propose a novel entropy embedding technique, which combines token embedding, segment embedding, and positional embedding of the Transformer encoder in our approach. After that, we utilize the Bug Injection framework to automatically generate specific types of buggy code for fine-tuning and evaluating the performance of vulnerability detection. The experimental results show that our proposed approach improves the performance in detecting reentrancy vulnerabilities and timestamp dependence. Moreover, our approach is more flexible and scalable than static and dynamic analysis approaches in detecting smart contract vulnerabilities. Our approach improves the baseline approaches by an average of 11.89% in term of F1 score.
Keywords: Smart contract; Bug injection; Transfer learning; Vulnerability detection

Wenxin Tao, Xiaohong Su, Jiayuan Wan, Hongwei Wei, Weining Zheng,
Vulnerability detection through cross-modal feature enhancement and fusion,
Computers & Security,
Volume 132,
2023,
103341,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103341.
(https://www.sciencedirect.com/science/article/pii/S0167404823002511)
Abstract: Software vulnerability detection is critical to computer security. Most existing vulnerability detection methods use single modal-based vulnerability detection models, which cannot effectively extract cross-modal features. To solve this problem, we propose a new multimodal deep learning based vulnerability detection method through a cross-modal feature enhancement and fusion. Firstly, we utilize a special compilation and debugging method to obtain the alignment relationship between source code statements and assembly instructions, as well as between source code variables and assembly code registers. Based on this alignment relationship and program slicing technology, we propose a cross-slicing method to generate bimodal program slices. Then, we propose a cross-modal feature enhanced code representation learning model to capture the fine-grained semantic correlation between source code and assembly code by using the co-attention mechanisms. Finally, vulnerability detection is achieved by feature level fusion of semantic features captured in fine-grained aligned source code and assembly code. Extensive experiments show that our method improves the performance of vulnerability detection compared with state-of-the-art methods. Specifically, our method achieves an accuracy of 97.4% and an F1-measure of 93.4% on the SARD dataset. An average accuracy of 95.4% and an F1-measure of 89.1% on two real-world software projects (i.e., FFmpeg and OpenSSL) is also achieved by our method, improving over SOTA method 4.5% and 2.9%.
Keywords: Software security; Multimodal deep learning; Fine-grained cross modal alignment; Co-attention; Vulnerability detection

Mingwei Tang, Wei Tang, Qingchi Gui, Jie Hu, Mingfeng Zhao,
A vulnerability detection algorithm based on residual graph attention networks for source code imbalance (RGAN),
Expert Systems with Applications,
Volume 238, Part D,
2024,
122216,
ISSN 0957-4174,
https://doi.org/10.1016/j.eswa.2023.122216.
(https://www.sciencedirect.com/science/article/pii/S0957417423027185)
Abstract: It is essential to detect potential vulnerabilities in software to ensure its safety. As software systems become more complex, traditional static vulnerability detection methods perform poorly. Currently, deep learning-based vulnerability detection models only extract source code vulnerability features using sequences or graphs. Sequential neural networks ignore structural information in the code, such as control flow diagrams and data flow diagrams. Additionally, graph neural networks cannot accurately extract features due to the lack of effective methods for extracting nodes’ features and aggregating global information. To address the above issue, we propose a vulnerability detection algorithm based on residual graph attention networks for source code imbalance (RGAN). Firstly, a local feature extraction module (PE-BL-A module) is designed. Using the sequence neural network, the module extracts various useful features, including node features in a control flow diagram based on local semantic features. Secondly, we present the Residual Graph Attention Network module (RGAT). To learn and update node features along the control flow direction, the module uses a graph attention network with residual connections. In this module, a mean biaffine attention pooling mechanism is proposed that can extract total graph vulnerability features more effectively. Thirdly, a dynamic cross-entropy loss function is designed. Using this function, it can handle sample imbalances during training. Finally, experiments conducted on several benchmark datasets demonstrate that the proposed model achieves state-of-the-art results.
Keywords: Source code vulnerability detection; Sequence neural network; Graph neural network; Attention mechanism; Imbalance processing

Wenjing Cai, Junlin Chen, Jiaping Yu, Lipeng Gao,
A software vulnerability detection method based on deep learning with complex network analysis and subgraph partition,
Information and Software Technology,
Volume 164,
2023,
107328,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107328.
(https://www.sciencedirect.com/science/article/pii/S0950584923001830)
Abstract: The increasing size and complexity of software programs have made them an integral part of modern society’s infrastructure, making software vulnerabilities a major threat to computer security. To address this issue, the use of deep learning-based software vulnerability detection methods has become increasingly popular. Although the effectiveness of the deep learning-based methods has been demonstrated, these methods have faced challenges in scalability and detection performance. To tackle this challenge, we propose a new vulnerability detection method based on deep learning with complex network analysis and subgraph partition that enhances detection accuracy while maintaining scalability. The method uses complex network analysis theory to convert the CPG into an image-like matrix, and then utilizes TextCNN for vulnerability detection. As a result, our method shows a 6% improvement in accuracy and a 10% reduction in false positive rates compared to state-of-the-art methods. In addition, our approach is able to detect some of the vulnerabilities recently released by CVE.
Keywords: Vulnerability detection; Code representation; Complex network analysis; TextCNN

Zeming Dong, Qiang Hu, Zhenya Zhang, Jianjun Zhao,
On the effectiveness of graph data augmentation for source code learning,
Knowledge-Based Systems,
Volume 285,
2024,
111328,
ISSN 0950-7051,
https://doi.org/10.1016/j.knosys.2023.111328.
(https://www.sciencedirect.com/science/article/pii/S0950705123010766)
Abstract: The methodology that employs deep learning to handle software engineering tasks, such as bug detection, is commonly referred to as source code learning. Given the inherent graph nature of source code, graph learning, bolstered by graph neural networks (GNNs), has seen an increasing adoption in the domain of source code learning. Similar to other contexts within deep learning, source code learning also relies on extensive high-quality training data, and the scarcity of such data has become a primary impediment that leads to performance bottlenecks. In practice, data augmentation is often used as a countermeasure to mitigate this issue, by synthesizing additional training data based on existing ones. However, most existing practice of data augmentation in source code learning is limited to simple program transformation methods, such as code refactoring, thus not sufficiently effective. In this work, in light of the graph nature of source code, we propose to apply the data augmentation methods used for graph-structured data in graph learning to the tasks of source code learning, and we conduct a comprehensive empirical study to evaluate whether such new data augmentation approaches bring better effectiveness, in terms of producing more accurate and robust models. Specifically, we evaluate four critical software engineering tasks and seven neural network architectures to assess the effectiveness of five data augmentation methods. Experimental results identify that, compared to the data augmentation-free training approach, the Manifold-Mixup method can significantly improve both the accuracy and robustness of the trained models of source code learning, for up to 1.60% and 4.09%, respectively.
Keywords: Graph neural networks; Data augmentation; Source code analysis

Da Chen, Lin Feng, Yuqi Fan, Siyuan Shang, Zhenchun Wei,
Smart contract vulnerability detection based on semantic graph and residual graph convolutional networks with edge attention,
Journal of Systems and Software,
Volume 202,
2023,
111705,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111705.
(https://www.sciencedirect.com/science/article/pii/S0164121223001000)
Abstract: Smart contracts are becoming the forefront of blockchain technology, allowing the performance of credible transactions without third parties. However, smart contracts on blockchain are not immune to vulnerability exploitation and cannot be modified after being deployed on the blockchain. Therefore, it is imperative to assure the security of smart contracts via intelligent vulnerability detection tools with the exponential increase in the number of smart contracts. The remarkably developing deep learning technology provides a promising way to detect potential smart contract vulnerabilities. Nevertheless, existing deep learning-based approaches fail to effectively capture the rich syntax and semantic information embedded in smart contracts for vulnerability detection. In this paper, we tackle the problem of smart contract vulnerability detection at the function level by constructing a novel semantic graph (SG) for each function and learning the SGs using graph convolutional networks (GCNs) with residual blocks and edge attention. Our proposed method consists of three stages. In the first stage, we create the SG which contains rich syntax and semantic information including the data–data, instruction–instruction and instruction–data relationships, variables, operations, etc., by building an abstract syntax tree (AST) from the code of each function, removing the unimportant nodes in the AST, and adding edges between the nodes to represent the data flows and the execution sequence of the statements. In the second stage, we propose a new graph convolutional network model EA-RGCN to learn the content and semantic features of the code. EA-RGCN contains three parts: node and edge representation via word2vec, content feature extraction with a residual GCN (RGCN) module, and semantic feature extraction using an edge attention (EA) module. In the third stage, we concatenate the code content features and the semantic features to obtain the global code feature and use a classifier to identify whether the function is vulnerable. We conduct experiments on the datasets constructed from real-world smart contracts. Experimental results demonstrate that the proposed semantic graph and the EA-RGCN model can effectively improve the performance in terms of accuracy, precision, recall, and F1-score on smart contract vulnerability detection.
Keywords: Smart contract vulnerability detection; Code graph; Graph convolutional networks; Edge attention; Residual block

Sanghoon Jeon, Huy Kang Kim,
AutoVAS: An automated vulnerability analysis system with a deep learning approach,
Computers & Security,
Volume 106,
2021,
102308,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2021.102308.
(https://www.sciencedirect.com/science/article/pii/S0167404821001322)
Abstract: Owing to the advances in automated hacking and analysis technologies in recent years, numerous software security vulnerabilities have been announced. Software vulnerabilities are increasing rapidly, whereas methods to analyze and cope with them depend on manual analyses, which result in a slow response. In recent years, studies concerning the prediction of vulnerabilities or the detection of patterns of previous vulnerabilities have been conducted by applying deep learning algorithms in an automated vulnerability search based on source code. However, existing methods target only certain security vulnerabilities or make limited use of source code to compile information. Few studies have been conducted on methods that represent source code as an embedding vector. Thus, this study proposes a deep learning-based automated vulnerability analysis system (AutoVAS) that effectively represents source code as embedding vectors by using datasets from various projects in the National Vulnerability Database (NVD) and Software Assurance Reference Database (SARD). To evaluate AutoVAS, we present and share a dataset for deep learning models. Experimental results show that AutoVAS achieves a false negative rate (FNR) of 3.62%, a false positive rate (FPR) of 1.88%, and an F1-score of 96.11%, which represent lower FNR and FPR values than those achieved by other approaches. We further apply AutoVAS to nine open-source projects and detect eleven vulnerabilities, most of which are missed by the other approaches we experimented with. Notably, we discovered three zero-day vulnerabilities, two of which were patched after being informed by AutoVAS. The other vulnerability received the Common Vulnerabilities and Exposures (CVE) ID after being detected by AutoVAS.
Keywords: Vulnerability detection; Cybersecurity; Data-driven security; Static analysis; Program slicing

Alyazia Aldhaheri, Fatima Alwahedi, Mohamed Amine Ferrag, Ammar Battah,
Deep learning for cyber threat detection in IoT networks: A review,
Internet of Things and Cyber-Physical Systems,
Volume 4,
2024,
Pages 110-128,
ISSN 2667-3452,
https://doi.org/10.1016/j.iotcps.2023.09.003.
(https://www.sciencedirect.com/science/article/pii/S2667345223000512)
Abstract: The Internet of Things (IoT) has revolutionized modern tech with interconnected smart devices. While these innovations offer unprecedented opportunities, they also introduce complex security challenges. Cybersecurity is a pivotal concern for intrusion detection systems (IDS). Deep Learning has shown promise in effectively detecting and preventing cyberattacks on IoT devices. Although IDS is vital for safeguarding sensitive information by identifying and mitigating suspicious activities, conventional IDS solutions grapple with challenges in the IoT context. This paper delves into the cutting-edge intrusion detection methods for IoT security, anchored in Deep Learning. We review recent advancements in IDS for IoT, highlighting the underlying deep learning algorithms, associated datasets, types of attacks, and evaluation metrics. Further, we discuss the challenges faced in deploying Deep Learning for IoT security and suggest potential areas for future research. This survey will guide researchers and industry experts in adopting Deep Learning techniques in IoT security and intrusion detection.
Keywords: Cyber threats; Deep learning; Intrusion detection; IoT; Machine learning

Miles Q. Li, Benjamin C.M. Fung, Ashita Diwan,
A Novel Deep Multi-head Attentive Vulnerable Line Detector,
Procedia Computer Science,
Volume 222,
2023,
Pages 35-44,
ISSN 1877-0509,
https://doi.org/10.1016/j.procs.2023.08.142.
(https://www.sciencedirect.com/science/article/pii/S1877050923009079)
Abstract: Detecting and fixing vulnerabilities in software programs before production is crucial in software engineering. Manual vulnerability detection is labor-intensive, especially for large programs, leading to the proposal of machine learning-based methods for automation. However, existing approaches primarily detect vulnerabilities at the function level, providing non-specific results that require additional developer effort to locate vulnerabilities. Detection at the line-of-code level is an underexplored area. In this paper, we propose a novel deep learning method for line-of-code vulnerability detection. Our hybrid neural network combines a memory network and multi-head attention mechanism. Through comprehensive experiments, we analyze the impact of each modification, demonstrating significant improvements in performance. Our approach outperforms existing methods for comparison, showcasing its effectiveness in vulnerability detection.
Keywords: Deep learning; vulnerability detection; memory networks; multi-head attention

Kamran Shaukat, Suhuai Luo, Vijay Varadharajan,
A novel deep learning-based approach for malware detection,
Engineering Applications of Artificial Intelligence,
Volume 122,
2023,
106030,
ISSN 0952-1976,
https://doi.org/10.1016/j.engappai.2023.106030.
(https://www.sciencedirect.com/science/article/pii/S0952197623002142)
Abstract: Malware detection approaches can be classified into two classes, including static analysis and dynamic analysis. Conventional approaches of the two classes have their respective advantages and disadvantages. For example, static analysis is faster but cannot detect the malware variants generated through code obfuscation, whereas dynamic analysis can effectively detect variants generated through code obfuscation but is slower and requires intensive resources. This paper proposes a novel deep learning-based approach for malware detection. It delivers better performance than conventional approaches by combining static and dynamic analysis advantages. First, it visualises a portable executable (PE) file as a coloured image. Second, it extracts deep features from the colour image using fine-tuned deep learning model. Third, it detects malware based on the deep features using support vector machines (SVM). The proposed method combines deep learning with machine learning and eliminates the need for intensive feature engineering tasks and domain knowledge. The proposed approach is scalable, cost-effective, and efficient. The detection effectiveness of the proposed method is validated through 12 machine learning models and 15 deep learning models. The generalisability of the proposed framework is validated on various benchmark datasets. The proposed approach outperformed with an accuracy of 99.06% on the Malimg dataset. The Wilcoxon signed-rank test is used to show the statistical significance of the proposed framework. The detailed experimental results demonstrate the superiority of the proposed method over the other state-of-the-art approaches, with an average increase in accuracy of 16.56%. Finally, to tackle the problems of imbalanced data and the shortage of publicly available datasets for malware detection, various data augmentation techniques are proposed, which lead to improved performance. It is evident from the results that the proposed framework can be useful to the defence industry, which will be helpful in devising more efficient malware detection solutions.
Keywords: Malware detection; Cybersecurity; Machine learning; Deep learning; Transfer learning; Ensembling; Support vector machine; Modelling; Malware; Image-based malware detection; Convolutional neural network; Classification; Cyberattack

Hao Sun, Lei Cui, Lun Li, Zhenquan Ding, Zhiyu Hao, Jiancong Cui, Peng Liu,
VDSimilar: Vulnerability detection based on code similarity of vulnerabilities and patches,
Computers & Security,
Volume 110,
2021,
102417,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2021.102417.
(https://www.sciencedirect.com/science/article/pii/S0167404821002418)
Abstract: Vulnerability detection using machine learning is a hot topic in improving software security. However, existing works formulate detection as a classification problem, which requires a large set of labelled data while capturing semantical and syntactic similarity. In this work, we argue that similarity in the view of vulnerability is the key in detecting vulnerabilities. We prepare a relatively smaller data set composed of both vulnerabilities and associated patches, and attempt to realize security similarity from (i) the similarity between pair of vulnerabilities and (ii) the difference between a pair of vulnerability and patch. To achieve this, we setup the detection model using the Siamese network cooperated with BiLSTM and Attention to deal with source code, Attention network to improve the detection accuracy. On a data set of 876 vulnerabilities and patches of OpenSSL and Linux, the proposed model (VDSimilar) achieves about 97.17% in AUC value of OpenSSL (where the Attention network contributes 1.21% than BiLSTM in Siamese), which is more outstanding than the most advanced methods based on deep learning.
Keywords: Siamese network; BiLSTM; Attention; Vulnerability detection; Code similarity

Khushnaseeb Roshan, Aasim Zafar, Shiekh Burhan Ul Haque,
Untargeted white-box adversarial attack with heuristic defence methods in real-time deep learning based network intrusion detection system,
Computer Communications,
Volume 218,
2024,
Pages 97-113,
ISSN 0140-3664,
https://doi.org/10.1016/j.comcom.2023.09.030.
(https://www.sciencedirect.com/science/article/pii/S0140366423003468)
Abstract: Network Intrusion Detection System (NIDS) is a key component in securing the computer network from various cyber security threats and network attacks. However, consider an unfortunate situation where the NIDS is itself attacked and vulnerable; more specifically, we can ask, “How to defend the defender?“. In Adversarial Machine Learning (AML), the malicious actors aim to fool the Machine Learning (ML) and Deep Learning (DL) models to produce incorrect predictions with intentionally crafted adversarial examples. These adversarial perturbed examples have become the biggest vulnerability of ML and DL based systems and are major obstacles to their adoption in real-time and mission-critical applications such as NIDS. AML is an emerging research domain, and it has become a necessity for the in-depth study of adversarial attacks and their defence strategies to safeguard the computer network from various cyber security threads. In this research work, we aim to cover important aspects related to NIDS, adversarial attacks and its defence mechanism to increase the robustness of the ML and DL based NIDS. We implemented four powerful adversarial attack techniques, namely, Fast Gradient Sign Method (FGSM), Jacobian Saliency Map Attack (JSMA), Projected Gradient Descent (PGD) and Carlini & Wagner (C&W) in NIDS. We analyzed its performance in terms of various performance metrics in detail. Furthermore, the three heuristics defence strategies, i.e., Adversarial Training (AT), Gaussian Data Augmentation (GDA) and High Confidence (HC), are implemented to improve the NIDS robustness under adversarial attack situations. The complete workflow is demonstrated in real-time network with data packet flow. This research work provides the overall background for the researchers interested in AML and its implementation from a computer network security point of view.
Keywords: Network intrusion detection; Deep neural network; Adversarial machine learning; Adversarial attack; Adversarial defence

Janaka Senanayake, Harsha Kalutarage, Andrei Petrovski, Luca Piras, Mhd Omar Al-Kadri,
Defendroid: Real-time Android code vulnerability detection via blockchain federated neural network with XAI,
Journal of Information Security and Applications,
Volume 82,
2024,
103741,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2024.103741.
(https://www.sciencedirect.com/science/article/pii/S2214212624000449)
Abstract: Ensuring strict adherence to security during the phases of Android app development is essential, primarily due to the prevalent issue of apps being released without adequate security measures in place. While a few automated tools are employed to reduce potential vulnerabilities during development, their effectiveness in detecting vulnerabilities may fall short. To address this, “Defendroid”, a blockchain-based federated neural network enhanced with Explainable Artificial Intelligence (XAI) is introduced in this work. Trained on the LVDAndro dataset, the vanilla neural network model achieves a 96% accuracy and 0.96 F1-Score in binary classification for vulnerability detection. Additionally, in multi-class classification, the model accurately identifies Common Weakness Enumeration (CWE) categories with a 93% accuracy and 0.91 F1-Score. In a move to foster collaboration and model improvement, the model has been deployed within a blockchain-based federated environment. This environment enables community-driven collaborative training and enhancements in partnership with other clients. The extended model demonstrates improved accuracy of 96% and F1-Score of 0.96 in both binary and multi-class classifications. The use of XAI plays a pivotal role in presenting vulnerability detection results to developers, offering prediction probabilities for each word within the code. This model has been integrated into an Application Programming Interface (API) as the backend and further incorporated into Android Studio as a plugin, facilitating real-time vulnerability detection. Notably, Defendroid exhibits high efficiency, delivering prediction probabilities for a single code line in an average processing time of a mere 300 ms. The weight-sharing transparency in the blockchain-driven federated model enhances trust and traceability, fostering community engagement while preserving source code privacy and contributing to accuracy improvement.
Keywords: Android application protection; Code vulnerability; Neural network; Federated learning; Source code privacy; Explainable AI; Blockchain

Irina V. Pustokhina, Denis A. Pustokhin, Thavavel Vaiyapuri, Deepak Gupta, Sachin Kumar, K. Shankar,
An automated deep learning based anomaly detection in pedestrian walkways for vulnerable road users safety,
Safety Science,
Volume 142,
2021,
105356,
ISSN 0925-7535,
https://doi.org/10.1016/j.ssci.2021.105356.
(https://www.sciencedirect.com/science/article/pii/S0925753521002009)
Abstract: Anomaly detection in pedestrian walkways is an important research topic, commonly used to improve the safety of pedestrians. Due to the wide utilization of video surveillance systems and the increased quantity of captured videos, the traditional manual examination of labeling abnormal events is a tiresome task. So, an automated surveillance system that detects anomalies becomes essential among computer vision researchers. Presently, the development of deep learning (DL) models has gained significant interest in different computer vision processes namely object classification and object detection, and these applications were depending on supervised learning that required labels. Therefore, this paper develops an automated deep learning based anomaly detection technique in pedestrian walkways (DLADT-PW) for vulnerable road user's safety. The goal of the DLADT-PW model is to detect and classify the various anomalies that exist in the pedestrian walkways such as cars, skating, jeep, etc. The DLADT-PW model involves preprocessing as the primary step, which is applied for removing the noise and raise the quality of the image. In addition, mask region convolutional neural network (Mask-RCNN) with densely connected networks (DenseNet) model is employed for the detection process. To ensure the better anomaly detection performance of the DLADT-PW technique, an extensive set of simulations were performed and the outcomes are investigated under distinct aspects. The obtained experimental values confirmed the superior characteristics of the DLADT-PW technique by achieving a maximum detection accuracy.
Keywords: Anomaly detection; Pedestrian walkways; Deep learning; Safety; Mask RCNN

Yukun Dong, Yeer Tang, Xiaotong Cheng, Yufei Yang, Shuqi Wang,
SedSVD: Statement-level software vulnerability detection based on Relational Graph Convolutional Network with subgraph embedding,
Information and Software Technology,
Volume 158,
2023,
107168,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107168.
(https://www.sciencedirect.com/science/article/pii/S0950584923000228)
Abstract: Context:
Current deep-learning based vulnerability detection methods have been proven more automatic and correct to a certain extent, nonetheless, they are limited to detect at function-level or file-level, which can hinder software developers from acquiring more detailed information and conducting more targeted repairs. Graph-based detection methods have shown dominant performance over others. Unfortunately, the information they reveal has not been fully utilized.
Objective:
We design SedSVD (Subgraph embedding driven Statement-level Vulnerability Detection) with two objectives: (i) to better utilize the information the code-related graphs can reflect; (ii) to detect vulnerabilities at a finer-grained level.
Method:
In our work, we propose a novel graph-based detection framework that embeds graphs at subgraph-level to realize statement-level detection. It first leverages Code Property Graph (CPG) to learn both semantic and syntactic information from source code, and then selects several center nodes (code elements) in CPG to build their subgraphs. After embedding each subgraph with its nodes and edges, we apply Relational Graph Convolutional Network (RGCN) to process different edges differently. A Multi-Layer Perceptron (MLP) layer is further added to ensure its prediction performance.
Results:
We conduct our experiments on C/C++ projects from NVD and SARD. Experimental results show that SedSVD achieves 95.15% in F1-measure which proves our work to be more effective.
Conclusion:
Our work detects at a finer-grained level and achieves higher F1-measure than existing state-of-art vulnerability detection techniques. Besides, we provide a more detailed detection report pointing the specific error code elements within statements.
Keywords: Software vulnerability detection; Code property graph; Relational graph convolutional network; Subgraph embedding; Statement-level detection

Himanshu Nandanwar, Rahul Katarya,
Deep learning enabled intrusion detection system for Industrial IOT environment,
Expert Systems with Applications,
Volume 249, Part C,
2024,
123808,
ISSN 0957-4174,
https://doi.org/10.1016/j.eswa.2024.123808.
(https://www.sciencedirect.com/science/article/pii/S0957417424006742)
Abstract: The prevalence of security vulnerabilities in Internet of Things (IoT) applications poses a serious threat to enterprise systems, necessitating sophisticated and reliable defense solutions to counter emerging and evolving threats. For the Industrial Internet of Things (IIoT), stakeholders require trustworthy and sustainable systems that can prevent the loss of human life during critical operations. The impact of multi-variant persistent and sophisticated bot attacks on connected IIoTs is potentially catastrophic, and their detection presents a highly complex and critical challenge. Therefore, there is a pressing need for efficient and timely detection of IIoT botnet attacks. This research paper proposes a robust deep learning model named AttackNet for the detection and classification of different botnet attacks in IIoT based on adaptive based CNN-GRU model. The model is extensively evaluated using the latest dataset and standard performance evaluation metrics, demonstrating its capacity to protect IIoT networks against sophisticated cyber-attacks with a testing accuracy of 99.75%, a loss of 0.0063, precision and recall score of 99.75% and 99.74% respectively. Our proposed model demonstrates superior accuracy, particularly within the N_BaIoT dataset. It achieves an outstanding accuracy of 99.75% across ten classes, surpassing state-of-the-art techniques by a substantial margin ranging from 3.2% to 16.07%. Moreover, the proposed model outperforms state-of-the-art anomaly detection systems in IIoT based on a real-time IoT device dataset in terms of detecting and classifying botnet attacks accurately.
Keywords: Cyber security; Deep learning; Dependability; Industrial Internet of Things(IIoT); Intrusion detection system(IDS); Privacy

Xin Li, Yang Xin, Hongliang Zhu, Yixian Yang, Yuling Chen,
Cross-domain vulnerability detection using graph embedding and domain adaptation,
Computers & Security,
Volume 125,
2023,
103017,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.103017.
(https://www.sciencedirect.com/science/article/pii/S0167404822004096)
Abstract: Vulnerability detection is an effective means to maintain cyberspace security. Machine learning methods have risen much attention in software security due to their advantage of accuracy and automation. However, current researches mainly focus on in-domain vulnerability detection where the training data and test data belong to the same domain. Due to application scenarios, coding habits, and other factors, vulnerabilities in different software projects may obey different probability distributions. This discrepancy compromises the performance of machine learning methods when they are applied to a brand-new project. To address this cold start problem, we propose a cross-domain vulnerability detection framework using graph embedding and deep domain adaption (VulGDA). It works in a variety of cross-domain fashions, including the Zero-Shot fashion that no labeled data in the target domain is available for training. VulGDA is decomposed to graph embedding and domain adaptation. At the graph embedding stage, we transform the samples in source code into graph representations where elements are directly concatenated according to their syntactic and semantic relationships. Then, we aggregate information from neighbors and edges defined in the graph into real-valued vectors. By graph embedding, VulGDA extracts comprehensive vulnerability features and compromises the challenge of long-term dependency. Aiming at the discrepancy between training data and test data, domain adaption is used to train a feature generator. This feature generator maps the graph embedding to a “deep” feature that is discriminative for vulnerability detection, and invariant to the shift between domains. We perform a systematic experiment to validate the effectiveness of VulGDA. The results show that combining graph embedding and deep domain adaptation promotes VulGDA's performance in cross-domain vulnerability detection. Compared with the state-of-the-art methods, our method has better performance under the cold start condition.
Keywords: Cross-domain; Vulnerability detection; Graph embedding; Domain adaption; Software security

Bolun Wu, Futai Zou, Ping Yi, Yue Wu, Liang Zhang,
SlicedLocator: Code vulnerability locator based on sliced dependence graph,
Computers & Security,
Volume 134,
2023,
103469,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103469.
(https://www.sciencedirect.com/science/article/pii/S0167404823003796)
Abstract: Machine learning-based fine-grained vulnerability detection is an important technique for locating vulnerable statements, which assists engineers in efficiently analyzing and fixing the vulnerabilities. However, due to insufficient code representations, code embeddings, and neural network design, current methods suffer low vulnerability localization performance. In this paper, we propose to address these shortcomings by presenting SlicedLocator, a novel fine-grained code vulnerability detection model that is trained in a dual-grained manner and can predict both program-level and statement-level vulnerabilities. We design the sliced dependence graph, a new code representation that not only preserves rich interprocedural relations but also eliminates vulnerability-irrelevant statements. We create attention-based code embedding networks that are trained with the entire model to extract vulnerability-aware code features. In addition, we present a new LSTM-GNN model as a fusion of semantic modeling and structural modeling. Experiment results on a large-scale C/C++ vulnerability dataset reveal that SlicedLocator outperforms state-of-the-art machine learning-based vulnerability detectors, especially in terms of localization metrics.
Keywords: Vulnerability detection; Localization; Program analysis; Program representation; Deep learning

Huan Mei, Guanjun Lin, Da Fang, Jun Zhang,
Detecting vulnerabilities in IoT software: New hybrid model and comprehensive data analysis,
Journal of Information Security and Applications,
Volume 74,
2023,
103467,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2023.103467.
(https://www.sciencedirect.com/science/article/pii/S2214212623000510)
Abstract: Software vulnerabilities have always been an essential issue in cyberspace, for which many vulnerability detection techniques have been investigated. Among them, deep learning-based detection techniques have demonstrated promising detection results. However, due to the various programming patterns of developers, vulnerabilities are usually associated with the code context, such as Internet of Things (IoT) programs. Therefore, we propose a contextual embedding model to integrate three hybrid models, CLSTM, CBiLSTM (sequential structure), and CNN-BiLSTM (parallel structure), based on the code characteristics of IoT applications. To further improve the precision and robustness, we apply information augment by adding synthetic data to the real-world vulnerability data to address the severe data imbalance and facilitate neural models learning vulnerability patterns. The new method inherits the architecture of CodeBERT with multiheaded attention mechanisms and learns a richer set of vulnerable code patterns with long-range context dependencies when processing code sequence data. To assess the effectiveness of hybrid contextual embedding, we contrast the neural network models developed using the representations obtained from the three embedding methods, including CodeBERT, Word2Vec, and FastText. The experiments involve IoT applications and well-known open-source APIs. The results show that the hybrid model built based on the neural features outperforms the non-hybrid model in vulnerability detection.
Keywords: Vulnerability detection; IoT; CodeBERT; Contextual embedding; Deep learning; Hybrid model

Chunyong Zhang, Yang Xin,
VulGAI: vulnerability detection based on graphs and images,
Computers & Security,
Volume 135,
2023,
103501,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103501.
(https://www.sciencedirect.com/science/article/pii/S016740482300411X)
Abstract: Deep learning models have been widely used in the field of vulnerability detection. Deep learning-based vulnerability detection methods can automatically learn code patterns. Some methods consider processing codes as text sequences to achieve scalable vulnerability detection. They leverage natural language processing models to extract code features. These methods do not consider the code's semantic structure and treat code slices as text. Vulnerability detection methods based on graph structures and graph neural networks are more accurate than text-based methods. However, these methods lack scalability in practice. Both graph generation and graph neural network training are all time-consuming. We propose a vulnerability detection method based on graphs and images (VulGAI). VulGAI choose the more reasonable node centrality to generate the image. It can preserve program details and distinguish node importance from different perspectives. In addition, we design a more efficient CNN model, which reduces computational overhead and improves detection performance (Time and Accuracy). We implement VulGAI and evaluate six methods (VulDePecker, SySeVR, Devign, VulCNN, mVulPreter, and VulGAI) on 40,657 functions. Experimental results show that VulGAI achieves higher Accuracy, TPR, and F1-Score than the others. In addition, we compare VulGAI and VulCNN on 30270 real-world functions. VulGAI outperforms VulCNN by 1.48 times in the number of TP. VulGAI is about 3.9 times faster than VulCNN in detection time.
Keywords: Vulnerability detection; Program dependency graph; Node centrality; RGB image; CNN

Hazim Hanif, Mohd Hairul Nizam Md Nasir, Mohd Faizal Ab Razak, Ahmad Firdaus, Nor Badrul Anuar,
The rise of software vulnerability: Taxonomy of software vulnerabilities detection and machine learning approaches,
Journal of Network and Computer Applications,
Volume 179,
2021,
103009,
ISSN 1084-8045,
https://doi.org/10.1016/j.jnca.2021.103009.
(https://www.sciencedirect.com/science/article/pii/S1084804521000369)
Abstract: The detection of software vulnerability requires critical attention during the development phase to make it secure and less vulnerable. Vulnerable software always invites hackers to perform malicious activities and disrupt the operation of the software, which leads to millions in financial losses to software companies. In order to reduce the losses, there are many reliable and effective vulnerability detection systems introduced by security communities aiming to detect the software vulnerabilities as early as in the development or testing phases. To summarise the software vulnerability detection system, existing surveys discussed the conventional and data mining approaches. These approaches are widely used and mostly consist of traditional detection techniques. However, they lack discussion on the newly trending machine learning approaches, such as supervised learning and deep learning techniques. Furthermore, existing studies fail to discuss the growing research interest in the software vulnerability detection community throughout the years. With more discussion on this, we can predict and focus on what are the research problems in software vulnerability detection that need to be urgently addressed. Aiming to reduce these gaps, this paper presents the research interests’ taxonomy in software vulnerability detection, such as methods, detection, features, code and dataset. The research interest categories exhibit current trends in software vulnerability detection. The analysis shows that there is considerable interest in addressing methods and detection problems, while only a few are interested in code and dataset problems. This indicates that there is still much work to be done in terms of code and dataset problems in the future. Furthermore, this paper extends the machine learning approaches taxonomy, which is used to detect the software vulnerabilities, like supervised learning, semi-supervised learning, ensemble learning and deep learning. Based on the analysis, supervised learning and deep learning approaches are trending in the software vulnerability detection community as these techniques are able to detect vulnerabilities such as buffer overflow, SQL injection and cross-site scripting effectively with a significant detection performance, up to 95% of F1 score. Finally, this paper concludes with several discussions on potential future work in software vulnerability detection in terms of datasets, multi-vulnerabilities detection, transfer learning and real-world applications.
Keywords: Software vulnerability detection; Software security; Computer security; Machine learning; Deep learning

Nami Ashizawa, Naoto Yanai, Jason Paul Cruz, Shingo Okamura,
Eth2Vec: Learning contract-wide code representations for vulnerability detection on Ethereum smart contracts,
Blockchain: Research and Applications,
Volume 3, Issue 4,
2022,
100101,
ISSN 2096-7209,
https://doi.org/10.1016/j.bcra.2022.100101.
(https://www.sciencedirect.com/science/article/pii/S2096720922000422)
Abstract: Ethereum smart contracts are computer programs that are deployed and executed on the Ethereum blockchain to enforce agreements among untrusting parties. Being the most prominent platform that supports smart contracts, Ethereum has been targeted by many attacks and plagued by security incidents. Consequently, many smart contract vulnerabilities have been discovered in the past decade. To detect and prevent such vulnerabilities, different security analysis tools, including static and dynamic analysis tools, have been created, but their performance decreases drastically when codes to be analyzed are constantly being rewritten. In this paper, we propose Eth2Vec, a machine-learning-based static analysis tool that detects smart contract vulnerabilities. Eth2Vec maintains its robustness against code rewrites; i.e., it can detect vulnerabilities even in rewritten codes. Other machine-learning-based static analysis tools require features, which analysts create manually, as inputs. In contrast, Eth2Vec uses a neural network for language processing to automatically learn the features of vulnerable contracts. In doing so, Eth2Vec can detect vulnerabilities in smart contracts by comparing the similarities between the codes of a target contract and those of the learned contracts. We performed experiments with existing open databases, such as Etherscan, and Eth2Vec was able to outperform a recent model based on support vector machine in terms of well-known metrics, i.e., precision, recall, and F1-score.
Keywords: Ethereum; Smart contracts; Blockchain; Neural networks; Static analysis; Code similarity; Vulnerability detection

Laura Wartschinski, Yannic Noller, Thomas Vogel, Timo Kehrer, Lars Grunske,
VUDENC: Vulnerability Detection with Deep Learning on a Natural Codebase for Python,
Information and Software Technology,
Volume 144,
2022,
106809,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2021.106809.
(https://www.sciencedirect.com/science/article/pii/S0950584921002421)
Abstract: Context:
Identifying potential vulnerable code is important to improve the security of our software systems. However, the manual detection of software vulnerabilities requires expert knowledge and is time-consuming, and must be supported by automated techniques.
Objective:
Such automated vulnerability detection techniques should achieve a high accuracy, point developers directly to the vulnerable code fragments, scale to real-world software, generalize across the boundaries of a specific software project, and require no or only moderate setup or configuration effort.
Method:
In this article, we present Vudenc (Vulnerability Detection with Deep Learning on a Natural Codebase), a deep learning-based vulnerability detection tool that automatically learns features of vulnerable code from a large and real-world Python codebase. Vudenc applies a word2vec model to identify semantically similar code tokens and to provide a vector representation. A network of long-short-term memory cells (LSTM) is then used to classify vulnerable code token sequences at a fine-grained level, highlight the specific areas in the source code that are likely to contain vulnerabilities, and provide confidence levels for its predictions.
Results:
To evaluate Vudenc, we used 1,009 vulnerability-fixing commits from different GitHub repositories that contain seven different types of vulnerabilities (SQL injection, XSS, Command injection, XSRF, Remote code execution, Path disclosure, Open redirect) for training. In the experimental evaluation, Vudenc achieves a recall of 78%–87%, a precision of 82%–96%, and an F1 score of 80%–90%. Vudenc’s code, the datasets for the vulnerabilities, and the Python corpus for the word2vec model are available for reproduction.
Conclusions:
Our experimental results suggest that Vudenc is capable of outperforming most of its competitors in terms of vulnerably detection capabilities on real-world software. Comparable accuracy was only achieved on synthetic benchmarks, within single projects, or on a much coarser level of granularity such as entire source code files.
Keywords: Static analysis; Vulnerability detection; Deep learning; Long-short-term memory network; Natural codebase; Software repository mining

Xue Yuan, Guanjun Lin, Huan Mei, Yonghang Tai, Jun Zhang,
Software vulnerable functions discovery based on code composite feature,
Journal of Information Security and Applications,
Volume 81,
2024,
103718,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2024.103718.
(https://www.sciencedirect.com/science/article/pii/S2214212624000218)
Abstract: Vulnerability identification is crucial to protecting software systems from attacks. Although numerous learning-based solutions have been suggested to assist in vulnerability identification, these approaches often face challenges due to the scarcity of real-world vulnerability data. To extract as much vulnerability information as possible from limited data, we consider obtaining the characteristics of vulnerabilities from different forms of code by leveraging two distinct deep neural models. First, source code functions are considered to be textual sequences, and Gated Recurrent Unit (GRU) is applied to extract serialized features. Then, Abstract Syntax Trees (ASTs) of these functions, which reflects the code structure, are fed to a Gated Graph Recurrent Network (GGRN) to obtain structural features indicative of software vulnerability. To better handle data imbalance issues in real-world scenarios, we employ Random Forest (RF) to construct a predictive model to learn the concatenation of serialized and structural features extracted by GRU and GGRN. To evaluate the proposed approach, we collected 12 open-source projects containing function-level samples and compared the proposed method with a series of baselines, including popular learning-based methods and static analysis tools. The empirical results demonstrate that our proposed approach outperforms the baselines and can identify more vulnerabilities.
Keywords: Vulnerability detection; Source code; Deep learning; Deep representation learning

Hariharan M., Sathish Kumar C., Anshul Tanwar, Krishna Sundaresan, Prasanna Ganesan, Sriram Ravi, R. Karthik,
Proximal Instance Aggregator networks for explainable security vulnerability detection,
Future Generation Computer Systems,
Volume 134,
2022,
Pages 303-318,
ISSN 0167-739X,
https://doi.org/10.1016/j.future.2022.04.008.
(https://www.sciencedirect.com/science/article/pii/S0167739X22001315)
Abstract: Security vulnerabilities in software are the root cause of cyberattacks. Considering that these defects have huge associated costs, they should be proactively detected and resolved before shipping the software. Data-driven approaches like Artificial Intelligence (AI) are vastly explored for automatic vulnerability detection, given their potential to leverage large-scale vulnerability data feeds and learn from these scenarios. This work introduces a novel Proximal Instance Aggregator (PIA) neural network for accurately capturing insecure C code patterns from Abstract Syntax Tree (AST). It is built upon the concept of Multiple Instance Learning (MIL), which treats the AST representation of the code as a ‘bag’ of tree path ‘instances’. The security vulnerability can manifest in one or multiple such AST path instances. The PIA model dynamically learns a set of abstract concepts to describe the patterns associated with the AST paths. Specifically, the vulnerable nature of an AST path is characterized by its proximity to these concepts. The model also employs the attention mechanism to generate deep representations. By drawing cross-correlation of features between the path instances, the self-attention robustly weighs the relevance of each AST path towards vulnerability classification. The MIL utilizes these deep feature sets to construct the concept space. Thus, even without explicit supervision for localizing the line of defect, the AI automatically learns AST instance classification in a weakly supervised manner. Since AST-level prediction is formed as an aggregation of instance classifications, the AI is inherently explainable. The model outperforms state-of-the-art methods by a fair margin. It achieves 95.63% detection accuracy and 95.65% F1-score on the benchmarked NIST SARD, NVD datasets for a range of vulnerabilities.
Keywords: Multiple-Instance learning; Interpretability; Deep learning; Vulnerability detection; Abstract Syntax Tree; Weakly supervised learning

Weiping Ding, Mohamed Abdel-Basset, Reda Mohamed,
DeepAK-IoT: An effective deep learning model for cyberattack detection in IoT networks,
Information Sciences,
Volume 634,
2023,
Pages 157-171,
ISSN 0020-0255,
https://doi.org/10.1016/j.ins.2023.03.052.
(https://www.sciencedirect.com/science/article/pii/S0020025523003511)
Abstract: Our daily lives have been profoundly changed over the past few years owing to the growing presence of the Internet of Things (IoT). Importantly, IoT makes our lives more convenient, simpler, and more efficient; however, gadgets are vulnerable to a wide variety of cyberattacks due to the lack of robust security mechanisms and hardware security support. This paper presents an alternative deep learning model known as DeepAK-IoT to detect cyberattacks against IoT devices. DeepAK-IoT uses three blocks as its foundation: the residual-based-spatial representation (RSR) block, the temporal representation block (TRB), and the detection block (DB). The RSR block uses five residual blocks to extract a feature representation from the output of the preceding layer. The four convolutional layers are connected in parallel with a skip connection within each block to avoid vanishing or exploding gradients. Then, the second block uses the extracted spatial representation to learn a temporal representation to detect cyber threats. The final block decides how to classify the input record. We evaluated the accuracy and generalization ability of DeepAK-IoT using three well-known public datasets: TON-IoT, Edge-IIoTset, and UNSW-NB15. The proposed model was compared to three state-of-the-art deep learning models to demonstrate its effectiveness in detecting cyber threats in IoT systems. According to the experimental results, DeepAK-IoT was found to be a powerful alternative model for managing cyber threats in IoT networks, as it provided 90.57% accuracy for TON IoT, 94.96% for Edge-IIoTset, and 98.41% for UNSW NB15.
Keywords: Cyber threats; Internet of things; Industrial internet of things; Deep learning

Sicong Cao, Xiaobing Sun, Lili Bo, Ying Wei, Bin Li,
BGNN4VD: Constructing Bidirectional Graph Neural-Network for Vulnerability Detection,
Information and Software Technology,
Volume 136,
2021,
106576,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2021.106576.
(https://www.sciencedirect.com/science/article/pii/S0950584921000586)
Abstract: Context:
Previous studies have shown that existing deep learning-based approaches can significantly improve the performance of vulnerability detection. They represent code in various forms and mine vulnerability features with deep learning models. However, the differences of code representation forms and deep learning models make various approaches still have some limitations. In practice, their false-positive rate (FPR) and false-negative rate (FNR) are still high.
Objective:
To address the limitations of existing deep learning-based vulnerability detection approaches, we propose BGNN4VD (Bidirectional Graph Neural Network for Vulnerability Detection), a vulnerability detection approach by constructing a Bidirectional Graph Neural-Network (BGNN).
Method:
In Phase 1, we extract the syntax and semantic information of source code through abstract syntax tree (AST), control flow graph (CFG), and data flow graph (DFG). Then in Phase 2, we use vectorized source code as input to Bidirectional Graph Neural-Network (BGNN). In Phase 3, we learn the different features between vulnerable code and non-vulnerable code by introducing backward edges on the basis of traditional Graph Neural-Network (GNN). Finally in Phase 4, a Convolutional Neural-Network (CNN) is used to further extract features and detect vulnerabilities through a classifier.
Results:
We evaluate BGNN4VD on four popular C/C++ projects from NVD and GitHub, and compare it with four state-of-the-art (Flawfinder, RATS, SySeVR, and VUDDY) vulnerab ility detection approaches. Experiment results show that, when compared these baselines, BGNN4VD achieves 4.9%, 11.0%, and 8.4% improvement in F1-measure, accuracy and precision, respectively.
Conclusion:
The proposed BGNN4VD achieves a higher precision and accuracy than the state-of-the-art methods. In addition, when applied on the latest vulnerabilities reported by CVE, BGNN4VD can still achieve a precision at 45.1%, which demonstrates the feasibility of BGNN4VD in practical application.
Keywords: Vulnerability detection; Bidirectional Graph Neural-Network; Code representation

Mehrnoosh Nobakht, Reza Javidan, Alireza Pourebrahimi,
SIM-FED: Secure IoT malware detection model with federated learning,
Computers and Electrical Engineering,
Volume 116,
2024,
109139,
ISSN 0045-7906,
https://doi.org/10.1016/j.compeleceng.2024.109139.
(https://www.sciencedirect.com/science/article/pii/S0045790624000673)
Abstract: Many IoT devices are presently in use without sufficient security measures. The vulnerability of these devices to malware highlights the necessity for effective methods to identify malicious activity while protecting data privacy. Federated Learning is a collaborative learning technique that can create a fair model while keeping the local data private. To this end, this paper presents the SIM-FED, a novel model for detecting malware in IoT devices. This model utilizes both deep learning and federated learning algorithms. The SIM-FED offers a privacy-preserving solution for IoT malware detection, without sharing data, enhancing security in distributed environments. The model utilizes a lightweight one-dimensional CNN with optimized hyperparameters, reducing preprocessing, and computational overhead. Various federated aggregation strategies are evaluated, and the FedAvg strategy is selected to integrate the results of local models in the proposed model. Moreover, the model's resilience against white-box and black box cyber-attacks is assessed, revealing minimal performance degradation and highlighting its robustness, which is often overlooked in previous studies. The performance of the SIM-FED is assessed by conducting a series of experiments using the IoT-23 dataset. The results show that the SIM-FED outperforms other deep learning and federated learning models in terms of all evaluation metrics, achieving a remarkable 99.52 % accuracy.
Keywords: Malware detection; Federated learning; Deep learning; Convolutional neural network; IoT

Clemens-Alexander Brust, Tim Sonnekalb, Bernd Gruner,
ROMEO: A binary vulnerability detection dataset for exploring Juliet through the lens of assembly language,
Computers & Security,
Volume 128,
2023,
103165,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103165.
(https://www.sciencedirect.com/science/article/pii/S0167404823000755)
Abstract: Context
Automatic vulnerability detection on C/C++ source code has benefitted from the introduction of machine learning to the field, with many recent publications targeting this combination. In contrast, assembly language or machine code artifacts receive less attention, although there are compelling reasons to study them. They are more representative of what is executed, more easily incorporated in dynamic analysis, and in the case of closed-source code, there is no alternative.
Objective
We evaluate the representative capability of assembly language compared to C/C++ source code for vulnerability detection. Furthermore, we investigate the role of call graph context in detecting function-spanning vulnerabilities. Finally, we verify whether compiling a benchmark dataset compromises an experiment’s soundness by inadvertently leaking label information.
Method
We propose ROMEO, a publicly available, reproducible and reusable binary vulnerability detection benchmark dataset derived from the synthetic Juliet test suite. Alongside, we introduce a simple text-based assembly language representation that includes context for function-spanning vulnerability detection and semantics to detect high-level vulnerabilities. It is constructed by disassembling the .text segment of the respective binaries.
Results
We evaluate an x86 assembly language representation of the compiled dataset, combined with an off-the-shelf classifier. It compares favorably to state-of-the-art methods, including those operating on the full C/C++ code. Including context information using the call graph improves detection of function-spanning vulnerabilities. There is no label information leaked during the compilation process.
Conclusion
Performing vulnerability detection on a compiled program instead of the source code is a worthwhile tradeoff. While certain information is lost, e.g., comments and certain identifiers, other valuable information is gained, e.g., about compiler optimizations.

Qianchong Zhao, Cheng Huang, Liuhu Dai,
VULDEFF: Vulnerability detection method based on function fingerprints and code differences,
Knowledge-Based Systems,
Volume 260,
2023,
110139,
ISSN 0950-7051,
https://doi.org/10.1016/j.knosys.2022.110139.
(https://www.sciencedirect.com/science/article/pii/S0950705122012357)
Abstract: The significant increase in Open Source Software has led to a sharp increase in code cloning vulnerabilities. Code similarity detection methods are usually used to detect these vulnerabilities. However, cloned code often modifies the original code to varying degrees, and the difference between vulnerable code and patch code can be very small. Traditional code similarity detection methods cannot effectively detect common mutation patterns in code cloning and distinguish vulnerable code from patch code. The paper proposes a vulnerability detection method named VULDEFF based on function fingerprints and code differences. This paper designs a lightweight function fingerprint method based on the Context Triggered Piecewise Hashing algorithm, which can characterize the basic syntax features of function source code. In particular, the fingerprint of the vulnerable function contains the syntax features, vulnerability features, and patch features of the vulnerable function. VULDEFF detects whether target function has vulnerabilities by searching target function fingerprint in the vulnerable function fingerprint library. Compared with five advanced software vulnerability detection tools, VULDEFF significantly reduces the false positive and false negative rates while ensuring the scalability of vulnerability detection. VULDEFF discovered 111 new vulnerabilities in 10 open source projects.
Keywords: Open source software; Vulnerability detection; Code similarity detection; Function fingerprint

Zixian Zhen, Xiangfu Zhao, Jinkai Zhang, Yichen Wang, Haiyue Chen,
DA-GNN: A smart contract vulnerability detection method based on Dual Attention Graph Neural Network,
Computer Networks,
Volume 242,
2024,
110238,
ISSN 1389-1286,
https://doi.org/10.1016/j.comnet.2024.110238.
(https://www.sciencedirect.com/science/article/pii/S1389128624000707)
Abstract: A smart contract is an automated computer program based on blockchain technology. In recent years, the security incidents of smart contracts have caused serious economic losses. However, existing smart contract vulnerability detection methods rely on fixed expert rules, resulting in reduced detection accuracy and scalability. Therefore, addressing the issues of low accuracy in traditional smart contract vulnerability detection methods and the insufficient feature extraction in neural network-based approaches for smart contracts, this paper introduces an intelligent contract vulnerability identification method, Dual Attention Graph Neural Network (DA-GNN). Firstly, DA-GNN transforms the operation code sequence of nodes in the smart contract Control Flow Graph (CFG) into a feature matrix of semantic features and relationships between nodes based on the five types of instructions we propose. Secondly, our proposed dual attention mechanism introduces node semantic features and relationship features between nodes into the GAT to achieve node embedding updates. The updated graph node information is fused through self-attention mechanism to obtain the graph features. Then, the classification and prediction of vulnerabilities are achieved through the classification module. Finally, we evaluated our method on 17,670 real smart contracts. The experimental results show that the precision in detecting integer overflow vulnerabilities, self-destruct vulnerabilities, and transaction sequence dependency vulnerabilities reaches 72.17%, 67.03%, and 73.66%, respectively.
Keywords: Smart contract; Vulnerability detection; Graph neural networks; Attention mechanisms; Opcodes

Chunyong Zhang, Yang Xin,
Static vulnerability detection based on class separation,
Journal of Systems and Software,
Volume 206,
2023,
111832,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111832.
(https://www.sciencedirect.com/science/article/pii/S0164121223002273)
Abstract: Software vulnerability detection is a key step to prevent the system from being attacked. However, tens of thousands of codes have brought great challenges to engineers, so we urgently need an automatic and intelligent vulnerability detection method. The existing vulnerability detection model based on deep learning has the problem that it is difficult to separate the features of vulnerable and neutral code. Based on the code data drive, this paper proposes a static vulnerability detection method SDV(Statically Detecting Vulnerability) for C∖C++ programs. SDV is a function-level vulnerability code detection method. This paper uses a code property graph to represent the code and decouples the feature extractor and the classifier. In the graph feature extraction stage, we use Jump Graph Attention Network layers and convolutional pooling layers. Their combination can not only prevent the over-smoothing problem but also separate the sample classes deeply. Finally, on the chrdeb dataset, SDV outperforms state-of-the-art function-level vulnerability detection methods by 52.3%, 15.9%, and 39.6% in Precision, Recall, and F1-Score, respectively. On the real project sard, the number of vulnerabilities detected by SDV is 10.7 times more than Reveal.
Keywords: Vulnerability detection; Code property graph; Jump structure; Graph attention network; Class separation

Koundinya Kuppa, Anushka Dayal, Shashank Gupta, Amit Dua, Pooja Chaudhary, Shailendra Rathore,
ConvXSS: A deep learning-based smart ICT framework against code injection attacks for HTML5 web applications in sustainable smart city infrastructure,
Sustainable Cities and Society,
Volume 80,
2022,
103765,
ISSN 2210-6707,
https://doi.org/10.1016/j.scs.2022.103765.
(https://www.sciencedirect.com/science/article/pii/S2210670722000968)
Abstract: In this paper we propose ConvXSS, a novel deep learning approach for the detection of XSS and code injection attacks, followed by context-based sanitization of the malicious code if the model detects any malicious code in the application. Firstly, we briefly discuss XSS and code injection attacks that might pose threat to sustainable smart cities. Along with this, we discuss various approaches proposed previously for the detection and alleviation of these attacks followed by their respective limitations. Then we propose our deep learning model adopting whose novelty is based on the approach followed for Data Pre-Processing. Then we finally propose Context-based Sanitization to replace the malicious part of the code with sanitized code. Numerical experiments conducted on various datasets have shown various results out of which the best model has an accuracy of 99.42%, a precision of 99.81% and a recall of 99.35%. When compared with other state of the art techniques in this domain, our approach shows at par or in the best case, better results in terms of detection speed and accuracy of CSS attacks.
Keywords: Sustainable smart cities; Security; Privacy; ICT; CPS; Web security; Deep learning; Data preprocessing; Training and testing; Neural Networks; Sanitization; CNN; XSS attack; Malicious code; Code injection attack

Weina Niu, Xiaosong Zhang, Xiaojiang Du, Lingyuan Zhao, Rong Cao, Mohsen Guizani,
A deep learning based static taint analysis approach for IoT software vulnerability location,
Measurement,
Volume 152,
2020,
107139,
ISSN 0263-2241,
https://doi.org/10.1016/j.measurement.2019.107139.
(https://www.sciencedirect.com/science/article/pii/S026322411931005X)
Abstract: Computer system vulnerabilities, computer viruses, and cyber attacks are rooted in software vulnerabilities. Reducing software defects, improving software reliability and security are urgent problems in the development of software. The core content is the discovery and location of software vulnerability. However, traditional human experts-based approaches are labor-consuming and time-consuming. Thus, some automatic detection approaches are proposed to solve the problem. But, they have a high false negative rate. In this paper, a deep learning based static taint analysis approach is proposed to automatically locate Internet of Things (IoT) software vulnerability, which can relieve tedious manual analysis and improve detection accuracy. Deep learning is used to detect vulnerability since it considers the program context. Firstly, the taint from the difference file between the source program and its patched program selection rules are designed. Secondly, the taint propagation paths are got using static taint analysis. Finally, the detection model based on two-stage Bidirectional Long Short Term Memory (BLSTM) is applied to discover and locate software vulnerabilities. The Code Gadget Database is used to evaluate the proposed approach, which includes two types of vulnerabilities in C/C++ programs, buffer error vulnerability (CWE-119) and resource management error vulnerability (CWE-399). Experimental results show that our proposed approach can achieve an accuracy of 0.9732 for CWE-119 and 0.9721 for CWE-399, which is higher than that of the other three models (the accuracy of RNN, LSTM, and BLSTM is under than 0.97) and achieve a lower false negative rate and false positive rate than the other approaches.
Keywords: IoT software vulnerability location; Deep learning; Software patching; Static taint analysis

Xiaobing Sun, Liangqiong Tu, Jiale Zhang, Jie Cai, Bin Li, Yu Wang,
ASSBert: Active and semi-supervised bert for smart contract vulnerability detection,
Journal of Information Security and Applications,
Volume 73,
2023,
103423,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2023.103423.
(https://www.sciencedirect.com/science/article/pii/S221421262300008X)
Abstract: With the popularity of blockchain, the amount of smart contracts has increased very fast, and the safety of smart contracts has come to more extensive notice. Recently, machine learning technology has been widely applied in vulnerability detection for smart contracts. However, it implements effective smart contract vulnerability detection still faces a major challenge, that is, there is a problem of insufficient labeled data in the current field. Active learning can label data more efficiently. Nevertheless, classical active learning only uses limited labeled data for model training, contrary to the deep learning of a large amount of data required for model training. Because of the above, we provide a new framework, called ASSBert, that leverages active and semi-supervised bidirectional encoder representation from transformers network, which is dedicated to completing the task of smart contract vulnerability classification with a little amount of labeled code data and a large number of unlabeled code data. In our framework, active learning is responsible for selecting highly uncertain code data from unlabeled sol files and putting them into the training set after manual labeling. Besides, semi-supervised learning is charged to continuously pick a certain number of high-confidence unlabeled code data from unlabeled sol files, and put them into the training dataset behind pseudo-labeling. Intuitively, by combining active learning and semi-supervised learning, we are able to get more valuable data to increase the performance of our detection model. In our experiments, we collect our benchmark dataset included 6 vulnerabilities in about 20829 smart contracts. The result of the experiment demonstrates that our framework is superior to the baseline methods with a little amount of labeled code data and a large number of unlabeled code data.
Keywords: Smart contract; Vulnerability detection; Active learning; Semi-supervised learning

Xuan Zhang, Wei Gao,
Predicting viral rumors and vulnerable users with graph-based neural multi-task learning for infodemic surveillance,
Information Processing & Management,
Volume 61, Issue 1,
2024,
103520,
ISSN 0306-4573,
https://doi.org/10.1016/j.ipm.2023.103520.
(https://www.sciencedirect.com/science/article/pii/S0306457323002571)
Abstract: In the age of the infodemic, it is crucial to have tools for effectively monitoring the spread of rampant rumors that can quickly go viral, as well as identifying vulnerable users who may be more susceptible to spreading such misinformation. This proactive approach allows for timely preventive measures to be taken, mitigating the negative impact of false information on society. We propose a novel approach to predict viral rumors and vulnerable users using a unified graph neural network model. We pre-train network-based user embeddings and leverage a cross-attention mechanism between users and posts, together with a community-enhanced vulnerability propagation (CVP) method to improve user and propagation graph representations. Furthermore, we employ two multi-task training strategies to mitigate negative transfer effects among tasks in different settings, enhancing the overall performance of our approach. We also construct two datasets with ground-truth annotations on information virality and user vulnerability in rumor and non-rumor events, which are automatically derived from existing rumor detection datasets. Extensive evaluation results of our joint learning model confirm its superiority over strong baselines in all three tasks: rumor detection, virality prediction, and user vulnerability scoring. For instance, compared to the best baselines based on the Weibo dataset, our model makes 3.8% and 3.0% improvements on Accuracy and MacF1 for rumor detection, and reduces mean squared error (MSE) by 23.9% and 16.5% for virality prediction and user vulnerability scoring, respectively. Our findings suggest that our approach effectively captures the correlation between rumor virality and user vulnerability, leveraging this information to improve prediction performance and provide a valuable tool for infodemic surveillance.
Keywords: Rumor detection; Virality prediction; User vulnerability; Neural multi-task learning; Infodemic surveillance

Chunyong Zhang, Tianxiang Yu, Bin Liu, Yang Xin,
Vulnerability detection based on federated learning,
Information and Software Technology,
Volume 167,
2024,
107371,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107371.
(https://www.sciencedirect.com/science/article/pii/S0950584923002264)
Abstract: Context:
Detecting potential vulnerabilities is a key step in defending against network attacks. However, manual detection is time-consuming and requires expertise. Therefore, vulnerability detection must require automated techniques.
Objective:
Vulnerability detection methods based on deep learning need to rely on sufficient vulnerable code samples. However, the problem of code islands has not been extensively researched. For example, in the case of multi-party vulnerability data, how to securely combine multi-party data to improve vulnerability detection performance. From the perspectives of data augmentation and data security, we propose a vulnerability detection framework based on federated learning (VDBFL). VDBFL is a new model for vulnerability code detection that combines multi-party data.
Method:
Firstly, VDBFL utilizes the code property graph as a code representation. The code property graph contains various semantic dependencies of the code. Secondly, VDBFL utilizes graph neural networks and convolutional neural networks as the code feature extractor. VDBFL utilizes the jump-structured graph attention network to aggregate node information of important neighbors. Finally, VDBFL utilizes horizontal federated learning to train a local vulnerability detection model for the client.
Result:
In the real world, VDBFL improves F1-Score by 37.4% compared to the vulnerability detection method Reveal. Among the 5401 vulnerability samples, VDBFL detected 11.8 times more vulnerabilities than Reveal.
Conclusion:
Under different datasets, VDBFL has shown better performance than advanced vulnerability detection methods in multiple metrics. In addition, the federated learning stage of VDBFL can be expanded on top of the feature extraction stage of any vulnerable detection method.
Keywords: Vulnerability detection; Code property graph; Graph neural network; Horizontal federated learning; Data security

Hao Sun, Lei Cui, Lun Li, Zhenquan Ding, Siyuan Li, Zhiyu Hao, Hongsong Zhu,
VDTriplet: Vulnerability detection with graph semantics using triplet model,
Computers & Security,
Volume 139,
2024,
103732,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103732.
(https://www.sciencedirect.com/science/article/pii/S0167404824000336)
Abstract: This study presents VDTriplet, a novel learning framework for building vulnerability detection models. VDTriplet is the first attempt using deep learning to avoid the potential known vulnerability function misjudgment due to the small difference between vulnerability and its fixed vulnerability function. Unlike prior work that treats the program as sequential tokens or randomly initialized graphs for supervised binary classification detection tasks, our model not only fuses rich syntactic and semantic information to obtain the most accurate program representation, but also utilizes the TripletNN model to reduce misjudgment of potential known vulnerabilities. VDTriplet first extracts the subgraphs that causes the vulnerability through the typical programming errors to reduce redundant code. Then, it uses the pre-trained model and unsupervised model for the graph encoding of subgraphs, thereby minimizing the influence of randomly initialized graph nodes and avoiding the need for supervised labeling. Finally, TripletNN model minimizes the distance between potential vulnerabilities and vulnerabilities with the same vulnerability type, and maximizes the distance between potential vulnerabilities and fixed vulnerabilities to reduce false positives. The results show that the performance of VDTriplet is significantly better than the studied baselines. Compared with the best performing model in the literature, our model achieves a total of 4.89%, 4.23%, 4.56% and 5.34% improvement in Accuracy, Precision, Recall and F1-Score in the test results respectively. Moreover, it exhibits well generalization in detecting new eight applications, demonstrating that it is potentially valuable in practical usage. Overall, this is indeed an outstanding improvement.
Keywords: Vulnerability detection; Deep learning; Extracting subgraphs; Encoding subgraphs; TripletNN model

Guilong Lu, Xiaolin Ju, Xiang Chen, Wenlong Pei, Zhilong Cai,
GRACE: Empowering LLM-based software vulnerability detection with graph structure and in-context learning,
Journal of Systems and Software,
Volume 212,
2024,
112031,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2024.112031.
(https://www.sciencedirect.com/science/article/pii/S0164121224000748)
Abstract: Software vulnerabilities inflict considerable economic and societal harm. Therefore, timely and accurate detection of these flaws has become vital. Large language models (LLMs) have emerged as a promising tool for vulnerability detection in recent studies. However, their effectiveness suffers when limited to plain text source code, which may ignore the syntactic and semantic information of the code. To address this limitation, we propose a novel vulnerability detection approach GRACE that empowers LLM-based software vulnerability detection by incorporating graph structural information in the code and in-context learning. We also design an effective demonstration retrieval approach that identifies highly relevant code examples by considering semantic, lexical, and syntactic similarities for the target code to provide better demonstrations for in-context learning. To evaluate the effectiveness of GRACE, we conducted an empirical study on three vulnerability detection datasets (i.e., Devign, Reveal, and Big-Vul). The results demonstrate that GRACE outperforms six state-of-the-art vulnerability detection baselines by at least 28.65% in terms of the F1 score across these three datasets. Therefore, our study highlights the effectiveness of integrating graph structural information and in-context learning in LLMs for vulnerability detection. These findings motivate further investigation into tailoring such approaches for specific vulnerability types or adapting them to other security tasks.
Keywords: Vulnerability detection; Large language model; In-context learning; Source code representation; Graph structure

Mirdula S, Roopa M,
MUD enabled deep learning framework for anomaly detection in IoT integrated smart building,
e-Prime - Advances in Electrical Engineering, Electronics and Energy,
Volume 5,
2023,
100186,
ISSN 2772-6711,
https://doi.org/10.1016/j.prime.2023.100186.
(https://www.sciencedirect.com/science/article/pii/S2772671123000815)
Abstract: Nowadays, many Internet of Things (IoT) devices of different types are used in creating smart applications like smart cities, smart industries, smart environments, and the applications of industry-4.0. IoT devices are used for different purposes, such as security, remote monitoring, resource allocation, threats, ecosystems, and vulnerabilities. This paper proposed a deep learning algorithm-based solution to tighten the security level in the IoT-Smart environment network. The Intrusion Detection System (IDS) considered in this paper is Network IDS, which investigates the manufacturer usage description, digital twins, and deep learning-based user behavior information. IoT devices' communication and the users in smart buildings are automatically connected in the Intelligent Communication system. Since many devices and users are interconnected in smart buildings, the probability of cyber-attack is high. Thus, better security is needed in smart buildings and smart environments. It should focus on securing IoT devices, users, and their communication. Hence, this paper developed a deep learning-based anomaly detection framework to dynamically monitor the issues and problems with MUD profiles and detect the anomaly behavior. The Manufacturer Usage Description (MUD) profiles, dynamic user behavior, IoT devices' traffic data the pattern of abnormal/anomaly traffic at the device level is predicted while traffic occurs. The MUD-ML-based model is implemented in Python software, verifying the results.
Keywords: Smart building; Deep learning; Manufacturer usage description; Anomaly detection

Muhammad Hamza Zafar, Syed Muhammad Salman Bukhari, Mohamad Abou Houran, Syed Kumayl Raza Moosavi, Majad Mansoor, Nedaa Al-Tawalbeh, Filippo Sanfilippo,
Step towards secure and reliable smart grids in Industry 5.0: A federated learning assisted hybrid deep learning model for electricity theft detection using smart meters,
Energy Reports,
Volume 10,
2023,
Pages 3001-3019,
ISSN 2352-4847,
https://doi.org/10.1016/j.egyr.2023.09.100.
(https://www.sciencedirect.com/science/article/pii/S2352484723013458)
Abstract: The integration of Smart Grid technology and conceptual Industry 5.0 has paved the way for advanced energy management systems that enhance efficiency and revolutionized the parallel integration of power sources in a sustainable manner. However, this digitization has opened a new stream of the threat and opportunities of electricity theft posing a significant challenge to the security and reliability of Smart Grid networks. In this paper, we propose a secure and reliable theft detection technique using deep federated learning (FL) mechanism. The technique leverages the collaborative power of FL to train a Convolutional Gated Recurrent Unit (ConvGRU) model on distributed data sources without compromising data privacy. The training deep learning model backbone consists of a ConvGRU model that combines convolutional and gated recurrent units to capture spatial and temporal patterns in electricity consumption data. An improvised preprocessing mechanism and hyperparameter tuning is done to facilitate FL mechanism. The halving randomized search algorithm is used for hyperparameters tuning of the ConvGRU model. The impact of hyperparameters involved in the ConvGRU model such as number of layers, filters, kernel size, activation function, pooling, GRU layers, hidden state dimension, learning rate, and the dropout rate is elaborated. The proposed technique achieves promising results, with high accuracy, precision, recall, and F1 score, demonstrating its efficacy in detecting electricity theft in Smart Grid networks. Comparative analysis with existing techniques reveal the superior performance of the deep FL-based ConvGRU model. The findings highlight the potential of this approach in enhancing the security and efficiency of Smart Grid systems while preserving data privacy.
Keywords: Smart meters; Theft detection; Deep learning; Federated learning; Security and reliability; Smart grid; Industry 5.0

Yukun Dong, Yeer Tang, Xiaotong Cheng, Yufei Yang,
DeKeDVer: A deep learning-based multi-type software vulnerability classification framework using vulnerability description and source code,
Information and Software Technology,
Volume 163,
2023,
107290,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107290.
(https://www.sciencedirect.com/science/article/pii/S0950584923001441)
Abstract: Context:
Software vulnerabilities have confused software developers for a long time. Vulnerability classification is thus crucial, through which we can know the specific type of vulnerability and then conduct targeted repair. Stack of papers have looked into deep learning-based multi-type vulnerability classification, among which most are based on vulnerability descriptions and some are based on source code. While vulnerability descriptions can sometimes mislead vulnerability classification and source code-based approaches have been rarely explored in multi-type vulnerability classification.
Objective:
We design DeKeDVer (Vulnerability Descriptions and Key Domain based Vulnerability Classifier) with two objectives: (i) to extract more useful information from vulnerability descriptions; (ii) to better utilize the information source code can reflect.
Method:
In this work, we propose a multi-type vulnerability classifier which combine vulnerability descriptions and source code together. We process vulnerability descriptions and source code of each project separately. For the vulnerability description of a sample, we preprocess it using a specified way we design based on our observations on numerous descriptions and then select text features. After that, Text Recurrent Convolutional Neural Network (TextRCNN) is applied to learn text information. For source code, we leverage its Code Property Graph (CPG) and extract key domain from it which are then embedded. Acquired feature vectors are then fed into Relational Graph Attention Network (RGAT). Result vectors gained from TextRCNN and RGAT are combined together as the feature vector of the current sample. A Multi-Layer Perceptron (MLP) layer is further added to undertake classification.
Results:
We conduct our experiments on C/C++ projects from NVD. Experimental results show that our work achieves 84.49% in weighted F1-measure which proves our work to be more effective.
Conclusion:
Our work utilizes information reflected both from vulnerability descriptions and source code to facilitate vulnerability classification and achieves higher weighted F1-measure than existing vulnerability classification tools.
Keywords: Multi-type vulnerability classification; Vulnerability description; Source code; Text Recurrent Convolutional Neural Network; Relational graph attention network

Junfeng Tian, Wenjing Xing, Zhen Li,
BVDetector: A program slice-based binary code vulnerability intelligent detection system,
Information and Software Technology,
Volume 123,
2020,
106289,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2020.106289.
(https://www.sciencedirect.com/science/article/pii/S0950584920300392)
Abstract: Context
Software vulnerability detection is essential to ensure cybersecurity. Currently, most software is published in binary form, thus researchers can only detect vulnerabilities in these software by analysing binary programs. Although existing research approaches have made a substantial contribution to binary vulnerability detection, there are still many deficiencies, such as high false positive rate, detection with coarse granularity, and dependence on expert experience.
Objective
The goal of this study is to perform fine-grained intelligent detection on the vulnerabilities in binary programs. This leads us to propose a fine-grained representation of binary programs and introduce deep learning techniques to intelligently detect the vulnerabilities.
Method
We use program slices of library/API function calls to represent binary programs. Additionally, we design and construct a Binary Gated Recurrent Unit (BGRU) network model to intelligently learn vulnerability patterns and automatically detect vulnerabilities in binary programs.
Results
This approach yields the design and implementation of a program slice-based binary code vulnerability intelligent detection system called BVDetector. We show that BVDetector can effectively detect vulnerabilities related to library/API function calls in binary programs, which reduces the false positive rate and false negative rate of vulnerability detection.
Conclusion
This paper proposes a program slice-based binary code vulnerability intelligent detection system called BVDetector. The experimental results show that BVDetector can effectively reduce the false negative rate and false positive rate of binary vulnerability detection.
Keywords: Binary program; Vulnerability detection; Deep learning; Program slice; Library/API function call

Huakun Huang, Longtao Guo, Lingjun Zhao, Haoda Wang, Chenkai Xu, Shan Jiang,
Effective combining source code and opcode for accurate vulnerability detection of smart contracts in edge AI systems,
Applied Soft Computing,
Volume 158,
2024,
111556,
ISSN 1568-4946,
https://doi.org/10.1016/j.asoc.2024.111556.
(https://www.sciencedirect.com/science/article/pii/S1568494624003302)
Abstract: Automating transactions using smart contracts extends the functionality of blockchains and secures the decentralization of blockchains in edge AI systems. Whereas, since plenty of smart contracts are deployed to support various decentralized edge applications, the security vulnerabilities of smart contracts will lead to huge irreversible losses. To deal with this problem, many deep learning-based methods have been developed for vulnerability detection. However, most existing methods use only contract source codes for feature extraction, resulting in low accuracy. In contrast, we propose a method based on deep learning model to integrate both the features of contract source codes and opcodes for vulnerability detection. Particularly, the contextual features are extracted based on opcodes while the expert pattern features are extracted from the source codes. Using the real-world dataset of Ethereum smart contracts targeting reentrancy vulnerability, experiment results demonstrate that our method outperforms the state-of-the-art methods and achieves 96.89% accuracy and 95.41% F1-Score.
Keywords: Smart contract; Edge AI; Vulnerability detection; Deep learning

Chen Tsfaty, Michael Fire,
Malicious source code detection using a translation model,
Patterns,
Volume 4, Issue 7,
2023,
100773,
ISSN 2666-3899,
https://doi.org/10.1016/j.patter.2023.100773.
(https://www.sciencedirect.com/science/article/pii/S2666389923001241)
Abstract: Summary
Modern software development often relies on open-source code sharing. Open-source code reuse, however, allows hackers to access wide developer communities, thereby potentially affecting many products. An increasing number of such “supply chain attacks” have occurred in recent years, taking advantage of open-source software development practices. Here, we introduce the Malicious Source code Detection using a Translation model (MSDT) algorithm. MSDT is a novel deep-learning-based analysis method that detects real-world code injections into source code packages. We have tested MSDT by embedding examples from a dataset of over 600,000 different functions and then applying a clustering algorithm to the resulting embedding vectors to identify malicious functions by detecting outliers. We evaluated MSDT’s performance with extensive experiments and demonstrated that MSDT could detect malicious code injections with precision@k values of up to 0.909.
Keywords: malware analysis; deep learning; static analysis; software supply chain attack; open source; PyPi

Jinfu Chen, Weijia Wang, Bo Liu, Saihua Cai, Dave Towey, Shengran Wang,
Hybrid semantics-based vulnerability detection incorporating a Temporal Convolutional Network and Self-attention Mechanism,
Information and Software Technology,
Volume 171,
2024,
107453,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2024.107453.
(https://www.sciencedirect.com/science/article/pii/S0950584924000582)
Abstract: Context:
Desirable characteristics in vulnerability-detection (VD) systems (VDSs) include both good detection capability (high accuracy, low false positive rate, low false negative rate, etc.) and low time overheads. The widely used VDSs based on models such as Recurrent Neural Networks (RNNs) have some problems, such as low time efficiency, failing to learn the vulnerability features better, and insufficient amounts of vulnerability features. Therefore, it is very important to construct an automatic detection model with high detection accuracy.
Objective:
This paper reports on training based on the source code to analyze and learn from the code’s patterns and structures by deep-learning techniques to generate an efficient VD model that does not require manual feature design.
Method:
We propose a software VD model based on multi-feature fusion and deep neural networks called AIdetectorX-SP. It first uses a Temporal Convolutional Network (TCN) and adds a Self-attention Mechanism (SaM) to the TCN to build a model for extracting vulnerability logic features, then transforms the source code into an image input to a Convolutional Neural Network (CNN) to extract structural and semantic information. Finally, we use feature-fusion technology to design and implement an improved deep-learning-based VDS, called AIdetectorX Sequence with Picturization (AIdetectorX-SP).
Results:
We report on experiments conducted using publicly-available and widely-used datasets to evaluate the effectiveness of AIdetectorX-SP, with results indicating that AIdetectorX-SP is an effective VDS; that the combination of TCN and SaM can effectively extract vulnerability logic features; and that the pictorial code can extract code structure features, which can further improve the VD capability.
Conclusion:
In this paper, we propose a novel detection model for software vulnerability based on TCNs, SaM, and software picturization. The proposed model solves some shortcomings and limitations of existing VDSs, and obtains a high software-VD accuracy with a high degree of stability.
Keywords: Deep learning; Software vulnerability detection; Temporal Convolutional Network; Self-attention Mechanism; Source-code picturization; Feature fusion

Isam Kareem Thajeel, Khairulmizam Samsudin, Shaiful Jahari Hashim, Fazirulhisyam Hashim,
Machine and Deep Learning-based XSS Detection Approaches: A Systematic Literature Review,
Journal of King Saud University - Computer and Information Sciences,
Volume 35, Issue 7,
2023,
101628,
ISSN 1319-1578,
https://doi.org/10.1016/j.jksuci.2023.101628.
(https://www.sciencedirect.com/science/article/pii/S1319157823001829)
Abstract: Web applications are paramount tools for facilitating services providing in the modern world. Unfortunately, the tremendous growth in the web application usage has resulted in a rise in cyberattacks. Cross-site scripting (XSS) is one of the most frequent cyber security attack vectors that threaten the end user as well as the service provider with the same degree of severity. Recently, an obvious increase of the Machine learning and deep learning ML/DL techniques adoption in XSS attack detection. The goal of this review is to come with a special attention and highlight of Machine learning and deep learning approaches. Thus, in this paper, we present a review of recent advances applied in ML/DL for XSS attack detection and classification. The existing proposed ML/DL approaches for XSS attack detection are analyzed and taxonomized comprehensively in terms of domain areas, data preprocessing, feature extraction, feature selection, dimensionality reduction, Data imbalance, performance metrics, datasets, and data types. Our analysis reveals that the way of how the XSS data is preprocessed considerably impacts the performance and the attack detection models. Proposing a full preprocessing cycle reveals how various ML/DL approaches for XSS attacks detection take advantage of different input data preprocessing techniques. The most used ML/DL and preprocessing stages have also been identified. The limitations of existing ML/DL-based XSS attack detection mechanisms are highlighted to identify the potential gaps and future trends.
Keywords: Cross-site scripting (XSS) attacks; Web application security; Cybersecurity; Machine learning; Deep learning

Hanting Chu, Pengcheng Zhang, Hai Dong, Yan Xiao, Shunhui Ji, Wenrui Li,
A survey on smart contract vulnerabilities: Data sources, detection and repair,
Information and Software Technology,
Volume 159,
2023,
107221,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2023.107221.
(https://www.sciencedirect.com/science/article/pii/S0950584923000757)
Abstract: Smart contracts contain many built-in security features, such as non-immutability once being deployed and non-involvement of third parties for contract execution. These features reduce security risks and enhance users’ trust towards smart contracts. However, smart contract security issues still persist, resulting in huge financial losses. Contract publishers cannot fully cover contract vulnerabilities through contract version updating. These security issues affect further development of blockchain technologies. So far, there are many related studies focusing on smart contract security issues and tend to discuss from a particular perspective (e.g., development cycle, vulnerability attack methods, security detection tools, etc.). However, smart contract security is a complicated issue that needs to be explored from a multi-dimensional perspective. In this paper, we explore smart contract security from the perspectives of vulnerability data sources, vulnerability detection, and vulnerability defense. We first analyze the existing security issues and challenges of smart contracts, investigate the existing vulnerability classification frameworks and common security vulnerabilities, followed by reviewing the existing contract vulnerability injection, detection, and repair methods. We then analyze the performance of existing security methods. Next, we summarize the current status of smart contract security-related research. Finally, we summarize the state of the art and future trends of smart contract security-related research. This paper aims to provide systematic knowledge and references to this research field.
Keywords: Blockchains; Smart contracts; Vulnerability detection; Vulnerability repair; Information security

Wei Zheng, Jialiang Gao, Xiaoxue Wu, Fengyu Liu, Yuxing Xun, Guoliang Liu, Xiang Chen,
The impact factors on the performance of machine learning-based vulnerability detection: A comparative study,
Journal of Systems and Software,
Volume 168,
2020,
110659,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2020.110659.
(https://www.sciencedirect.com/science/article/pii/S0164121220301229)
Abstract: Machine learning-based Vulnerability detection is an active research topic in software security. Different traditional machine learning-based and deep learning-based vulnerability detection methods have been proposed. To our best knowledge, we are the first to identify four impact factors and conduct a comparative study to investigate the performance influence of these factors. In particular, the quality of datasets, classification models and vectorization methods can directly affect the detection performance, in contrast function/variable name replacement can affect the features of vulnerability detection and indirectly affect the performance. We collect three different vulnerability code datasets from two various sources (i.e., NVD and SARD). These datasets can correspond to different types of vulnerabilities. Moreover, we extract and analyze the features of vulnerability code datasets to explain some experimental results. Our findings based on the experimental results can be summarized as follows: (1) Deep learning models can achieve better performance than traditional machine learning models. Of all the models, BLSTM can achieve the best performance. (2) CountVectorizer can significantly improve the performance of traditional machine learning models. (3) Features generated by the random forest algorithm include system-related functions, syntax keywords, and user-defined names. Different vulnerability types and code sources will generate different features. (4) Datasets with user-defined variable and function name replacement will decrease the performance of vulnerability detection. (5) As the proportion of code from SARD increases, the performance of vulnerability detection will increase.
Keywords: Vulnerability detection; Machine learning; Comparative study; Deep learning; Feature extraction

Hengyan Zhang, Weizhe Zhang, Yuming Feng, Yang Liu,
SVScanner: Detecting smart contract vulnerabilities via deep semantic extraction,
Journal of Information Security and Applications,
Volume 75,
2023,
103484,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2023.103484.
(https://www.sciencedirect.com/science/article/pii/S2214212623000686)
Abstract: Blockchain is a significant advancement in technology recently, transforming the traditional centralized system into a decentralized one. Smart contracts, as one of the best applications of blockchain, show great potential in various fields, such as finance, supply chain, and the Internet of Things (IoT). As the world’s first blockchain platform to support turing complete smart contracts, Ethereum has become the most critical infrastructure for the digital world. However, with the vigorous development of smart contracts, malicious attacks against smart contracts have frequently occurred in recent years. The issue of smart contract security has attracted widespread attention due to the huge financial losses caused by smart contract vulnerabilities. Although researchers have made some progress in detecting smart contract vulnerabilities through symbolic execution and fuzzing-based methods, existing methods mainly rely on expert knowledge and hand-crafted features, leading to many detection errors. Even worse, existing methods take tens of seconds or even minutes to detect each smart contract on average, which is extremely time-consuming. In this work, we present SVScanner, the new method combining two features of heterogeneous patterns to detect smart contract vulnerabilities in the blockchain. Specifically, we first extract global semantic features from the sequence of contract code tokens. Then we further use the attention mechanism to capture deep structural semantics from the Abstract Syntax Tree (AST) of smart contracts. Finally, we combine these two features from different patterns and use a text convolutional neural network (TextCNN) to detect contract bugs. Experimental results show that SVScanner has the ability to detect vulnerabilities effectively in real-world smart contract datasets. SVScanner achieves a 7.33% improvement in accuracy compared with other traditional methods. Moreover, our method requires significantly less detection time.
Keywords: Blockchain; Smart contract; Vulnerability detection; Deep learning; Deep semantic extraction

Pengbin Feng, Dawei Wei, Qiaoyang Li, Qin Wang, Youbing Hu, Ning Xi, Jianfeng Ma,
GlareShell: Graph learning-based PHP webshell detection for web server of industrial internet,
Computer Networks,
Volume 245,
2024,
110406,
ISSN 1389-1286,
https://doi.org/10.1016/j.comnet.2024.110406.
(https://www.sciencedirect.com/science/article/pii/S138912862400238X)
Abstract: With the explosive growth of the Industrial Internet scale, cyberattacks targeting industrial control systems also increased. The management and operation of Industrial Internet are usually performed via web servers which retain a large attack surface. In the Industrial Internet, attackers usually exploit vulnerabilities to inject malicious codes for remotely executing commands, stealing confidential data, and invading web servers. Existing approaches capture statistical and contextual dependence information from Webshell using machine learning (ML) or deep learning (DL) algorithms. However, the semantic feature mining of program code within Webshell is not sufficient when entering new types of Webshell. In this paper, we propose a graph learning-based PHP Webshell detection framework, GlareShell, using the word embedding technique, a risk weight allocation mechanism, and the graph neural network (GNN). First, GlareShell leverages static analysis to extract interprocedural control flow graphs (ICFGs) from PHP script files and then prunes these ICFGs to remove noisy statements. Then, word embedding techniques are employed to generate semantic representations from PHP statements. Next, we design a risk weight allocation mechanism to derive the risk levels of statements and concatenate them with word embeddings as attributions. The identified risk levels could guide the passing of potential attack patterns inside GNN models. Finally, GlareShell builds a GNN classifier directly from the ICFG with corresponding node attributions to identify the malicious PHP scripts. Experiment results on collected datasets prove the promise of our graph learning framework in the Webshell detection domain.
Keywords: Webshell detection; Graph neural network; Word embedding; ICFG

Melanie Ehrenberg, Shahram Sarkani, Thomas A. Mazzuchi,
Python source code vulnerability detection with named entity recognition,
Computers & Security,
Volume 140,
2024,
103802,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103802.
(https://www.sciencedirect.com/science/article/pii/S0167404824001032)
Abstract: Vulnerabilities within source code have grown over the last 20 years to become a common threat to systems and networks. As the implementation of open-source software continues to develop, more unknown vulnerabilities will exist throughout system networks. This research proposes an enhanced vulnerability detection method specific to Python source code that utilizes pre-trained, BERT-based transformer models to apply tokenization, embedding, and named entity recognition (a natural language processing technique). The use of named entity recognition not only allows for the detection of potential vulnerabilities, but also for the classification of different vulnerability types. This research uses the publicly available CodeBERT, RoBERTa, and DistilBERT models to fine-tune for the downstream task of token classification for six different common weakness enumeration specifications. The results achieved in this research outperform previous Python-based vulnerability detection methods and demonstrate the effectiveness of applying named entity recognition to enhance the overall research into Python source code vulnerabilities.
Keywords: Vulnerability detection; Natural language processing; Machine learning; Named entity recognition; Transformer; Python; BERT; Programming language; Common weakness enumeration; CWE

Donghai Tian, Xiaoqi Jia, Rui Ma, Shuke Liu, Wenjing Liu, Changzhen Hu,
BinDeep: A deep learning approach to binary code similarity detection,
Expert Systems with Applications,
Volume 168,
2021,
114348,
ISSN 0957-4174,
https://doi.org/10.1016/j.eswa.2020.114348.
(https://www.sciencedirect.com/science/article/pii/S0957417420310332)
Abstract: Binary code similarity detection (BCSD) plays an important role in malware analysis and vulnerability discovery. Existing methods mainly rely on the expert’s knowledge for the BCSD, which may not be reliable in some cases. More importantly, the detection accuracy (or performance) of these methods are not so satisfied. To address these issues, we propose BinDeep, a deep learning approach for binary code similarity detection. This method firstly extracts the instruction sequence from the binary function and then uses the instruction embedding model to vectorize the instruction features. Next, BinDeep applies a Recurrent Neural Network (RNN) deep learning model to identify the specific types of two functions for later comparison. According to the type information, BinDeep selects the corresponding deep learning model for similarity comparison. Specifically, BinDeep uses the Siamese neural networks, which combine the LSTM and CNN to measure the similarities of two target functions. Different from the traditional deep learning model, our hybrid model takes advantage of the CNN spatial structure learning and the LSTM sequence learning. The evaluation shows that our approach can achieve good BCSD between cross-architecture, cross-compiler, cross-optimization, and cross-version binary code.
Keywords: Binary code; Deep learning; Similarity comparison; Siamese neural network; LSTM; CNN

Anjana Wijekoon, Nirmalie Wiratunga,
A user-centred evaluation of DisCERN: Discovering counterfactuals for code vulnerability detection and correction,
Knowledge-Based Systems,
Volume 278,
2023,
110830,
ISSN 0950-7051,
https://doi.org/10.1016/j.knosys.2023.110830.
(https://www.sciencedirect.com/science/article/pii/S0950705123005804)
Abstract: Counterfactual explanations highlight actionable knowledge which helps to understand how a machine learning model outcome could be altered to a more favourable outcome. Understanding actionable corrections in source code analysis can be critical to proactively mitigate security attacks that are caused by known vulnerabilities. In this paper, we present the DisCERN explainer for discovering counterfactuals for code vulnerability correction. Given a vulnerable code segment, DisCERN finds counterfactual (i.e. non-vulnerable) code segments and recommends actionable corrections. DisCERN uses feature attribution knowledge to identify potentially vulnerable code statements. Subsequently, it applies a substitution-focused correction, suggesting suitable fixes by analysing the nearest-unlike neighbour. Overall, DisCERN aims to identify vulnerabilities and correct them while preserving both the code syntax and the original functionality of the code. A user study evaluated the utility of counterfactuals for vulnerability detection and correction compared to more commonly used feature attribution explainers. The study revealed that counterfactuals foster positive shifts in mental models, effectively guiding users towards making vulnerability corrections. Furthermore, counterfactuals significantly reduced the cognitive load when detecting and correcting vulnerabilities in complex code segments. Despite these benefits, the user study showed that feature attribution explanations are still more widely accepted than counterfactuals, possibly due to the greater familiarity with the former and the novelty of the latter. These findings encourage further research and development into counterfactual explanations, as they demonstrate the potential for acceptability over time among developers as a reliable resource for both coding and training.
Keywords: Counterfactual explanations; Vulnerability detection; Explainable AI

Yiran Cheng, Shouguo Yang, Zhe Lang, Zhiqiang Shi, Limin Sun,
VERI: A Large-scale Open-Source Components Vulnerability Detection in IoT Firmware,
Computers & Security,
Volume 126,
2023,
103068,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.103068.
(https://www.sciencedirect.com/science/article/pii/S0167404822004606)
Abstract: IoT device manufacturers integrate open-source components (OSCs) to serve necessary and common functions for facilitating firmware development. However, outdated versions of OSC conceal N-day vulnerabilities and continue to function on IoT devices. The security risks can be predicted once we can identify the OSC versions employed in the firmware. Existing works make attempts at OSC version identification but fail to perform vulnerability detection on a large-scale IoT firmware due to i) unsuitable version identification method for IoT firmware scenario. ii) the lack of a large-scale version-vulnerability relation database. To this end, we propose a system VERI for large-scale vulnerability detection based on lightweight version identification. First, for OSC version identification, VERI leverages symbolic execution with static analysis to identify exact OSC versions even though there are many version-like strings in OSC. Second, VERI employs a deep learning-based method to extract OSC names and vulnerable version ranges from vulnerability descriptions, constructs and maintains an OSC version-vulnerability relation database to serve the vulnerability detection. Finally, VERI polls the relation database to confirm the N-day security risk of the OSC with identified version. The evaluation results show that VERI achieves 96.43% accuracy with high efficiency in OSC version identification. Meanwhile, the deep learning model accurately extracts the OSC names and versions from vulnerability descriptions dataset with 97.19% precision and 96.56% recall. Based on the model, we build a large-scale version-vulnerability relation database. Furthermore, we utilize VERI to conduct a large-scale analysis on 28,890 firmware and find 38,654 vulnerable OSCs with 266,109 N-day vulnerabilities, most of which are with high risks. From the detection results, we find that after the official patch for the vulnerability is released, manufacturers delay an average of 473 days to patch the firmware.
Keywords: IoT Firmware; Open-source component; Vulnerability detection; Version identification

Chongyang Liu, Xiang Chen, Xiangwei Li, Yinxing Xue,
Making vulnerability prediction more practical: Prediction, categorization, and localization,
Information and Software Technology,
Volume 171,
2024,
107458,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2024.107458.
(https://www.sciencedirect.com/science/article/pii/S0950584924000636)
Abstract: Context:
Due to the prevalence of software vulnerabilities, vulnerability detection becomes a fundamental problem in system security.
Objective:
To solve this problem, academics and industries have made great efforts to propose deep-learning-based (DL-based) approaches but these attempts have three main limitations: (1) perform poorly on real-world projects (e.g., Accuracy below 74.33% and F1 below 73.55%); (2) perform poorly in catching vulnerable patterns due to incomplete code representations; (3) mostly perform coarse-grained function-level prediction and lack interpretability analysis.
Methods:
In this paper, we propose VulPCL, a BLSTM and CodeBERT based approach, which makes the first attempt to perform vulnerability prediction, categorization, and localization automatically within a framework. To alleviate the above-mentioned limitations, our VulPCL considers multi-dimension (i.e., text-based, sequence-based, and graph-based) representations to catch latent vulnerable patterns and multi-model training to learn high-level semantics.
Results:
Through experiments on four real-world datasets containing 114+ CWE (Common Weakness Enumeration) types spanning from 2005 to 2022, we find that our VulPCL outperforms the baselines by (1) 13.51%∼60.64% and 14.34%∼180.23% on Accuracy, and F1 respectively on vulnerability prediction; (2) 10.32%∼46.79%, and 10.71%∼127.80% on Accuracy, and macro-F1 respectively on vulnerability categorization; (3) 9.23%∼36.54% on Top-10 Accuracy on vulnerability localization.
Conclusion:
These results indicate that our VulPCL is considerably more accurate, effective, fine-grained, and practical than previous studies. Besides, our further analyses show that VulPCL is indeed capable of capturing all vulnerability lines, and the result of line-level vulnerability localization is consistent with the function-level vulnerability prediction as the increase of predicted lines. Thus making VulPCL more interpretable than previous studies. Our additional investigation also shows that VulPCL effectively detects the Most Dangerous 25 CWEs in 2022, which is instructive for security researchers.
Keywords: Deep learning; Pre-trained language model; Semantic analysis; Vulnerability detection

Ahmed Alzahrani, Muhammad Zubair Asghar,
Cyber vulnerabilities detection system in logistics-based IoT data exchange,
Egyptian Informatics Journal,
Volume 25,
2024,
100448,
ISSN 1110-8665,
https://doi.org/10.1016/j.eij.2024.100448.
(https://www.sciencedirect.com/science/article/pii/S1110866524000112)
Abstract: Modern-day digitalization has a profound impact on business and society, revolutionizing logistics. Supply chain digitalization improves transparency, speed, and cost-effectiveness, increasingtech adoption—transportationbenefits from IoT-driven shipment tracking and web data storage. However, cyber threats target IoT data by exploiting cyber vulnerabilities. Although ML/DL approaches have showed potential in finding IoT vulnerabilities, the difficulty of selecting appropriate features remains. Existing research has produced surprising outcomes, and deep neural networks have been utilised to extract characteristics without taking sequence information into account. To address this, the paper presents a unique approach for accurate IoT vulnerability identification that combines deep learning and better feature selection. On the BoT-IoT dataset, the LSTM + CNN model achieved 95.73 % accuracy. This approach has the ability to successfully anticipate IoT based vulnerabilities by leveraging benchmark data, selecting relevant features, and enhancing overall system performance.
Keywords: Hybrid deep learning; Feature selection; IoT-based vulnerabilities; Logistics

Stanislav Abaimov, Giuseppe Bianchi,
A survey on the application of deep learning for code injection detection,
Array,
Volume 11,
2021,
100077,
ISSN 2590-0056,
https://doi.org/10.1016/j.array.2021.100077.
(https://www.sciencedirect.com/science/article/pii/S2590005621000254)
Abstract: Code injection is one of the top cyber security attack vectors in the modern world. To overcome the limitations of conventional signature-based detection techniques, and to complement them when appropriate, multiple machine learning approaches have been proposed. While analysing these approaches, the surveys focus predominantly on the general intrusion detection, which can be further applied to specific vulnerabilities. In addition, among the machine learning steps, data preprocessing, being highly critical in the data analysis process, appears to be the least researched in the context of Network Intrusion Detection, namely in code injection. The goal of this survey is to fill in the gap through analysing and classifying the existing machine learning techniques applied to the code injection attack detection, with special attention to Deep Learning. Our analysis reveals that the way the input data is preprocessed considerably impacts the performance and attack detection rate. The proposed full preprocessing cycle demonstrates how various machine-learning-based approaches for detection of code injection attacks take advantage of different input data preprocessing techniques. The most used machine learning methods and preprocessing stages have been also identified.
Keywords: Machine learning; Deep learning; Network intrusion detection; Code injection; Preprocessing

Santosh K. Smmarwar, Govind P. Gupta, Sanjay Kumar,
Android malware detection and identification frameworks by leveraging the machine and deep learning techniques: A comprehensive review,
Telematics and Informatics Reports,
Volume 14,
2024,
100130,
ISSN 2772-5030,
https://doi.org/10.1016/j.teler.2024.100130.
(https://www.sciencedirect.com/science/article/pii/S2772503024000161)
Abstract: The ever-increasing growth of online services and smart connectivity of devices have posed the threat of malware to computer system, android-based smart phones, Internet of Things (IoT)-based systems. The anti-malware software plays an important role in order to safeguard the system resources, data and information against these malware attacks. Nowadays, malware writers used advanced techniques like obfuscation, packing, encoding and encryption to hide the malicious activities. Because of these advanced techniques of malware evasion, traditional malware detection system unable to detect new variants of malware. Cyber security has attracted many researchers in the past for designing of Machine Learning (ML) or Deep Learning (DL) based malware detection models. In this study, we present a comprehensive review of the literature on malware detection approaches. The overall literature of the malware detection is grouped into three categories such as review of feature selection (FS) techniques proposed for malware detection, review of ML-based techniques proposed for malware detection and review of DL-based techniques proposed for malware detection. Based on literature review, we have identified the shortcoming and research gaps along with some future directives to design of an efficient malware detection and identification framework.
Keywords: Machine learning; Deep learning; Android malware detection; Malware detection

Xueshuo Xie, Haolong Wang, Zhaolong Jian, Yaozheng Fang, Zichun Wang, Tao Li,
Block-gram: Mining knowledgeable features for efficiently smart contract vulnerability detection,
Digital Communications and Networks,
2023,
,
ISSN 2352-8648,
https://doi.org/10.1016/j.dcan.2023.07.009.
(https://www.sciencedirect.com/science/article/pii/S2352864823001347)
Abstract: Smart contracts are widely used on the blockchain to implement complex transactions, such as decentralized applications on Ethereum. Effective vulnerability detection of large-scale smart contracts is critical, as attacks on smart contracts often cause huge economic losses. Since it is difficult to repair and update smart contracts, it is necessary to find the vulnerabilities before they are deployed. However, code analysis, which requires traversal paths, and learning methods, which require many features to be trained, are too time-consuming to detect large-scale on-chain contracts. Learning-based methods will obtain detection models from a feature space compared to code analysis methods such as symbol execution. But the existing features lack the interpretability of the detection results and training model, even worse, the large-scale feature space also affects the efficiency of detection. This paper focuses on improving the detection efficiency by reducing the dimension of the features, combined with expert knowledge. In this paper, a feature extraction model Block-gram is proposed to form low-dimensional knowledge-based features from bytecode. First, the metadata is separated and the runtime code is converted into a sequence of opcodes, which are divided into segments based on some instructions (jumps, etc.). Then, scalable Block-gram features, including 4-dimensional block features and 8-dimensional attribute features, are mined for the learning-based model training. Finally, feature contributions are calculated from SHAP values to measure the relationship between our features and the results of the detection model. In addition, six types of vulnerability labels are made on a dataset containing 33,885 contracts, and these knowledge-based features are evaluated using seven state-of-the-art learning algorithms, which show that the average detection latency speeds up 25× to 650×, compared with the features extracted by N-gram, and also can enhance the interpretability of the detection model.
Keywords: Smart contract; Bytecode & opcode; Knowledgeable features; Vulnerability detection; Feature contribution

Shahid Latif, Wadii Boulila, Anis Koubaa, Zhuo Zou, Jawad Ahmad,
DTL-IDS: An optimized Intrusion Detection Framework using Deep Transfer Learning and Genetic Algorithm,
Journal of Network and Computer Applications,
Volume 221,
2024,
103784,
ISSN 1084-8045,
https://doi.org/10.1016/j.jnca.2023.103784.
(https://www.sciencedirect.com/science/article/pii/S1084804523002035)
Abstract: In the dynamic field of the Industrial Internet of Things (IIoT), the networks are increasingly vulnerable to a diverse range of cyberattacks. This vulnerability necessitates the development of advanced intrusion detection systems (IDSs). Addressing this need, our research contributes to the existing cybersecurity literature by introducing an optimized Intrusion Detection System based on Deep Transfer Learning (DTL), specifically tailored for heterogeneous IIoT networks. Our framework employs a tri-layer architectural approach that synergistically integrates Convolutional Neural Networks (CNNs), Genetic Algorithms (GA), and bootstrap aggregation ensemble techniques. The methodology is executed in three critical stages: First, we convert a state-of-the-art cybersecurity dataset, Edge_IIoTset, into image data, thereby facilitating CNN-based analytics. Second, GA is utilized to fine-tune the hyperparameters of each base learning model, enhancing the model’s adaptability and performance. Finally, the outputs of the top-performing models are amalgamated using ensemble techniques, bolstering the robustness of the IDS. Through rigorous evaluation protocols, our framework demonstrated exceptional performance, reliably achieving a 100% attack detection accuracy rate. This result establishes our framework as highly effective against 14 distinct types of cyberattacks. The findings bear significant implications for the ongoing development of secure, efficient, and adaptive IDS solutions in the complex landscape of IIoT networks.
Keywords: Cybersecurity; Genetic Algorithm; IIoT; Intrusion Detection; Transfer learning

Jinfu Chen, Wei Lin, Saihua Cai, Yemin Yin, Haibo Chen, Dave Towey,
BiTCN_DRSN: An effective software vulnerability detection model based on an improved temporal convolutional network,
Journal of Systems and Software,
Volume 204,
2023,
111772,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111772.
(https://www.sciencedirect.com/science/article/pii/S016412122300167X)
Abstract: The detection of software vulnerabilities is a challenging task in the field of security. With the increasing scale of software and the rapid development of artificial intelligence technology, deep learning has been extensively applied to automatic vulnerability detection. Temporal Convolutional Networks (TCNs) have been shown to perform well in tasks that can be processed in parallel; they can adaptively learn complex structures (including in-time series data); and they have exhibited stable gradients — they are relatively easier to train, and can quickly converge to an optimal solution. However, TCNs cannot simultaneously capture the bidirectional semantics of the source code, since they do not have a bidirectional network structure. Furthermore, because of the weak noise resistance of residual TCN connections, TCNs are also susceptible to learning features that are not related to vulnerabilities when learning the source code features. To overcome the limitations of the traditional TCN, we propose a bidirectional TCN model based on the Deep Residual Shrinkage Network (DRSN), namely BiTCN_DRSN. BiTCN_DRSN combines TCN and DRSN to enhance the noise immunity and make the network model more attentive to the features associated with vulnerabilities. In addition, addressing the limitation that the TCN is a unidirectional network structure, the forward and backward sequences are utilized for bidirectional source-code feature learning. The experimental results show that the proposed BiTCN_DRSN model can effectively improve the accuracy of source-code vulnerability detection, compared with some existing neural-network models. Compared with the traditional TCN, our model increases the accuracy by 4.22%, 2.42% and 2.66% on the BE-ALL, RM-ALL and HY-ALL datasets, respectively. The proposed BiTCN_DRSN model also exhibits improved detection stability.
Keywords: Software security; Vulnerability detection; Deep learning; Deep residual shrinkage network

Wei Xiao, Zhengzhang Hou, Tao Wang, Chengxian Zhou, Chao Pan,
MSGVUL: Multi-semantic integration vulnerability detection based on relational graph convolutional neural networks,
Information and Software Technology,
Volume 170,
2024,
107442,
ISSN 0950-5849,
https://doi.org/10.1016/j.infsof.2024.107442.
(https://www.sciencedirect.com/science/article/pii/S0950584924000478)
Abstract: Software security has drawn extensive attention as software projects have grown increasingly large and complex. Since the traditional manual or equipment vulnerability detection technology cannot meet today's software development needs, there is a recognized need to create more effective techniques to address security issues. Although various vulnerability detection systems have been proposed, most are based only on serialization or graph representation, to inadequate effect. We propose a system, MSGVUL, that provides superior vulnerability detection using a new multi-semantic approach. MSGVUL uses versatile and efficient code slicing employing a search algorithm based on sensitive data and functions and innovatively constructs an SSVEC model to fully integrate the semantic and structural information into the code. We also developed a novel BAG model, made up of BAP and PAG frameworks, that enables the hierarchical extraction of code vulnerability representations from the graph and sequence levels. The MSGVUL model is evaluated on slice-level and function-level vulnerability datasets, and the results demonstrate that the MSGVUL method outperforms other state-of-the-art methods.
Keywords: Vulnerability detection; Code representation; Program slicing; Graph convolutional neural networks

Faria Nawshin, Radwa Gad, Devrim Unal, Abdulla Khalid Al-Ali, Ponnuthurai N. Suganthan,
Malware detection for mobile computing using secure and privacy-preserving machine learning approaches: A comprehensive survey,
Computers and Electrical Engineering,
Volume 117,
2024,
109233,
ISSN 0045-7906,
https://doi.org/10.1016/j.compeleceng.2024.109233.
(https://www.sciencedirect.com/science/article/pii/S0045790624001617)
Abstract: Mobile devices have become an essential element in our day-to-day lives. The chances of mobile attacks are rapidly increasing with the growing use of mobile devices. Exploiting vulnerabilities from devices as well as stealing personal information, are the principal targets of the attackers. Researchers are also developing various techniques for detecting and analyzing mobile malware to overcome these issues. As new malware gets introduced frequently by malware developers, it is very challenging to come up with comprehensive algorithms to detect this malware. There are many machine-learning and deep-learning algorithms have been developed by researchers. The accuracy of these models largely depends on the size and quality of the training dataset. Training the model with a diversified dataset is necessary to predict new malware accurately. However, this training process may raise the issue of privacy loss due to the disclosure of sensitive information of the users. Researchers have proposed various techniques to mitigate this issue, such as differential privacy, homomorphic encryption, and federated learning. This survey paper explores the significance of applying federated learning to the mobile operating systems, contrasting traditional machine learning and deep learning approaches for mobile malware detection. We delve into the unique challenges and opportunities of the architecture of in-built mobile operating systems and their implications for user privacy and security. Moreover, we assess the risks associated with federated learning in real-life applications and recommend strategies for developing a secure federated learning framework in the domain of mobile malware detection.
Keywords: Mobile malware analysis; Privacy-preserving machine-learning; Secure machine-learning; Mobile security attacks; Federated learning; Mobile vulnerabilities

Longtao Guo, Huakun Huang, Lingjun Zhao, Peiliang Wang, Shan Jiang, Chunhua Su,
Reentrancy vulnerability detection based on graph convolutional networks and expert patterns under subspace mapping,
Computers & Security,
Volume 142,
2024,
103894,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2024.103894.
(https://www.sciencedirect.com/science/article/pii/S0167404824001962)
Abstract: Smart contracts with automatic execution capability provide a vast development space for transactions in Blockchain. However, due to the vulnerabilities in smart contracts, Blockchain has suffered huge economic losses, which greatly undermines people’s trust in Blockchain and smart contracts. In this paper, we explore a vulnerability detection method based on graph neural networks and combine both contract source code and opcode. The structure of the method consists of four modules, i.e., preprocessing, subspace mapping, feature extraction, and detection modules. In the feature mapping module, we use a multi-subspace mapping approach to explore the impact of different subspace mappings on the detection method. For reentrancy vulnerability, we conducted extensive experiments. The experiments prove that our method achieves 95% accuracy and 94% F1-Score on average.
Keywords: Blockchain; Smart contract; Vulnerability detection; Graph neural network; Subspace mapping

Siegfried K Wagner, Bart Liefers, Meera Radia, Gongyu Zhang, Robbert Struyven, Livia Faes, Jonathan Than, Shafi Balal, Charlie Hennings, Caroline Kilduff, Pakinee Pooprasert, Sophie Glinton, Meena Arunakirinathan, Periklis Giannakis, Imoro Zeba Braimah, Islam S H Ahmed, Mariam Al-Feky, Hagar Khalid, Daniel Ferraz, Juliana Vieira, Rodrigo Jorge, Shahid Husain, Janette Ravelo, Anne-Marie Hinds, Robert Henderson, Himanshu I Patel, Susan Ostmo, J Peter Campbell, Nikolas Pontikos, Praveen J Patel, Pearse A Keane, Gill Adams, Konstantinos Balaskas,
Development and international validation of custom-engineered and code-free deep-learning models for detection of plus disease in retinopathy of prematurity: a retrospective study,
The Lancet Digital Health,
Volume 5, Issue 6,
2023,
Pages e340-e349,
ISSN 2589-7500,
https://doi.org/10.1016/S2589-7500(23)00050-X.
(https://www.sciencedirect.com/science/article/pii/S258975002300050X)
Abstract: Summary
Background
Retinopathy of prematurity (ROP), a leading cause of childhood blindness, is diagnosed through interval screening by paediatric ophthalmologists. However, improved survival of premature neonates coupled with a scarcity of available experts has raised concerns about the sustainability of this approach. We aimed to develop bespoke and code-free deep learning-based classifiers for plus disease, a hallmark of ROP, in an ethnically diverse population in London, UK, and externally validate them in ethnically, geographically, and socioeconomically diverse populations in four countries and three continents. Code-free deep learning is not reliant on the availability of expertly trained data scientists, thus being of particular potential benefit for low resource health-care settings.
Methods
This retrospective cohort study used retinal images from 1370 neonates admitted to a neonatal unit at Homerton University Hospital NHS Foundation Trust, London, UK, between 2008 and 2018. Images were acquired using a Retcam Version 2 device (Natus Medical, Pleasanton, CA, USA) on all babies who were either born at less than 32 weeks gestational age or had a birthweight of less than 1501 g. Each images was graded by two junior ophthalmologists with disagreements adjudicated by a senior paediatric ophthalmologist. Bespoke and code-free deep learning models (CFDL) were developed for the discrimination of healthy, pre-plus disease, and plus disease. Performance was assessed internally on 200 images with the majority vote of three senior paediatric ophthalmologists as the reference standard. External validation was on 338 retinal images from four separate datasets from the USA, Brazil, and Egypt with images derived from Retcam and the 3nethra neo device (Forus Health, Bengaluru, India).
Findings
Of the 7414 retinal images in the original dataset, 6141 images were used in the final development dataset. For the discrimination of healthy versus pre-plus or plus disease, the bespoke model had an area under the curve (AUC) of 0·986 (95% CI 0·973–0·996) and the CFDL model had an AUC of 0·989 (0·979–0·997) on the internal test set. Both models generalised well to external validation test sets acquired using the Retcam for discriminating healthy from pre-plus or plus disease (bespoke range was 0·975–1·000 and CFDL range was 0·969–0·995). The CFDL model was inferior to the bespoke model on discriminating pre-plus disease from healthy or plus disease in the USA dataset (CFDL 0·808 [95% CI 0·671–0·909, bespoke 0·942 [0·892–0·982]], p=0·0070). Performance also reduced when tested on the 3nethra neo imaging device (CFDL 0·865 [0·742–0·965] and bespoke 0·891 [0·783–0·977]).
Interpretation
Both bespoke and CFDL models conferred similar performance to senior paediatric ophthalmologists for discriminating healthy retinal images from ones with features of pre-plus or plus disease; however, CFDL models might generalise less well when considering minority classes. Care should be taken when testing on data acquired using alternative imaging devices from that used for the development dataset. Our study justifies further validation of plus disease classifiers in ROP screening and supports a potential role for code-free approaches to help prevent blindness in vulnerable neonates.
Funding
National Institute for Health Research Biomedical Research Centre based at Moorfields Eye Hospital NHS Foundation Trust and the University College London Institute of Ophthalmology.
Translations
For the Portuguese and Arabic translations of the abstract see Supplementary Materials section.

Xiaojun Ren, Yongtang Wu, Jiaqing Li, Dongmin Hao, Muhammad Alam,
Smart contract vulnerability detection based on a semantic code structure and a self-designed neural network,
Computers and Electrical Engineering,
Volume 109, Part B,
2023,
108766,
ISSN 0045-7906,
https://doi.org/10.1016/j.compeleceng.2023.108766.
(https://www.sciencedirect.com/science/article/pii/S0045790623001908)
Abstract: Smart contracts are riddled with vulnerabilities due to flaws in programming languages and the inexperience of developers, causing damage. Nonetheless, the current research on smart contract vulnerability detection is insufficient. In this study, we propose a novel approach, namely, Blass, based on a semantic code structure and a self-designed neural network. Blass constructs program slices with complete semantic structure information (CPSs) and uses an abstract syntax tree and a depth-first traversal algorithm to convert CPSs into code chains during the process of CPS vectorization, which increases its ability to express vulnerability features. Blass also uses a self-designed neural network, Bi-LSTM-Att, as the classification model, which introduces an attention mechanism to capture the key features of vulnerabilities and effectively achieve improved smart contract vulnerability detection performance. The CPSs and the Bi-LSTM-Att can improve the vulnerability detection effectiveness of Blass, and Blass can be applied to malicious contract detection with satisfactory precision, recall, and F1 values.
Keywords: Smart contract; Vulnerability; Semantic code structure; Code chain; Bi-LSTM-Att classification model

Vladimir Ciric, Marija Milosevic, Danijel Sokolovic, Ivan Milentijevic,
Modular deep learning-based network intrusion detection architecture for real-world cyber-attack simulation,
Simulation Modelling Practice and Theory,
Volume 133,
2024,
102916,
ISSN 1569-190X,
https://doi.org/10.1016/j.simpat.2024.102916.
(https://www.sciencedirect.com/science/article/pii/S1569190X24000303)
Abstract: In an increasingly digitalized world, cybersecurity has emerged as a critical component of safeguarding sensitive information and infrastructure from malicious threats. The threat actors are often in line or even one step ahead of the defense, causing the increasing reliance of security teams on artificial intelligence while trying to detect zero-day attacks. However, most of the cybersecurity solutions based on artificial intelligence that can be found in the literature are trained and tested on reference datasets that are at least five or more years old, which gives a vague insight into their security performances. Moreover, they often tend to be designed as isolated, self-focused components. The aim of this paper is to design and implement a modular network intrusion detection architecture capable of simulating cyberattacks based on real-world scenarios while evaluating its defense capabilities. The architecture is designed as a full pipeline from real-time network data collection and transformation to threat-information presentation and visualization, with a pre-trained artificial intelligence module at its core. Well-known components like CICFlowMeter, Prometheus, and Grafana are used and modified to fit our data preparation and core modules to form the proposed architecture for real-world network traffic security monitoring. For the sake of cyberattack simulation, the proposed architecture is situated within a virtual environment, surrounded by the Kali Linux-based penetration simulation agent on one side and a vulnerable agent on the other. The intrusion detection artificial intelligence module is trained on the CICIDS-2017 dataset, and it is demonstrated using the proposed architecture that, despite being trained on an outdated dataset, the trained module is still effective in detecting sophisticated modern attacks. Two case studies are given to illustrate how modular architectures and virtual environments can be valuable tools to assess the security properties of artificial intelligence-based solutions through simulation in real-world scenarios.
Keywords: Cybersecurity; Network intrusion detection systems; Artificial intelligence; Virtual environments simulation

Tao Yi, Xingshu Chen, Yi Zhu, Weijing Ge, Zhenhui Han,
Review on the application of deep learning in network attack detection,
Journal of Network and Computer Applications,
Volume 212,
2023,
103580,
ISSN 1084-8045,
https://doi.org/10.1016/j.jnca.2022.103580.
(https://www.sciencedirect.com/science/article/pii/S1084804522002211)
Abstract: With the development of new technologies such as big data, cloud computing, and the Internet of Things, network attack technology is constantly evolving and upgrading, and network attack detection technology is forced to undergo corresponding iterative evolution. Three main problems are associated with these technologies: the automatic representation of heterogeneous and complex network traffic data, the uneven network attack samples, and the contradiction between the accuracy of the anomaly detection model and the continuous evolution of attacks. Researchers have proposed several network attack detection techniques based on deep learning to address these problems. This study reviews and analyzes the studies aimed at dealing with such problems, considering multiple factors, such as models, traffic representation and feature extraction, threat detection model training, and model robustness improvement. Finally, the existing problems and challenges associated with the current research are analyzed with respect to data category imbalance, high-dimensional massive data processing, concept distribution drift, real-time interpretability of the detection model, and the security of the model.
Keywords: Network attack; Deep learning; Flow characterization; Detection model; Model security

Yuanhai Fan, Chuanhao Wan, Cai Fu, Lansheng Han, Hao Xu,
VDoTR: Vulnerability detection based on tensor representation of comprehensive code graphs,
Computers & Security,
Volume 130,
2023,
103247,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2023.103247.
(https://www.sciencedirect.com/science/article/pii/S0167404823001578)
Abstract: Code vulnerability detection has long been a critical issue due to its potential threat to computer systems. It is imperative to detect source code vulnerabilities in software and remediate them to avoid cyber attacks. To automate detection and reduce labor costs, many deep learning-based methods have been proposed. However, these approaches have been found to be either ineffective in detecting multiple classes of vulnerabilities or limited by treating original source code as a natural language sequence without exploiting the structural information of code. In this paper, we propose VDoTR, a model that leverages a new tensor representation of comprehensive code graphs, including AST, CFG, DFG, and NCS, to detect multiple types of vulnerabilities. Firstly, a tensor structure is introduced to represent the structured information of code, which deeply captures code features. Secondly, a new Circle Gated Graph Neural Network (CircleGGNN) is designed based on tensor for hidden state embedding of nodes. CircleGGNN can perform heterogeneous graph information fusion more directly and effectively. Lastly, a 1-D convolution-based output layer is applied to hidden embedding features for classification. The experimental results demonstrate that the detection performance of VDoTR is superior to other approaches with higher accuracy, precision, recall, and F1-measure on multiple datasets for vulnerability detection. Moreover, we illustrate which code graph contributes the most to the performance of VDoTR and which code graph is more sensitive to represent vulnerability features for different types of vulnerabilities through ablation experiments.
Keywords: Source code vulnerability detection; Tensor-based feature; GGNN; Code graphs; Heterogeneous information fusion

Tushar Sharma, Maria Kechagia, Stefanos Georgiou, Rohit Tiwari, Indira Vats, Hadi Moazen, Federica Sarro,
A survey on machine learning techniques applied to source code,
Journal of Systems and Software,
Volume 209,
2024,
111934,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111934.
(https://www.sciencedirect.com/science/article/pii/S0164121223003291)
Abstract: The advancements in machine learning techniques have encouraged researchers to apply these techniques to a myriad of software engineering tasks that use source code analysis, such as testing and vulnerability detection. Such a large number of studies hinders the community from understanding the current research landscape. This paper aims to summarize the current knowledge in applied machine learning for source code analysis. We review studies belonging to twelve categories of software engineering tasks and corresponding machine learning techniques, tools, and datasets that have been applied to solve them. To do so, we conducted an extensive literature search and identified 494 studies. We summarize our observations and findings with the help of the identified studies. Our findings suggest that the use of machine learning techniques for source code analysis tasks is consistently increasing. We synthesize commonly used steps and the overall workflow for each task and summarize machine learning techniques employed. We identify a comprehensive list of available datasets and tools useable in this context. Finally, the paper discusses perceived challenges in this area, including the availability of standard datasets, reproducibility and replicability, and hardware resources. Editor’s note: Open Science material was validated by the Journal of Systems and Software Open Science Board.
Keywords: Machine learning for software engineering; Source code analysis; Deep learning; Datasets; Tools

Rongze Xu, Zhanyong Tang, Guixin Ye, Huanting Wang, Xin Ke, Dingyi Fang, Zheng Wang,
Detecting code vulnerabilities by learning from large-scale open source repositories,
Journal of Information Security and Applications,
Volume 69,
2022,
103293,
ISSN 2214-2126,
https://doi.org/10.1016/j.jisa.2022.103293.
(https://www.sciencedirect.com/science/article/pii/S221421262200148X)
Abstract: Machine learning methods are widely used to identify common, repeatedly occurring bugs and code vulnerabilities. The performance of a machine-learned model is bounded by the quality and quantity of training data and the model’s capability in extracting and capturing the essential information of the problem domain. Unfortunately, there is a storage of high-quality samples for training code vulnerability detection models, and existing machine learning methods are inadequate in capturing code vulnerability patterns. We present Developer,11Developer = Detecting codE VulnerabilitiEs at the Large scale by learning from OPen sourcE Repositories. a novel learning framework for building code vulnerability detection models. To address the data scarcity challenge, Developer automatically gathers training samples from open-source projects and applies constraints rules to the collected data to filter out noisy data to improve the quality of the collected samples. The collected data provides many real-world vulnerable code training samples to complement the samples available in standard vulnerable databases. To build an effective code vulnerability detection model, Developer employs a convolutional neural network architecture with attention mechanisms to extract code representation from the program abstract syntax tree. The extracted program representation is then fed to a downstream network – a bidirectional long–short term memory architecture – to predict if the target code contains a vulnerability or not. We apply Developer to identify vulnerabilities at the program source-code level. Our evaluation shows that Developer outperforms state-of-the-art methods by uncovering more vulnerabilities with a lower false-positive rate.
Keywords: Code vulnerability detection; Deep learning; Attention mechanism; Software vulnerability

Son Nguyen, Thu-Trang Nguyen, Thanh Trong Vu, Thanh-Dat Do, Kien-Tuan Ngo, Hieu Dinh Vo,
Code-centric learning-based just-in-time vulnerability detection,
Journal of Systems and Software,
Volume 214,
2024,
112014,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2024.112014.
(https://www.sciencedirect.com/science/article/pii/S0164121224000578)
Abstract: Attacks against computer systems exploiting software vulnerabilities can cause substantial damage to the cyber infrastructure of our modern society and economy. To minimize the consequences, it is vital to detect and fix vulnerabilities as soon as possible. Just-in-time vulnerability detection (JIT-VD) discovers vulnerability-prone (“dangerous”) commits to prevent them from being merged into source code and causing vulnerabilities. By JIT-VD, the commits’ authors, who understand the commits properly, can review these dangerous commits and fix them if necessary while the relevant modifications are still fresh in their minds. In this paper, we propose CodeJIT, a novel graph-based code-centric learning-based approach for just-in-time vulnerability detection. The key idea of CodeJIT is that the meaning of the code changes of a commit is the direct and deciding factor for determining if the commit is dangerous for the code. Based on that idea, we design a novel graph-based representation, Code Transformation Graph (CTG) to represent the semantics of code changes in terms of both code syntactic structure and program dependencies. A graph neural network (GNN) model is developed to capture the meaning of the code changes represented by our graph-based representation and learn to discriminate between dangerous and safe commits. We conducted experiments to evaluate the JIT-VD performance of CodeJIT on a dataset of 20K+ dangerous and safe commits in 506 real-world projects from 1998 to 2022. Our results show that CodeJIT significantly improves the state-of-the-art JIT-VD methods by up to 66% in Recall, 136% in Precision, and 68% in F1. Moreover, CodeJIT correctly classifies nearly 9/10 of dangerous/safe (benign) commits and even detects 69 commits that fix a vulnerability yet produce other issues in source code.
Keywords: Just-in-time vulnerability detection; Code-centric; Code change representation; Graph-based model; Commit-level bugs

Katarzyna Filus, Joanna Domańska,
Software vulnerabilities in TensorFlow-based deep learning applications,
Computers & Security,
Volume 124,
2023,
102948,
ISSN 0167-4048,
https://doi.org/10.1016/j.cose.2022.102948.
(https://www.sciencedirect.com/science/article/pii/S0167404822003406)
Abstract: Usage of Deep Learning (DL) methods is ubiquitous. It is common in the DL/Artificial Intelligence domain to use 3rd party software. TensorFlow is one of the most popular Machine Learning (ML) platforms. Every software product is a subject to security failures which often result from software vulnerabilities. In this paper, we focus on threats related to 6 common types of threats in TensorFlow implementation. We identify them using Common Weakness Enumeration. We analyze more than 100 vulnerability instances. We focus on vulnerabilities’ severity, impact on confidentiality, integrity and availability, as well as possible results of exploitation. We also use Orthogonal Defect Classification (ODC). The results show that a majority of vulnerabilities are caused by missing/incorrect checking statements, however some fixes require more advanced algorithmic changes. Static Analysis Tools tested in our study show low effectiveness in detecting known vulnerabilities in TensorFlow, but we provide some recommendations based on the obtained alerts to improve overall code quality. Further analysis of vulnerabilities helped us to understand and characterize different vulnerability types and provide a set of observations. We believe that these observations can be useful for the creators of new static analysis tools as a source of inspiration and to build the test cases. We also aim to draw the programmers’ attention to the prevalence of vulnerabilities in deep learning applications and a low effectiveness of automatic tools to find software vulnerabilities in such products.
Keywords: Software vulnerability; TensorFlow; Deep learning; Security; Static analysis

Wei Tang, Mingwei Tang, Minchao Ban, Ziguo Zhao, Mingjun Feng,
CSGVD: A deep learning approach combining sequence and graph embedding for source code vulnerability detection,
Journal of Systems and Software,
Volume 199,
2023,
111623,
ISSN 0164-1212,
https://doi.org/10.1016/j.jss.2023.111623.
(https://www.sciencedirect.com/science/article/pii/S0164121223000183)
Abstract: In order to secure software, it is critical to detect potential vulnerabilities. The performance of traditional static vulnerability detection methods is limited by predefined rules, which rely heavily on the expertise of developers. Existing deep learning-based vulnerability detection models usually use only a single sequence or graph embedding approach to extract vulnerability features. Sequence embedding-based models ignore the structured information inherent in the code, and graph embedding-based models lack effective node and graph embedding methods. As a result, we propose a novel deep learning-based approach, CSGVD (Combining Sequence and Graph embedding for Vulnerability Detection), which considers function-level vulnerability detection as a graph binary classification task. Firstly, we propose a PE-BL module, which inherits and enhances the knowledge from the pre-trained language model. It extracts the code’s local semantic features as node embedding in the control flow graph by using sequence embedding. Secondly, CSGVD uses graph neural networks to extract the structured information of the graph. Finally, we propose a mean biaffine attention pooling, M-BFA, to better aggregate node information as a graph’s feature representation. The experimental results show that CSGVD outperforms the existing state-of-the-art models and obtains 64.46% accuracy on the real-world benchmark dataset from CodeXGLUE for vulnerability detection.
Keywords: Graph neural networks; Vulnerability detection; Sequence embedding; Graph embedding; Pre-trained language model; Attention pooling

Prabith GS, Rohit Narayanan M, Arya A, Aneesh Nadh R, Binu PK,
BiT5: A Bidirectional NLP Approach for Advanced Vulnerability Detection in Codebase,
Procedia Computer Science,
Volume 233,
2024,
Pages 812-821,
ISSN 1877-0509,
https://doi.org/10.1016/j.procs.2024.03.270.
(https://www.sciencedirect.com/science/article/pii/S1877050924006306)
Abstract: In this research paper, a detailed investigation presents the utilization of the BiT5 Bidirectional NLP model for detecting vulnerabilities within codebases. The study addresses the pressing need for techniques enhancing software security by effectively identifying vulnerabilities. Methodologically, the paper introduces BiT5, specifically designed for code analysis and vulnerability detection, encompassing dataset collection, preprocessing steps, and model fine-tuning. The key findings underscore BiT5’s efficacy in pinpointing vulnerabilities within code snippets, notably reducing both false positives and false negatives. This research contributes by offering a methodology for leveraging BiT5 in vulnerability detection, thus significantly bolstering software security and mitigating risks associated with code vulnerabilities.
Keywords: Bidirectional Transformer; BiT5 Model; Code Analysis; Code Vulnerabilities; Machine Learning; Natural Language Processing (NLP); Software Security; Vulnerability Detection

Abdulrahman Alruban, Fatma S. Alrayes, Fadoua Kouki, Faiz Abdullah Alotaibi, Nojood O. Aljehane, Abdullah Mohamed,
Chaotic tumbleweed optimization algorithm with stacked deep learning based cyberattack detection in industrial CPS environment,
Alexandria Engineering Journal,
Volume 84,
2023,
Pages 250-261,
ISSN 1110-0168,
https://doi.org/10.1016/j.aej.2023.10.061.
(https://www.sciencedirect.com/science/article/pii/S1110016823009729)
Abstract: Cyberattacks on cyber-physical systems (CPS) have led to severe concerns, and then it is most significant to identify the attacks in the initial phase. But, there are major problems that are resolved in this area; it contains the capability of the security method for detecting earlier unknown attacks. These challenges are resolved with system behaviour analysis manners and semi-supervised or unsupervised machine learning (ML) approaches. The efficacy of the attack recognition method is strongly dependent upon the databases utilized for training the ML approaches. Anomaly detection is the procedure of recognizing anomalous procedures, which could not equal the predictable system behaviour. It permits the recognition of novel and secret attacks. Presently, anomaly detection systems are frequently executed utilizing ML like shallow (or traditional) learning and deep learning (DL). This article develops a Chaotic Tumbleweed Optimization Algorithm with Stacked Deep Learning based Cyberattack Detection (CTOASDL-CD) approach in the Industrial CPS platform. The CTOASDL-CD technique intends to exploit the FS with an optimal hyperparameter-tuned DL model for the detection of cyberattacks. To resolve the high dimensionality issue, the CTOASDL-CD technique uses CTOA for feature selection (FS) purposes. Besides, the stacked deep belief network (SDBN) model can be utilized for the recognition of cyberattacks. Finally, the tunicate swarm algorithm (TSA) has been deployed for the capable selection of hyperparameter values of the SDBN approach. To determine the improved performance of the CTOASDL-CD approach, a wide-ranging simulation value was performed. The experimental values demonstrated the capable outcome of the CTOASDL-CD methodology in accomplishing security in the industrial CPS environment.
Keywords: Industry 4.0; Cyber-physical systems; Security; Anomaly detection; Deep learning

Ahmed Bensaoud, Jugal Kalita, Mahmoud Bensaoud,
A survey of malware detection using deep learning,
Machine Learning with Applications,
Volume 16,
2024,
100546,
ISSN 2666-8270,
https://doi.org/10.1016/j.mlwa.2024.100546.
(https://www.sciencedirect.com/science/article/pii/S2666827024000227)
Abstract: The problem of malicious software (malware) detection and classification is a complex task, and there is no perfect approach. There is still a lot of work to be done. Unlike most other research areas, standard benchmarks are difficult to find for malware detection. This paper aims to investigate recent advances in malware detection on MacOS, Windows, iOS, Android, and Linux using deep learning (DL) by investigating DL in text and image classification, the use of pre-trained and multi-task learning models for malware detection approaches to obtain high accuracy and which the best approach if we have a standard benchmark dataset. We discuss the issues and the challenges in malware detection using DL classifiers by reviewing the effectiveness of these DL classifiers and their inability to explain their decisions and actions to DL developers presenting the need to use Explainable Machine Learning (XAI) or Interpretable Machine Learning (IML) programs. Additionally, we discuss the impact of adversarial attacks on deep learning models, negatively affecting their generalization capabilities and resulting in poor performance on unseen data. We believe there is a need to train and test the effectiveness and efficiency of the current state-of-the-art deep learning models on different malware datasets. We examine eight popular DL approaches on various datasets. This survey will help researchers develop a general understanding of malware recognition using deep learning.
Keywords: Malware detection; Multi-task learning; Malware image; Generative adversarial networks; Mobile malware; Convolutional neural network

Tarek Gaber, Joseph Bamidele Awotunde, Mohamed Torky, Sunday A. Ajagbe, Mohammad Hammoudeh, Wei Li,
Metaverse-IDS: Deep learning-based intrusion detection system for Metaverse-IoT networks,
Internet of Things,
Volume 24,
2023,
100977,
ISSN 2542-6605,
https://doi.org/10.1016/j.iot.2023.100977.
(https://www.sciencedirect.com/science/article/pii/S2542660523003001)
Abstract: Combining the metaverse and the Internet of Things (IoT) will lead to the development of diverse, virtual, and more advanced networks in the future. The integration of IoT networks with the metaverse will enable more meaningful connections between the 'real' and 'virtual' worlds, allowing for real-time data analysis, access, and processing. However, these metaverse-IoT networks will face numerous security and privacy threats. Intrusion Detection Systems (IDS) offer an effective means of early detection for such attacks. Nevertheless, the metaverse generates substantial volumes of data due to its interactive nature and the multitude of user interactions within virtual environments, posing a computational challenge for building an intrusion detection system. To address this challenge, this paper introduces an innovative intrusion detection system model based on deep learning. This model aims to detect most attacks targeting metaverse-IoT communications and combines two techniques: KPCA (Kernel Principal Component Analysis which was used for attack feature extraction and CNN (Convolutional Neural Networks for attack recognition and classification. The efficiency of this proposed IDS model is assessed using two widely recognized benchmark datasets, BoT-IoT and ToN-IoT, which contain various IoT attacks potentially targeting IoT communications. Experimental results confirmed the effectiveness of the proposed IDS model in identifying 12 classes of attacks relevant to metaverse-IoT, achieving a remarkable accuracy of 99.8% and a False Negative Rate FNR less than 0.2. Furthermore, when compared with other models in the literature, our IDS model demonstrates superior performance in attack detection accuracy.
Keywords: Metaverse; Intrusion detection; Internet of Things; Security and privacy; Convolutional neural network; CNN; Kernel principal component analysis; IoT attacks










































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































